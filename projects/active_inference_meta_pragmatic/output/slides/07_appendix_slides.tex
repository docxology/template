% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
  ignorenonframetext,
]{beamer}
\newif\ifbibliography
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% remove section numbering
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{section title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{subsection title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.50,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.50,0.00}{\textbf{#1}}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\newcounter{none} % for unnumbered tables
\usepackage{calc} % for calculating minipage widths
\usepackage{caption}
% Make caption package work with longtable
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{\texorpdfstring{}{}}
\date{}

\begin{document}

\begin{frame}[fragile]{Appendix}
\protect\phantomsection\label{sec:appendix}
This appendix provides technical details, mathematical derivations,
extended examples, and implementation specifications supporting the main
text.

\begin{block}{Mathematical Foundations}
\protect\phantomsection\label{sec:mathematical_foundations}
\begin{block}{Expected Free Energy Complete Derivation}
\protect\phantomsection\label{expected-free-energy-complete-derivation}
The Expected Free Energy combines epistemic and pragmatic components
(see Equation \eqref{eq:efe}):

\begin{equation}
\mathcal{F}(\pi) = \mathbb{E}_{q(s_\tau)}[\log q(s_\tau) - \log p(s_\tau \mid \pi)] + \mathbb{E}_{q(o_\tau)}[\log p(o_\tau \mid s_\tau) + \log p(s_\tau) - \log q(s_\tau)]
\label{eq:efe_complete}
\end{equation}

Using the generative model, the pragmatic component becomes:

\begin{equation}
G(\pi) = \mathbb{E}_{q(o_\tau)}[\log \sigma(C) + \log A - \log q(s_\tau)]
\label{eq:pragmatic_generative}
\end{equation}

Where \(\sigma(C)\) represents the softmax normalization of preferences.
\end{block}

\begin{block}{Generative Model Complete Specifications}
\protect\phantomsection\label{generative-model-complete-specifications}
\textbf{Matrix A (Observation Likelihoods):}

\[A = \begin{pmatrix}
P(o_1 \mid s_1) & P(o_1 \mid s_2) & \cdots & P(o_1 \mid s_n) \\
P(o_2 \mid s_1) & P(o_2 \mid s_2) & \cdots & P(o_2 \mid s_n) \\
\vdots & \vdots & \ddots & \vdots \\
P(o_m \mid s_1) & P(o_m \mid s_2) & \cdots & P(o_m \mid s_n)
\end{pmatrix}\]

\textbf{Normalization:} Each column sums to 1: \(\sum_i A[i,j] = 1\) for
all \(j\).

\textbf{Matrix B (State Transitions):}

\[B(a) = \begin{pmatrix}
P(s_1' \mid s_1,a) & P(s_2' \mid s_1,a) & \cdots & P(s_n' \mid s_1,a) \\
P(s_1' \mid s_2,a) & P(s_2' \mid s_2,a) & \cdots & P(s_n' \mid s_2,a) \\
\vdots & \vdots & \ddots & \vdots \\
P(s_1' \mid s_n,a) & P(s_2' \mid s_n,a) & \cdots & P(s_n' \mid s_n,a) \\
\end{pmatrix}\]

\textbf{Structure:} 3D tensor
\(\text{states} \times \text{states} \times \text{actions}\).
\end{block}
\end{block}

\begin{block}{Meta-Cognitive Algorithms}
\protect\phantomsection\label{sec:meta_cognitive_algorithms}
\begin{block}{Confidence Assessment}
\protect\phantomsection\label{confidence-assessment}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ assess\_confidence(posterior\_beliefs, observation\_uncertainty):}
\NormalTok{    entropy }\OperatorTok{=} \OperatorTok{{-}}\NormalTok{np.}\BuiltInTok{sum}\NormalTok{(posterior\_beliefs }\OperatorTok{*}\NormalTok{ np.log(posterior\_beliefs }\OperatorTok{+} \FloatTok{1e{-}10}\NormalTok{))}
\NormalTok{    max\_belief }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{max}\NormalTok{(posterior\_beliefs)}
\NormalTok{    normalized\_entropy }\OperatorTok{=} \FloatTok{1.0} \OperatorTok{{-}}\NormalTok{ entropy }\OperatorTok{/}\NormalTok{ np.log(}\BuiltInTok{len}\NormalTok{(posterior\_beliefs))}
\NormalTok{    confidence }\OperatorTok{=}\NormalTok{ (}\FloatTok{0.4} \OperatorTok{*}\NormalTok{ max\_belief }\OperatorTok{+}
                 \FloatTok{0.3} \OperatorTok{*}\NormalTok{ normalized\_entropy }\OperatorTok{+}
                 \FloatTok{0.2} \OperatorTok{*}\NormalTok{ (}\FloatTok{1.0} \OperatorTok{{-}}\NormalTok{ np.std(posterior\_beliefs)) }\OperatorTok{+}
                 \FloatTok{0.1} \OperatorTok{*}\NormalTok{ (}\FloatTok{1.0} \OperatorTok{{-}}\NormalTok{ observation\_uncertainty))}
    \ControlFlowTok{return} \BuiltInTok{min}\NormalTok{(}\BuiltInTok{max}\NormalTok{(confidence, }\FloatTok{0.0}\NormalTok{), }\FloatTok{1.0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{block}

\begin{block}{Adaptive Attention Allocation}
\protect\phantomsection\label{adaptive-attention-allocation}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ allocate\_attention(confidence\_level, available\_resources):}
\NormalTok{    base\_allocation }\OperatorTok{=}\NormalTok{ \{k: }\FloatTok{1.0} \OperatorTok{/} \BuiltInTok{len}\NormalTok{(available\_resources)}
                      \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ available\_resources.keys()\}}
    \ControlFlowTok{if}\NormalTok{ confidence\_level }\OperatorTok{\textless{}} \FloatTok{0.7}\NormalTok{:}
\NormalTok{        adjustments }\OperatorTok{=}\NormalTok{ \{}\StringTok{\textquotesingle{}inference\_monitoring\textquotesingle{}}\NormalTok{: }\FloatTok{1.5}\NormalTok{,}
                       \StringTok{\textquotesingle{}basic\_processing\textquotesingle{}}\NormalTok{: }\FloatTok{0.8}\NormalTok{,}
                       \StringTok{\textquotesingle{}strategy\_evaluation\textquotesingle{}}\NormalTok{: }\FloatTok{1.2}\NormalTok{\}}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        adjustments }\OperatorTok{=}\NormalTok{ \{k: }\FloatTok{1.0} \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ available\_resources.keys()\}}
\NormalTok{    allocation }\OperatorTok{=}\NormalTok{ \{k: base }\OperatorTok{*}\NormalTok{ adjustments.get(k, }\FloatTok{1.0}\NormalTok{)}
                 \ControlFlowTok{for}\NormalTok{ k, base }\KeywordTok{in}\NormalTok{ base\_allocation.items()\}}
\NormalTok{    total }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(allocation.values())}
    \ControlFlowTok{return}\NormalTok{ \{k: v }\OperatorTok{/}\NormalTok{ total }\ControlFlowTok{for}\NormalTok{ k, v }\KeywordTok{in}\NormalTok{ allocation.items()\}}
\end{Highlighting}
\end{Shaded}
\end{block}
\end{block}

\begin{block}{Extended Examples}
\protect\phantomsection\label{sec:extended_examples}
\begin{block}{Quadrant 1: Temperature Regulation (Complete)}
\protect\phantomsection\label{quadrant-1-temperature-regulation-complete}
\textbf{Generative Model:} - States: \{cold, comfortable, hot\} -
Observations: \{cold\_sensor, comfortable\_sensor, hot\_sensor\} -
Actions: \{heat, no\_change, cool\}

\textbf{Matrix Specifications:}

\[A = \begin{pmatrix}
0.8 & 0.1 & 0.0 \\
0.1 & 0.8 & 0.1 \\
0.0 & 0.1 & 0.8
\end{pmatrix} \quad C = \begin{pmatrix} -1.0 \\ 2.0 \\ -1.0 \end{pmatrix}\]
\end{block}

\begin{block}{Quadrant 3: Self-Reflective Control}
\protect\phantomsection\label{quadrant-3-self-reflective-control}
\textbf{Confidence Dynamics:}

\[\frac{dc}{dt} = -\alpha (c - c_{\text{target}}) + \beta \cdot \text{accuracy}\]

Where: - \(c\): current confidence (0 to 1) - \(c_{\text{target}}\):
target confidence based on task demands - \(\alpha\): adaptation rate -
\(\beta\): performance feedback strength
\end{block}

\begin{block}{Quadrant 4: Framework Optimization}
\protect\phantomsection\label{quadrant-4-framework-optimization}
\textbf{Meta-Parameter Learning:}

\[\Theta^* = \arg\max_{\Theta} \mathbb{E}[\log p(data|\Theta) - complexity(\Theta)]\]
\end{block}
\end{block}

\begin{block}{Statistical Validation}
\protect\phantomsection\label{sec:validation_results}
\begin{block}{Hypothesis Testing Results}
\protect\phantomsection\label{hypothesis-testing-results}
\textbf{H1: Meta-data integration improves performance} - t-test: t(98)
= 5.23, p \textless{} 0.001 - Effect size: Cohen's d = 1.05 (large)

\textbf{H2: Meta-cognitive control enhances robustness} - ANOVA: F(3,96)
= 12.45, p \textless{} 0.001 - Post-hoc: All quadrant pairs significant
(p \textless{} 0.01)

\textbf{H3: Framework optimization provides adaptive advantage} - Paired
t-test: t(29) = 4.67, p \textless{} 0.001 - Effect size: Cohen's d =
0.85 (large)
\end{block}

\begin{block}{Performance Regression Model}
\protect\phantomsection\label{performance-regression-model}
\begin{equation}
\text{performance} = \beta_0 + \beta_1 \cdot \text{meta\_data} + \beta_2 \cdot \text{meta\_cognition} + \beta_3 \cdot \text{framework} + \epsilon
\label{eq:performance_regression}
\end{equation}

Results: \(R^2 = 0.87\); All coefficients significant (\(p < 0.001\)).
\end{block}
\end{block}

\begin{block}{Computational Benchmarks}
\protect\phantomsection\label{sec:computational_benchmarks}
\begin{block}{Runtime Analysis}
\protect\phantomsection\label{runtime-analysis}
{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Quadrant & Runtime & Overhead \\
\midrule\noalign{}
\endhead
Q1 & 15ms & baseline \\
Q2 & 28ms & +87\% \\
Q3 & 42ms & +180\% \\
Q4 & 67ms & +347\% \\
\bottomrule\noalign{}
\end{longtable}
}
\end{block}

\begin{block}{Complexity Analysis}
\protect\phantomsection\label{complexity-analysis}
\begin{itemize}
\tightlist
\item
  \textbf{EFE Calculation:}
  \(O(n_{\text{states}} \times n_{\text{actions}} \times \text{horizon})\)
\item
  \textbf{Inference:}
  \(O(n_{\text{states}} \times n_{\text{observations}})\)
\item
  \textbf{Meta-Cognitive Assessment:} \(O(n_{\text{beliefs}})\)
\item
  \textbf{Framework Optimization:}
  \(O(\text{iterations} \times n_{\text{parameters}})\)
\end{itemize}
\end{block}
\end{block}

\begin{block}{Implementation Architecture}
\protect\phantomsection\label{sec:implementation_architecture}
\begin{block}{Code Structure}
\protect\phantomsection\label{code-structure}
\textbf{Infrastructure Layer:} - \texttt{infrastructure/core/}: Logging,
exceptions, file management - \texttt{infrastructure/validation/}: PDF
and markdown validation - \texttt{infrastructure/rendering/}: LaTeX/PDF
generation - \texttt{infrastructure/figure\_manager/}: Automated figure
registration

\textbf{Project Layer:} - \texttt{src/active\_inference.py}: EFE
calculations and policy selection -
\texttt{src/free\_energy\_principle.py}: FEP system boundary analysis -
\texttt{src/quadrant\_framework.py}: 2Ã—2 matrix framework -
\texttt{src/generative\_models.py}: A, B, C, D matrix implementations -
\texttt{src/meta\_cognition.py}: Confidence assessment and adaptive
control
\end{block}

\begin{block}{Testing Philosophy}
\protect\phantomsection\label{testing-philosophy}
\textbf{No Mocks Policy:} All tests use real data and computations only.

\textbf{Coverage Requirements:} - Project Code: 90\% minimum (currently
91.44\%) - Infrastructure Code: 60\% minimum (currently 83.3\%)
\end{block}
\end{block}

\begin{block}{References}
\protect\phantomsection\label{sec:references_appendix}
\begin{block}{Key Papers}
\protect\phantomsection\label{key-papers}
\begin{itemize}
\tightlist
\item
  Friston, K. (2010). The free-energy principle: a unified brain theory?
\item
  Friston, K., et al.~(2012). Active inference and epistemic value
\item
  Parr, T., \& Friston, K. J. (2017). The active inference framework
\item
  Tschantz, A., et al.~(2020). Scaling active inference
\end{itemize}
\end{block}

\begin{block}{Mathematical Background}
\protect\phantomsection\label{mathematical-background}
\begin{itemize}
\tightlist
\item
  Bishop, C. M. (2006). Pattern recognition and machine learning
\item
  MacKay, D. J. C. (2003). Information theory, inference, and learning
  algorithms
\item
  Jaynes, E. T. (2003). Probability theory: The logic of science
\end{itemize}
\end{block}
\end{block}
\end{frame}

\end{document}
