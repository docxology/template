<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>S01_supplemental_methods</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
</head>
<body>
<h1 id="sec:supplemental_methods">Supplemental Methods</h1>
<p>This supplemental section provides methodological details, including
generative model specifications, mathematical derivations, and
implementation algorithms. These materials support the main text by
providing complete technical specifications that enable replication and
extension of the quadrant structure analysis.</p>
<h2 id="sec:complete_generative_models">Generative Model
Specifications</h2>
<h3 id="matrix-a-observation-likelihoods">Matrix A: Observation
Likelihoods</h3>
<p>The observation likelihood matrix defines the probabilistic mapping
from hidden states to observations:</p>
<p><strong>Normalization:</strong> Each column sums to 1: (_i A[i,j] =
1) for all (j), representing a valid probability distribution over
observations for each state. This ensures that for any hidden state
(s_j), the probabilities of all possible observations sum to 1.</p>
<p><strong>Interpretation:</strong> - Rows correspond to observation
modalities (different types of sensory inputs: visual, auditory,
tactile, etc.) - Columns correspond to hidden state conditions
(different possible world states: object present/absent, temperature
high/low, etc.) - Entry (A[i,j]) represents the probability of observing
(o_i) given state (s_j), encoding how reliably observations indicate
underlying states - High diagonal values ((A[i,i])) indicate reliable
observations (state (s_i) strongly predicts observation (o_i)) -
Non-zero off-diagonal values indicate observation ambiguity (multiple
states can produce the same observation, creating uncertainty)</p>
<h3 id="matrix-b-state-transition-dynamics">Matrix B: State Transition
Dynamics</h3>
<p>The transition matrix defines how actions influence state
changes:</p>
<p><strong>Structure:</strong> 3D tensor with dimensions ( ), where each
slice (B[:,:,a]) is a (n_{} n_{}) transition matrix for action (a).</p>
<p><strong>Properties:</strong> - Each (B[:,:,a]) is a stochastic
matrix: (_j B[i,j,a] = 1) for all (i, a), ensuring valid probability
distributions over next states - Enables modeling of controllable state
transitions: different actions lead to different transition
probabilities - Different actions can implement different transition
dynamics: action (a_1) might make certain transitions likely while
action (a_2) makes different transitions likely - The tensor structure
allows modeling of how the same action can have different effects
depending on the current state</p>
<h3 id="matrix-c-preference-landscape">Matrix C: Preference
Landscape</h3>
<p>The preference matrix defines the desirability of different
observations:</p>
<p><strong>Interpretation:</strong> - Positive values indicate preferred
observations - Negative values indicate avoided observations - Magnitude
indicates strength of preference/aversion - Used in softmax
normalization: (P(o) (C))</p>
<h3 id="matrix-d-prior-state-distribution">Matrix D: Prior State
Distribution</h3>
<p>The prior beliefs over hidden states:</p>
<p><strong>Properties:</strong> - Sums to 1 (valid probability
distribution) - Represents initial beliefs before observation - Can
encode innate biases or learned priors</p>
<h2 id="sec:extended_efe_derivation">EFE Derivation</h2>
<h3 id="efe-formulation">EFE Formulation</h3>
<p>The Expected Free Energy combines epistemic and pragmatic
components:</p>
<h3 id="epistemic-component-expansion">Epistemic Component
Expansion</h3>
<p>The epistemic affordance measures information gain:</p>
<p>[H[Q()] = <em>{q(s</em>)}[q(s_)] - <em>{q(s</em>)}[p(s_)]]</p>
<p>This can be rewritten using KL divergence:</p>
<p>[H[Q()] = KL[q(s_)||p(s_)]]</p>
<h3 id="pragmatic-component-expansion">Pragmatic Component
Expansion</h3>
<p>The pragmatic value measures goal achievement:</p>
<p>[G() = <em>{q(o</em>,s_|)}[p(o_,s_) - q(s_,o_|)]]</p>
<p>Using the generative model decomposition:</p>
<p>[G() = <em>{q(o</em>,s_)}[p(o_s_) + p(s_) - q(s_) - p(o_)]]</p>
<p>The pragmatic value becomes:</p>
<p>[G() = <em>{q(o</em>,s_)}[(o_,s_) + p(s_) - q(s_)]]</p>
<p>Where () includes the preference weighting.</p>
<h2 id="sec:meta_data_integration">Meta-Data Integration Methods</h2>
<h3 id="confidence-weighted-inference">Confidence-Weighted
Inference</h3>
<p>Incorporate observation confidence into belief updating:</p>
<p>[q(s o,c) q(s) A(o s) w(c)]</p>
<p>Where (w(c)) is a confidence-dependent weighting function:</p>
<h3 id="temporal-meta-data-processing">Temporal Meta-Data
Processing</h3>
<p>Incorporate temporal consistency information:</p>
<p>[q(s_t o_{1:t}, m_t) q(s_t o_t) (m_t s_{t-1})]</p>
<p>Where () represents temporal meta-data likelihood.</p>
<h3 id="multi-source-meta-data-fusion">Multi-Source Meta-Data
Fusion</h3>
<p>Combine multiple meta-data sources:</p>
<p>[w_{combined} = _{k=1}^K w_k(m_k)]</p>
<p>Where each (w_k) represents a different meta-data weighting
function.</p>
<h2 id="sec:meta_cognitive_algorithms">Meta-Cognitive Control
Algorithms</h2>
<h3 id="confidence-assessment-algorithm">Confidence Assessment
Algorithm</h3>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> assess_confidence(posterior_beliefs, observation_uncertainty):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate entropy</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    entropy <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(posterior_beliefs <span class="op">*</span> np.log(posterior_beliefs <span class="op">+</span> <span class="fl">1e-10</span>))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate max belief strength</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    max_belief <span class="op">=</span> np.<span class="bu">max</span>(posterior_beliefs)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Composite confidence score</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    normalized_entropy <span class="op">=</span> <span class="fl">1.0</span> <span class="op">-</span> entropy <span class="op">/</span> np.log(<span class="bu">len</span>(posterior_beliefs))</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    confidence <span class="op">=</span> (<span class="fl">0.4</span> <span class="op">*</span> max_belief <span class="op">+</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>                 <span class="fl">0.3</span> <span class="op">*</span> normalized_entropy <span class="op">+</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                 <span class="fl">0.2</span> <span class="op">*</span> (<span class="fl">1.0</span> <span class="op">-</span> np.std(posterior_beliefs)) <span class="op">+</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>                 <span class="fl">0.1</span> <span class="op">*</span> (<span class="fl">1.0</span> <span class="op">-</span> observation_uncertainty))</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">min</span>(<span class="bu">max</span>(confidence, <span class="fl">0.0</span>), <span class="fl">1.0</span>)</span></code></pre></div>
<h3 id="adaptive-attention-allocation">Adaptive Attention
Allocation</h3>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> allocate_attention(confidence_level, available_resources):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Base allocation</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    base_allocation <span class="op">=</span> {k: <span class="fl">1.0</span> <span class="op">/</span> <span class="bu">len</span>(available_resources)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>                      <span class="cf">for</span> k <span class="kw">in</span> available_resources.keys()}</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> confidence_level <span class="op">&lt;</span> <span class="fl">0.7</span>:</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Low confidence: increase monitoring</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        adjustments <span class="op">=</span> {</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;inference_monitoring&#39;</span>: <span class="fl">1.5</span>,</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;basic_processing&#39;</span>: <span class="fl">0.8</span>,</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;strategy_evaluation&#39;</span>: <span class="fl">1.2</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># High confidence: efficient allocation</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        adjustments <span class="op">=</span> {k: <span class="fl">1.0</span> <span class="cf">for</span> k <span class="kw">in</span> available_resources.keys()}</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply adjustments</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    allocation <span class="op">=</span> {k: base <span class="op">*</span> adjustments.get(k, <span class="fl">1.0</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>                 <span class="cf">for</span> k, base <span class="kw">in</span> base_allocation.items()}</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="bu">sum</span>(allocation.values())</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {k: v <span class="op">/</span> total <span class="cf">for</span> k, v <span class="kw">in</span> allocation.items()}</span></code></pre></div>
<h2 id="sec:framework_optimization">Framework Optimization Methods</h2>
<h3 id="meta-parameter-learning">Meta-Parameter Learning</h3>
<p>Optimize framework parameters using performance feedback:</p>
<p>[^* = <em>{} </em>{data} [p(data|) - complexity()]]</p>
<p>Where () includes framework parameters: - Confidence thresholds (_c)
- Adaptation rates () - Strategy selection parameters () - Meta-data
weighting functions (w_k)</p>
<h3 id="hierarchical-optimization">Hierarchical Optimization</h3>
<p>Multi-level optimization for complex systems:</p>
<ol type="1">
<li><strong>Level 1:</strong> Optimize EFE for immediate action
selection</li>
<li><strong>Level 2:</strong> Optimize meta-cognitive parameters for
attention allocation</li>
<li><strong>Level 3:</strong> Optimize framework parameters for
long-term adaptation</li>
</ol>
<h3 id="gradient-based-meta-learning">Gradient-Based Meta-Learning</h3>
<p>Use gradient information for framework adaptation:</p>
<p>[ = -_{} (performance, )]</p>
<p>Where ((, )) measures performance degradation due to suboptimal
framework parameters ().</p>
<h2 id="sec:implementation_validation">Implementation Validation</h2>
<h3 id="numerical-stability-tests">Numerical Stability Tests</h3>
<ul>
<li><strong>Gradient Bounds:</strong> Ensure gradients remain within
reasonable bounds</li>
<li><strong>Probability Normalization:</strong> Verify distributions
stay normalized</li>
<li><strong>Convergence Criteria:</strong> Check optimization converges
reliably</li>
<li><strong>Edge Case Handling:</strong> Test behavior with extreme
inputs</li>
</ul>
<h3 id="theoretical-correctness-validation">Theoretical Correctness
Validation</h3>
<ul>
<li><strong>EFE Equivalence:</strong> Verify EFE matches mathematical
definition</li>
<li><strong>Free Energy Minimization:</strong> Confirm free energy
decreases over time</li>
<li><strong>Bayesian Consistency:</strong> Ensure inference follows
Bayesian principles</li>
<li><strong>Meta-Level Consistency:</strong> Validate meta-cognitive
operations</li>
</ul>
<h3 id="performance-benchmarks">Performance Benchmarks</h3>
<ul>
<li><strong>Scalability:</strong> Test with increasing state/observation
spaces</li>
<li><strong>Computational Efficiency:</strong> Measure time
complexity</li>
<li><strong>Memory Usage:</strong> Monitor memory consumption</li>
<li><strong>Accuracy:</strong> Validate against known analytical
solutions</li>
</ul>
<h2 id="sec:complexity_analysis">Algorithm Complexity Analysis</h2>
<h3 id="time-complexity">Time Complexity</h3>
<ul>
<li><strong>EFE Calculation:</strong> (O(n_{} n_{} ))</li>
<li><strong>Inference:</strong> (O(n_{} n_{}))</li>
<li><strong>Meta-Cognitive Assessment:</strong> (O(n_{}))</li>
<li><strong>Framework Optimization:</strong> (O( n_{}))</li>
</ul>
<h3 id="space-complexity">Space Complexity</h3>
<ul>
<li><strong>Generative Model:</strong> (O(n_{} n_{} + n_{}^2 n_{}))</li>
<li><strong>Belief States:</strong> (O(n_{}))</li>
<li><strong>Meta-Cognitive History:</strong> (O( n_{}))</li>
<li><strong>Optimization State:</strong> (O(n_{}))</li>
</ul>
<h3 id="optimizations">Optimizations</h3>
<ul>
<li><strong>Sparse Representations:</strong> Use sparse matrices for
large state spaces</li>
<li><strong>Approximate Inference:</strong> Implement variational
approximations</li>
<li><strong>Hierarchical Models:</strong> Reduce complexity through
hierarchical structure</li>
<li><strong>Parallel Computation:</strong> Distribute computation across
processing units</li>
</ul>
<p>This supplemental methods section provides the technical foundation
for implementing and validating the Active Inference meta-pragmatic
framework across all four quadrants of the (2 ) matrix.</p>
</body>
</html>
