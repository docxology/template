@article{hou2022conditions,
  title={Conditions for none to be whipped by `Rank and Yank' under the majority rule},
  author={Fujun Hou},
  year={2022},
  url={http://arxiv.org/abs/2208.05093v1},
  abstract={`Rank and Yank' is practiced in many organizations. This paper is concerned with the condtions for none to be whipped by `Rank and Yank' when the evaluation data under each criterion are assumed to be ordinal rankings and the majority rule is used. Two sufficient conditions are set forth of which the first one formulates the alternatives indifference definition in terms of the election matrix, while the second one specifies a certain balance in the probabilities of alternatives being ranked at positions. In a sense, `none to be whipped' means that the organization is of stability. Thus the second sufficient condition indicates an intrinsic relation of balance and organization stability. In addition, directions for future research are put forward.},
  journal={arXiv}
}

@article{noone2017visual,
  title={Visual and Textual Programming Languages: A Systematic Review of the Literature},
  author={Mark Noone and Aidan Mooney},
  year={2017},
  url={http://arxiv.org/abs/1710.01547v2},
  abstract={It is well documented, and has been the topic of much research, that Computer Science courses tend to have higher than average drop out rates at third level. This is a problem that needs to be addressed with urgency but also caution. The required number of Computer Science graduates is growing every year but the number of graduates is not meeting this demand and one way that this problem can be alleviated is to encourage students at an early age towards studying Computer Science courses.   This paper presents a systematic literature review on the role of visual and textual programming languages when learning to program, particularly as a first programming language. The approach is systematic, in that a structured search of electronic resources has been conducted, and the results are presented and quantitatively analysed. This study will give insight into whether or not the current approaches to teaching young learners programming are viable, and examines what we can do to increase the interest and retention of these students as they progress through their education.},
  doi={10.1007/s40692-018-0101-5},
  journal={arXiv}
}

@article{noone2017first,
  title={First Programming Language: Visual or Textual?},
  author={Mark Noone and Aidan Mooney},
  year={2017},
  url={http://arxiv.org/abs/1710.11557v2},
  abstract={In modern day society, the ability to code is a highly desirable skill. So much so that the current supply from third level institutes across the world does not meet the high demands of industry. One of the major issues is the low progression rates from first to second year in third level Computer Science courses with introductory programming courses proving to be a high contributing factor. This is something that needs to be addressed. One such way to address the issue is to get children involved and engaged with computing at young ages.   This paper describes a study undertaken that is the first step in a body of work that aims to garner the interest of potential Computer Science students at an early age. The study involves a comparison of two short courses; one based in Java and one based in Snap. The goal is to determine whether either of these languages is a better first programming language for students than the other, or if both are viable. These languages were chosen to allow for a comparison between a Visual Programming Language and a Textual Programming Language.   Feedback in the form of a survey will be used to gather the opinions of the students. This will provide data on issues such as which language was easier to learn and which language was preferred amongst others. Based on the outcomes of this study, a full-scale curriculum will be developed in the coming year. The outcomes of this study will help to establish which is the best programming language to suit the learning needs of students.},
  journal={arXiv}
}

@article{zhou2022none,
  title={None Class Ranking Loss for Document-Level Relation Extraction},
  author={Yang Zhou and Wee Sun Lee},
  year={2022},
  url={http://arxiv.org/abs/2205.00476v2},
  abstract={Document-level relation extraction (RE) aims at extracting relations among entities expressed across multiple sentences, which can be viewed as a multi-label classification problem. In a typical document, most entity pairs do not express any pre-defined relation and are labeled as "none" or "no relation". For good document-level RE performance, it is crucial to distinguish such none class instances (entity pairs) from those of pre-defined classes (relations). However, most existing methods only estimate the probability of pre-defined relations independently without considering the probability of "no relation". This ignores the context of entity pairs and the label correlations between the none class and pre-defined classes, leading to sub-optimal predictions. To address this problem, we propose a new multi-label loss that encourages large margins of label confidence scores between each pre-defined class and the none class, which enables captured label correlations and context-dependent thresholding for label prediction. To gain further robustness against positive-negative imbalance and mislabeled data that could appear in real-world RE datasets, we propose a margin regularization and a margin shifting technique. Experimental results demonstrate that our method significantly outperforms existing multi-label losses for document-level RE and works well in other multi-label tasks such as emotion classification when none class instances are available for training.},
  journal={arXiv}
}

@article{boyer2025on,
  title={On 3-manifolds admitting co-orientable taut foliations, but none with vanishing Euler class},
  author={Steven Boyer and Cameron McA. Gordon and Ying Hu and Duncan McCoy},
  year={2025},
  url={http://arxiv.org/abs/2509.20135v2},
  abstract={In this article, we construct infinitely many (small Seifert fibred, hyperbolic and toroidal) rational homology $3$-spheres that admit co-orientable taut foliations, but none with vanishing Euler class. In the context of the $L$-space conjecture, these examples provide rational homology $3$-spheres that admit co-orientable taut foliations (and hence are not $L$-spaces) and have left-orderable fundamental groups, yet none of the left orders arise directly from the universal circle actions associated to co-orientable taut foliations.   The hyperbolic and non-Seifert toroidal examples are obtained from Dehn surgeries on knots in the $3$-sphere and use Heegaard Floer homology to obstruct the existence of a co-orientable foliation with vanishing Euler class. For the Seifert fibred case, we establish necessary and sufficient conditions for the Euler class of the normal bundle of the Seifert fibration to vanish. Moreover, when the base orbifold is hyperbolic, we also provide a second proof of this condition from the viewpoint of discrete faithful representations of Fuchsian groups.},
  journal={arXiv}
}

@article{li2022deep,
  title={Deep Reinforcement Learning for Online Routing of Unmanned Aerial Vehicles with Wireless Power Transfer},
  author={Kaiwen Li and Tao Zhang and Rui Wang and Ling Wang},
  year={2022},
  url={http://arxiv.org/abs/2204.11477v1},
  abstract={The unmanned aerial vehicle (UAV) plays an vital role in various applications such as delivery, military mission, disaster rescue, communication, etc., due to its flexibility and versatility. This paper proposes a deep reinforcement learning method to solve the UAV online routing problem with wireless power transfer, which can charge the UAV remotely without wires, thus extending the capability of the battery-limited UAV. Our study considers the power consumption of the UAV and the wireless charging process. Unlike the previous works, we solve the problem by a designed deep neural network. The model is trained using a deep reinforcement learning method offline, and is used to optimize the UAV routing problem online. On small and large scale instances, the proposed model runs from four times to 500 times faster than Google OR-tools, the state-of-the-art combinatorial optimization solver, with identical solution quality. It also outperforms different types of heuristic and local search methods in terms of both run-time and optimality. In addition, once the model is trained, it can scale to new generated problem instances with arbitrary topology that are not seen during training. The proposed method is practically applicable when the problem scale is large and the response time is crucial.},
  journal={arXiv}
}

@article{tam2025none,
  title={None of the Above, Less of the Right: Parallel Patterns between Humans and LLMs on Multi-Choice Questions Answering},
  author={Zhi Rui Tam and Cheng-Kuang Wu and Chieh-Yen Lin and Yun-Nung Chen},
  year={2025},
  url={http://arxiv.org/abs/2503.01550v1},
  abstract={Multiple-choice exam questions with "None of the above" (NA) options have been extensively studied in educational testing, in which existing research suggests that they better assess true knowledge. However, their impact on Large Language Models (LLMs) evaluation remains underexplored. Through systematic experiments with 28 LLMs on the MMLU benchmark, we examine how NA options affect model performance and confidence calibration. Our analysis reveals that NA options, when used as the correct answer, lead to a consistent 30-50\% performance drop across models regardless of scale--suggesting that LLMs lack the meta-cognitive ability to systematically evaluate and reject all given options when none are correct. This degradation shows strong domain dependence, with minimal impact on mathematical reasoning (14.6\% drop) but severe effects on tasks requiring uncertainty handling like business ethics (48.1\% drop). Our results highlight important implications for benchmark design and raise questions about LLMs' ability to handle uncertainty in real-world applications.},
  journal={arXiv}
}

@article{liu2022deep,
  title={Deep Reinforcement Learning for Orienteering Problems Based on Decomposition},
  author={Wei Liu and Tao Zhang and Rui Wang and Kaiwen Li and Wenhua Li and Kang Yang},
  year={2022},
  url={http://arxiv.org/abs/2204.11575v2},
  abstract={This paper presents a new method for solving an orienteering problem (OP) by breaking it down into two parts: a knapsack problem (KP) and a traveling salesman problem (TSP). A KP solver is responsible for picking nodes, while a TSP solver is responsible for designing the proper path and assisting the KP solver in judging constraint violations. To address constraints, we propose a dual-population coevolutionary algorithm (DPCA) as the KP solver, which simultaneously maintains both feasible and infeasible populations. A dynamic pointer network (DYPN) is introduced as the TSP solver, which takes city locations as inputs and immediately outputs a permutation of nodes. The model, which is trained by reinforcement learning, can capture both the structural and dynamic patterns of the given problem. The model can generalize to other instances with different scales and distributions. Experimental results show that the proposed algorithm can outperform conventional approaches in terms of training, inference, and generalization ability.},
  journal={arXiv}
}

@article{wang2023learning,
  title={Learning to Branch in Combinatorial Optimization with Graph Pointer Networks},
  author={Rui Wang and Zhiming Zhou and Tao Zhang and Ling Wang and Xin Xu and Xiangke Liao and Kaiwen Li},
  year={2023},
  url={http://arxiv.org/abs/2307.01434v1},
  abstract={Branch-and-bound is a typical way to solve combinatorial optimization problems. This paper proposes a graph pointer network model for learning the variable selection policy in the branch-and-bound. We extract the graph features, global features and historical features to represent the solver state. The proposed model, which combines the graph neural network and the pointer mechanism, can effectively map from the solver state to the branching variable decisions. The model is trained to imitate the classic strong branching expert rule by a designed top-k Kullback-Leibler divergence loss function. Experiments on a series of benchmark problems demonstrate that the proposed approach significantly outperforms the widely used expert-designed branching rules. Our approach also outperforms the state-of-the-art machine-learning-based branch-and-bound methods in terms of solving speed and search tree size on all the test instances. In addition, the model can generalize to unseen instances and scale to larger instances.},
  journal={arXiv}
}

@article{marconato2024all,
  title={All or None: Identifiable Linear Properties of Next-token Predictors in Language Modeling},
  author={Emanuele Marconato and Sébastien Lachapelle and Sebastian Weichwald and Luigi Gresele},
  year={2024},
  url={http://arxiv.org/abs/2410.23501v2},
  abstract={We analyze identifiability as a possible explanation for the ubiquity of linear properties across language models, such as the vector difference between the representations of "easy" and "easiest" being parallel to that between "lucky" and "luckiest". For this, we ask whether finding a linear property in one model implies that any model that induces the same distribution has that property, too. To answer that, we first prove an identifiability result to characterize distribution-equivalent next-token predictors, lifting a diversity requirement of previous results. Second, based on a refinement of relational linearity [Paccanaro and Hinton, 2001; Hernandez et al., 2024], we show how many notions of linearity are amenable to our analysis. Finally, we show that under suitable conditions, these linear properties either hold in all or none distribution-equivalent next-token predictors.},
  journal={arXiv}
}

@article{watson2020active,
  title={Active Inference or Control as Inference? A Unifying View},
  author={Joe Watson and Abraham Imohiosen and Jan Peters},
  year={2020},
  url={http://arxiv.org/abs/2010.00262v1},
  abstract={Active inference (AI) is a persuasive theoretical framework from computational neuroscience that seeks to describe action and perception as inference-based computation. However, this framework has yet to provide practical sensorimotor control algorithms that are competitive with alternative approaches. In this work, we frame active inference through the lens of control as inference (CaI), a body of work that presents trajectory optimization as inference. From the wider view of `probabilistic numerics', CaI offers principled, numerically robust optimal control solvers that provide uncertainty quantification, and can scale to nonlinear problems with approximate inference. We show that AI may be framed as partially-observed CaI when the cost function is defined specifically in the observation states.},
  journal={arXiv}
}

@article{sennesh2022deriving,
  title={Deriving time-averaged active inference from control principles},
  author={Eli Sennesh and Jordan Theriault and Jan-Willem van de Meent and Lisa Feldman Barrett and Karen Quigley},
  year={2022},
  url={http://arxiv.org/abs/2208.10601v1},
  abstract={Active inference offers a principled account of behavior as minimizing average sensory surprise over time. Applications of active inference to control problems have heretofore tended to focus on finite-horizon or discounted-surprise problems, despite deriving from the infinite-horizon, average-surprise imperative of the free-energy principle. Here we derive an infinite-horizon, average-surprise formulation of active inference from optimal control principles. Our formulation returns to the roots of active inference in neuroanatomy and neurophysiology, formally reconnecting active inference to optimal feedback control. Our formulation provides a unified objective functional for sensorimotor control and allows for reference states to vary over time.},
  journal={arXiv}
}

@article{heins2022spin,
  title={Spin glass systems as collective active inference},
  author={Conor Heins and Brennan Klein and Daphne Demekas and Miguel Aguilera and Christopher Buckley},
  year={2022},
  url={http://arxiv.org/abs/2207.06970v1},
  abstract={An open question in the study of emergent behaviour in multi-agent Bayesian systems is the relationship, if any, between individual and collective inference. In this paper we explore the correspondence between generative models that exist at two distinct scales, using spin glass models as a sandbox system to investigate this question. We show that the collective dynamics of a specific type of active inference agent is equivalent to sampling from the stationary distribution of a spin glass system. A collective of specifically-designed active inference agents can thus be described as implementing a form of sampling-based inference (namely, from a Boltzmann machine) at the higher level. However, this equivalence is very fragile, breaking upon simple modifications to the generative models of the individual agents or the nature of their interactions. We discuss the implications of this correspondence and its fragility for the study of multiscale systems composed of Bayesian agents.},
  journal={arXiv}
}

@article{maele2023integrating,
  title={Integrating cognitive map learning and active inference for planning in ambiguous environments},
  author={Toon Van de Maele and Bart Dhoedt and Tim Verbelen and Giovanni Pezzulo},
  year={2023},
  url={http://arxiv.org/abs/2308.08307v1},
  abstract={Living organisms need to acquire both cognitive maps for learning the structure of the world and planning mechanisms able to deal with the challenges of navigating ambiguous environments. Although significant progress has been made in each of these areas independently, the best way to integrate them is an open research question. In this paper, we propose the integration of a statistical model of cognitive map formation within an active inference agent that supports planning under uncertainty. Specifically, we examine the clone-structured cognitive graph (CSCG) model of cognitive map formation and compare a naive clone graph agent with an active inference-driven clone graph agent, in three spatial navigation scenarios. Our findings demonstrate that while both agents are effective in simple scenarios, the active inference agent is more effective when planning in challenging scenarios, in which sensory observations provide ambiguous information about location.},
  journal={arXiv}
}

@article{kouw2025message,
  title={Message passing-based inference in an autoregressive active inference agent},
  author={Wouter M. Kouw and Tim N. Nisslbeck and Wouter L. N. Nuijten},
  year={2025},
  url={http://arxiv.org/abs/2509.25482v1},
  abstract={We present the design of an autoregressive active inference agent in the form of message passing on a factor graph. Expected free energy is derived and distributed across a planning graph. The proposed agent is validated on a robot navigation task, demonstrating exploration and exploitation in a continuous-valued observation space with bounded continuous-valued actions. Compared to a classical optimal controller, the agent modulates action based on predictive uncertainty, arriving later but with a better model of the robot's dynamics.},
  journal={arXiv}
}

@article{friston2020some,
  title={Some interesting observations on the free energy principle},
  author={Karl Friston and Lancelot Da Costa and Thomas Parr},
  year={2020},
  url={http://arxiv.org/abs/2002.04501v1},
  abstract={Biehl et al (2020) present some interesting observations on an early formulation of the free energy principle in (Friston, 2013). We use these observations to scaffold a discussion of the technical arguments that underwrite the free energy principle. This discussion focuses on solenoidal coupling between various (subsets of) states in sparsely coupled systems that possess a Markov blanket - and the distinction between exact and approximate Bayesian inference, implied by the ensuing Bayesian mechanics.},
  doi={10.3390/e23081076},
  journal={arXiv}
}

@article{collaboration2005dark,
  title={The Dark Energy Survey},
  author={ The Dark Energy Survey Collaboration},
  year={2005},
  url={http://arxiv.org/abs/astro-ph/0510346v1},
  abstract={We describe the Dark Energy Survey (DES), a proposed optical-near infrared survey of 5000 sq. deg of the South Galactic Cap to ~24th magnitude in SDSS griz, that would use a new 3 sq. deg CCD camera to be mounted on the Blanco 4-m telescope at Cerro Telolo Inter-American Observatory (CTIO). The survey data will allow us to measure the dark energy and dark matter densities and the dark energy equation of state through four independent methods: galaxy clusters, weak gravitational lensing tomography, galaxy angular clustering, and supernova distances. These methods are doubly complementary: they constrain different combinations of cosmological model parameters and are subject to different systematic errors. By deriving the four sets of measurements from the same data set with a common analysis framework, we will obtain important cross checks of the systematic errors and thereby make a substantial and robust advance in the precision of dark energy measurements.},
  journal={arXiv}
}

@article{collaboration2012large,
  title={Large Synoptic Survey Telescope: Dark Energy Science Collaboration},
  author={ LSST Dark Energy Science Collaboration},
  year={2012},
  url={http://arxiv.org/abs/1211.0310v1},
  abstract={This white paper describes the LSST Dark Energy Science Collaboration (DESC), whose goal is the study of dark energy and related topics in fundamental physics with data from the Large Synoptic Survey Telescope (LSST). It provides an overview of dark energy science and describes the current and anticipated state of the field. It makes the case for the DESC by laying out a robust analytical framework for dark energy science that has been defined by its members and the comprehensive three-year work plan they have developed for implementing that framework. The analysis working groups cover five key probes of dark energy: weak lensing, large scale structure, galaxy clusters, Type Ia supernovae, and strong lensing. The computing working groups span cosmological simulations, galaxy catalogs, photon simulations and a systematic software and computational framework for LSST dark energy data analysis. The technical working groups make the connection between dark energy science and the LSST system. The working groups have close linkages, especially through the use of the photon simulations to study the impact of instrument design and survey strategy on analysis methodology and cosmological parameter estimation. The white paper describes several high priority tasks identified by each of the 16 working groups. Over the next three years these tasks will help prepare for LSST analysis, make synergistic connections with ongoing cosmological surveys and provide the dark energy community with state of the art analysis tools. Members of the community are invited to join the LSST DESC, according to the membership policies described in the white paper. Applications to sign up for associate membership may be made by submitting the Web form at http://www.slac.stanford.edu/exp/lsst/desc/signup.html with a short statement of the work they wish to pursue that is relevant to the LSST DESC.},
  journal={arXiv}
}

@article{thomas2022knowledge,
  title={Knowledge as Fruits of Ignorance: A global Free Energy Principle of our way of thinking},
  author={Cailleteau Thomas},
  year={2022},
  url={http://arxiv.org/abs/2206.05684v1},
  abstract={In this second article, we show a simple use of the Ignorance as defined in "Jaynes & Shannon's Constrained Ignorance and Surprise". By giving an example about the journey of a person, we believe to show some simple, obvious but mathematically encoded philosophical implications about how we could think, learn and memorize. In this basic model we will separate how we learn from Ignorance, and how we anticipate the world using Bayes formula, both should however be more entangled to best reflect reality. In fact, as we have seen after achieving this work, applying Ignorance on the system constituting a person finally turns out to be the global approach of its local counterpart on systems like neurons, cells and other complex probabilistic systems, described using the free energy principle, a much more complex and detailed approach. The aim of this article is therefore to show, as seen from a person, another aspect of the application of the free energy principle which represents the constrained Shannon's entropy, and leads to Bayes'formula. We show that, using only ignorance as a single quantity, and its minimization as the main process, we can take into account his understandings, assertions, doubts and assumptions about how he perceives the world, by describing them mathematically.},
  journal={arXiv}
}

@article{glazebrook2005dark,
  title={Dark Energy and Cosmic Sound: w(z) Surveys with the Gemini/Subaru Wide-Field Multi-Object Spectrograph},
  author={Karl Glazebrook and Daniel Eisenstein and Arjun Dey and Bob Nichol and The WFMOS Feasibility Study Dark Energy Team},
  year={2005},
  url={http://arxiv.org/abs/astro-ph/0507457v2},
  abstract={This white paper gives an overview of the proposed Gemini/Subaru Wide-Field Multi-Object Spectrograph (WFMOS) and the proposed redshift surveys of 2.6 million galaxies with 0.5<z<3.3 over 2000 deg^2 of sky. These surveys will probe the baryonic acoustic oscillations in the galaxy power spectrum with unprecedented precision and over a range of redshifts and deliver dark energy w(z) constraints an order of magnitude better than current limits. We discuss the requirements on precursor observations and on calibrations, the systematics in the method and the quantitative precision obtainaible in distance-redshift and expansion-rate-redshift measurements which feed in to the w(z) precision. We also outline the technological and scientific strengths and risks which might be associated with the project and the relationship of WFMOS to other baryon oscillation experiments.},
  journal={arXiv}
}

@article{piat2004precise,
  title={Precise measurement of CMB polarisation from Dome-C: the BRAIN and CLOVER experiments},
  author={M. Piat and C. Rosset and the BRAIN and CLOVER Collaboration},
  year={2004},
  url={http://arxiv.org/abs/astro-ph/0412590v2},
  abstract={The characterisation of CMB polarisation is one of the next challenge in observationnal cosmology. This is especially true for the so-called B-modes that are at least 3 order of magnitude lower than CMB temperature fluctuations. A precise measurement of the angular power spectrum of these B-modes will give important constraints on inflation parameters. In this talk, I will describe two complementary experiments, BRAIN and CLOVER, dedicated to CMB polarisation measurement. These experiments are proposed to be installed in Dome-C, Antarctica, to take advantage of the extreme dryness of the atmosphere and to allow long integration time.},
  journal={arXiv}
}

@article{messaoudi2020efficient,
  title={Efficient embedding network for 3D brain tumor segmentation},
  author={Hicham Messaoudi and Ahror Belaid and Mohamed Lamine Allaoui and Ahcene Zetout and Mohand Said Allili and Souhil Tliba and Douraied Ben Salem and Pierre-Henri Conze},
  year={2020},
  url={http://arxiv.org/abs/2011.11052v1},
  abstract={3D medical image processing with deep learning greatly suffers from a lack of data. Thus, studies carried out in this field are limited compared to works related to 2D natural image analysis, where very large datasets exist. As a result, powerful and efficient 2D convolutional neural networks have been developed and trained. In this paper, we investigate a way to transfer the performance of a two-dimensional classiffication network for the purpose of three-dimensional semantic segmentation of brain tumors. We propose an asymmetric U-Net network by incorporating the EfficientNet model as part of the encoding branch. As the input data is in 3D, the first layers of the encoder are devoted to the reduction of the third dimension in order to fit the input of the EfficientNet network. Experimental results on validation and test data from the BraTS 2020 challenge demonstrate that the proposed method achieve promising performance.},
  journal={arXiv}
}

@article{himst2020deep,
  title={Deep Active Inference for Partially Observable MDPs},
  author={Otto van der Himst and Pablo Lanillos},
  year={2020},
  url={http://arxiv.org/abs/2009.03622v1},
  abstract={Deep active inference has been proposed as a scalable approach to perception and action that deals with large policy and state spaces. However, current models are limited to fully observable domains. In this paper, we describe a deep active inference model that can learn successful policies directly from high-dimensional sensory inputs. The deep learning architecture optimizes a variant of the expected free energy and encodes the continuous state representation by means of a variational autoencoder. We show, in the OpenAI benchmark, that our approach has comparable or better performance than deep Q-learning, a state-of-the-art deep reinforcement learning algorithm.},
  doi={10.1007/978-3-030-64919-7_8},
  journal={arXiv}
}

@article{collis2024learning,
  title={Learning in Hybrid Active Inference Models},
  author={Poppy Collis and Ryan Singh and Paul F Kinghorn and Christopher L Buckley},
  year={2024},
  url={http://arxiv.org/abs/2409.01066v1},
  abstract={An open problem in artificial intelligence is how systems can flexibly learn discrete abstractions that are useful for solving inherently continuous problems. Previous work in computational neuroscience has considered this functional integration of discrete and continuous variables during decision-making under the formalism of active inference (Parr, Friston & de Vries, 2017; Parr & Friston, 2018). However, their focus is on the expressive physical implementation of categorical decisions and the hierarchical mixed generative model is assumed to be known. As a consequence, it is unclear how this framework might be extended to learning. We therefore present a novel hierarchical hybrid active inference agent in which a high-level discrete active inference planner sits above a low-level continuous active inference controller. We make use of recent work in recurrent switching linear dynamical systems (rSLDS) which implement end-to-end learning of meaningful discrete representations via the piecewise linear decomposition of complex continuous dynamics (Linderman et al., 2016). The representations learned by the rSLDS inform the structure of the hybrid decision-making agent and allow us to (1) specify temporally-abstracted sub-goals in a method reminiscent of the options framework, (2) lift the exploration into discrete space allowing us to exploit information-theoretic exploration bonuses and (3) `cache' the approximate solutions to low-level problems in the discrete planner. We apply our model to the sparse Continuous Mountain Car task, demonstrating fast system identification via enhanced exploration and successful planning through the delineation of abstract sub-goals.},
  journal={arXiv}
}

@article{baioumy2021towards,
  title={Towards Stochastic Fault-tolerant Control using Precision Learning and Active Inference},
  author={Mohamed Baioumy and Corrado Pezzato and Carlos Hernandez Corbato and Nick Hawes and Riccardo Ferrari},
  year={2021},
  url={http://arxiv.org/abs/2109.05870v1},
  abstract={This work presents a fault-tolerant control scheme for sensory faults in robotic manipulators based on active inference. In the majority of existing schemes, a binary decision of whether a sensor is healthy (functional) or faulty is made based on measured data. The decision boundary is called a threshold and it is usually deterministic. Following a faulty decision, fault recovery is obtained by excluding the malfunctioning sensor. We propose a stochastic fault-tolerant scheme based on active inference and precision learning which does not require a priori threshold definitions to trigger fault recovery. Instead, the sensor precision, which represents its health status, is learned online in a model-free way allowing the system to gradually, and not abruptly exclude a failing unit. Experiments on a robotic manipulator show promising results and directions for future work are discussed.},
  doi={10.1007/978-3-030-93736-2_48},
  journal={arXiv}
}

@article{nisslbeck2024coupled,
  title={Coupled autoregressive active inference agents for control of multi-joint dynamical systems},
  author={Tim N. Nisslbeck and Wouter M. Kouw},
  year={2024},
  url={http://arxiv.org/abs/2410.10415v1},
  abstract={We propose an active inference agent to identify and control a mechanical system with multiple bodies connected by joints. This agent is constructed from multiple scalar autoregressive model-based agents, coupled together by virtue of sharing memories. Each subagent infers parameters through Bayesian filtering and controls by minimizing expected free energy over a finite time horizon. We demonstrate that a coupled agent of this kind is able to learn the dynamics of a double mass-spring-damper system, and drive it to a desired position through a balance of explorative and exploitative actions. It outperforms the uncoupled subagents in terms of surprise and goal alignment.},
  journal={arXiv}
}

@article{schubert2025active,
  title={Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions},
  author={Johan Schubert and Farzad Kamrani and Tove Gustavi},
  year={2025},
  url={http://arxiv.org/abs/2510.17450v1},
  abstract={We develop an active inference route-planning method for the autonomous control of intelligent agents. The aim is to reconnoiter a geographical area to maintain a common operational picture. To achieve this, we construct an evidence map that reflects our current understanding of the situation, incorporating both positive and "negative" sensor observations of possible target objects collected over time, and diffusing the evidence across the map as time progresses. The generative model of active inference uses Dempster-Shafer theory and a Gaussian sensor model, which provides input to the agent. The generative process employs a Bayesian approach to update a posterior probability distribution. We calculate the variational free energy for all positions within the area by assessing the divergence between a pignistic probability distribution of the evidence map and a posterior probability distribution of a target object based on the observations, including the level of surprise associated with receiving new observations. Using the free energy, we direct the agents' movements in a simulation by taking an incremental step toward a position that minimizes the free energy. This approach addresses the challenge of exploration and exploitation, allowing agents to balance searching extensive areas of the geographical map while tracking identified target objects.},
  journal={arXiv}
}

@article{he2024large,
  title={Large Language Models (LLMs) Inference Offloading and Resource Allocation in Cloud-Edge Computing: An Active Inference Approach},
  author={Ying He and Jingcheng Fang and F. Yu and V. Leung},
  year={2024},
  url={https://www.semanticscholar.org/paper/4b82d9fbaf5427ff3799de777ffbe3efbf98b81d},
  abstract={With the increasing popularity and demands for large language model applications on mobile devices, it is difficult for resource-limited mobile terminals to run large-model inference tasks efficiently. Traditional deep reinforcement learning (DRL) based approaches have been used to offload large language models (LLMs) inference tasks to servers. However, existing DRL solutions suffer from data inefficiency, insensitivity to latency requirements, and non-adaptability to task load variations, which will degrade the performance of LLMs. In this paper, we propose a novel approach based on active inference for LLMs inference task offloading and resource allocation in cloud-edge computing. Extensive simulation results show that our proposed method has superior performance over mainstream DRLs, improves in data utilization efficiency, and is more adaptable to changing task load scenarios.},
  doi={10.1109/TMC.2024.3415661},
  journal={IEEE Transactions on Mobile Computing}
}

@article{friston2024from,
  title={From pixels to planning: scale-free active inference},
  author={Karl J. Friston and Conor Heins and Tim Verbelen and Lancelot Da Costa and Tommaso Salvatori and Dimitrije Markovic and Alexander Tschantz and Magnus T. Koudahl and Christopher L. Buckley and Thomas Parr},
  year={2024},
  url={https://www.semanticscholar.org/paper/72cc98148b7c0092ce4babcb03d3c021753935bc},
  abstract={This paper describes a discrete state-space model -- and accompanying methods -- for generative modelling. This model generalises partially observed Markov decision processes to include paths as latent variables, rendering it suitable for active inference and learning in a dynamic setting. Specifically, we consider deep or hierarchical forms using the renormalisation group. The ensuing renormalising generative models (RGM) can be regarded as discrete homologues of deep convolutional neural networks or continuous state-space models in generalised coordinates of motion. By construction, these scale-invariant models can be used to learn compositionality over space and time, furnishing models of paths or orbits; i.e., events of increasing temporal depth and itinerancy. This technical note illustrates the automatic discovery, learning and deployment of RGMs using a series of applications. We start with image classification and then consider the compression and generation of movies and music. Finally, we apply the same variational principles to the learning of Atari-like games.},
  doi={10.48550/arXiv.2407.20292},
  journal={arXiv.org}
}

@article{bouizegarene2024narrative,
  title={Narrative as active inference: an integrative account of cognitive and social functions in adaptation},
  author={Nabil Bouizegarene and M. Ramstead and Axel Constant and K. Friston and Laurence J. Kirmayer},
  year={2024},
  url={https://www.semanticscholar.org/paper/7c7b1aaa0e31360dd888770184e3b6d3c38c829a},
  abstract={While the ubiquity and importance of narratives for human adaptation is widely recognized, there is no integrative framework for understanding the roles of narrative in human adaptation. Research has identified several cognitive and social functions of narratives that are conducive to well-being and adaptation as well as to coordinated social practices and enculturation. In this paper, we characterize the cognitive and social functions of narratives in terms of active inference, to support the claim that one of the main adaptive functions of narrative is to generate more useful (i.e., accurate, parsimonious) predictions for the individual, as well as to coordinate group action (over multiple timescales) through shared predictions about collective behavior. Active inference is a theory that depicts the fundamental tendency of living organisms to adapt by proactively inferring the causes of their sensations (including their own actions). We review narrative research on identity, event segmentation, episodic memory, future projections, storytelling practices, enculturation, and master narratives. We show how this research dovetails with the active inference framework and propose an account of the cognitive and social functions of narrative that emphasizes that narratives are for the future—even when they are focused on recollecting or recounting the past. Understanding narratives as cognitive and cultural tools for mutual prediction in social contexts can guide research on narrative in adaptive behavior and psychopathology, based on a parsimonious mechanistic model of some of the basic adaptive functions of narrative.},
  doi={10.3389/fpsyg.2024.1345480},
  journal={Frontiers in Psychology}
}

@article{albarracin2024feeling,
  title={Feeling our place in the world: an active inference account of self-esteem},
  author={Mahault Albarracin and Gabriel Bouchard-Joly and Z. Sheikhbahaee and Mark Miller and R. J. Pitliya and Pierre Poirier},
  year={2024},
  url={https://www.semanticscholar.org/paper/61d1429db543660df4c2682efed81e4a399800c1},
  abstract={Abstract Self-esteem, the evaluation of one’s own worth or value, is a critical aspect of psychological well-being and mental health. In this paper, we propose an active inference account of self-esteem, casting it as a sociometer or an inferential capacity to interpret one’s standing within a social group. This approach allows us to explore the interaction between an individual’s self-perception and the expectations of their social environment.When there is a mismatch between these perceptions and expectations, the individual needs to adjust their actions or update their self-perception to better align with their current experiences. We also consider this hypothesis in relation with recent research on affective inference, suggesting that self-esteem enables the individual to track and respond to this discrepancy through affective states such as anxiety or positive affect. By acting as an inferential sociometer, self-esteem allows individuals to navigate and adapt to their social environment, ultimately impacting their psychological well-being and mental health.},
  doi={10.1093/nc/niae007},
  journal={Neuroscience of Consciousness}
}

@article{hoeffelen2021deep,
  title={Deep Active Inference for Pixel-Based Discrete Control: Evaluation on the Car Racing Problem},
  author={Niels van Hoeffelen and Pablo Lanillos},
  year={2021},
  url={http://arxiv.org/abs/2109.04155v1},
  abstract={Despite the potential of active inference for visual-based control, learning the model and the preferences (priors) while interacting with the environment is challenging. Here, we study the performance of a deep active inference (dAIF) agent on OpenAI's car racing benchmark, where there is no access to the car's state. The agent learns to encode the world's state from high-dimensional input through unsupervised representation learning. State inference and control are learned end-to-end by optimizing the expected free energy. Results show that our model achieves comparable performance to deep Q-learning. However, vanilla dAIF does not reach state-of-the-art performance compared to other world model approaches. Hence, we discuss the current model implementation's limitations and potential architectures to overcome them.},
  journal={arXiv}
}

@article{kouw2024planning,
  title={Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors in active inference agents},
  author={Wouter M. Kouw},
  year={2024},
  url={http://arxiv.org/abs/2409.01974v2},
  abstract={In nature, active inference agents must learn how observations of the world represent the state of the agent. In engineering, the physics behind sensors is often known reasonably accurately and measurement functions can be incorporated into generative models. When a measurement function is non-linear, the transformed variable is typically approximated with a Gaussian distribution to ensure tractable inference. We show that Gaussian approximations that are sensitive to the curvature of the measurement function, such as a second-order Taylor approximation, produce a state-dependent ambiguity term. This induces a preference over states, based on how accurately the state can be inferred from the observation. We demonstrate this preference with a robot navigation experiment where agents plan trajectories.},
  journal={arXiv}
}

@article{hinrichs2025geometric,
  title={Geometric Hyperscanning of Affect under Active Inference},
  author={Nicolas Hinrichs and Mahault Albarracin and Dimitris Bolis and Yuyue Jiang and Leonardo Christov-Moore and Leonhard Schilbach},
  year={2025},
  url={http://arxiv.org/abs/2506.08599v4},
  abstract={Second-person neuroscience holds social cognition as embodied meaning co-regulation through reciprocal interaction, modeled here as coupled active inference with affect emerging as inference over identity-relevant surprise. Each agent maintains a self-model that tracks violations in its predictive coherence while recursively modeling the other. Valence is computed from self-model prediction error, weighted by self-relevance, and modulated by prior affective states and by what we term temporal aiming, which captures affective appraisal over time. This accommodates shifts in the self-other boundary, allowing affect to emerge at individual and dyadic levels. We propose a novel method termed geometric hyperscanning, based on the Forman-Ricci curvature, to empirically operationalize these processes: it tracks topological reconfigurations in inter-brain networks, with its entro-py serving as a proxy for affective phase transitions such as rupture, co-regulation, and re-attunement.},
  journal={arXiv}
}

@article{klar2025active,
  title={An Active Inference Model of Mouse Point-and-Click Behaviour},
  author={Markus Klar and Sebastian Stein and Fraser Paterson and John H. Williamson and Roderick Murray-Smith},
  year={2025},
  url={http://arxiv.org/abs/2510.14611v1},
  abstract={We explore the use of Active Inference (AIF) as a computational user model for spatial pointing, a key problem in Human-Computer Interaction (HCI). We present an AIF agent with continuous state, action, and observation spaces, performing one-dimensional mouse pointing and clicking. We use a simple underlying dynamic system to model the mouse cursor dynamics with realistic perceptual delay. In contrast to previous optimal feedback control-based models, the agent's actions are selected by minimizing Expected Free Energy, solely based on preference distributions over percepts, such as observing clicking a button correctly. Our results show that the agent creates plausible pointing movements and clicks when the cursor is over the target, with similar end-point variance to human users. In contrast to other models of pointing, we incorporate fully probabilistic, predictive delay compensation into the agent. The agent shows distinct behaviour for differing target difficulties without the need to retune system parameters, as done in other approaches. We discuss the simulation results and emphasize the challenges in identifying the correct configuration of an AIF agent interacting with continuous systems.},
  journal={arXiv}
}

@article{perez2025cognitive,
  title={Cognitive Effort in the Two-Step Task: An Active Inference Drift-Diffusion Model Approach},
  author={Alvaro Garrido Perez and Viktor Lemoine and Amrapali Pednekar and Yara Khaluf and Pieter Simoens},
  year={2025},
  url={http://arxiv.org/abs/2508.04435v2},
  abstract={High-level theories rooted in the Bayesian Brain Hypothesis often frame cognitive effort as the cost of resolving the conflict between habits and optimal policies. In parallel, evidence accumulator models (EAMs) provide a mechanistic account of how effort arises from competition between the subjective values of available options. Although EAMs have been combined with frameworks like Reinforcement Learning to bridge the gap between high-level theories and process-level mechanisms, relatively less attention has been paid to their implications for a unified notion of cognitive effort. Here, we combine Active Inference (AIF) with the Drift-Diffusion Model (DDM) to investigate whether the resulting AIF-DDM can simultaneously account for effort arising from both habit violation and value discriminability. To our knowledge, this is the first time AIF has been combined with an EAM. We tested the AIF-DDM on a behavioral dataset from the two-step task and compared its predictions to an information-theoretic definition of cognitive effort based on AIF. The model's predictions successfully accounted for second-stage reaction times but failed to capture the dynamics of the first stage. We argue the latter discrepancy likely stems from the experimental design rather than a fundamental flaw in the model's assumptions about cognitive effort. Accordingly, we propose several modifications of the two-step task to better measure and isolate cognitive effort. Finally, we found that integrating the DDM significantly improved parameter recovery, which could help future studies to obtain more reliable parameter estimates.},
  journal={arXiv}
}

@article{collis2023understanding,
  title={Understanding Tool Discovery and Tool Innovation Using Active Inference},
  author={Poppy Collis and Paul F Kinghorn and Christopher L Buckley},
  year={2023},
  url={http://arxiv.org/abs/2311.03893v1},
  abstract={The ability to invent new tools has been identified as an important facet of our ability as a species to problem solve in dynamic and novel environments. While the use of tools by artificial agents presents a challenging task and has been widely identified as a key goal in the field of autonomous robotics, far less research has tackled the invention of new tools by agents. In this paper, (1) we articulate the distinction between tool discovery and tool innovation by providing a minimal description of the two concepts under the formalism of active inference. We then (2) apply this description to construct a toy model of tool innovation by introducing the notion of tool affordances into the hidden states of the agent's probabilistic generative model. This particular state factorisation facilitates the ability to not just discover tools but invent them through the offline induction of an appropriate tool property. We discuss the implications of these preliminary results and outline future directions of research.},
  journal={arXiv}
}

@article{rood2020deep,
  title={A deep active inference model of the rubber-hand illusion},
  author={Thomas Rood and Marcel van Gerven and Pablo Lanillos},
  year={2020},
  url={http://arxiv.org/abs/2008.07408v2},
  abstract={Understanding how perception and action deal with sensorimotor conflicts, such as the rubber-hand illusion (RHI), is essential to understand how the body adapts to uncertain situations. Recent results in humans have shown that the RHI not only produces a change in the perceived arm location, but also causes involuntary forces. Here, we describe a deep active inference agent in a virtual environment, which we subjected to the RHI, that is able to account for these results. We show that our model, which deals with visual high-dimensional inputs, produces similar perceptual and force patterns to those found in humans.},
  doi={10.1007/978-3-030-64919-7_10},
  journal={arXiv}
}

@article{biehl2018geometry,
  title={Geometry of Friston's active inference},
  author={Martin Biehl},
  year={2018},
  url={http://arxiv.org/abs/1811.08241v1},
  abstract={We reconstruct Karl Friston's active inference and give a geometrical interpretation of it.},
  journal={arXiv}
}

@article{sloun2024active,
  title={Active inference and deep generative modeling for cognitive ultrasound},
  author={Ruud JG van Sloun},
  year={2024},
  url={http://arxiv.org/abs/2410.13310v1},
  abstract={Ultrasound (US) has the unique potential to offer access to medical imaging to anyone, everywhere. Devices have become ultra-portable and cost-effective, akin to the stethoscope. Nevertheless US image quality and diagnostic efficacy are still highly operator- and patient-dependent. In difficult-to-image patients, image quality is often insufficient for reliable diagnosis. In this paper, we put forth that US imaging systems can be recast as information-seeking agents that engage in reciprocal interactions with their anatomical environment. Such agents autonomously adapt their transmit-receive sequences to fully personalize imaging and actively maximize information gain in-situ. To that end, we will show that the sequence of pulse-echo experiments that a US system performs can be interpreted as a perception-action loop: the action is the data acquisition, probing tissue with acoustic waves and recording reflections at the detection array, and perception is the inference of the anatomical and or functional state, potentially including associated diagnostic quantities. We then equip systems with a mechanism to actively reduce uncertainty and maximize diagnostic value across a sequence of experiments, treating action and perception jointly using Bayesian inference given generative models of the environment and action-conditional pulse-echo observations. Since the representation capacity of the generative models dictates both the quality of inferred anatomical states and the effectiveness of inferred sequences of future imaging actions, we will be greatly leveraging the enormous advances in deep generative modelling that are currently disrupting many fields and society at large. Finally, we show some examples of cognitive, closed-loop, US systems that perform active beamsteering and adaptive scanline selection, based on deep generative models that track anatomical belief states.},
  doi={10.1109/TUFFC.2024.3466290},
  journal={arXiv}
}

@article{zhang2021double,
  title={Double Robust Semi-Supervised Inference for the Mean: Selection Bias under MAR Labeling with Decaying Overlap},
  author={Yuqian Zhang and Abhishek Chakrabortty and Jelena Bradic},
  year={2021},
  url={http://arxiv.org/abs/2104.06667v2},
  abstract={Semi-supervised (SS) inference has received much attention in recent years. Apart from a moderate-sized labeled data, L, the SS setting is characterized by an additional, much larger sized, unlabeled data, U. The setting of |U| >> |L|, makes SS inference unique and different from the standard missing data problems, owing to natural violation of the so-called "positivity" or "overlap" assumption. However, most of the SS literature implicitly assumes L and U to be equally distributed, i.e., no selection bias in the labeling. Inferential challenges in missing at random (MAR) type labeling allowing for selection bias, are inevitably exacerbated by the decaying nature of the propensity score (PS). We address this gap for a prototype problem, the estimation of the response's mean. We propose a double robust SS (DRSS) mean estimator and give a complete characterization of its asymptotic properties. The proposed estimator is consistent as long as either the outcome or the PS model is correctly specified. When both models are correctly specified, we provide inference results with a non-standard consistency rate that depends on the smaller size |L|. The results are also extended to causal inference with imbalanced treatment groups. Further, we provide several novel choices of models and estimators of the decaying PS, including a novel offset logistic model and a stratified labeling model. We present their properties under both high and low dimensional settings. These may be of independent interest. Lastly, we present extensive simulations and also a real data application.},
  doi={10.1093/imaiai/iaad021},
  journal={arXiv}
}

@article{baioumy2021solving,
  title={On Solving a Stochastic Shortest-Path Markov Decision Process as Probabilistic Inference},
  author={Mohamed Baioumy and Bruno Lacerda and Paul Duckworth and Nick Hawes},
  year={2021},
  url={http://arxiv.org/abs/2109.05866v1},
  abstract={Previous work on planning as active inference addresses finite horizon problems and solutions valid for online planning. We propose solving the general Stochastic Shortest-Path Markov Decision Process (SSP MDP) as probabilistic inference. Furthermore, we discuss online and offline methods for planning under uncertainty. In an SSP MDP, the horizon is indefinite and unknown a priori. SSP MDPs generalize finite and infinite horizon MDPs and are widely used in the artificial intelligence community. Additionally, we highlight some of the differences between solving an MDP using dynamic programming approaches widely used in the artificial intelligence community and approaches used in the active inference community.},
  journal={arXiv}
}

@article{weis2013discontinuities,
  title={Discontinuities in the Maximum-Entropy Inference},
  author={Stephan Weis},
  year={2013},
  url={http://arxiv.org/abs/1308.6126v1},
  abstract={We revisit the maximum-entropy inference of the state of a finite-level quantum system under linear constraints. The constraints are specified by the expected values of a set of fixed observables. We point out the existence of discontinuities in this inference method. This is a pure quantum phenomenon since the maximum-entropy inference is continuous for mutually commuting observables. The question arises why some sets of observables are distinguished by a discontinuity in an inference method which is still discussed as a universal inference method. In this paper we make an example of a discontinuity and we explain a characterization of the discontinuities in terms of the openness of the (restricted) linear map that assigns expected values to states.},
  doi={10.1063/1.4820000},
  journal={arXiv}
}

@article{he2024expertflow,
  title={ExpertFlow: Optimized Expert Activation and Token Allocation for Efficient Mixture-of-Experts Inference},
  author={Xin He and Shunkang Zhang and Yuxin Wang and Haiyan Yin and Zihao Zeng and Shaohuai Shi and Zhenheng Tang and Xiaowen Chu and Ivor Tsang and Ong Yew Soon},
  year={2024},
  url={http://arxiv.org/abs/2410.17954v1},
  abstract={Sparse Mixture of Experts (MoE) models, while outperforming dense Large Language Models (LLMs) in terms of performance, face significant deployment challenges during inference due to their high memory demands. Existing offloading techniques, which involve swapping activated and idle experts between the GPU and CPU, often suffer from rigid expert caching mechanisms. These mechanisms fail to adapt to dynamic routing, leading to inefficient cache utilization, or incur prohibitive costs for prediction training. To tackle these inference-specific challenges, we introduce ExpertFlow, a comprehensive system specifically designed to enhance inference efficiency by accommodating flexible routing and enabling efficient expert scheduling between CPU and GPU. This reduces overhead and boosts system performance. Central to our approach is a predictive routing path-based offloading mechanism that utilizes a lightweight predictor to accurately forecast routing paths before computation begins. This proactive strategy allows for real-time error correction in expert caching, significantly increasing cache hit ratios and reducing the frequency of expert transfers, thereby minimizing I/O overhead. Additionally, we implement a dynamic token scheduling strategy that optimizes MoE inference by rearranging input tokens across different batches. This method not only reduces the number of activated experts per batch but also improves computational efficiency. Our extensive experiments demonstrate that ExpertFlow achieves up to 93.72\% GPU memory savings and enhances inference speed by 2 to 10 times compared to baseline methods, highlighting its effectiveness and utility as a robust solution for resource-constrained inference scenarios.},
  journal={arXiv}
}

@article{lee2015causal,
  title={Causal inference via algebraic geometry: feasibility tests for functional causal structures with two binary observed variables},
  author={Ciarán M. Lee and Robert W. Spekkens},
  year={2015},
  url={http://arxiv.org/abs/1506.03880v2},
  abstract={We provide a scheme for inferring causal relations from uncontrolled statistical data based on tools from computational algebraic geometry, in particular, the computation of Groebner bases. We focus on causal structures containing just two observed variables, each of which is binary. We consider the consequences of imposing different restrictions on the number and cardinality of latent variables and of assuming different functional dependences of the observed variables on the latent ones (in particular, the noise need not be additive). We provide an inductive scheme for classifying functional causal structures into distinct observational equivalence classes. For each observational equivalence class, we provide a procedure for deriving constraints on the joint distribution that are necessary and sufficient conditions for it to arise from a model in that class. We also demonstrate how this sort of approach provides a means of determining which causal parameters are identifiable and how to solve for these. Prospects for expanding the scope of our scheme, in particular to the problem of quantum causal inference, are also discussed.},
  doi={10.1515/jci-2016-0013},
  journal={arXiv}
}

@article{zhang2018theory,
  title={The Theory and Algorithm of Ergodic Inference},
  author={Yichuan Zhang},
  year={2018},
  url={http://arxiv.org/abs/1811.07192v1},
  abstract={Approximate inference algorithm is one of the fundamental research fields in machine learning. The two dominant theoretical inference frameworks in machine learning are variational inference (VI) and Markov chain Monte Carlo (MCMC). However, because of the fundamental limitation in the theory, it is very challenging to improve existing VI and MCMC methods on both the computational scalability and statistical efficiency. To overcome this obstacle, we propose a new theoretical inference framework called ergodic Inference based on the fundamental property of ergodic transformations. The key contribution of this work is to establish the theoretical foundation of ergodic inference for the development of practical algorithms in future work.},
  journal={arXiv}
}

@article{paige2016inference,
  title={Inference Networks for Sequential Monte Carlo in Graphical Models},
  author={Brooks Paige and Frank Wood},
  year={2016},
  url={http://arxiv.org/abs/1602.06701v2},
  abstract={We introduce a new approach for amortizing inference in directed graphical models by learning heuristic approximations to stochastic inverses, designed specifically for use as proposal distributions in sequential Monte Carlo methods. We describe a procedure for constructing and learning a structured neural network which represents an inverse factorization of the graphical model, resulting in a conditional density estimator that takes as input particular values of the observed random variables, and returns an approximation to the distribution of the latent variables. This recognition model can be learned offline, independent from any particular dataset, prior to performing inference. The output of these networks can be used as automatically-learned high-quality proposal distributions to accelerate sequential Monte Carlo across a diverse range of problem settings.},
  journal={arXiv}
}

@article{weber2018physics,
  title={Physics of Active Emulsions},
  author={Christoph A. Weber and David Zwicker and Frank Jülicher and Chiu Fan Lee},
  year={2018},
  url={http://arxiv.org/abs/1806.09552v2},
  abstract={Phase separating systems that are maintained away from thermodynamic equilibrium via molecular processes represent a class of active systems, which we call active emulsions. These systems are driven by external energy input for example provided by an external fuel reservoir. The external energy input gives rise to novel phenomena that are not present in passive systems. For instance, concentration gradients can spatially organise emulsions and cause novel droplet size distributions. Another example are active droplets that are subject to chemical reactions such that their nucleation and size can be controlled and they can spontaneously divide. In this review we discuss the physics of phase separation and emulsions and show how the concepts that governs such phenomena can be extended to capture the physics of active emulsions. This physics is relevant to the spatial organisation of the biochemistry in living cells, for the development novel applications in chemical engineering and models for the origin of life.},
  doi={10.1088/1361-6633/ab052b},
  journal={arXiv}
}

@article{mueller2021phase,
  title={Phase field models of active matter},
  author={Romain Mueller and Amin Doostmohammadi},
  year={2021},
  url={http://arxiv.org/abs/2102.05557v2},
  abstract={We present an overview of phase field modeling of active matter systems as a tool for capturing various aspects of complex and active interfaces. We first describe how interfaces between different phases are characterized in phase field models and provide simple fundamental governing equations that describe their evolution. For a simple model, we then show how physical properties of the interface, such as surface tension and interface thickness, can be recovered from these equations. We then explain how the phase field formulation can be coupled to various active matter realizations and discuss three particular examples of continuum biphasic active matter: active nematic-isotropic interfaces, active matter in viscoelastic environments, and active shells in fluid background. Finally, we describe how multiple phase fields can be used to model active cellular monolayers and present a general framework that can be applied to the study of tissue behaviour and collective migration.},
  journal={arXiv}
}

@article{llorente2020adaptive,
  title={Adaptive quadrature schemes for Bayesian inference via active learning},
  author={F. Llorente and L. Martino and V. Elvira and D. Delgado and J. López-Santiago},
  year={2020},
  url={http://arxiv.org/abs/2006.00535v3},
  abstract={Numerical integration and emulation are fundamental topics across scientific fields. We propose novel adaptive quadrature schemes based on an active learning procedure. We consider an interpolative approach for building a surrogate posterior density, combining it with Monte Carlo sampling methods and other quadrature rules. The nodes of the quadrature are sequentially chosen by maximizing a suitable acquisition function, which takes into account the current approximation of the posterior and the positions of the nodes. This maximization does not require additional evaluations of the true posterior. We introduce two specific schemes based on Gaussian and Nearest Neighbors (NN) bases. For the Gaussian case, we also provide a novel procedure for fitting the bandwidth parameter, in order to build a suitable emulator of a density function. With both techniques, we always obtain a positive estimation of the marginal likelihood (a.k.a., Bayesian evidence). An equivalent importance sampling interpretation is also described, which allows the design of extended schemes. Several theoretical results are provided and discussed. Numerical results show the advantage of the proposed approach, including a challenging inference problem in an astronomic dynamical model, with the goal of revealing the number of planets orbiting a star.},
  doi={10.1109/ACCESS.2020.3038333},
  journal={arXiv}
}

@article{ijju2023markovian,
  title={A Markovian Formalism for Active Querying},
  author={Sid Ijju},
  year={2023},
  url={http://arxiv.org/abs/2306.08001v1},
  abstract={Active learning algorithms have been an integral part of recent advances in artificial intelligence. However, the research in the field is widely varying and lacks an overall organizing leans. We outline a Markovian formalism for the field of active learning and survey the literature to demonstrate the organizing capability of our proposed formalism. Our formalism takes a partially observable Markovian system approach to the active learning process as a whole. We specifically outline how querying, dataset augmentation, reward updates, and other aspects of active learning can be viewed as a transition between meta-states in a Markovian system, and give direction into how other aspects of active learning can fit into our formalism.},
  journal={arXiv}
}

@article{zhu2025activeo3,
  title={Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO},
  author={Muzhi Zhu and Hao Zhong and Canyu Zhao and Zongze Du and Zheng Huang and Mingyu Liu and Hao Chen and Cheng Zou and Jingdong Chen and Ming Yang and Chunhua Shen},
  year={2025},
  url={http://arxiv.org/abs/2505.21457v1},
  abstract={Active vision, also known as active perception, refers to the process of actively selecting where and how to look in order to gather task-relevant information. It is a critical component of efficient perception and decision-making in humans and advanced embodied agents. Recently, the use of Multimodal Large Language Models (MLLMs) as central planning and decision-making modules in robotic systems has gained extensive attention. However, despite the importance of active perception in embodied intelligence, there is little to no exploration of how MLLMs can be equipped with or learn active perception capabilities. In this paper, we first provide a systematic definition of MLLM-based active perception tasks. We point out that the recently proposed GPT-o3 model's zoom-in search strategy can be regarded as a special case of active perception; however, it still suffers from low search efficiency and inaccurate region selection. To address these issues, we propose ACTIVE-O3, a purely reinforcement learning based training framework built on top of GRPO, designed to equip MLLMs with active perception capabilities. We further establish a comprehensive benchmark suite to evaluate ACTIVE-O3 across both general open-world tasks, such as small-object and dense object grounding, and domain-specific scenarios, including small object detection in remote sensing and autonomous driving, as well as fine-grained interactive segmentation. In addition, ACTIVE-O3 also demonstrates strong zero-shot reasoning abilities on the V* Benchmark, without relying on any explicit reasoning data. We hope that our work can provide a simple codebase and evaluation protocol to facilitate future research on active perception in MLLMs.},
  journal={arXiv}
}

@article{wang2015stochastic,
  title={Stochastic Collapsed Variational Inference for Sequential Data},
  author={Pengyu Wang and Phil Blunsom},
  year={2015},
  url={http://arxiv.org/abs/1512.01666v1},
  abstract={Stochastic variational inference for collapsed models has recently been successfully applied to large scale topic modelling. In this paper, we propose a stochastic collapsed variational inference algorithm in the sequential data setting. Our algorithm is applicable to both finite hidden Markov models and hierarchical Dirichlet process hidden Markov models, and to any datasets generated by emission distributions in the exponential family. Our experiment results on two discrete datasets show that our inference is both more efficient and more accurate than its uncollapsed version, stochastic variational inference.},
  journal={arXiv}
}

@article{figurnov2016robust,
  title={Robust Variational Inference},
  author={Michael Figurnov and Kirill Struminsky and Dmitry Vetrov},
  year={2016},
  url={http://arxiv.org/abs/1611.09226v1},
  abstract={Variational inference is a powerful tool for approximate inference. However, it mainly focuses on the evidence lower bound as variational objective and the development of other measures for variational inference is a promising area of research. This paper proposes a robust modification of evidence and a lower bound for the evidence, which is applicable when the majority of the training set samples are random noise objects. We provide experiments for variational autoencoders to show advantage of the objective over the evidence lower bound on synthetic datasets obtained by adding uninformative noise objects to MNIST and OMNIGLOT. Additionally, for the original MNIST and OMNIGLOT datasets we observe a small improvement over the non-robust evidence lower bound.},
  journal={arXiv}
}

@article{lueckmann2018likelihoodfree,
  title={Likelihood-free inference with emulator networks},
  author={Jan-Matthis Lueckmann and Giacomo Bassetto and Theofanis Karaletsos and Jakob H. Macke},
  year={2018},
  url={http://arxiv.org/abs/1805.09294v2},
  abstract={Approximate Bayesian Computation (ABC) provides methods for Bayesian inference in simulation-based stochastic models which do not permit tractable likelihoods. We present a new ABC method which uses probabilistic neural emulator networks to learn synthetic likelihoods on simulated data -- both local emulators which approximate the likelihood for specific observed data, as well as global ones which are applicable to a range of data. Simulations are chosen adaptively using an acquisition function which takes into account uncertainty about either the posterior distribution of interest, or the parameters of the emulator. Our approach does not rely on user-defined rejection thresholds or distance functions. We illustrate inference with emulator networks on synthetic examples and on a biophysical neuron model, and show that emulators allow accurate and efficient inference even on high-dimensional problems which are challenging for conventional ABC approaches.},
  journal={arXiv}
}

@article{ren2022robot,
  title={Robot Active Neural Sensing and Planning in Unknown Cluttered Environments},
  author={Hanwen Ren and Ahmed H. Qureshi},
  year={2022},
  url={http://arxiv.org/abs/2208.11079v2},
  abstract={Active sensing and planning in unknown, cluttered environments is an open challenge for robots intending to provide home service, search and rescue, narrow-passage inspection, and medical assistance. Although many active sensing methods exist, they often consider open spaces, assume known settings, or mostly do not generalize to real-world scenarios. We present the active neural sensing approach that generates the kinematically feasible viewpoint sequences for the robot manipulator with an in-hand camera to gather the minimum number of observations needed to reconstruct the underlying environment. Our framework actively collects the visual RGBD observations, aggregates them into scene representation, and performs object shape inference to avoid unnecessary robot interactions with the environment. We train our approach on synthetic data with domain randomization and demonstrate its successful execution via sim-to-real transfer in reconstructing narrow, covered, real-world cabinet environments cluttered with unknown objects. The natural cabinet scenarios impose significant challenges for robot motion and scene reconstruction due to surrounding obstacles and low ambient lighting conditions. However, despite unfavorable settings, our method exhibits high performance compared to its baselines in terms of various environment reconstruction metrics, including planning speed, the number of viewpoints, and overall scene coverage.},
  journal={arXiv}
}

@article{yan2023active,
  title={Active Neural Mapping},
  author={Zike Yan and Haoxiang Yang and Hongbin Zha},
  year={2023},
  url={http://arxiv.org/abs/2308.16246v1},
  abstract={We address the problem of active mapping with a continually-learned neural scene representation, namely Active Neural Mapping. The key lies in actively finding the target space to be explored with efficient agent movement, thus minimizing the map uncertainty on-the-fly within a previously unseen environment. In this paper, we examine the weight space of the continually-learned neural field, and show empirically that the neural variability, the prediction robustness against random weight perturbation, can be directly utilized to measure the instant uncertainty of the neural map. Together with the continuous geometric information inherited in the neural map, the agent can be guided to find a traversable path to gradually gain knowledge of the environment. We present for the first time an active mapping system with a coordinate-based implicit neural representation for online scene reconstruction. Experiments in the visually-realistic Gibson and Matterport3D environment demonstrate the efficacy of the proposed method.},
  journal={arXiv}
}

@article{tong2024integrating,
  title={Integrating Optimal Transport and Structural Inference Models for GRN Inference from Single-cell Data},
  author={Tsz Pan Tong and Aoran Wang and George Panagopoulos and Jun Pang},
  year={2024},
  url={http://arxiv.org/abs/2409.15080v1},
  abstract={We introduce a novel gene regulatory network (GRN) inference method that integrates optimal transport (OT) with a deep-learning structural inference model. Advances in next-generation sequencing enable detailed yet destructive gene expression assays at the single-cell level, resulting in the loss of cell evolutionary trajectories. Due to technological and cost constraints, single-cell experiments often feature cells sampled at irregular and sparse time points with a small sample size. Although trajectory-based structural inference models can accurately reveal the underlying interaction graph from observed data, their efficacy depends on the inputs of thousands of regularly sampled trajectories. The irregularly-sampled nature of single-cell data precludes the direct use of these powerful models for reconstructing GRNs. Optimal transport, a classical mathematical framework that minimize transportation costs between distributions, has shown promise in multi-omics data integration and cell fate prediction. Utilizing OT, our method constructs mappings between consecutively sampled cells to form cell-level trajectories, which are given as input to a structural inference model that recovers the GRN from single-cell data. Through case studies in two synthetic datasets, we demonstrate the feasibility of our proposed method and its promising performance over eight state-of-the-art GRN inference methods.},
  journal={arXiv}
}

@article{sousa2025selfpropulsive,
  title={Self-propulsive active nematics},
  author={Niels de Graaf Sousa and Simon Guldager Andersen and Aleksandra Ardaševa and Amin Doostmohammadi},
  year={2025},
  url={http://arxiv.org/abs/2509.02386v1},
  abstract={Increasing evidence suggests that active matter exhibits instances of mixed symmetry that cannot be fully described by either polar or nematic formalism. Here, we introduce a minimal model that integrates self-propulsion into the active nematic framework. Our linear stability analyses reveal how self-propulsion shifts the onset of instability, fundamentally altering the dynamical landscape. Numerical simulations confirm these predictions, showing that self-propulsion induces anti-hyperuniform fluctuations, anomalous long-range order in vorticity, and non-universal self-similar energy cascades. Notably, these long-range ordered states emerge within the active turbulence regime well before the transition to a flocking state. Additionally, our analyses highlight a non-monotonic dependence of self-organization on self-propulsion, with optimal states characterized by a peak in correlation length. These findings are relevant for understanding of active nematic systems that self-propel, such as migrating cell layers or swarming bacteria, and offer new avenues for designing synthetic systems with tailored collective behaviours, bridging the gap between active nematics and self-propulsive systems.},
  journal={arXiv}
}

@article{xie2019kind,
  title={Kind Inference for Datatypes: Technical Supplement},
  author={Ningning Xie and Richard A. Eisenberg and Bruno C. d. S. Oliveira},
  year={2019},
  url={http://arxiv.org/abs/1911.06153v1},
  abstract={In recent years, languages like Haskell have seen a dramatic surge of new features that significantly extends the expressive power of their type systems. With these features, the challenge of kind inference for datatype declarations has presented itself and become a worthy research problem on its own.   This paper studies kind inference for datatypes. Inspired by previous research on type-inference, we offer declarative specifications for what datatype declarations should be accepted, both for Haskell98 and for a more advanced system we call PolyKinds, based on the extensions in modern Haskell, including a limited form of dependent types. We believe these formulations to be novel and without precedent, even for Haskell98. These specifications are complemented with implementable algorithmic versions. We study soundness, completeness and the existence of principal kinds in these systems, proving the properties where they hold. This work can serve as a guide both to language designers who wish to formalize their datatype declarations and also to implementors keen to have principled inference of principal types.   This technical supplement to Kind Inference for Datatypes serves to expand upon the text in the main paper. It contains detailed typing rules, proofs, and connections to the Glasgow Haskell Compiler (GHC).},
  doi={10.1145/3371121},
  journal={arXiv}
}

@article{bleier2017truncationfree,
  title={Truncation-free Hybrid Inference for DPMM},
  author={Arnim Bleier},
  year={2017},
  url={http://arxiv.org/abs/1701.03743v1},
  abstract={Dirichlet process mixture models (DPMM) are a cornerstone of Bayesian non-parametrics. While these models free from choosing the number of components a-priori, computationally attractive variational inference often reintroduces the need to do so, via a truncation on the variational distribution. In this paper we present a truncation-free hybrid inference for DPMM, combining the advantages of sampling-based MCMC and variational methods. The proposed hybridization enables more efficient variational updates, while increasing model complexity only if needed. We evaluate the properties of the hybrid updates and their empirical performance in single- as well as mixed-membership models. Our method is easy to implement and performs favorably compared to existing schemas.},
  journal={arXiv}
}

@article{parmar2025scaling,
  title={Scaling Group Inference for Diverse and High-Quality Generation},
  author={Gaurav Parmar and Or Patashnik and Daniil Ostashev and Kuan-Chieh Wang and Kfir Aberman and Srinivasa Narasimhan and Jun-Yan Zhu},
  year={2025},
  url={http://arxiv.org/abs/2508.15773v1},
  abstract={Generative models typically sample outputs independently, and recent inference-time guidance and scaling algorithms focus on improving the quality of individual samples. However, in real-world applications, users are often presented with a set of multiple images (e.g., 4-8) for each prompt, where independent sampling tends to lead to redundant results, limiting user choices and hindering idea exploration. In this work, we introduce a scalable group inference method that improves both the diversity and quality of a group of samples. We formulate group inference as a quadratic integer assignment problem: candidate outputs are modeled as graph nodes, and a subset is selected to optimize sample quality (unary term) while maximizing group diversity (binary term). To substantially improve runtime efficiency, we progressively prune the candidate set using intermediate predictions, allowing our method to scale up to large candidate sets. Extensive experiments show that our method significantly improves group diversity and quality compared to independent sampling baselines and recent inference algorithms. Our framework generalizes across a wide range of tasks, including text-to-image, image-to-image, image prompting, and video generation, enabling generative models to treat multiple outputs as cohesive groups rather than independent samples.},
  journal={arXiv}
}

@article{zhou2023framework,
  title={A Framework for Transmission Design for Active RIS-Aided Communication with Partial CSI},
  author={Gui Zhou and Cunhua Pan and Hong Ren and Dongfang Xu and Zaichen Zhang and Jiangzhou Wang and Robert Schober},
  year={2023},
  url={http://arxiv.org/abs/2302.09353v1},
  abstract={Active reconfigurable intelligent surfaces (RISs) have recently been proposed to compensate for the severe multiplicative fading effect of conventional passive RIS-aided systems. Each reflecting element of active RISs is assisted by an amplifier such that the incident signal can be reflected and amplified instead of only being reflected as in passive RIS-aided systems. This work addresses the practical challenge that, on the one hand, in active RIS-aided systems the perfect individual CSI of the RIS-aided channels cannot be acquired due to the lack of signal processing power at the active RISs, but, on the other hand, this CSI is required to calculate the expected system data rate and RIS transmit power needed for transceiver design. To address this issue, we first derive closed-form expressions for the average achievable rate and the average RIS transmit power based on partial CSI of the RIS-aided channels. Then, we formulate an average achievable rate maximization problem for jointly optimizing the active beamforming at both the base station (BS) and the RIS. This problem is then tackled using the majorization--minimization (MM) algorithm framework, and, for each iteration, semi-closed-form solutions for the BS and RIS beamforming are derived based on the Karush-Kuhn-Tucker (KKT) conditions. To ensure the quality of service (QoS) of each user, we further formulate a rate outage constrained beamforming problem, which is solved using the Bernstein-Type inequality (BTI) and semidefinite relaxation (SDR) techniques. Numerical results show that the proposed algorithms can efficiently overcome the challenges imposed by imperfect CSI in active RIS-aided wireless systems.},
  journal={arXiv}
}

@article{zhang2021active,
  title={Active RIS vs. Passive RIS: Which Will Prevail in 6G?},
  author={Zijian Zhang and Linglong Dai and Xibi Chen and Changhao Liu and Fan Yang and Robert Schober and H. Vincent Poor},
  year={2021},
  url={http://arxiv.org/abs/2103.15154v8},
  abstract={As a revolutionary paradigm for controlling wireless channels, reconfigurable intelligent surfaces (RISs) have emerged as a candidate technology for future 6G networks. However, due to the "multiplicative fading" effect, the existing passive RISs only achieve limited capacity gains in many scenarios with strong direct links. In this paper, the concept of active RISs is proposed to overcome this fundamental limitation. Unlike passive RISs that reflect signals without amplification, active RISs can amplify the reflected signals via amplifiers integrated into their elements. To characterize the signal amplification and incorporate the noise introduced by the active components, we develop and verify the signal model of active RISs through the experimental measurements based on a fabricated active RIS element. Based on the verified signal model, we further analyze the asymptotic performance of active RISs to reveal the substantial capacity gain they provide for wireless communications. Finally, we formulate the sum-rate maximization problem for an active RIS aided multi-user multiple-input single-output (MU-MISO) system and a joint transmit beamforming and reflect precoding scheme is proposed to solve this problem. Simulation results show that, in a typical wireless system, passive RISs can realize only a limited sum-rate gain of 22%, while active RISs can achieve a significant sum-rate gain of 130%, thus overcoming the "multiplicative fading" effect.},
  doi={10.1109/TCOMM.2022.3231893},
  journal={arXiv}
}

@article{omar2020phase,
  title={Phase Diagram of Active Brownian Spheres: Crystallization and the Metastability of Motility-Induced Phase Separation},
  author={Ahmad K. Omar and Katherine Klymko and Trevor GrandPre and Phillip L. Geissler},
  year={2020},
  url={http://arxiv.org/abs/2012.09803v4},
  abstract={Motility-induced phase separation (MIPS), the phenomenon in which purely repulsive active particles undergo a liquid-gas phase separation, is among the simplest and most widely studied examples of a nonequilibrium phase transition. Here, we show that states of MIPS coexistence are in fact only metastable for three-dimensional active Brownian particles over a very broad range of conditions, decaying at long times through an ordering transition we call active crystallization. At an activity just above the MIPS critical point, the liquid-gas binodal is superseded by the crystal-fluid coexistence curve, with solid, liquid, and gas all coexisting at the triple point where the two curves intersect. Nucleating an active crystal from a disordered fluid, however, requires a rare fluctuation that exhibits the nearly close-packed density of the solid phase. The corresponding barrier to crystallization is surmountable on a feasible timescale only at high activity, and only at fluid densities near maximal packing. The glassiness expected for such dense liquids at equilibrium is strongly mitigated by active forces, so that the lifetime of liquid-gas coexistence declines steadily with increasing activity, manifesting in simulations as a facile spontaneous crystallization at extremely high activity.},
  doi={10.1103/PhysRevLett.126.188002},
  journal={arXiv}
}

@article{huang2021deepal,
  title={DeepAL: Deep Active Learning in Python},
  author={Kuan-Hao Huang},
  year={2021},
  url={http://arxiv.org/abs/2111.15258v1},
  abstract={We present DeepAL, a Python library that implements several common strategies for active learning, with a particular emphasis on deep active learning. DeepAL provides a simple and unified framework based on PyTorch that allows users to easily load custom datasets, build custom data handlers, and design custom strategies without much modification of codes. DeepAL is open-source on Github and welcome any contribution.},
  journal={arXiv}
}

@article{ueltzhöffer2017deep,
  title={Deep Active Inference},
  author={Kai Ueltzhöffer},
  year={2017},
  url={http://arxiv.org/abs/1709.02341v5},
  abstract={This work combines the free energy principle from cognitive neuroscience and the ensuing active inference dynamics with recent advances in variational inference in deep generative models, and evolution strategies to introduce the "deep active inference" agent. This agent minimises a variational free energy bound on the average surprise of its sensations, which is motivated by a homeostatic argument. It does so by optimising the parameters of a generative latent variable model of its sensory inputs, together with a variational density approximating the posterior distribution over the latent variables, given its observations, and by acting on its environment to actively sample input that is likely under this generative model. The internal dynamics of the agent are implemented using deep and recurrent neural networks, as used in machine learning, making the deep active inference agent a scalable and very flexible class of active inference agent. Using the mountain car problem, we show how goal directed behaviour can be implemented by defining appropriate priors on the latent states in the agent's model. Furthermore, we show that the deep active inference agent can learn a generative model of the environment, which can be sampled from to understand the agent's beliefs about the environment and its interaction therewith.},
  doi={10.1007/s00422-018-0785-7},
  journal={arXiv}
}

@article{németh2024computeefficient,
  title={Compute-Efficient Active Learning},
  author={Gábor Németh and Tamás Matuszka},
  year={2024},
  url={http://arxiv.org/abs/2401.07639v1},
  abstract={Active learning, a powerful paradigm in machine learning, aims at reducing labeling costs by selecting the most informative samples from an unlabeled dataset. However, the traditional active learning process often demands extensive computational resources, hindering scalability and efficiency. In this paper, we address this critical issue by presenting a novel method designed to alleviate the computational burden associated with active learning on massive datasets. To achieve this goal, we introduce a simple, yet effective method-agnostic framework that outlines how to strategically choose and annotate data points, optimizing the process for efficiency while maintaining model performance. Through case studies, we demonstrate the effectiveness of our proposed method in reducing computational costs while maintaining or, in some cases, even surpassing baseline model outcomes. Code is available at https://github.com/aimotive/Compute-Efficient-Active-Learning.},
  journal={arXiv}
}

@article{costa2024active,
  title={Active Inference as a Model of Agency},
  author={Lancelot Da Costa and Samuel Tenka and Dominic Zhao and Noor Sajid},
  year={2024},
  url={http://arxiv.org/abs/2401.12917v1},
  abstract={Is there a canonical way to think of agency beyond reward maximisation? In this paper, we show that any type of behaviour complying with physically sound assumptions about how macroscopic biological agents interact with the world canonically integrates exploration and exploitation in the sense of minimising risk and ambiguity about states of the world. This description, known as active inference, refines the free energy principle, a popular descriptive framework for action and perception originating in neuroscience. Active inference provides a normative Bayesian framework to simulate and model agency that is widely used in behavioural neuroscience, reinforcement learning (RL) and robotics. The usefulness of active inference for RL is three-fold. \emph{a}) Active inference provides a principled solution to the exploration-exploitation dilemma that usefully simulates biological agency. \emph{b}) It provides an explainable recipe to simulate behaviour, whence behaviour follows as an explainable mixture of exploration and exploitation under a generative world model, and all differences in behaviour are explicit in differences in world model. \emph{c}) This framework is universal in the sense that it is theoretically possible to rewrite any RL algorithm conforming to the descriptive assumptions of active inference as an active inference algorithm. Thus, active inference can be used as a tool to uncover and compare the commitments and assumptions of more specific models of agency.},
  journal={arXiv}
}

@article{sajid2019active,
  title={Active inference: demystified and compared},
  author={Noor Sajid and Philip J. Ball and Thomas Parr and Karl J. Friston},
  year={2019},
  url={http://arxiv.org/abs/1909.10863v3},
  abstract={Active inference is a first principle account of how autonomous agents operate in dynamic, non-stationary environments. This problem is also considered in reinforcement learning (RL), but limited work exists on comparing the two approaches on the same discrete-state environments. In this paper, we provide: 1) an accessible overview of the discrete-state formulation of active inference, highlighting natural behaviors in active inference that are generally engineered in RL; 2) an explicit discrete-state comparison between active inference and RL on an OpenAI gym baseline. We begin by providing a condensed overview of the active inference literature, in particular viewing the various natural behaviors of active inference agents through the lens of RL. We show that by operating in a pure belief-based setting, active inference agents can carry out epistemic exploration, and account for uncertainty about their environment in a Bayes-optimal fashion. Furthermore, we show that the reliance on an explicit reward signal in RL is removed in active inference, where reward can simply be treated as another observation; even in the total absence of rewards, agent behaviors are learned through preference learning. We make these properties explicit by showing two scenarios in which active inference agents can infer behaviors in reward-free environments compared to both Q-learning and Bayesian model-based RL agents; by placing zero prior preferences over rewards and by learning the prior preferences over the observations corresponding to reward. We conclude by noting that this formalism can be applied to more complex settings if appropriate generative models can be formulated. In short, we aim to demystify the behavior of active inference agents by presenting an accessible discrete state-space and time formulation, and demonstrate these behaviors in a OpenAI gym environment, alongside RL agents.},
  doi={10.1162/neco_a_01357},
  journal={arXiv}
}

@article{zrnic2024active,
  title={Active Statistical Inference},
  author={Tijana Zrnic and Emmanuel J. Candès},
  year={2024},
  url={http://arxiv.org/abs/2403.03208v2},
  abstract={Inspired by the concept of active learning, we propose active inference$\unicode{x2013}$a methodology for statistical inference with machine-learning-assisted data collection. Assuming a budget on the number of labels that can be collected, the methodology uses a machine learning model to identify which data points would be most beneficial to label, thus effectively utilizing the budget. It operates on a simple yet powerful intuition: prioritize the collection of labels for data points where the model exhibits uncertainty, and rely on the model's predictions where it is confident. Active inference constructs provably valid confidence intervals and hypothesis tests while leveraging any black-box machine learning model and handling any data distribution. The key point is that it achieves the same level of accuracy with far fewer samples than existing baselines relying on non-adaptively-collected data. This means that for the same number of collected samples, active inference enables smaller confidence intervals and more powerful p-values. We evaluate active inference on datasets from public opinion research, census analysis, and proteomics.},
  journal={arXiv}
}

@article{logan2022decal,
  title={DECAL: DEployable Clinical Active Learning},
  author={Yash-yee Logan and Mohit Prabhushankar and Ghassan AlRegib},
  year={2022},
  url={http://arxiv.org/abs/2206.10120v2},
  abstract={Conventional machine learning systems that operate on natural images assume the presence of attributes within the images that lead to some decision. However, decisions in medical domain are a resultant of attributes within medical diagnostic scans and electronic medical records (EMR). Hence, active learning techniques that are developed for natural images are insufficient for handling medical data. We focus on reducing this insufficiency by designing a deployable clinical active learning (DECAL) framework within a bi-modal interface so as to add practicality to the paradigm. Our approach is a "plug-in" method that makes natural image based active learning algorithms generalize better and faster. We find that on two medical datasets on three architectures and five learning strategies, DECAL increases generalization across 20 rounds by approximately 4.81%. DECAL leads to a 5.59% and 7.02% increase in average accuracy as an initialization strategy for optical coherence tomography (OCT) and X-Ray respectively. Our active learning results were achieved using 3000 (5%) and 2000 (38%) samples of OCT and X-Ray data respectively.},
  journal={arXiv}
}

@article{mazzaglia2021contrastive,
  title={Contrastive Active Inference},
  author={Pietro Mazzaglia and Tim Verbelen and Bart Dhoedt},
  year={2021},
  url={http://arxiv.org/abs/2110.10083v4},
  abstract={Active inference is a unifying theory for perception and action resting upon the idea that the brain maintains an internal model of the world by minimizing free energy. From a behavioral perspective, active inference agents can be seen as self-evidencing beings that act to fulfill their optimistic predictions, namely preferred outcomes or goals. In contrast, reinforcement learning requires human-designed rewards to accomplish any desired outcome. Although active inference could provide a more natural self-supervised objective for control, its applicability has been limited because of the shortcomings in scaling the approach to complex environments. In this work, we propose a contrastive objective for active inference that strongly reduces the computational burden in learning the agent's generative model and planning future actions. Our method performs notably better than likelihood-based active inference in image-based tasks, while also being computationally cheaper and easier to train. We compare to reinforcement learning agents that have access to human-designed reward functions, showing that our approach closely matches their performance. Finally, we also show that contrastive methods perform significantly better in the case of distractors in the environment and that our method is able to generalize goals to variations in the background. Website and code: https://contrastive-aif.github.io/},
  journal={arXiv}
}

@article{nuijten2025active,
  title={Active Inference is a Subtype of Variational Inference},
  author={Wouter W. L. Nuijten and Mykola Lukashchuk},
  year={2025},
  url={http://arxiv.org/abs/2511.18955v1},
  abstract={Automated decision-making under uncertainty requires balancing exploitation and exploration. Classical methods treat these separately using heuristics, while Active Inference unifies them through Expected Free Energy (EFE) minimization. However, EFE minimization is computationally expensive, limiting scalability. We build on recent theory recasting EFE minimization as variational inference, formally unifying it with Planning-as-Inference and showing the epistemic drive as a unique entropic contribution. Our main contribution is a novel message-passing scheme for this unified objective, enabling scalable Active Inference in factored-state MDPs and overcoming high-dimensional planning intractability.},
  journal={arXiv}
}

@article{liu2017quasibayesian,
  title={Quasi-Bayesian Inference for Production Frontiers},
  author={Xiaobin Liu and Thomas Tao Yang and Yichong Zhang},
  year={2017},
  url={http://arxiv.org/abs/1709.08846v3},
  abstract={We propose a quasi-Bayesian method to conduct inference for the production frontier. This approach combines multiple first-stage extreme quantile estimates by the quasi-Bayesian method to produce the point estimate and confidence interval for the production frontier. We show the asymptotic properties of the proposed estimator and the validity of the inference procedure. The finite sample performance of our method is illustrated through simulations and an empirical application.},
  journal={arXiv}
}

@article{dufresne2019active,
  title={Active Materials: Biological Benchmarks and Transport Limitations},
  author={Eric R. Dufresne},
  year={2019},
  url={http://arxiv.org/abs/1903.09584v1},
  abstract={These lecture notes were prepared for the 2018 Summer School on `Active Matter and Non-equilibrium Statistical Physics' at l'École de Physique des Houches. They survey metabolic activity across a wide range of living organisms, and consider size limitations due to the transport of fuel, waste, and heat for active materials at biomimetic levels of activity.},
  journal={arXiv}
}

@article{darwiche2022causal,
  title={Causal Inference Using Tractable Circuits},
  author={Adnan Darwiche},
  year={2022},
  url={http://arxiv.org/abs/2202.02891v1},
  abstract={The aim of this paper is to discuss a recent result which shows that probabilistic inference in the presence of (unknown) causal mechanisms can be tractable for models that have traditionally been viewed as intractable. This result was reported recently to facilitate model-based supervised learning but it can be interpreted in a causality context as follows. One can compile a non-parametric causal graph into an arithmetic circuit that supports inference in time linear in the circuit size. The circuit is also non-parametric so it can be used to estimate parameters from data and to further reason (in linear time) about the causal graph parametrized by these estimates. Moreover, the circuit size can sometimes be bounded even when the treewidth of the causal graph is not, leading to tractable inference on models that have been deemed intractable previously. This has been enabled by a new technique that can exploit causal mechanisms computationally but without needing to know their identities (the classical setup in causal inference). Our goal is to provide a causality-oriented exposure to these new results and to speculate on how they may potentially contribute to more scalable and versatile causal inference.},
  journal={arXiv}
}

@article{kim2023convergence,
  title={On the Convergence of Black-Box Variational Inference},
  author={Kyurae Kim and Jisu Oh and Kaiwen Wu and Yi-An Ma and Jacob R. Gardner},
  year={2023},
  url={http://arxiv.org/abs/2305.15349v4},
  abstract={We provide the first convergence guarantee for full black-box variational inference (BBVI), also known as Monte Carlo variational inference. While preliminary investigations worked on simplified versions of BBVI (e.g., bounded domain, bounded support, only optimizing for the scale, and such), our setup does not need any such algorithmic modifications. Our results hold for log-smooth posterior densities with and without strong log-concavity and the location-scale variational family. Also, our analysis reveals that certain algorithm design choices commonly employed in practice, particularly, nonlinear parameterizations of the scale of the variational approximation, can result in suboptimal convergence rates. Fortunately, running BBVI with proximal stochastic gradient descent fixes these limitations, and thus achieves the strongest known convergence rate guarantees. We evaluate this theoretical insight by comparing proximal SGD against other standard implementations of BBVI on large-scale Bayesian inference problems.},
  journal={arXiv}
}

@article{you2021wireless,
  title={Wireless Communication Aided by Intelligent Reflecting Surface: Active or Passive?},
  author={Changsheng You and Rui Zhang},
  year={2021},
  url={http://arxiv.org/abs/2106.10963v2},
  abstract={In this letter, we consider an intelligent reflecting surface (IRS)-aided wireless communication system, where an active or passive IRS is employed to assist the communication between an access point and a user. First, we consider the downlink/uplink communication separately and optimize the IRS placement for rate maximization with an active or passive IRS. We show that the active IRS should be deployed closer to the receiver with the IRS's decreasing amplification power; while in contrast, the passive IRS should be deployed near either the transmitter or receiver. Moreover, with optimized IRS placement, the passive IRS is shown to outperform its active counterpart when the number of reflecting elements is sufficiently large and/or the active-IRS amplification power is too small. Next, we optimize the IRS placement for both active and passive IRSs to maximize the weighted sum-rate of uplink and downlink communications. We show that in this case, the passive IRS is more likely to achieve superior rate performance. This is because the optimal active-IRS placement needs to balance the rate performance in the uplink and downlink, while deploying the passive IRS near the transmitter or receiver is optimal regardless of the uplink or downlink.},
  journal={arXiv}
}

@article{desislavov2021compute,
  title={Compute and Energy Consumption Trends in Deep Learning Inference},
  author={Radosvet Desislavov and Fernando Martínez-Plumed and José Hernández-Orallo},
  year={2021},
  url={http://arxiv.org/abs/2109.05472v2},
  abstract={The progress of some AI paradigms such as deep learning is said to be linked to an exponential growth in the number of parameters. There are many studies corroborating these trends, but does this translate into an exponential increase in energy consumption? In order to answer this question we focus on inference costs rather than training costs, as the former account for most of the computing effort, solely because of the multiplicative factors. Also, apart from algorithmic innovations, we account for more specific and powerful hardware (leading to higher FLOPS) that is usually accompanied with important energy efficiency optimisations. We also move the focus from the first implementation of a breakthrough paper towards the consolidated version of the techniques one or two year later. Under this distinctive and comprehensive perspective, we study relevant models in the areas of computer vision and natural language processing: for a sustained increase in performance we see a much softer growth in energy consumption than previously anticipated. The only caveat is, yet again, the multiplicative factor, as future AI increases penetration and becomes more pervasive.},
  doi={10.1016/j.suscom.2023.100857},
  journal={arXiv}
}

@article{li2023towards,
  title={Towards Enabling Cardiac Digital Twins of Myocardial Infarction Using Deep Computational Models for Inverse Inference},
  author={Lei Li and Julia Camps and  Zhinuo and  Wang and Abhirup Banerjee and Marcel Beetz and Blanca Rodriguez and Vicente Grau},
  year={2023},
  url={http://arxiv.org/abs/2307.04421v3},
  abstract={Cardiac digital twins (CDTs) have the potential to offer individualized evaluation of cardiac function in a non-invasive manner, making them a promising approach for personalized diagnosis and treatment planning of my-ocardial infarction (MI). The inference of accurate myocardial tissue properties is crucial in creating a reliable CDT of MI. In this work, we investigate the feasibility of inferring myocardial tissue properties from the electrocardiogram (ECG) within a CDT platform. The platform integrates multi-modal data, such as cardiac MRI and ECG, to enhance the accuracy and reliability of the inferred tissue properties. We perform a sensitivity analysis based on computer simulations, systematically exploring the effects of infarct location, size, degree of transmurality, and electrical ac-tivity alteration on the simulated QRS complex of ECG, to establish the limits of the approach. We subsequently present a novel deep computational model, comprising a dual-branch variational autoencoder and an inference model, to infer infarct location and distribution from the simulated QRS. The proposed model achieves mean Dice scores of 0.457 \pm 0.317 and 0.302 \pm 0.273 for the inference of left ventricle scars and border zone, respectively. The sensitivity analysis enhances our understanding of the complex relationship between infarct characteristics and electrophysiological features. The in silico experimental results show that the model can effectively capture the relationship for the inverse inference, with promising potential for clinical application in the future. The code will be released publicly once the manuscript is accepted for publication.},
  journal={arXiv}
}

@article{haluts2024models,
  title={Models of Animal Behavior as Active Particle Systems with Nonreciprocal Interactions},
  author={Amir Haluts and Dan Gorbonos and Nir S. Gov},
  year={2024},
  url={http://arxiv.org/abs/2401.14850v2},
  abstract={Active particle systems of interacting self-propelled particles offer a versatile framework for modeling complex systems. When employed to describe aspects of animal behavior, the complexity of animal movement and decision-making often requires the use of unique types of effective interactions between the particles -- notably nonreciprocal effective forces that do not obey the usual conservation laws of Newtonian mechanics. Here we review two recent empirically-motivated models, of two very different types of animal behavior, where the behavior is described in terms of active particles which interact through nonreciprocal effective forces. The first model describes the dynamics of animal contests, wherein typically two rivals fight over a localized resource. The uniquely shaped effective potentials between the model's 'contestant particles' manifest the adversarial nature of contest interactions and capture the dynamical essence of contest behavior in space and time. The second model describes the stabilization of cohesive swarms through long-range and adaptive gravity-like attraction. This 'adaptive gravity' model explains the observed mass and velocity profiles of laboratory midge swarms. These examples demonstrate that theoretical models that use the framework of active particles to describe animal behavior can expand the scope of active-particle research, as well as explain complex phenomena in animal behavior.},
  doi={10.1007/978-3-031-73423-6_4},
  journal={arXiv}
}

@article{caticha2010entropic,
  title={Entropic Inference},
  author={Ariel Caticha},
  year={2010},
  url={http://arxiv.org/abs/1011.0723v1},
  abstract={In this tutorial we review the essential arguments behing entropic inference. We focus on the epistemological notion of information and its relation to the Bayesian beliefs of rational agents. The problem of updating from a prior to a posterior probability distribution is tackled through an eliminative induction process that singles out the logarithmic relative entropy as the unique tool for inference. The resulting method of Maximum relative Entropy (ME), includes as special cases both MaxEnt and Bayes' rule, and therefore unifies the two themes of these workshops -- the Maximum Entropy and the Bayesian methods -- into a single general inference scheme.},
  doi={10.1063/1.3573619},
  journal={arXiv}
}

@article{nguyen2021active,
  title={Active Learning in Incomplete Label Multiple Instance Multiple Label Learning},
  author={Tam Nguyen and Raviv Raich},
  year={2021},
  url={http://arxiv.org/abs/2107.10804v2},
  abstract={In multiple instance multiple label learning, each sample, a bag, consists of multiple instances. To alleviate labeling complexity, each sample is associated with a set of bag-level labels leaving instances within the bag unlabeled. This setting is more convenient and natural for representing complicated objects, which have multiple semantic meanings. Compared to single instance labeling, this approach allows for labeling larger datasets at an equivalent labeling cost. However, for sufficiently large datasets, labeling all bags may become prohibitively costly. Active learning uses an iterative labeling and retraining approach aiming to provide reasonable classification performance using a small number of labeled samples. To our knowledge, only a few works in the area of active learning in the MIML setting are available. These approaches can provide practical solutions to reduce labeling cost but their efficacy remains unclear. In this paper, we propose a novel bag-class pair based approach for active learning in the MIML setting. Due to the partial availability of bag-level labels, we focus on the incomplete-label MIML setting for the proposed active learning approach. Our approach is based on a discriminative graphical model with efficient and exact inference. For the query process, we adapt active learning criteria to the novel bag-class pair selection strategy. Additionally, we introduce an online stochastic gradient descent algorithm to provide an efficient model update after each query. Numerical experiments on benchmark datasets illustrate the robustness of the proposed approach.},
  journal={arXiv}
}

@article{bambhaniya2025understanding,
  title={Understanding and Optimizing Multi-Stage AI Inference Pipelines},
  author={Abhimanyu Rajeshkumar Bambhaniya and Hanjiang Wu and Suvinay Subramanian and Sudarshan Srinivasan and Souvik Kundu and Amir Yazdanbakhsh and Midhilesh Elavazhagan and Madhu Kumar and Tushar Krishna},
  year={2025},
  url={http://arxiv.org/abs/2504.09775v4},
  abstract={The rapid evolution of Large Language Models (LLMs) has driven the need for increasingly sophisticated inference pipelines and hardware platforms. Modern LLM serving extends beyond traditional prefill-decode workflows, incorporating multi-stage processes such as Retrieval Augmented Generation (RAG), key-value (KV) cache retrieval, dynamic model routing, and multi step reasoning. These stages exhibit diverse computational demands, requiring distributed systems that integrate GPUs, ASICs, CPUs, and memory-centric architectures. However, existing simulators lack the fidelity to model these heterogeneous, multi-engine workflows, limiting their ability to inform architectural decisions.   To address this gap, we introduce HERMES, a Heterogeneous Multi-stage LLM inference Execution Simulator. HERMES models diverse request stages; including RAG, KV retrieval, reasoning, prefill, and decode across complex hardware hierarchies. HERMES supports heterogeneous clients executing multiple models concurrently unlike prior frameworks while incorporating advanced batching strategies and multi-level memory hierarchies. By integrating real hardware traces with analytical modeling, HERMES captures critical trade-offs such as memory bandwidth contention, inter-cluster communication latency, and batching efficiency in hybrid CPU-accelerator deployments. Through case studies, we explore the impact of reasoning stages on end-to-end latency, optimal batching strategies for hybrid pipelines, and the architectural implications of remote KV cache retrieval. HERMES empowers system designers to navigate the evolving landscape of LLM inference, providing actionable insights into optimizing hardware-software co-design for next-generation AI workloads.},
  journal={arXiv}
}

@article{nguyen2023opportunityfinder,
  title={OpportunityFinder: A Framework for Automated Causal Inference},
  author={Huy Nguyen and Prince Grover and Devashish Khatwani},
  year={2023},
  url={http://arxiv.org/abs/2309.13103v1},
  abstract={We introduce OpportunityFinder, a code-less framework for performing a variety of causal inference studies with panel data for non-expert users. In its current state, OpportunityFinder only requires users to provide raw observational data and a configuration file. A pipeline is then triggered that inspects/processes data, chooses the suitable algorithm(s) to execute the causal study. It returns the causal impact of the treatment on the configured outcome, together with sensitivity and robustness results. Causal inference is widely studied and used to estimate the downstream impact of individual's interactions with products and features. It is common that these causal studies are performed by scientists and/or economists periodically. Business stakeholders are often bottle-necked on scientist or economist bandwidth to conduct causal studies. We offer OpportunityFinder as a solution for commonly performed causal studies with four key features: (1) easy to use for both Business Analysts and Scientists, (2) abstraction of multiple algorithms under a single I/O interface, (3) support for causal impact analysis under binary treatment with panel data and (4) dynamic selection of algorithm based on scale of data.},
  journal={arXiv}
}

@article{sussman2021nonmetric,
  title={Non-metric interaction rules in models of active matter},
  author={Daniel M. Sussman},
  year={2021},
  url={http://arxiv.org/abs/2103.10239v1},
  abstract={It is common in the study of a dizzying array of soft matter systems to perform agent-based simulations of particles interacting via conservative and often short-ranged forces. In this context, well-established algorithms for efficiently computing the set of pairs of interacting particles have established excellent open-source packages to efficiently simulate large systems over long time scales -- a crucial consideration given the separation in time- and length-scales often observed in soft matter. What happens, though, when we think more broadly about what it means to construct a neighbor list? What if interactions are non-reciprocal, or if the "range" of an interaction is determined not by a distance scale but according to some other consideration? As the field of soft and active matter increasingly considers the properties of living matter -- from the cellular to the super-organismal scale -- these questions become increasingly relevant, and encourage us to think about new physical and computational paradigms in the modeling of active matter. In this chapter we examine case studies in the use of non-metric interactions.},
  journal={arXiv}
}

@article{tschantz2019scaling,
  title={Scaling active inference},
  author={Alexander Tschantz and Manuel Baltieri and Anil. K. Seth and Christopher L. Buckley},
  year={2019},
  url={http://arxiv.org/abs/1911.10601v1},
  abstract={In reinforcement learning (RL), agents often operate in partially observed and uncertain environments. Model-based RL suggests that this is best achieved by learning and exploiting a probabilistic model of the world. 'Active inference' is an emerging normative framework in cognitive and computational neuroscience that offers a unifying account of how biological agents achieve this. On this framework, inference, learning and action emerge from a single imperative to maximize the Bayesian evidence for a niched model of the world. However, implementations of this process have thus far been restricted to low-dimensional and idealized situations. Here, we present a working implementation of active inference that applies to high-dimensional tasks, with proof-of-principle results demonstrating efficient exploration and an order of magnitude increase in sample efficiency over strong model-free baselines. Our results demonstrate the feasibility of applying active inference at scale and highlight the operational homologies between active inference and current model-based approaches to RL.},
  journal={arXiv}
}

@article{bache2013passive,
  title={The passive and active periods for the intermittent use of an active sensor to detect an evasive target},
  author={Niels Bache},
  year={2013},
  url={http://arxiv.org/abs/1312.5224v1},
  abstract={Your task is to detect a submarine with your active sonar. The submarine can hear your active sonar before you can detect him. If the submarine is fast enough he can evade you before you can detect him. How do you then detect him? If you are using your active sonar continuously you will not detect him. Likewise, if you are not using your sonar at all. In between those two extremes there is an optimum. We will find that optimum. Or said more precisely and general: In the same two dimensional region two platforms are present. One platform, the searcher, equipped with one active sensor (sonar, radar, lidar etc.), is trying to detect the other platform, the target, by means of its active sensor. The target tries to avoid detection using only a passive sensor to detect the searcher. The target can detect the active sensor before the searcher can detect the target (forestalling). The active sensor is therefore used intermittently to surprise the target. The aim of this study is to quantify the passive period of the active sensor by minimizing missed detection opportunities. The active period is subsequently found by maximizing the average detection width of the searcher sensor over time.},
  journal={arXiv}
}

@article{torzoni2025active,
  title={Active Digital Twins via Active Inference},
  author={Matteo Torzoni and Domenico Maisto and Andrea Manzoni and Francesco Donnarumma and Giovanni Pezzulo and Alberto Corigliano},
  year={2025},
  url={http://arxiv.org/abs/2506.14453v1},
  abstract={Digital twins are transforming engineering and applied sciences by enabling real-time monitoring, simulation, and predictive analysis of physical systems and processes. However, conventional digital twins rely primarily on passive data assimilation, which limits their adaptability in uncertain and dynamic environments. This paper introduces the active digital twin paradigm, based on active inference. Active inference is a neuroscience-inspired, Bayesian framework for probabilistic reasoning and predictive modeling that unifies inference, decision-making, and learning under a unique, free energy minimization objective. By formulating the evolution of the active digital twin as a partially observable Markov decision process, the active inference agent continuously refines its generative model through Bayesian updates and forecasts future states and observations. Decision-making emerges from an optimization process that balances pragmatic exploitation (maximizing goal-directed utility) and epistemic exploration or information gain (actively resolving uncertainty). Actions are dynamically planned to minimize expected free energy, which quantifies both the divergence between predicted and preferred future observations, and the epistemic value of expected information gain about hidden states. This approach enables a new level of autonomy and resilience in digital twins, offering superior spontaneous exploration capabilities. The proposed framework is assessed on the health monitoring and predictive maintenance of a railway bridge.},
  journal={arXiv}
}

@article{murraysmith2024active,
  title={Active Inference and Human--Computer Interaction},
  author={Roderick Murray-Smith and John H. Williamson and Sebastian Stein},
  year={2024},
  url={http://arxiv.org/abs/2412.14741v1},
  abstract={Active Inference is a closed-loop computational theoretical basis for understanding behaviour, based on agents with internal probabilistic generative models that encode their beliefs about how hidden states in their environment cause their sensations. We review Active Inference and how it could be applied to model the human-computer interaction loop. Active Inference provides a coherent framework for managing generative models of humans, their environments, sensors and interface components. It informs off-line design and supports real-time, online adaptation. It provides model-based explanations for behaviours observed in HCI, and new tools to measure important concepts such as agency and engagement. We discuss how Active Inference offers a new basis for a theory of interaction in HCI, tools for design of modern, complex sensor-based systems, and integration of artificial intelligence technologies, enabling it to cope with diversity in human users and contexts. We discuss the practical challenges in implementing such Active Inference-based systems.},
  journal={arXiv}
}

@article{gehnen2025bayesian,
  title={Bayesian Inference in Quantum Programs},
  author={Christina Gehnen and Dominique Unruh and Joost-Pieter Katoen},
  year={2025},
  url={http://arxiv.org/abs/2504.20732v1},
  abstract={Conditioning is a key feature in probabilistic programming to enable modeling the influence of data (also known as observations) to the probability distribution described by such programs. Determining the posterior distribution is also known as Bayesian inference. This paper equips a quantum while-language with conditioning, defines its denotational and operational semantics over infinite-dimensional Hilbert spaces, and shows their equivalence. We provide sufficient conditions for the existence of weakest (liberal) precondition-transformers and derive inductive characterizations of these transformers. It is shown how w(l)p-transformers can be used to assess the effect of Bayesian inference on (possibly diverging) quantum programs.},
  journal={arXiv}
}

@article{costa2020reward,
  title={Reward Maximisation through Discrete Active Inference},
  author={Lancelot Da Costa and Noor Sajid and Thomas Parr and Karl Friston and Ryan Smith},
  year={2020},
  url={http://arxiv.org/abs/2009.08111v4},
  abstract={Active inference is a probabilistic framework for modelling the behaviour of biological and artificial agents, which derives from the principle of minimising free energy. In recent years, this framework has successfully been applied to a variety of situations where the goal was to maximise reward, offering comparable and sometimes superior performance to alternative approaches. In this paper, we clarify the connection between reward maximisation and active inference by demonstrating how and when active inference agents perform actions that are optimal for maximising reward. Precisely, we show the conditions under which active inference produces the optimal solution to the Bellman equation--a formulation that underlies several approaches to model-based reinforcement learning and control. On partially observed Markov decision processes, the standard active inference scheme can produce Bellman optimal actions for planning horizons of 1, but not beyond. In contrast, a recently developed recursive active inference scheme (sophisticated inference) can produce Bellman optimal actions on any finite temporal horizon. We append the analysis with a discussion of the broader relationship between active inference and reinforcement learning.},
  journal={arXiv}
}

@article{sengupta2023planktonic,
  title={Planktonic Active Matter},
  author={Anupam Sengupta},
  year={2023},
  url={http://arxiv.org/abs/2301.09550v1},
  abstract={Planktonic active matter represents an emergent system spanning different scales: individual, population and community; and complexity arising from sub-cellular and cellular to collective and ecosystem scale dynamics. This cross-scale active matter system responds to a range of abiotic (temperature, fluid flow and light conditions) and biotic factors (nutrients, pH, secondary metabolites) characteristic to the relevant ecosystems they are part of. Active modulation of cell phenotypes, including morphology, motility, and intracellular organization enable planktonic microbes to dynamically interact with other individuals and species; and adapt - often rapidly - to the changes in their environment. In this chapter, I discuss both traditional and contemporary approaches to study the dynamics of this multi-scale active matter system from a mechanistic standpoint, with specific references to their local settings and their ability to actively tune the behaviour and physiology, and the emergent structures and functions they elicit under natural ecological constraints as well as due to the shifting climatic trends.},
  journal={arXiv}
}

@article{mogali2013templatebased,
  title={Template-Based Active Contours},
  author={Jayanth Krishna Mogali and Adithya Kumar Pediredla and Chandra Sekhar Seelamantula},
  year={2013},
  url={http://arxiv.org/abs/1312.0760v1},
  abstract={We develop a generalized active contour formalism for image segmentation based on shape templates. The shape template is subjected to a restricted affine transformation (RAT) in order to segment the object of interest. RAT allows for translation, rotation, and scaling, which give a total of five degrees of freedom. The proposed active contour comprises an inner and outer contour pair, which are closed and concentric. The active contour energy is a contrast function defined based on the intensities of pixels that lie inside the inner contour and those that lie in the annulus between the inner and outer contours. We show that the contrast energy functional is optimal under certain conditions. The optimal RAT parameters are computed by maximizing the contrast function using a gradient descent optimizer. We show that the calculations are made efficient through use of Green's theorem. The proposed formalism is capable of handling a variety of shapes because for a chosen template, optimization is carried with respect to the RAT parameters only. The proposed formalism is validated on multiple images to show robustness to Gaussian and Poisson noise, to initialization, and to partial loss of structure in the object to be segmented.},
  journal={arXiv}
}

@article{orhan2015alevs,
  title={ALEVS: Active Learning by Statistical Leverage Sampling},
  author={Cem Orhan and Öznur Taştan},
  year={2015},
  url={http://arxiv.org/abs/1507.04155v1},
  abstract={Active learning aims to obtain a classifier of high accuracy by using fewer label requests in comparison to passive learning by selecting effective queries. Many active learning methods have been developed in the past two decades, which sample queries based on informativeness or representativeness of unlabeled data points. In this work, we explore a novel querying criterion based on statistical leverage scores. The statistical leverage scores of a row in a matrix are the squared row-norms of the matrix containing its (top) left singular vectors and is a measure of influence of the row on the matrix. Leverage scores have been used for detecting high influential points in regression diagnostics and have been recently shown to be useful for data analysis and randomized low-rank matrix approximation algorithms. We explore how sampling data instances with high statistical leverage scores perform in active learning. Our empirical comparison on several binary classification datasets indicate that querying high leverage points is an effective strategy.},
  journal={arXiv}
}

@article{millidge2022successor,
  title={Successor Representation Active Inference},
  author={Beren Millidge and Christopher L Buckley},
  year={2022},
  url={http://arxiv.org/abs/2207.09897v1},
  abstract={Recent work has uncovered close links between between classical reinforcement learning algorithms, Bayesian filtering, and Active Inference which lets us understand value functions in terms of Bayesian posteriors. An alternative, but less explored, model-free RL algorithm is the successor representation, which expresses the value function in terms of a successor matrix of expected future state occupancies. In this paper, we derive the probabilistic interpretation of the successor representation in terms of Bayesian filtering and thus design a novel active inference agent architecture utilizing successor representations instead of model-based planning. We demonstrate that active inference successor representations have significant advantages over current active inference agents in terms of planning horizon and computational cost. Moreover, we demonstrate how the successor representation agent can generalize to changing reward functions such as variants of the expected free energy.},
  journal={arXiv}
}

@article{douglas2017universal,
  title={A Universal Marginalizer for Amortized Inference in Generative Models},
  author={Laura Douglas and Iliyan Zarov and Konstantinos Gourgoulias and Chris Lucas and Chris Hart and Adam Baker and Maneesh Sahani and Yura Perov and Saurabh Johri},
  year={2017},
  url={http://arxiv.org/abs/1711.00695v1},
  abstract={We consider the problem of inference in a causal generative model where the set of available observations differs between data instances. We show how combining samples drawn from the graphical model with an appropriate masking function makes it possible to train a single neural network to approximate all the corresponding conditional marginal distributions and thus amortize the cost of inference. We further demonstrate that the efficiency of importance sampling may be improved by basing proposals on the output of the neural network. We also outline how the same network can be used to generate samples from an approximate joint posterior via a chain decomposition of the graph.},
  journal={arXiv}
}

@article{werner2023towards,
  title={Towards Comparable Active Learning},
  author={Thorben Werner and Johannes Burchert and Lars Schmidt-Thieme},
  year={2023},
  url={http://arxiv.org/abs/2311.18356v2},
  abstract={Active Learning has received significant attention in the field of machine learning for its potential in selecting the most informative samples for labeling, thereby reducing data annotation costs. However, we show that the reported lifts in recent literature generalize poorly to other domains leading to an inconclusive landscape in Active Learning research. Furthermore, we highlight overlooked problems for reproducing AL experiments that can lead to unfair comparisons and increased variance in the results. This paper addresses these issues by providing an Active Learning framework for a fair comparison of algorithms across different tasks and domains, as well as a fast and performant oracle algorithm for evaluation. To the best of our knowledge, we propose the first AL benchmark that tests algorithms in 3 major domains: Tabular, Image, and Text. We report empirical results for 6 widely used algorithms on 7 real-world and 2 synthetic datasets and aggregate them into a domain-specific ranking of AL algorithms.},
  journal={arXiv}
}

@article{albarracin2022mapping,
  title={Mapping Husserlian phenomenology onto active inference},
  author={Mahault Albarracin and Riddhi J. Pitliya and Maxwell J. D. Ramstead and Jeffrey Yoshimi},
  year={2022},
  url={http://arxiv.org/abs/2208.09058v3},
  abstract={Phenomenology is the rigorous descriptive study of conscious experience. Recent attempts to formalize Husserlian phenomenology provide us with a mathematical model of perception as a function of prior knowledge and expectation. In this paper, we re-examine elements of Husserlian phenomenology through the lens of active inference. In doing so, we aim to advance the project of computational phenomenology, as recently outlined by proponents of active inference. We propose that key aspects of Husserl's descriptions of consciousness can be mapped onto aspects of the generative models associated with the active inference approach. We first briefly review active inference. We then discuss Husserl's phenomenology, with a focus on time consciousness. Finally, we present our mapping from Husserlian phenomenology to active inference.},
  journal={arXiv}
}

@article{dehouche2024enhancing,
  title={Enhancing Population-based Search with Active Inference},
  author={Nassim Dehouche and Daniel Friedman},
  year={2024},
  url={http://arxiv.org/abs/2408.09548v1},
  abstract={The Active Inference framework models perception and action as a unified process, where agents use probabilistic models to predict and actively minimize sensory discrepancies. In complement and contrast, traditional population-based metaheuristics rely on reactive environmental interactions without anticipatory adaptation. This paper proposes the integration of Active Inference into these metaheuristics to enhance performance through anticipatory environmental adaptation. We demonstrate this approach specifically with Ant Colony Optimization (ACO) on the Travelling Salesman Problem (TSP). Experimental results indicate that Active Inference can yield some improved solutions with only a marginal increase in computational cost, with interesting patterns of performance that relate to number and topology of nodes in the graph. Further work will characterize where and when different types of Active Inference augmentation of population metaheuristics may be efficacious.},
  journal={arXiv}
}

@article{qiu2025saffron1,
  title={Saffron-1: Safety Inference Scaling},
  author={Ruizhong Qiu and Gaotang Li and Tianxin Wei and Jingrui He and Hanghang Tong},
  year={2025},
  url={http://arxiv.org/abs/2506.06444v2},
  abstract={Existing safety assurance research has primarily focused on training-phase alignment to instill safe behaviors into LLMs. However, recent studies have exposed these methods' susceptibility to diverse jailbreak attacks. Concurrently, inference scaling has significantly advanced LLM reasoning capabilities but remains unexplored in the context of safety assurance. Addressing this gap, our work pioneers inference scaling for robust and effective LLM safety against emerging threats. We reveal that conventional inference scaling techniques, despite their success in reasoning tasks, perform poorly in safety contexts, even falling short of basic approaches like Best-of-N Sampling. We attribute this inefficiency to a newly identified challenge, the exploration--efficiency dilemma, arising from the high computational overhead associated with frequent process reward model (PRM) evaluations. To overcome this dilemma, we propose SAFFRON, a novel inference scaling paradigm tailored explicitly for safety assurance. Central to our approach is the introduction of a multifurcation reward model (MRM) that significantly reduces the required number of reward model evaluations. To operationalize this paradigm, we further propose: (i) a partial supervision training objective for MRM, (ii) a conservative exploration constraint to prevent out-of-distribution explorations, and (iii) a Trie-based key--value caching strategy that facilitates cache sharing across sequences during tree search. Extensive experiments validate the effectiveness of our method. Additionally, we publicly release our trained multifurcation reward model (Saffron-1) and the accompanying token-level safety reward dataset (Safety4M) to accelerate future research in LLM safety. Our code, model, and data are publicly available at https://github.com/q-rz/saffron , and our project homepage is at https://q-rz.github.io/p/saffron .},
  journal={arXiv}
}

@article{mehta2019active,
  title={Active Domain Randomization},
  author={Bhairav Mehta and Manfred Diaz and Florian Golemo and Christopher J. Pal and Liam Paull},
  year={2019},
  url={http://arxiv.org/abs/1904.04762v2},
  abstract={Domain randomization is a popular technique for improving domain transfer, often used in a zero-shot setting when the target domain is unknown or cannot easily be used for training. In this work, we empirically examine the effects of domain randomization on agent generalization. Our experiments show that domain randomization may lead to suboptimal, high-variance policies, which we attribute to the uniform sampling of environment parameters. We propose Active Domain Randomization, a novel algorithm that learns a parameter sampling strategy. Our method looks for the most informative environment variations within the given randomization ranges by leveraging the discrepancies of policy rollouts in randomized and reference environment instances. We find that training more frequently on these instances leads to better overall agent generalization. Our experiments across various physics-based simulated and real-robot tasks show that this enhancement leads to more robust, consistent policies.},
  journal={arXiv}
}

@article{millidge2019deep,
  title={Deep Active Inference as Variational Policy Gradients},
  author={Beren Millidge},
  year={2019},
  url={http://arxiv.org/abs/1907.03876v1},
  abstract={Active Inference is a theory of action arising from neuroscience which casts action and planning as a bayesian inference problem to be solved by minimizing a single quantity - the variational free energy. Active Inference promises a unifying account of action and perception coupled with a biologically plausible process theory. Despite these potential advantages, current implementations of Active Inference can only handle small, discrete policy and state-spaces and typically require the environmental dynamics to be known. In this paper we propose a novel deep Active Inference algorithm which approximates key densities using deep neural networks as flexible function approximators, which enables Active Inference to scale to significantly larger and more complex tasks. We demonstrate our approach on a suite of OpenAIGym benchmark tasks and obtain performance comparable with common reinforcement learning baselines. Moreover, our algorithm shows similarities with maximum entropy reinforcement learning and the policy gradients algorithm, which reveals interesting connections between the Active Inference framework and reinforcement learning.},
  journal={arXiv}
}

@article{sherlock2018direct,
  title={Direct statistical inference for finite Markov jump processes via the matrix exponential},
  author={Chris Sherlock},
  year={2018},
  url={http://arxiv.org/abs/1809.07110v2},
  abstract={Given noisy, partial observations of a time-homogeneous, finite-statespace Markov chain, conceptually simple, direct statistical inference is available, in theory, via its rate matrix, or infinitesimal generator, $\mathsf{Q}$, since $\exp (\mathsf{Q}t)$ is the transition matrix over time $t$. However, perhaps because of inadequate tools for matrix exponentiation in programming languages commonly used amongst statisticians or a belief that the necessary calculations are prohibitively expensive, statistical inference for continuous-time Markov chains with a large but finite state space is typically conducted via particle MCMC or other relatively complex inference schemes.   When, as in many applications $\mathsf{Q}$ arises from a reaction network, it is usually sparse. We describe variations on known algorithms which allow fast, robust and accurate evaluation of the product of a non-negative vector with the exponential of a large, sparse rate matrix. Our implementation uses relatively recently developed, efficient, linear algebra tools that take advantage of such sparsity. We demonstrate the straightforward statistical application of the key algorithm on a model for the mixing of two alleles in a population and on the Susceptible-Infectious-Removed epidemic model.},
  journal={arXiv}
}

@article{heins2022pymdp,
  title={pymdp: A Python library for active inference in discrete state spaces},
  author={Conor Heins and Beren Millidge and Daphne Demekas and Brennan Klein and Karl Friston and Iain Couzin and Alexander Tschantz},
  year={2022},
  url={http://arxiv.org/abs/2201.03904v2},
  abstract={Active inference is an account of cognition and behavior in complex systems which brings together action, perception, and learning under the theoretical mantle of Bayesian inference. Active inference has seen growing applications in academic research, especially in fields that seek to model human or animal behavior. While in recent years, some of the code arising from the active inference literature has been written in open source languages like Python and Julia, to-date, the most popular software for simulating active inference agents is the DEM toolbox of SPM, a MATLAB library originally developed for the statistical analysis and modelling of neuroimaging data. Increasing interest in active inference, manifested both in terms of sheer number as well as diversifying applications across scientific disciplines, has thus created a need for generic, widely-available, and user-friendly code for simulating active inference in open-source scientific computing languages like Python. The Python package we present here, pymdp (see https://github.com/infer-actively/pymdp), represents a significant step in this direction: namely, we provide the first open-source package for simulating active inference with partially-observable Markov Decision Processes or POMDPs. We review the package's structure and explain its advantages like modular design and customizability, while providing in-text code blocks along the way to demonstrate how it can be used to build and run active inference processes with ease. We developed pymdp to increase the accessibility and exposure of the active inference framework to researchers, engineers, and developers with diverse disciplinary backgrounds. In the spirit of open-source software, we also hope that it spurs new innovation, development, and collaboration in the growing active inference community.},
  doi={10.21105/joss.04098},
  journal={arXiv}
}

@article{ogden2016asymptotic,
  title={On asymptotic validity of naive inference with an approximate likelihood},
  author={Helen Ogden},
  year={2016},
  url={http://arxiv.org/abs/1601.07911v2},
  abstract={Many statistical models have likelihoods which are intractable: it is impossible or too expensive to compute the likelihood exactly. In such settings, a common approach is to replace the likelihood with an approximation, and proceed with inference as if the approximate likelihood were the exact likelihood. In this paper, we describe conditions on the approximate likelihood which guarantee that this naive inference with an approximate likelihood has the same first-order asymptotic properties as inference with the exact likelihood. We investigate the implications of these results for inference using a Laplace approximation to the likelihood in a simple two-level latent variable model, and using reduced dependence approximations to the likelihood in an Ising model on a lattice.},
  journal={arXiv}
}

@article{li2025dynamic,
  title={Dynamic Pricing for On-Demand DNN Inference in the Edge-AI Market},
  author={Songyuan Li and Jia Hu and Geyong Min and Haojun Huang and Jiwei Huang},
  year={2025},
  url={http://arxiv.org/abs/2503.04521v1},
  abstract={The convergence of edge computing and AI gives rise to Edge-AI, which enables the deployment of real-time AI applications and services at the network edge. One of the fundamental research issues in Edge-AI is edge inference acceleration, which aims to realize low-latency high-accuracy DNN inference services by leveraging the fine-grained offloading of partitioned inference tasks from end devices to edge servers. However, existing research has yet to adopt a practical Edge-AI market perspective, which would systematically explore the personalized inference needs of AI users (e.g., inference accuracy, latency, and task complexity), the revenue incentives for AI service providers that offer edge inference services, and multi-stakeholder governance within a market-oriented context. To bridge this gap, we propose an Auction-based Edge Inference Pricing Mechanism (AERIA) for revenue maximization to tackle the multi-dimensional optimization problem of DNN model partition, edge inference pricing, and resource allocation. We investigate the multi-exit device-edge synergistic inference scheme for on-demand DNN inference acceleration, and analyse the auction dynamics amongst the AI service providers, AI users and edge infrastructure provider. Owing to the strategic mechanism design via randomized consensus estimate and cost sharing techniques, the Edge-AI market attains several desirable properties, including competitiveness in revenue maximization, incentive compatibility, and envy-freeness, which are crucial to maintain the effectiveness, truthfulness, and fairness of our auction outcomes. The extensive simulation experiments based on four representative DNN inference workloads demonstrate that our AERIA mechanism significantly outperforms several state-of-the-art approaches in revenue maximization, demonstrating the efficacy of AERIA for on-demand DNN inference in the Edge-AI market.},
  journal={arXiv}
}

@article{chiang2023genuinely,
  title={Genuinely Robust Inference for Clustered Data},
  author={Harold D. Chiang and Yuya Sasaki and Yulong Wang},
  year={2023},
  url={http://arxiv.org/abs/2308.10138v8},
  abstract={Conventional cluster-robust inference can be invalid when data contain clusters of unignorably large size. We formalize this issue by deriving a necessary and sufficient condition for its validity, and show that this condition is frequently violated in practice: specifications from 77% of empirical research articles in American Economic Review and Econometrica during 2020-2021 appear not to meet it. To address this limitation, we propose a genuinely robust inference procedure based on a new cluster score bootstrap. We establish its validity and size control across broad classes of data-generating processes where conventional methods break down. Simulation studies corroborate our theoretical findings, and empirical applications illustrate that employing the proposed method can substantially alter conventional statistical conclusions.},
  journal={arXiv}
}

@article{munezero2018efficient,
  title={Efficient Particle Smoothing for Bayesian Inference in Dynamic Survival Models},
  author={Parfait Munezero},
  year={2018},
  url={http://arxiv.org/abs/1806.07048v3},
  abstract={This article proposes an efficient Bayesian inference for piecewise exponential hazard (PEH) models, which allow the effect of a covariate on the survival time to vary over time. The proposed inference methodology is based on a particle smoothing (PS) algorithm that depends on three particle filters. Efficient proposal (importance) distributions for the particle filters tailored to the nature of survival data and PEH models are developed using the Laplace approximation of the posterior distribution and linear Bayes theory. The algorithm is applied to both simulated and real data, and the results show that it generates an effective sample size that is more than two orders of magnitude larger than a state-of-the-art MCMC sampler for the same computing time, and scales well in high-dimensional and relatively large data.},
  journal={arXiv}
}

@article{myers2020hierarchical,
  title={A Hierarchical Approach to Scaling Batch Active Search Over Structured Data},
  author={Vivek Myers and Peyton Greenside},
  year={2020},
  url={http://arxiv.org/abs/2007.10263v1},
  abstract={Active search is the process of identifying high-value data points in a large and often high-dimensional parameter space that can be expensive to evaluate. Traditional active search techniques like Bayesian optimization trade off exploration and exploitation over consecutive evaluations, and have historically focused on single or small (<5) numbers of examples evaluated per round. As modern data sets grow, so does the need to scale active search to large data sets and batch sizes. In this paper, we present a general hierarchical framework based on bandit algorithms to scale active search to large batch sizes by maximizing information derived from the unique structure of each dataset. Our hierarchical framework, Hierarchical Batch Bandit Search (HBBS), strategically distributes batch selection across a learned embedding space by facilitating wide exploration of different structural elements within a dataset. We focus our application of HBBS on modern biology, where large batch experimentation is often fundamental to the research process, and demonstrate batch design of biological sequences (protein and DNA). We also present a new Gym environment to easily simulate diverse biological sequences and to enable more comprehensive evaluation of active search methods across heterogeneous data sets. The HBBS framework improves upon standard performance, wall-clock, and scalability benchmarks for batch search by using a broad exploration strategy across coarse partitions and fine-grained exploitation within each partition of structured data.},
  journal={arXiv}
}

@article{çatal2020deep,
  title={Deep Active Inference for Autonomous Robot Navigation},
  author={Ozan Çatal and Samuel Wauthier and Tim Verbelen and Cedric De Boom and Bart Dhoedt},
  year={2020},
  url={http://arxiv.org/abs/2003.03220v1},
  abstract={Active inference is a theory that underpins the way biological agent's perceive and act in the real world. At its core, active inference is based on the principle that the brain is an approximate Bayesian inference engine, building an internal generative model to drive agents towards minimal surprise. Although this theory has shown interesting results with grounding in cognitive neuroscience, its application remains limited to simulations with small, predefined sensor and state spaces.   In this paper, we leverage recent advances in deep learning to build more complex generative models that can work without a predefined states space. State representations are learned end-to-end from real-world, high-dimensional sensory data such as camera frames. We also show that these generative models can be used to engage in active inference. To the best of our knowledge this is the first application of deep active inference for a real-world robot navigation task.},
  journal={arXiv}
}

@article{lalchand2019approximate,
  title={Approximate Inference for Fully Bayesian Gaussian Process Regression},
  author={Vidhi Lalchand and Carl Edward Rasmussen},
  year={2019},
  url={http://arxiv.org/abs/1912.13440v2},
  abstract={Learning in Gaussian Process models occurs through the adaptation of hyperparameters of the mean and the covariance function. The classical approach entails maximizing the marginal likelihood yielding fixed point estimates (an approach called \textit{Type II maximum likelihood} or ML-II). An alternative learning procedure is to infer the posterior over hyperparameters in a hierarchical specification of GPs we call \textit{Fully Bayesian Gaussian Process Regression} (GPR). This work considers two approximation schemes for the intractable hyperparameter posterior: 1) Hamiltonian Monte Carlo (HMC) yielding a sampling-based approximation and 2) Variational Inference (VI) where the posterior over hyperparameters is approximated by a factorized Gaussian (mean-field) or a full-rank Gaussian accounting for correlations between hyperparameters. We analyze the predictive performance for fully Bayesian GPR on a range of benchmark data sets.},
  journal={arXiv}
}

@article{esaki2024environmentcentric,
  title={Environment-Centric Active Inference},
  author={Kanako Esaki and Tadayuki Matsumura and Takeshi Kato and Shunsuke Minusa and Yang Shao and Hiroyuki Mizuno},
  year={2024},
  url={http://arxiv.org/abs/2408.12777v1},
  abstract={To handle unintended changes in the environment by agents, we propose an environment-centric active inference EC-AIF in which the Markov Blanket of active inference is defined starting from the environment. In normal active inference, the Markov Blanket is defined starting from the agent. That is, first the agent was defined as the entity that performs the "action" such as a robot or a person, then the environment was defined as other people or objects that are directly affected by the agent's "action," and the boundary between the agent and the environment was defined as the Markov Blanket. This agent-centric definition does not allow the agent to respond to unintended changes in the environment caused by factors outside of the defined environment. In the proposed EC-AIF, there is no entity corresponding to an agent. The environment includes all observable things, including people and things conventionally considered to be the environment, as well as entities that perform "actions" such as robots and people. Accordingly, all states, including robots and people, are included in inference targets, eliminating unintended changes in the environment. The EC-AIF was applied to a robot arm and validated with an object transport task by the robot arm. The results showed that the robot arm successfully transported objects while responding to changes in the target position of the object and to changes in the orientation of another robot arm.},
  journal={arXiv}
}

@article{ciravegna2021knowledgedriven,
  title={Knowledge-driven Active Learning},
  author={Gabriele Ciravegna and Frédéric Precioso and Alessandro Betti and Kevin Mottin and Marco Gori},
  year={2021},
  url={http://arxiv.org/abs/2110.08265v4},
  abstract={The deployment of Deep Learning (DL) models is still precluded in those contexts where the amount of supervised data is limited. To answer this issue, active learning strategies aim at minimizing the amount of labelled data required to train a DL model. Most active strategies are based on uncertain sample selection, and even often restricted to samples lying close to the decision boundary. These techniques are theoretically sound, but an understanding of the selected samples based on their content is not straightforward, further driving non-experts to consider DL as a black-box. For the first time, here we propose to take into consideration common domain-knowledge and enable non-expert users to train a model with fewer samples. In our Knowledge-driven Active Learning (KAL) framework, rule-based knowledge is converted into logic constraints and their violation is checked as a natural guide for sample selection. We show that even simple relationships among data and output classes offer a way to spot predictions for which the model need supervision. We empirically show that KAL (i) outperforms many active learning strategies, particularly in those contexts where domain knowledge is rich, (ii) it discovers data distribution lying far from the initial training data, (iii) it ensures domain experts that the provided knowledge is acquired by the model, (iv) it is suitable for regression and object recognition tasks unlike uncertainty-based strategies, and (v) its computational demand is low.},
  doi={10.1007/978-3-031-43412-9_3},
  journal={arXiv}
}

@article{martínezcalvo2021active,
  title={Active transport in complex environments},
  author={Alejandro Martínez-Calvo and Carolina Trenado-Yuste and Sujit S. Datta},
  year={2021},
  url={http://arxiv.org/abs/2108.07011v2},
  abstract={The ability of many living systems to actively self-propel underlies critical biomedical, environmental, and industrial processes. While such active transport is well-studied in uniform settings, environmental complexities such as geometric constraints, mechanical cues, and external stimuli such as chemical gradients and fluid flow can strongly influence transport. In this chapter, we describe recent progress in the study of active transport in such complex environments, focusing on two prominent biological systems -- bacteria and eukaryotic cells -- as archetypes of active matter. We review research findings highlighting how environmental factors can fundamentally alter cellular motility, hindering or promoting active transport in unexpected ways, and giving rise to fascinating behaviors such as directed migration and large-scale clustering. In parallel, we describe specific open questions and promising avenues for future research. Furthermore, given the diverse forms of active matter -- ranging from enzymes and driven biopolymer assemblies, to microorganisms and synthetic microswimmers, to larger animals and even robots -- we also describe connections to other active systems as well as more general theoretical/computational models of transport processes in complex environments.},
  journal={arXiv}
}

@article{li2025robust,
  title={Robust Sampling for Active Statistical Inference},
  author={Puheng Li and Tijana Zrnic and Emmanuel Candès},
  year={2025},
  url={http://arxiv.org/abs/2511.08991v1},
  abstract={Active statistical inference is a new method for inference with AI-assisted data collection. Given a budget on the number of labeled data points that can be collected and assuming access to an AI predictive model, the basic idea is to improve estimation accuracy by prioritizing the collection of labels where the model is most uncertain. The drawback, however, is that inaccurate uncertainty estimates can make active sampling produce highly noisy results, potentially worse than those from naive uniform sampling. In this work, we present robust sampling strategies for active statistical inference. Robust sampling ensures that the resulting estimator is never worse than the estimator using uniform sampling. Furthermore, with reliable uncertainty estimates, the estimator usually outperforms standard active inference. This is achieved by optimally interpolating between uniform and active sampling, depending on the quality of the uncertainty scores, and by using ideas from robust optimization. We demonstrate the utility of the method on a series of real datasets from computational social science and survey research.},
  journal={arXiv}
}

@article{mcgregor2015minimal,
  title={A Minimal Active Inference Agent},
  author={Simon McGregor and Manuel Baltieri and Christopher L. Buckley},
  year={2015},
  url={http://arxiv.org/abs/1503.04187v1},
  abstract={Research on the so-called "free-energy principle'' (FEP) in cognitive neuroscience is becoming increasingly high-profile. To date, introductions to this theory have proved difficult for many readers to follow, but it depends mainly upon two relatively simple ideas: firstly that normative or teleological values can be expressed as probability distributions (active inference), and secondly that approximate Bayesian reasoning can be effectively performed by gradient descent on model parameters (the free-energy principle). The notion of active inference is of great interest for a number of disciplines including cognitive science and artificial intelligence, as well as cognitive neuroscience, and deserves to be more widely known.   This paper attempts to provide an accessible introduction to active inference and informational free-energy, for readers from a range of scientific backgrounds. In this work introduce an agent-based model with an agent trying to make predictions about its position in a one-dimensional discretized world using methods from the FEP.},
  journal={arXiv}
}

@article{smithe2024structured,
  title={Structured Active Inference (Extended Abstract)},
  author={Toby St Clere Smithe},
  year={2024},
  url={http://arxiv.org/abs/2406.07577v1},
  abstract={We introduce structured active inference, a large generalization and formalization of active inference using the tools of categorical systems theory. We cast generative models formally as systems "on an interface", with the latter being a compositional abstraction of the usual notion of Markov blanket; agents are then 'controllers' for their generative models, formally dual to them. This opens the active inference landscape to new horizons, such as: agents with structured interfaces (e.g. with 'mode-dependence', or that interact with computer APIs); agents that can manage other agents; and 'meta-agents', that use active inference to change their (internal or external) structure. With structured interfaces, we also gain structured ('typed') policies, which are amenable to formal verification, an important step towards safe artificial agents. Moreover, we can make use of categorical logic to describe express agents' goals as formal predicates, whose satisfaction may be dependent on the interaction context. This points towards powerful compositional tools to constrain and control self-organizing ensembles of agents.},
  journal={arXiv}
}

@article{acharya2018distributed,
  title={Distributed Simulation and Distributed Inference},
  author={Jayadev Acharya and Clément L. Canonne and Himanshu Tyagi},
  year={2018},
  url={http://arxiv.org/abs/1804.06952v3},
  abstract={Independent samples from an unknown probability distribution $\bf p$ on a domain of size $k$ are distributed across $n$ players, with each player holding one sample. Each player can communicate $\ell$ bits to a central referee in a simultaneous message passing model of communication to help the referee infer a property of the unknown $\bf p$. What is the least number of players for inference required in the communication-starved setting of $\ell<\log k$? We begin by exploring a general "simulate-and-infer" strategy for such inference problems where the center simulates the desired number of samples from the unknown distribution and applies standard inference algorithms for the collocated setting. Our first result shows that for $\ell<\log k$ perfect simulation of even a single sample is not possible. Nonetheless, we present a Las Vegas algorithm that simulates a single sample from the unknown distribution using $O(k/2^\ell)$ samples in expectation. As an immediate corollary, we get that simulate-and-infer attains the optimal sample complexity of $Θ(k^2/2^\ellε^2)$ for learning the unknown distribution to total variation distance $ε$. For the prototypical testing problem of identity testing, simulate-and-infer works with $O(k^{3/2}/2^\ellε^2)$ samples, a requirement that seems to be inherent for all communication protocols not using any additional resources. Interestingly, we can break this barrier using public coins. Specifically, we exhibit a public-coin communication protocol that performs identity testing using $O(k/\sqrt{2^\ell}ε^2)$ samples. Furthermore, we show that this is optimal up to constant factors. Our theoretically sample-optimal protocol is easy to implement in practice. Our proof of lower bound entails showing a contraction in $χ^2$ distance of product distributions due to communication constraints and may be of independent interest.},
  journal={arXiv}
}

@article{priorelli2024dynamic,
  title={Dynamic planning in hierarchical active inference},
  author={Matteo Priorelli and Ivilin Peev Stoianov},
  year={2024},
  url={http://arxiv.org/abs/2402.11658v3},
  abstract={By dynamic planning, we refer to the ability of the human brain to infer and impose motor trajectories related to cognitive decisions. A recent paradigm, active inference, brings fundamental insights into the adaptation of biological organisms, constantly striving to minimize prediction errors to restrict themselves to life-compatible states. Over the past years, many studies have shown how human and animal behaviors could be explained in terms of active inference - either as discrete decision-making or continuous motor control - inspiring innovative solutions in robotics and artificial intelligence. Still, the literature lacks a comprehensive outlook on effectively planning realistic actions in changing environments. Setting ourselves the goal of modeling complex tasks such as tool use, we delve into the topic of dynamic planning in active inference, keeping in mind two crucial aspects of biological behavior: the capacity to understand and exploit affordances for object manipulation, and to learn the hierarchical interactions between the self and the environment, including other agents. We start from a simple unit and gradually describe more advanced structures, comparing recently proposed design choices and providing basic examples. This study distances itself from traditional views centered on neural networks and reinforcement learning, and points toward a yet unexplored direction in active inference: hybrid representations in hierarchical models.},
  journal={arXiv}
}

@article{çatal2020learning,
  title={Learning Perception and Planning with Deep Active Inference},
  author={Ozan Çatal and Tim Verbelen and Johannes Nauta and Cedric De Boom and Bart Dhoedt},
  year={2020},
  url={http://arxiv.org/abs/2001.11841v2},
  abstract={Active inference is a process theory of the brain that states that all living organisms infer actions in order to minimize their (expected) free energy. However, current experiments are limited to predefined, often discrete, state spaces. In this paper we use recent advances in deep learning to learn the state space and approximate the necessary probability distributions to engage in active inference.},
  journal={arXiv}
}

@article{mohammaddjafari2001bayesian,
  title={Bayesian inference for inverse problems},
  author={Ali Mohammad-Djafari},
  year={2001},
  url={http://arxiv.org/abs/physics/0110093v1},
  abstract={Traditionally, the MaxEnt workshops start by a tutorial day. This paper summarizes my talk during 2001'th workshop at John Hopkins University. The main idea in this talk is to show how the Bayesian inference can naturally give us all the necessary tools we need to solve real inverse problems: starting by simple inversion where we assume to know exactly the forward model and all the input model parameters up to more realistic advanced problems of myopic or blind inversion where we may be uncertain about the forward model and we may have noisy data. Starting by an introduction to inverse problems through a few examples and explaining their ill posedness nature, I briefly presented the main classical deterministic methods such as data matching and classical regularization methods to show their limitations. I then presented the main classical probabilistic methods based on likelihood, information theory and maximum entropy and the Bayesian inference framework for such problems. I show that the Bayesian framework, not only generalizes all these methods, but also gives us natural tools, for example, for inferring the uncertainty of the computed solutions, for the estimation of the hyperparameters or for handling myopic or blind inversion problems. Finally, through a deconvolution problem example, I presented a few state of the art methods based on Bayesian inference particularly designed for some of the mass spectrometry data processing problems.},
  doi={10.1063/1.1477067},
  journal={arXiv}
}

@article{markovic2021empirical,
  title={An empirical evaluation of active inference in multi-armed bandits},
  author={Dimitrije Markovic and Hrvoje Stojic and Sarah Schwoebel and Stefan J. Kiebel},
  year={2021},
  url={http://arxiv.org/abs/2101.08699v4},
  abstract={A key feature of sequential decision making under uncertainty is a need to balance between exploiting--choosing the best action according to the current knowledge, and exploring--obtaining information about values of other actions. The multi-armed bandit problem, a classical task that captures this trade-off, served as a vehicle in machine learning for developing bandit algorithms that proved to be useful in numerous industrial applications. The active inference framework, an approach to sequential decision making recently developed in neuroscience for understanding human and animal behaviour, is distinguished by its sophisticated strategy for resolving the exploration-exploitation trade-off. This makes active inference an exciting alternative to already established bandit algorithms. Here we derive an efficient and scalable approximate active inference algorithm and compare it to two state-of-the-art bandit algorithms: Bayesian upper confidence bound and optimistic Thompson sampling. This comparison is done on two types of bandit problems: a stationary and a dynamic switching bandit. Our empirical evaluation shows that the active inference algorithm does not produce efficient long-term behaviour in stationary bandits. However, in the more challenging switching bandit problem active inference performs substantially better than the two state-of-the-art bandit algorithms. The results open exciting venues for further research in theoretical and applied machine learning, as well as lend additional credibility to active inference as a general framework for studying human and animal behaviour.},
  doi={10.1016/j.neunet.2021.08.018},
  journal={arXiv}
}

@article{paquet2015convergence,
  title={On the Convergence of Stochastic Variational Inference in Bayesian Networks},
  author={Ulrich Paquet},
  year={2015},
  url={http://arxiv.org/abs/1507.04505v1},
  abstract={We highlight a pitfall when applying stochastic variational inference to general Bayesian networks. For global random variables approximated by an exponential family distribution, natural gradient steps, commonly starting from a unit length step size, are averaged to convergence. This useful insight into the scaling of initial step sizes is lost when the approximation factorizes across a general Bayesian network, and care must be taken to ensure practical convergence. We experimentally investigate how much of the baby (well-scaled steps) is thrown out with the bath water (exact gradients).},
  journal={arXiv}
}

@article{millidge2020relationship,
  title={On the Relationship Between Active Inference and Control as Inference},
  author={Beren Millidge and Alexander Tschantz and Anil K Seth and Christopher L Buckley},
  year={2020},
  url={http://arxiv.org/abs/2006.12964v3},
  abstract={Active Inference (AIF) is an emerging framework in the brain sciences which suggests that biological agents act to minimise a variational bound on model evidence. Control-as-Inference (CAI) is a framework within reinforcement learning which casts decision making as a variational inference problem. While these frameworks both consider action selection through the lens of variational inference, their relationship remains unclear. Here, we provide a formal comparison between them and demonstrate that the primary difference arises from how value is incorporated into their respective generative models. In the context of this comparison, we highlight several ways in which these frameworks can inform one another.},
  journal={arXiv}
}

@article{pezzato2025mobile,
  title={Mobile Manipulation with Active Inference for Long-Horizon Rearrangement Tasks},
  author={Corrado Pezzato and Ozan Çatal and Toon Van de Maele and Riddhi J. Pitliya and Tim Verbelen},
  year={2025},
  url={http://arxiv.org/abs/2507.17338v1},
  abstract={Despite growing interest in active inference for robotic control, its application to complex, long-horizon tasks remains untested. We address this gap by introducing a fully hierarchical active inference architecture for goal-directed behavior in realistic robotic settings. Our model combines a high-level active inference model that selects among discrete skills realized via a whole-body active inference controller. This unified approach enables flexible skill composition, online adaptability, and recovery from task failures without requiring offline training. Evaluated on the Habitat Benchmark for mobile manipulation, our method outperforms state-of-the-art baselines across the three long-horizon tasks, demonstrating for the first time that active inference can scale to the complexity of modern robotics benchmarks.},
  journal={arXiv}
}

@article{lanzaro2023rheology,
  title={Rheology of active fluids},
  author={Alfredo Lanzaro and Luigi Gentile},
  year={2023},
  url={http://arxiv.org/abs/2304.00316v1},
  abstract={This chapter on the rheology of active fluids is an attempt to correlate theoretical and experimental work. A considerable amount of theoretical work and most of the experimental data focus on the rheology of active fluids in a Newtonian matrix, which displays uncommon macroscopic rheological behaviors, such as the apparent superfluid-like state of the pusher suspensions. The failure of the "scallop theorem" for reciprocal swimmers in a non-Newtonian matrix is highlighted. Finally, recent findings concerning the turbulent-like behaviour in concentrated systems are described in detail.},
  doi={10.1039/9781839169465},
  journal={arXiv}
}

@article{paul2021active,
  title={Active Inference for Stochastic Control},
  author={Aswin Paul and Noor Sajid and Manoj Gopalkrishnan and Adeel Razi},
  year={2021},
  url={http://arxiv.org/abs/2108.12245v1},
  abstract={Active inference has emerged as an alternative approach to control problems given its intuitive (probabilistic) formalism. However, despite its theoretical utility, computational implementations have largely been restricted to low-dimensional, deterministic settings. This paper highlights that this is a consequence of the inability to adequately model stochastic transition dynamics, particularly when an extensive policy (i.e., action trajectory) space must be evaluated during planning. Fortunately, recent advancements propose a modified planning algorithm for finite temporal horizons. We build upon this work to assess the utility of active inference for a stochastic control setting. For this, we simulate the classic windy grid-world task with additional complexities, namely: 1) environment stochasticity; 2) learning of transition dynamics; and 3) partial observability. Our results demonstrate the advantage of using active inference, compared to reinforcement learning, in both deterministic and stochastic settings.},
  doi={10.1007/978-3-030-93736-2_47},
  journal={arXiv}
}

@article{silva2017behavior,
  title={The behavior of the spotless active regions during the solar minimum 23-24},
  author={Alexandre J. Oliveira e Silva and Caius L. Selhorst},
  year={2017},
  url={http://arxiv.org/abs/1703.00926v1},
  abstract={In this work, we analysed the physical parameters of the spotless actives regions observed during solar minimum 23 - 24 (2007 - 2010). The study was based on radio maps at 17~GHz obtained by the Nobeyama Radioheliograph (NoRH) and magnetograms provided by the Michelson Doppler Imager (MDI) on board the Solar and Heliospheric Observatory (SOHO). The results shows that the spotless active regions presents the same radio characteristics of a ordinary one, they can live in the solar surface for long periods (>10 days), and also can present small flares.},
  doi={10.1017/S1743921317004069},
  journal={arXiv}
}

@article{shin2021prior,
  title={Prior Preference Learning from Experts:Designing a Reward with Active Inference},
  author={Jin young Shin and Cheolhyeong Kim and Hyung Ju Hwang},
  year={2021},
  url={http://arxiv.org/abs/2101.08937v3},
  abstract={Active inference may be defined as Bayesian modeling of a brain with a biologically plausible model of the agent. Its primary idea relies on the free energy principle and the prior preference of the agent. An agent will choose an action that leads to its prior preference for a future observation. In this paper, we claim that active inference can be interpreted using reinforcement learning (RL) algorithms and find a theoretical connection between them. We extend the concept of expected free energy (EFE), which is a core quantity in active inference, and claim that EFE can be treated as a negative value function. Motivated by the concept of prior preference and a theoretical connection, we propose a simple but novel method for learning a prior preference from experts. This illustrates that the problem with inverse RL can be approached with a new perspective of active inference. Experimental results of prior preference learning show the possibility of active inference with EFE-based rewards and its application to an inverse RL problem.},
  journal={arXiv}
}

@article{gonen2012efficient,
  title={Efficient Active Learning of Halfspaces: an Aggressive Approach},
  author={Alon Gonen and Sivan Sabato and Shai Shalev-Shwartz},
  year={2012},
  url={http://arxiv.org/abs/1208.3561v3},
  abstract={We study pool-based active learning of half-spaces. We revisit the aggressive approach for active learning in the realizable case, and show that it can be made efficient and practical, while also having theoretical guarantees under reasonable assumptions. We further show, both theoretically and experimentally, that it can be preferable to mellow approaches. Our efficient aggressive active learner of half-spaces has formal approximation guarantees that hold when the pool is separable with a margin. While our analysis is focused on the realizable setting, we show that a simple heuristic allows using the same algorithm successfully for pools with low error as well. We further compare the aggressive approach to the mellow approach, and prove that there are cases in which the aggressive approach results in significantly better label complexity compared to the mellow approach. We demonstrate experimentally that substantial improvements in label complexity can be achieved using the aggressive approach, for both realizable and low-error settings.},
  journal={arXiv}
}

@article{schneider2022active,
  title={Active Inference for Robotic Manipulation},
  author={Tim Schneider and Boris Belousov and Hany Abdulsamad and Jan Peters},
  year={2022},
  url={http://arxiv.org/abs/2206.10313v1},
  abstract={Robotic manipulation stands as a largely unsolved problem despite significant advances in robotics and machine learning in the last decades. One of the central challenges of manipulation is partial observability, as the agent usually does not know all physical properties of the environment and the objects it is manipulating in advance. A recently emerging theory that deals with partial observability in an explicit manner is Active Inference. It does so by driving the agent to act in a way that is not only goal-directed but also informative about the environment. In this work, we apply Active Inference to a hard-to-explore simulated robotic manipulation tasks, in which the agent has to balance a ball into a target zone. Since the reward of this task is sparse, in order to explore this environment, the agent has to learn to balance the ball without any extrinsic feedback, purely driven by its own curiosity. We show that the information-seeking behavior induced by Active Inference allows the agent to explore these challenging, sparse environments systematically. Finally, we conclude that using an information-seeking objective is beneficial in sparse environments and allows the agent to solve tasks in which methods that do not exhibit directed exploration fail.},
  journal={arXiv}
}

@article{adam2017structured,
  title={Structured Variational Inference for Coupled Gaussian Processes},
  author={Vincent Adam},
  year={2017},
  url={http://arxiv.org/abs/1711.01131v2},
  abstract={Sparse variational approximations allow for principled and scalable inference in Gaussian Process (GP) models. In settings where several GPs are part of the generative model, theses GPs are a posteriori coupled. For many applications such as regression where predictive accuracy is the quantity of interest, this coupling is not crucial. Howewer if one is interested in posterior uncertainty, it cannot be ignored. A key element of variational inference schemes is the choice of the approximate posterior parameterization. When the number of latent variables is large, mean field (MF) methods provide fast and accurate posterior means while more structured posterior lead to inference algorithm of greater computational complexity. Here, we extend previous sparse GP approximations and propose a novel parameterization of variational posteriors in the multi-GP setting allowing for fast and scalable inference capturing posterior dependencies.},
  journal={arXiv}
}

@article{li2025normalizing,
  title={Normalizing Flow Regression for Bayesian Inference with Offline Likelihood Evaluations},
  author={Chengkun Li and Bobby Huggins and Petrus Mikkola and Luigi Acerbi},
  year={2025},
  url={http://arxiv.org/abs/2504.11554v1},
  abstract={Bayesian inference with computationally expensive likelihood evaluations remains a significant challenge in many scientific domains. We propose normalizing flow regression (NFR), a novel offline inference method for approximating posterior distributions. Unlike traditional surrogate approaches that require additional sampling or inference steps, NFR directly yields a tractable posterior approximation through regression on existing log-density evaluations. We introduce training techniques specifically for flow regression, such as tailored priors and likelihood functions, to achieve robust posterior and model evidence estimation. We demonstrate NFR's effectiveness on synthetic benchmarks and real-world applications from neuroscience and biology, showing superior or comparable performance to existing methods. NFR represents a promising approach for Bayesian inference when standard methods are computationally prohibitive or existing model evaluations can be recycled.},
  journal={arXiv}
}

@article{sajid2021active,
  title={Active inference, Bayesian optimal design, and expected utility},
  author={Noor Sajid and Lancelot Da Costa and Thomas Parr and Karl Friston},
  year={2021},
  url={http://arxiv.org/abs/2110.04074v1},
  abstract={Active inference, a corollary of the free energy principle, is a formal way of describing the behavior of certain kinds of random dynamical systems that have the appearance of sentience. In this chapter, we describe how active inference combines Bayesian decision theory and optimal Bayesian design principles under a single imperative to minimize expected free energy. It is this aspect of active inference that allows for the natural emergence of information-seeking behavior. When removing prior outcomes preferences from expected free energy, active inference reduces to optimal Bayesian design, i.e., information gain maximization. Conversely, active inference reduces to Bayesian decision theory in the absence of ambiguity and relative risk, i.e., expected utility maximization. Using these limiting cases, we illustrate how behaviors differ when agents select actions that optimize expected utility, expected information gain, and expected free energy. Our T-maze simulations show optimizing expected free energy produces goal-directed information-seeking behavior while optimizing expected utility induces purely exploitive behavior and maximizing information gain engenders intrinsically motivated behavior.},
  journal={arXiv}
}

@article{colonhernandez2023adversarial,
  title={Adversarial Transformer Language Models for Contextual Commonsense Inference},
  author={Pedro Colon-Hernandez and Henry Lieberman and Yida Xin and Claire Yin and Cynthia Breazeal and Peter Chin},
  year={2023},
  url={http://arxiv.org/abs/2302.05406v1},
  abstract={Contextualized or discourse aware commonsense inference is the task of generating coherent commonsense assertions (i.e., facts) from a given story, and a particular sentence from that story. Some problems with the task are: lack of controllability for topics of the inferred facts; lack of commonsense knowledge during training; and, possibly, hallucinated or false facts. In this work, we utilize a transformer model for this task and develop techniques to address the aforementioned problems in the task. We control the inference by introducing a new technique we call "hinting". Hinting is a kind of language model prompting, that utilizes both hard prompts (specific words) and soft prompts (virtual learnable templates). This serves as a control signal to advise the language model "what to talk about". Next, we establish a methodology for performing joint inference with multiple commonsense knowledge bases. Joint inference of commonsense requires care, because it is imprecise and the level of generality is more flexible. You want to be sure that the results "still make sense" for the context. To this end, we align the textual version of assertions from three knowledge graphs (ConceptNet, ATOMIC2020, and GLUCOSE) with a story and a target sentence. This combination allows us to train a single model to perform joint inference with multiple knowledge graphs. We show experimental results for the three knowledge graphs on joint inference. Our final contribution is exploring a GAN architecture that generates the contextualized commonsense assertions and scores them as to their plausibility through a discriminator. The result is an integrated system for contextual commonsense inference in stories, that can controllably generate plausible commonsense assertions, and takes advantage of joint inference between multiple commonsense knowledge bases.},
  journal={arXiv}
}

@article{dan2018comparative,
  title={A Comparative Study: Adaptive Fuzzy Inference Systems for Energy Prediction in Urban Buildings},
  author={Mainak Dan and Seshadhri Srinivasan},
  year={2018},
  url={http://arxiv.org/abs/1809.08860v1},
  abstract={This investigation aims to study different adaptive fuzzy inference algorithms capable of real-time sequential learning and prediction of time-series data. A brief qualitative description of these algorithms namely meta-cognitive fuzzy inference system (McFIS), sequential adaptive fuzzy inference system (SAFIS) and evolving Takagi-Sugeno (ETS) model provide a comprehensive comparison of their working principle, especially their unique characteristics are discussed. These algorithms are then simulated with dataset collected at one of the academic buildings at Nanyang Technological University, Singapore. The performance are compared by means of the root mean squared error (RMSE) and non-destructive error index (NDEI) of the predicted output. Analysis shows that McFIS shows promising results either with lower RMSE and NDEI or with lower architectural complexity over ETS and SAFIS. Statistical Analysis also reveals the significance of the outcome of these algorithms.},
  journal={arXiv}
}

@article{huggins2019validated,
  title={Validated Variational Inference via Practical Posterior Error Bounds},
  author={Jonathan H. Huggins and Mikołaj Kasprzak and Trevor Campbell and Tamara Broderick},
  year={2019},
  url={http://arxiv.org/abs/1910.04102v4},
  abstract={Variational inference has become an increasingly attractive fast alternative to Markov chain Monte Carlo methods for approximate Bayesian inference. However, a major obstacle to the widespread use of variational methods is the lack of post-hoc accuracy measures that are both theoretically justified and computationally efficient. In this paper, we provide rigorous bounds on the error of posterior mean and uncertainty estimates that arise from full-distribution approximations, as in variational inference. Our bounds are widely applicable, as they require only that the approximating and exact posteriors have polynomial moments. Our bounds are also computationally efficient for variational inference because they require only standard values from variational objectives, straightforward analytic calculations, and simple Monte Carlo estimates. We show that our analysis naturally leads to a new and improved workflow for validated variational inference. Finally, we demonstrate the utility of our proposed workflow and error bounds on a robust regression problem and on a real-data example with a widely used multilevel hierarchical model.},
  journal={arXiv}
}

@article{costa2020active,
  title={Active inference on discrete state-spaces: a synthesis},
  author={Lancelot Da Costa and Thomas Parr and Noor Sajid and Sebastijan Veselic and Victorita Neacsu and Karl Friston},
  year={2020},
  url={http://arxiv.org/abs/2001.07203v2},
  abstract={Active inference is a normative principle underwriting perception, action, planning, decision-making and learning in biological or artificial agents. From its inception, its associated process theory has grown to incorporate complex generative models, enabling simulation of a wide range of complex behaviours. Due to successive developments in active inference, it is often difficult to see how its underlying principle relates to process theories and practical implementation. In this paper, we try to bridge this gap by providing a complete mathematical synthesis of active inference on discrete state-space models. This technical summary provides an overview of the theory, derives neuronal dynamics from first principles and relates this dynamics to biological processes. Furthermore, this paper provides a fundamental building block needed to understand active inference for mixed generative models; allowing continuous sensations to inform discrete representations. This paper may be used as follows: to guide research towards outstanding challenges, a practical guide on how to implement active inference to simulate experimental behaviour, or a pointer towards various in-silico neurophysiological responses that may be used to make empirical predictions.},
  doi={10.1016/j.jmp.2020.102447},
  journal={arXiv}
}

@article{baioumy2022unbiased,
  title={Unbiased Active Inference for Classical Control},
  author={Mohamed Baioumy and Corrado Pezzato and Riccardo Ferrari and Nick Hawes},
  year={2022},
  url={http://arxiv.org/abs/2207.13409v1},
  abstract={Active inference is a mathematical framework that originated in computational neuroscience. Recently, it has been demonstrated as a promising approach for constructing goal-driven behavior in robotics. Specifically, the active inference controller (AIC) has been successful on several continuous control and state-estimation tasks. Despite its relative success, some established design choices lead to a number of practical limitations for robot control. These include having a biased estimate of the state, and only an implicit model of control actions. In this paper, we highlight these limitations and propose an extended version of the unbiased active inference controller (u-AIC). The u-AIC maintains all the compelling benefits of the AIC and removes its limitations. Simulation results on a 2-DOF arm and experiments on a real 7-DOF manipulator show the improved performance of the u-AIC with respect to the standard AIC. The code can be found at https://github.com/cpezzato/unbiased_aic.},
  journal={arXiv}
}

@article{mauas2017solar,
  title={Solar activity forcing of terrestrial hydrological phenomena},
  author={P. J. D. Mauas and A. P. Buccino and E. Flamenco},
  year={2017},
  url={http://arxiv.org/abs/1709.09170v2},
  abstract={Recently, the study of the influence of solar activity on the Earth's climate received strong attention, mainly due to the possibility, proposed by several authors, that global warming is not anthropogenic, but is due to an increase in solar activity. Although this possibility has been ruled out, there are strong evidences that solar variability has an influence on Earth's climate, in regional scales.   Here we review some of these evidences, focusing in a particular aspect of climate: atmospheric moisture and related quantities like precipitation. In particular, we studied the influence of activity on South American precipitations during centuries. First, we analyzed the stream flow of the Paraná and other rivers of the region, and found a very strong correlation with Sunspot Number in decadal time scales. We found a similar correlation between Sunspot Number and tree-ring chronologies, which allows us to extend our study to cover the last two centuries.},
  doi={10.1017/S1743921317003933},
  journal={arXiv}
}

@article{miller2020efficient,
  title={Efficient Graph-Based Active Learning with Probit Likelihood via Gaussian Approximations},
  author={Kevin Miller and Hao Li and Andrea L. Bertozzi},
  year={2020},
  url={http://arxiv.org/abs/2007.11126v1},
  abstract={We present a novel adaptation of active learning to graph-based semi-supervised learning (SSL) under non-Gaussian Bayesian models. We present an approximation of non-Gaussian distributions to adapt previously Gaussian-based acquisition functions to these more general cases. We develop an efficient rank-one update for applying "look-ahead" based methods as well as model retraining. We also introduce a novel "model change" acquisition function based on these approximations that further expands the available collection of active learning acquisition functions for such methods.},
  journal={arXiv}
}

@article{diolatzis2022active,
  title={Active Exploration for Neural Global Illumination of Variable Scenes},
  author={Stavros Diolatzis and Julien Philip and George Drettakis},
  year={2022},
  url={http://arxiv.org/abs/2203.08272v1},
  abstract={Neural rendering algorithms introduce a fundamentally new approach for photorealistic rendering, typically by learning a neural representation of illumination on large numbers of ground truth images. When training for a given variable scene, i.e., changing objects, materials, lights and viewpoint, the space D of possible training data instances quickly becomes unmanageable as the dimensions of variable parameters increase. We introduce a novel Active Exploration method using Markov Chain Monte Carlo, which explores D, generating samples (i.e., ground truth renderings) that best help training and interleaves training and on-the-fly sample data generation. We introduce a self-tuning sample reuse strategy to minimize the expensive step of rendering training samples. We apply our approach on a neural generator that learns to render novel scene instances given an explicit parameterization of the scene configuration. Our results show that Active Exploration trains our network much more efficiently than uniformly sampling, and together with our resolution enhancement approach, achieves better quality than uniform sampling at convergence. Our method allows interactive rendering of hard light transport paths (e.g., complex caustics) -- that require very high samples counts to be captured -- and provides dynamic scene navigation and manipulation, after training for 5-18 hours depending on required quality and variations.},
  journal={arXiv}
}

@article{whyte2024minimal,
  title={On the Minimal Theory of Consciousness Implicit in Active Inference},
  author={Christopher J. Whyte and Andrew W. Corcoran and Jonathan Robinson and Ryan Smith and Rosalyn J. Moran and Thomas Parr and Karl J. Friston and Anil K. Seth and Jakob Hohwy},
  year={2024},
  url={http://arxiv.org/abs/2410.06633v2},
  abstract={The multifaceted nature of subjective experience poses a challenge to the study of consciousness. Traditional neuroscientific approaches often concentrate on isolated facets, such as perceptual awareness or the global state of consciousness and construct a theory around the relevant empirical paradigms and findings. Theories of consciousness are, therefore, often difficult to compare; indeed, there might be little overlap in the phenomena such theories aim to explain. Here, we take a different approach: starting with active inference, a first principles framework for modelling behaviour as (approximate) Bayesian inference, and building up to a minimal theory of consciousness, which emerges from the shared features of computational models derived under active inference. We review a body of work applying active inference models to the study of consciousness and argue that there is implicit in all these models a small set of theoretical commitments that point to a minimal (and testable) theory of consciousness.},
  journal={arXiv}
}

@article{tschantz2020reinforcement,
  title={Reinforcement Learning through Active Inference},
  author={Alexander Tschantz and Beren Millidge and Anil K. Seth and Christopher L. Buckley},
  year={2020},
  url={http://arxiv.org/abs/2002.12636v1},
  abstract={The central tenet of reinforcement learning (RL) is that agents seek to maximize the sum of cumulative rewards. In contrast, active inference, an emerging framework within cognitive and computational neuroscience, proposes that agents act to maximize the evidence for a biased generative model. Here, we illustrate how ideas from active inference can augment traditional RL approaches by (i) furnishing an inherent balance of exploration and exploitation, and (ii) providing a more flexible conceptualization of reward. Inspired by active inference, we develop and implement a novel objective for decision making, which we term the free energy of the expected future. We demonstrate that the resulting algorithm successfully balances exploration and exploitation, simultaneously achieving robust performance on several challenging RL benchmarks with sparse, well-shaped, and no rewards.},
  journal={arXiv}
}

@article{kosovichev2024subsurface,
  title={Subsurface Flows Associated with Formation and Flaring Activity of Solar Active Regions},
  author={Alexander G. Kosovichev and Viacheslav M. Sadykov},
  year={2024},
  url={http://arxiv.org/abs/2401.17598v1},
  abstract={We investigate the evolution of subsurface flows during the emergence and the active phase of sunspot regions using the time-distance helioseismology analysis of the full-disk Dopplergrams from the Helioseismic and Magnetic Imager (HMI) onboard the Solar Dynamics Observatory (SDO). We present an analysis of emerging active regions of various types, including delta-type active regions and regions with the reverse polarity order (`anti-Hale active regions'). The results reveal strong vortical and shearing flows during the emergence of magnetic flux, as well as the process of formation of large-scale converging flow patterns around developing active regions, predominantly in the top 6 Mm deep layers of the convection zone. Our analysis revealed a significant correlation between the flow divergence and helicity in the active regions with their flaring activity, indicating that measuring characteristics of subsurface flows can contribute to flare forecasting.},
  doi={10.1017/S1743921324000991},
  journal={arXiv}
}

@article{li2008dust,
  title={Dust in Active Galactic Nuclei},
  author={Aigen Li},
  year={2008},
  url={http://arxiv.org/abs/0808.4117v1},
  abstract={Dust plays an essential role in the unification theory of active galactic nuclei (AGNs). This review summarizes our current understanding of the extinction and infrared emission properties of the circumnuclear dust in AGNs as well as the inferred dust composition and size distribution.},
  journal={arXiv}
}

@article{bodin2017nonparametric,
  title={Nonparametric Inference for Auto-Encoding Variational Bayes},
  author={Erik Bodin and Iman Malik and Carl Henrik Ek and Neill D. F. Campbell},
  year={2017},
  url={http://arxiv.org/abs/1712.06536v1},
  abstract={We would like to learn latent representations that are low-dimensional and highly interpretable. A model that has these characteristics is the Gaussian Process Latent Variable Model. The benefits and negative of the GP-LVM are complementary to the Variational Autoencoder, the former provides interpretable low-dimensional latent representations while the latter is able to handle large amounts of data and can use non-Gaussian likelihoods. Our inspiration for this paper is to marry these two approaches and reap the benefits of both. In order to do so we will introduce a novel approximate inference scheme inspired by the GP-LVM and the VAE. We show experimentally that the approximation allows the capacity of the generative bottle-neck (Z) of the VAE to be arbitrarily large without losing a highly interpretable representation, allowing reconstruction quality to be unlimited by Z at the same time as a low-dimensional space can be used to perform ancestral sampling from as well as a means to reason about the embedded data.},
  journal={arXiv}
}

@article{bartolomei2024active,
  title={Active Stereo in the Wild through Virtual Pattern Projection},
  author={Luca Bartolomei and Matteo Poggi and Fabio Tosi and Andrea Conti and Stefano Mattoccia},
  year={2024},
  url={http://arxiv.org/abs/2406.04345v2},
  abstract={This paper presents a novel general-purpose guided stereo paradigm that mimics the active stereo principle by replacing the unreliable physical pattern projector with a depth sensor. It works by projecting virtual patterns consistent with the scene geometry onto the left and right images acquired by a conventional stereo camera, using the sparse hints obtained from a depth sensor, to facilitate the visual correspondence. Purposely, any depth sensing device can be seamlessly plugged into our framework, enabling the deployment of a virtual active stereo setup in any possible environment and overcoming the severe limitations of physical pattern projection, such as the limited working range and environmental conditions. Exhaustive experiments on indoor and outdoor datasets featuring both long and close range, including those providing raw, unfiltered depth hints from off-the-shelf depth sensors, highlight the effectiveness of our approach in notably boosting the robustness and accuracy of algorithms and deep stereo without any code modification and even without re-training. Additionally, we assess the performance of our strategy on active stereo evaluation datasets with conventional pattern projection. Indeed, in all these scenarios, our virtual pattern projection paradigm achieves state-of-the-art performance. The source code is available at: https://github.com/bartn8/vppstereo.},
  journal={arXiv}
}

@article{baltieri2017active,
  title={An active inference implementation of phototaxis},
  author={Manuel Baltieri and Christopher L. Buckley},
  year={2017},
  url={http://arxiv.org/abs/1707.01806v1},
  abstract={Active inference is emerging as a possible unifying theory of perception and action in cognitive and computational neuroscience. On this theory, perception is a process of inferring the causes of sensory data by minimising the error between actual sensations and those predicted by an inner \emph{generative} (probabilistic) model. Action on the other hand is drawn as a process that modifies the world such that the consequent sensory input meets expectations encoded in the same internal model. These two processes, inferring properties of the world and inferring actions needed to meet expectations, close the sensory/motor loop and suggest a deep symmetry between action and perception. In this work we present a simple agent-based model inspired by this new theory that offers insights on some of its central ideas. Previous implementations of active inference have typically examined a "perception-oriented" view of this theory, assuming that agents are endowed with a detailed generative model of their surrounding environment. In contrast, we present an "action-oriented" solution showing how adaptive behaviour can emerge even when agents operate with a simple model which bears little resemblance to their environment. We examine how various parameters of this formulation allow phototaxis and present an example of a different, "pathological" behaviour.},
  doi={10.1162/isal_a_011},
  journal={arXiv}
}

@article{priorelli2023modeling,
  title={Modeling motor control in continuous-time Active Inference: a survey},
  author={Matteo Priorelli and Federico Maggiore and Antonella Maselli and Francesco Donnarumma and Domenico Maisto and Francesco Mannella and Ivilin Peev Stoianov and Giovanni Pezzulo},
  year={2023},
  url={http://arxiv.org/abs/2310.05144v1},
  abstract={The way the brain selects and controls actions is still widely debated. Mainstream approaches based on Optimal Control focus on stimulus-response mappings that optimize cost functions. Ideomotor theory and cybernetics propose a different perspective: they suggest that actions are selected and controlled by activating action effects and by continuously matching internal predictions with sensations. Active Inference offers a modern formulation of these ideas, in terms of inferential mechanisms and prediction-error-based control, which can be linked to neural mechanisms of living organisms. This article provides a technical illustration of Active Inference models in continuous time and a brief survey of Active Inference models that solve four kinds of control problems; namely, the control of goal-directed reaching movements, active sensing, the resolution of multisensory conflict during movement and the integration of decision-making and motor control. Crucially, in Active Inference, all these different facets of motor control emerge from the same optimization process - namely, the minimization of Free Energy - and do not require designing separate cost functions. Therefore, Active Inference provides a unitary perspective on various aspects of motor control that can inform both the study of biological control mechanisms and the design of artificial and robotic systems.},
  doi={10.1109/TCDS.2023.3338491},
  journal={arXiv}
}

@article{yeganeh2024active,
  title={Active Inference Meeting Energy-Efficient Control of Parallel and Identical Machines},
  author={Yavar Taheri Yeganeh and Mohsen Jafari and Andrea Matta},
  year={2024},
  url={http://arxiv.org/abs/2406.09322v2},
  abstract={We investigate the application of active inference in developing energy-efficient control agents for manufacturing systems. Active inference, rooted in neuroscience, provides a unified probabilistic framework integrating perception, learning, and action, with inherent uncertainty quantification elements. Our study explores deep active inference, an emerging field that combines deep learning with the active inference decision-making framework. Leveraging a deep active inference agent, we focus on controlling parallel and identical machine workstations to enhance energy efficiency. We address challenges posed by the problem's stochastic nature and delayed policy response by introducing tailored enhancements to existing agent architectures. Specifically, we introduce multi-step transition and hybrid horizon methods to mitigate the need for complex planning. Our experimental results demonstrate the effectiveness of these enhancements and highlight the potential of the active inference-based approach.},
  doi={10.1007/978-3-031-82481-4_33},
  journal={arXiv}
}

@article{schachtsiek2023class,
  title={Class Balanced Dynamic Acquisition for Domain Adaptive Semantic Segmentation using Active Learning},
  author={Marc Schachtsiek and Simone Rossi and Thomas Hannagan},
  year={2023},
  url={http://arxiv.org/abs/2311.14146v1},
  abstract={Domain adaptive active learning is leading the charge in label-efficient training of neural networks. For semantic segmentation, state-of-the-art models jointly use two criteria of uncertainty and diversity to select training labels, combined with a pixel-wise acquisition strategy. However, we show that such methods currently suffer from a class imbalance issue which degrades their performance for larger active learning budgets. We then introduce Class Balanced Dynamic Acquisition (CBDA), a novel active learning method that mitigates this issue, especially in high-budget regimes. The more balanced labels increase minority class performance, which in turn allows the model to outperform the previous baseline by 0.6, 1.7, and 2.4 mIoU for budgets of 5%, 10%, and 20%, respectively. Additionally, the focus on minority classes leads to improvements of the minimum class performance of 0.5, 2.9, and 4.6 IoU respectively. The top-performing model even exceeds the fully supervised baseline, showing that a more balanced label than the entire ground truth can be beneficial.},
  journal={arXiv}
}

@article{thomas2025cascade,
  title={Cascade: Token-Sharded Private LLM Inference},
  author={Rahul Thomas and Louai Zahran and Erica Choi and Akilesh Potti and Micah Goldblum and Arka Pal},
  year={2025},
  url={http://arxiv.org/abs/2507.05228v1},
  abstract={As LLMs continue to increase in parameter size, the computational resources required to run them are available to fewer parties. Therefore, third-party inference services -- where LLMs are hosted by third parties with significant computational resources -- are becoming increasingly popular. However, third party inference raises critical concerns about user data privacy. To mitigate these risks, privacy researchers have developed provably secure schemes for third-party inference, such as Secure Multi-Party Computation (SMPC). However, SMPC protocols have significant computational and communication overhead, and do not scale to large models. In this work, we propose a new multi-party inference protocol, Cascade, that avoids these punitive costs by leveraging sharding in the sequence dimension to maintain privacy, trading off cryptographic privacy guarantees for increased performance and scalability. We demonstrate that Cascade is resistant to a generalization of a recent attack that is highly effective against other statistical privacy schemes, and that it is further resistant to learning-based attacks. As Cascade is orders of magnitude faster than existing schemes, our findings offer practical solutions for secure deployment of modern state-of-the-art LLMs.},
  journal={arXiv}
}

@article{gondhalekar2024convolutional,
  title={Convolutional Vision Transformer for Cosmology Parameter Inference},
  author={Yash Gondhalekar and Kana Moriwaki},
  year={2024},
  url={http://arxiv.org/abs/2411.14392v2},
  abstract={Parameter inference is a crucial task in modern cosmology that requires accurate and fast computational methods to handle the high precision and volume of observational datasets. In this study, we explore a hybrid vision transformer, the Convolution vision Transformer (CvT), which combines the benefits of vision transformers (ViTs) and convolutional neural networks (CNNs). We use this approach to infer the $Ω_m$ and $σ_8$ cosmological parameters from simulated dark matter and halo fields. Our experiments indicate that the constraints on $Ω_m$ and $σ_8$ obtained using CvT are better than ViT and CNN, using either dark matter or halo fields. For CvT, pretraining on dark matter fields proves advantageous for improving constraints using halo fields compared to training a model from the beginning. However, ViT and CNN do not show these benefits. The CvT is more efficient than ViT since, despite having more parameters, it requires a training time similar to that of ViT and has similar inference times. The code is available at \url{https://github.com/Yash-10/cvt-cosmo-inference/}.},
  journal={arXiv}
}

@article{bennett2022inference,
  title={Inference on Strongly Identified Functionals of Weakly Identified Functions},
  author={Andrew Bennett and Nathan Kallus and Xiaojie Mao and Whitney Newey and Vasilis Syrgkanis and Masatoshi Uehara},
  year={2022},
  url={http://arxiv.org/abs/2208.08291v3},
  abstract={In a variety of applications, including nonparametric instrumental variable (NPIV) analysis, proximal causal inference under unmeasured confounding, and missing-not-at-random data with shadow variables, we are interested in inference on a continuous linear functional (e.g., average causal effects) of nuisance function (e.g., NPIV regression) defined by conditional moment restrictions. These nuisance functions are generally weakly identified, in that the conditional moment restrictions can be severely ill-posed as well as admit multiple solutions. This is sometimes resolved by imposing strong conditions that imply the function can be estimated at rates that make inference on the functional possible. In this paper, we study a novel condition for the functional to be strongly identified even when the nuisance function is not; that is, the functional is amenable to asymptotically-normal estimation at $\sqrt{n}$-rates. The condition implies the existence of debiasing nuisance functions, and we propose penalized minimax estimators for both the primary and debiasing nuisance functions. The proposed nuisance estimators can accommodate flexible function classes, and importantly they can converge to fixed limits determined by the penalization regardless of the identifiability of the nuisances. We use the penalized nuisance estimators to form a debiased estimator for the functional of interest and prove its asymptotic normality under generic high-level conditions, which provide for asymptotically valid confidence intervals. We also illustrate our method in a novel partially linear proximal causal inference problem and a partially linear instrumental variable regression problem.},
  journal={arXiv}
}

@article{malialis2022data,
  title={Data augmentation on-the-fly and active learning in data stream classification},
  author={Kleanthis Malialis and Dimitris Papatheodoulou and Stylianos Filippou and Christos G. Panayiotou and Marios M. Polycarpou},
  year={2022},
  url={http://arxiv.org/abs/2210.06873v1},
  abstract={There is an emerging need for predictive models to be trained on-the-fly, since in numerous machine learning applications data are arriving in an online fashion. A critical challenge encountered is that of limited availability of ground truth information (e.g., labels in classification tasks) as new data are observed one-by-one online, while another significant challenge is that of class imbalance. This work introduces the novel Augmented Queues method, which addresses the dual-problem by combining in a synergistic manner online active learning, data augmentation, and a multi-queue memory to maintain separate and balanced queues for each class. We perform an extensive experimental study using image and time-series augmentations, in which we examine the roles of the active learning budget, memory size, imbalance level, and neural network type. We demonstrate two major advantages of Augmented Queues. First, it does not reserve additional memory space as the generation of synthetic data occurs only at training times. Second, learning models have access to more labelled data without the need to increase the active learning budget and / or the original memory size. Learning on-the-fly poses major challenges which, typically, hinder the deployment of learning models. Augmented Queues significantly improves the performance in terms of learning quality and speed. Our code is made publicly available.},
  doi={10.1109/SSCI51031.2022.10022133},
  journal={arXiv}
}

@article{cugliandolo2018phases,
  title={Phases of active matter in two dimensions},
  author={Leticia F. Cugliandolo and Giuseppe Gonnella},
  year={2018},
  url={http://arxiv.org/abs/1810.11833v1},
  abstract={These notes focus on the description of the phases of matter in two dimensions. Firstly, we present a brief discussion of the phase diagrams of bidimensional interacting passive systems, and their numerical and experimental measurements. The presentation will be short and schematic. We will complement these notes with a rather complete bibliography that should guide the students in their study of the development of this very rich subject over the last century. Secondly, we summarise very recent results on the phase diagrams of active Brownian disks and active dumbbell systems in two dimensions. The idea is to identify all the phases and to relate, when this is possible, the ones found in the passive limit with the ones observed at large values of the activity, at high and low densities, and for both types of constituents. Proposals for the mechanisms leading to these phases will be discussed. The physics of bidimensional active systems open many questions, some of which will be listed by the end of the Chapter.},
  journal={arXiv}
}

@article{kulveit2023predictive,
  title={Predictive Minds: LLMs As Atypical Active Inference Agents},
  author={Jan Kulveit and Clem von Stengel and Roman Leventov},
  year={2023},
  url={http://arxiv.org/abs/2311.10215v1},
  abstract={Large language models (LLMs) like GPT are often conceptualized as passive predictors, simulators, or even stochastic parrots. We instead conceptualize LLMs by drawing on the theory of active inference originating in cognitive science and neuroscience. We examine similarities and differences between traditional active inference systems and LLMs, leading to the conclusion that, currently, LLMs lack a tight feedback loop between acting in the world and perceiving the impacts of their actions, but otherwise fit in the active inference paradigm. We list reasons why this loop may soon be closed, and possible consequences of this including enhanced model self-awareness and the drive to minimize prediction error by changing the world.},
  journal={arXiv}
}

@article{moosavi2024valid,
  title={Valid causal inference with unobserved confounding in high-dimensional settings},
  author={Niloofar Moosavi and Tetiana Gorbach and Xavier de Luna},
  year={2024},
  url={http://arxiv.org/abs/2401.06564v1},
  abstract={Various methods have recently been proposed to estimate causal effects with confidence intervals that are uniformly valid over a set of data generating processes when high-dimensional nuisance models are estimated by post-model-selection or machine learning estimators. These methods typically require that all the confounders are observed to ensure identification of the effects. We contribute by showing how valid semiparametric inference can be obtained in the presence of unobserved confounders and high-dimensional nuisance models. We propose uncertainty intervals which allow for unobserved confounding, and show that the resulting inference is valid when the amount of unobserved confounding is small relative to the sample size; the latter is formalized in terms of convergence rates. Simulation experiments illustrate the finite sample properties of the proposed intervals and investigate an alternative procedure that improves the empirical coverage of the intervals when the amount of unobserved confounding is large. Finally, a case study on the effect of smoking during pregnancy on birth weight is used to illustrate the use of the methods introduced to perform a sensitivity analysis to unobserved confounding.},
  doi={10.1515/jci-2023-0069},
  journal={arXiv}
}

@article{zhi2021active,
  title={Active RIS Versus Passive RIS: Which Is Superior with the Same Power Budget?},
  author={Kangda Zhi and Cunhua Pan and Hong Ren and Kok Keong Chai and Maged Elkashlan},
  year={2021},
  url={http://arxiv.org/abs/2112.07510v1},
  abstract={This letter theoretically compares the active reconfigurable intelligent surface (RIS)-aided system with the passive RIS-aided system. For fair comparison, we consider that these two systems have the same overall power budget that can be used at both the base station (BS) and the RIS. For active RIS, we first derive the optimal power allocation between the BS's transmit signal power and RIS's output signal power. We also analyze the impact of various system parameters on the optimal power allocation ratio. Then, we compare the performance between the active RIS and the passive RIS, which demonstrates that the active RIS would be superior if the power budget is not very small and the number of RIS elements is not very large.},
  journal={arXiv}
}

@article{nazabal2022inference,
  title={Inference and Learning for Generative Capsule Models},
  author={Alfredo Nazabal and Nikolaos Tsagkas and Christopher K. I. Williams},
  year={2022},
  url={http://arxiv.org/abs/2209.03115v2},
  abstract={Capsule networks (see e.g. Hinton et al., 2018) aim to encode knowledge of and reason about the relationship between an object and its parts. In this paper we specify a generative model for such data, and derive a variational algorithm for inferring the transformation of each model object in a scene, and the assignments of observed parts to the objects. We derive a learning algorithm for the object models, based on variational expectation maximization (Jordan et al., 1999). We also study an alternative inference algorithm based on the RANSAC method of Fischler and Bolles (1981). We apply these inference methods to (i) data generated from multiple geometric objects like squares and triangles ("constellations"), and (ii) data from a parts-based model of faces. Recent work by Kosiorek et al. (2019) has used amortized inference via stacked capsule autoencoders (SCAEs) to tackle this problem -- our results show that we significantly outperform them where we can make comparisons (on the constellations data).},
  doi={10.1162/neco_a_01564},
  journal={arXiv}
}

@article{gusmão2017analysis,
  title={Analysis Of Kepler-71 Activity Through Planetary Transit},
  author={Eber A. Gusmão and Caius L. Selhorst and Alexandre S. Oliveira},
  year={2017},
  url={http://arxiv.org/abs/1703.00883v1},
  abstract={An exoplanet transiting in front of the disk of its parent star may hide a dark starspot causing a detectable change in the light curve, that allows to infer physical characteristics of the spot such as size and intensity. We have analysed the Kepler Space Telescope observations of the star Kepler-71 in order to search for variabilities in 28 transit light curves. Kepler-71 is a star with 0.923Ms and 0.816Rs orbited by the hot Jupiter planet Kepler-71b with radius of 1.0452RJ. The physical parameters of the starspots are determined by fitting the data with a model that simulates planetary transits and enables the inclusion of spots on the stellar surface with different sizes, intensities, and positions. The results show that Kepler-71 is a very active star, with several spot detections, with a mean value of 6 spots per transit with size 0.6Rp and 0.5 Ic, as a function of stellar intensity at disk center (maximum value).},
  doi={10.1017/S1743921317004057},
  journal={arXiv}
}

@article{ding2017bridging,
  title={Bridging Finite and Super Population Causal Inference},
  author={Peng Ding and Xinran Li and Luke W. Miratrix},
  year={2017},
  url={http://arxiv.org/abs/1702.08615v1},
  abstract={There are two general views in causal analysis of experimental data: the super population view that the units are an independent sample from some hypothetical infinite populations, and the finite population view that the potential outcomes of the experimental units are fixed and the randomness comes solely from the physical randomization of the treatment assignment. These two views differs conceptually and mathematically, resulting in different sampling variances of the usual difference-in-means estimator of the average causal effect. Practically, however, these two views result in identical variance estimators. By recalling a variance decomposition and exploiting a completeness-type argument, we establish a connection between these two views in completely randomized experiments. This alternative formulation could serve as a template for bridging finite and super population causal inference in other scenarios.},
  journal={arXiv}
}

@article{oostrum2024concise,
  title={A Concise Mathematical Description of Active Inference in Discrete Time},
  author={Jesse van Oostrum and Carlotta Langer and Nihat Ay},
  year={2024},
  url={http://arxiv.org/abs/2406.07726v4},
  abstract={In this paper we present a concise mathematical description of active inference in discrete time. The main part of the paper serves as a basic introduction to the topic, including a detailed example of the action selection mechanism. The appendix discusses the more subtle mathematical details, targeting readers who have already studied the active inference literature but struggle to make sense of the mathematical details and derivations. Throughout, we emphasize precise and standard mathematical notation, ensuring consistency with existing texts and linking all equations to widely used references on active inference. Additionally, we provide Python code that implements the action selection and learning mechanisms described in this paper and is compatible with pymdp environments.},
  doi={10.1016/j.jmp.2025.102921},
  journal={arXiv}
}

@article{naseh2025riddle,
  title={Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation},
  author={Ali Naseh and Yuefeng Peng and Anshuman Suri and Harsh Chaudhari and Alina Oprea and Amir Houmansadr},
  year={2025},
  url={http://arxiv.org/abs/2502.00306v2},
  abstract={Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to generate grounded responses by leveraging external knowledge databases without altering model parameters. Although the absence of weight tuning prevents leakage via model parameters, it introduces the risk of inference adversaries exploiting retrieved documents in the model's context. Existing methods for membership inference and data extraction often rely on jailbreaking or carefully crafted unnatural queries, which can be easily detected or thwarted with query rewriting techniques common in RAG systems. In this work, we present Interrogation Attack (IA), a membership inference technique targeting documents in the RAG datastore. By crafting natural-text queries that are answerable only with the target document's presence, our approach demonstrates successful inference with just 30 queries while remaining stealthy; straightforward detectors identify adversarial prompts from existing methods up to ~76x more frequently than those generated by our attack. We observe a 2x improvement in TPR@1%FPR over prior inference attacks across diverse RAG configurations, all while costing less than $0.02 per document inference.},
  journal={arXiv}
}

@article{meo2021multimodal,
  title={Multimodal VAE Active Inference Controller},
  author={Cristian Meo and Pablo Lanillos},
  year={2021},
  url={http://arxiv.org/abs/2103.04412v1},
  abstract={Active inference, a theoretical construct inspired by brain processing, is a promising alternative to control artificial agents. However, current methods do not yet scale to high-dimensional inputs in continuous control. Here we present a novel active inference torque controller for industrial arms that maintains the adaptive characteristics of previous proprioceptive approaches but also enables large-scale multimodal integration (e.g., raw images). We extended our previous mathematical formulation by including multimodal state representation learning using a linearly coupled multimodal variational autoencoder. We evaluated our model on a simulated 7DOF Franka Emika Panda robot arm and compared its behavior with a previous active inference baseline and the Panda built-in optimized controller. Results showed improved tracking and control in goal-directed reaching due to the increased representation power, high robustness to noise and adaptability in changes on the environmental conditions and robot parameters without the need to relearn the generative models nor parameters retuning.},
  journal={arXiv}
}

@article{smithe2022compositional,
  title={Compositional Active Inference II: Polynomial Dynamics. Approximate Inference Doctrines},
  author={Toby St. Clere Smithe},
  year={2022},
  url={http://arxiv.org/abs/2208.12173v1},
  abstract={We develop the compositional theory of active inference by introducing activity, functorially relating statistical games to the dynamical systems which play them, using the new notion of approximate inference doctrine. In order to exhibit such functors, we first develop the necessary theory of dynamical systems, using a generalization of the language of polynomial functors to supply compositional interfaces of the required types: with the resulting polynomially indexed categories of coalgebras, we construct monoidal bicategories of differential and dynamical ``hierarchical inference systems'', in which approximate inference doctrines have semantics. We then describe ``externally parameterized'' statistical games, and use them to construct two approximate inference doctrines found in the computational neuroscience literature, which we call the `Laplace' and the `Hebb-Laplace' doctrines: the former produces dynamical systems which optimize the posteriors of Gaussian models; and the latter produces systems which additionally optimize the parameters (or `weights') which determine their predictions.},
  journal={arXiv}
}

@article{vries2023toward,
  title={Toward Design of Synthetic Active Inference Agents by Mere Mortals},
  author={Bert de Vries},
  year={2023},
  url={http://arxiv.org/abs/2307.14145v1},
  abstract={The theoretical properties of active inference agents are impressive, but how do we realize effective agents in working hardware and software on edge devices? This is an interesting problem because the computational load for policy exploration explodes exponentially, while the computational resources are very limited for edge devices. In this paper, we discuss the necessary features for a software toolbox that supports a competent non-expert engineer to develop working active inference agents. We introduce a toolbox-in-progress that aims to accelerate the democratization of active inference agents in a similar way as TensorFlow propelled applications of deep learning technology.},
  journal={arXiv}
}

@article{yan2022mitigating,
  title={Mitigating shortage of labeled data using clustering-based active learning with diversity exploration},
  author={Xuyang Yan and Shabnam Nazmi and Biniam Gebru and Mohd Anwar and Abdollah Homaifar and Mrinmoy Sarkar and Kishor Datta Gupta},
  year={2022},
  url={http://arxiv.org/abs/2207.02964v1},
  abstract={In this paper, we proposed a new clustering-based active learning framework, namely Active Learning using a Clustering-based Sampling (ALCS), to address the shortage of labeled data. ALCS employs a density-based clustering approach to explore the cluster structure from the data without requiring exhaustive parameter tuning. A bi-cluster boundary-based sample query procedure is introduced to improve the learning performance for classifying highly overlapped classes. Additionally, we developed an effective diversity exploration strategy to address the redundancy among queried samples. Our experimental results justified the efficacy of the ALCS approach.},
  journal={arXiv}
}

@article{biehl2018expanding,
  title={Expanding the Active Inference Landscape: More Intrinsic Motivations in the Perception-Action Loop},
  author={Martin Biehl and Christian Guckelsberger and Christoph Salge and Simón C. Smith and Daniel Polani},
  year={2018},
  url={http://arxiv.org/abs/1806.08083v1},
  abstract={Active inference is an ambitious theory that treats perception, inference and action selection of autonomous agents under the heading of a single principle. It suggests biologically plausible explanations for many cognitive phenomena, including consciousness. In active inference, action selection is driven by an objective function that evaluates possible future actions with respect to current, inferred beliefs about the world. Active inference at its core is independent from extrinsic rewards, resulting in a high level of robustness across e.g.\ different environments or agent morphologies. In the literature, paradigms that share this independence have been summarised under the notion of intrinsic motivations. In general and in contrast to active inference, these models of motivation come without a commitment to particular inference and action selection mechanisms. In this article, we study if the inference and action selection machinery of active inference can also be used by alternatives to the originally included intrinsic motivation. The perception-action loop explicitly relates inference and action selection to the environment and agent memory, and is consequently used as foundation for our analysis. We reconstruct the active inference approach, locate the original formulation within, and show how alternative intrinsic motivations can be used while keeping many of the original features intact. Furthermore, we illustrate the connection to universal reinforcement learning by means of our formalism. Active inference research may profit from comparisons of the dynamics induced by alternative intrinsic motivations. Research on intrinsic motivations may profit from an additional way to implement intrinsically motivated agents that also share the biological plausibility of active inference.},
  journal={arXiv}
}

@article{malialis2022nonstationary,
  title={Nonstationary data stream classification with online active learning and siamese neural networks},
  author={Kleanthis Malialis and Christos G. Panayiotou and Marios M. Polycarpou},
  year={2022},
  url={http://arxiv.org/abs/2210.01090v1},
  abstract={We have witnessed in recent years an ever-growing volume of information becoming available in a streaming manner in various application areas. As a result, there is an emerging need for online learning methods that train predictive models on-the-fly. A series of open challenges, however, hinder their deployment in practice. These are, learning as data arrive in real-time one-by-one, learning from data with limited ground truth information, learning from nonstationary data, and learning from severely imbalanced data, while occupying a limited amount of memory for data storage. We propose the ActiSiamese algorithm, which addresses these challenges by combining online active learning, siamese networks, and a multi-queue memory. It develops a new density-based active learning strategy which considers similarity in the latent (rather than the input) space. We conduct an extensive study that compares the role of different active learning budgets and strategies, the performance with/without memory, the performance with/without ensembling, in both synthetic and real-world datasets, under different data nonstationarity characteristics and class imbalance levels. ActiSiamese outperforms baseline and state-of-the-art algorithms, and is effective under severe imbalance, even only when a fraction of the arriving instances' labels is available. We publicly release our code to the community.},
  doi={10.1016/j.neucom.2022.09.065},
  journal={arXiv}
}

@article{franke2015statistical,
  title={Statistical Inference, Learning and Models in Big Data},
  author={Beate Franke and Jean-François Plante and Ribana Roscher and Annie Lee and Cathal Smyth and Armin Hatefi and Fuqi Chen and Einat Gil and Alexander Schwing and Alessandro Selvitella and Michael M. Hoffman and Roger Grosse and Dieter Hendricks and Nancy Reid},
  year={2015},
  url={http://arxiv.org/abs/1509.02900v2},
  abstract={The need for new methods to deal with big data is a common theme in most scientific fields, although its definition tends to vary with the context. Statistical ideas are an essential part of this, and as a partial response, a thematic program on statistical inference, learning, and models in big data was held in 2015 in Canada, under the general direction of the Canadian Statistical Sciences Institute, with major funding from, and most activities located at, the Fields Institute for Research in Mathematical Sciences. This paper gives an overview of the topics covered, describing challenges and strategies that seem common to many different areas of application, and including some examples of applications to make these challenges and strategies more concrete.},
  doi={10.1111/insr.12176},
  journal={arXiv}
}

@article{albarracin2024modeling,
  title={Modeling Sustainable Resource Management using Active Inference},
  author={Mahault Albarracin and Ines Hipolito and Maria Raffa and Paul Kinghorn},
  year={2024},
  url={http://arxiv.org/abs/2406.07593v1},
  abstract={Active inference helps us simulate adaptive behavior and decision-making in biological and artificial agents. Building on our previous work exploring the relationship between active inference, well-being, resilience, and sustainability, we present a computational model of an agent learning sustainable resource management strategies in both static and dynamic environments. The agent's behavior emerges from optimizing its own well-being, represented by prior preferences, subject to beliefs about environmental dynamics. In a static environment, the agent learns to consistently consume resources to satisfy its needs. In a dynamic environment where resources deplete and replenish based on the agent's actions, the agent adapts its behavior to balance immediate needs with long-term resource availability. This demonstrates how active inference can give rise to sustainable and resilient behaviors in the face of changing environmental conditions. We discuss the implications of our model, its limitations, and suggest future directions for integrating more complex agent-environment interactions. Our work highlights active inference's potential for understanding and shaping sustainable behaviors.},
  journal={arXiv}
}

@article{singh2014manybody,
  title={Many-body microhydrodynamics of colloidal particles with active boundary layers},
  author={Rajesh Singh and Somdeb Ghose and R. Adhikari},
  year={2014},
  url={http://arxiv.org/abs/1411.0278v3},
  abstract={Colloidal particles with active boundary layers - regions surrounding the particles where nonequilibrium processes produce large velocity gradients - are common in many physical, chemical and biological contexts. The velocity or stress at the edge of the boundary layer determines the exterior fluid flow and, hence, the many-body interparticle hydrodynamic interaction. Here, we present a method to compute the many-body hydrodynamic interaction between $N$ spherical active particles induced by their exterior microhydrodynamic flow. First, we use a boundary integral representation of the Stokes equation to eliminate bulk fluid degrees of freedom. Then, we expand the boundary velocities and tractions of the integral representation in an infinite-dimensional basis of tensorial spherical harmonics and, on enforcing boundary conditions in a weak sense on the surface of each particle, obtain a system of linear algebraic equations for the unknown expansion coefficients. The truncation of the infinite series, fixed by the degree of accuracy required, yields a finite linear system that can be solved accurately and efficiently by iterative methods. The solution linearly relates the unknown rigid body motion to the known values of the expansion coefficients, motivating the introduction of propulsion matrices. These matrices completely characterize hydrodynamic interactions in active suspensions just as mobility matrices completely characterize hydrodynamic interactions in passive suspensions. The reduction in the dimensionality of the problem, from a three-dimensional partial differential equation to a two-dimensional integral equation, allows for dynamic simulations of hundreds of thousands of active particles on multi-core computational architectures.},
  doi={10.1088/1742-5468/2015/06/P06017},
  journal={arXiv}
}

@article{wakayama2024active,
  title={Active Inference in Contextual Multi-Armed Bandits for Autonomous Robotic Exploration},
  author={Shohei Wakayama and Alberto Candela and Paul Hayne and Nisar Ahmed},
  year={2024},
  url={http://arxiv.org/abs/2408.04119v2},
  abstract={Autonomous selection of optimal options for data collection from multiple alternatives is challenging in uncertain environments. When secondary information about options is accessible, such problems can be framed as contextual multi-armed bandits (CMABs). Neuro-inspired active inference has gained interest for its ability to balance exploration and exploitation using the expected free energy objective function. Unlike previous studies that showed the effectiveness of active inference based strategy for CMABs using synthetic data, this study aims to apply active inference to realistic scenarios, using a simulated mineralogical survey site selection problem. Hyperspectral data from AVIRIS-NG at Cuprite, Nevada, serves as contextual information for predicting outcome probabilities, while geologists' mineral labels represent outcomes. Monte Carlo simulations assess the robustness of active inference against changing expert preferences. Results show that active inference requires fewer iterations than standard bandit approaches with real-world noisy and biased data, and performs better when outcome preferences vary online by adapting the selection strategy to align with expert shifts.},
  doi={10.1109/TRO.2025.3577041},
  journal={arXiv}
}

@article{im2023active,
  title={Active and Passive Causal Inference Learning},
  author={Daniel Jiwoong Im and Kyunghyun Cho},
  year={2023},
  url={http://arxiv.org/abs/2308.09248v2},
  abstract={This paper serves as a starting point for machine learning researchers, engineers and students who are interested in but not yet familiar with causal inference. We start by laying out an important set of assumptions that are collectively needed for causal identification, such as exchangeability, positivity, consistency and the absence of interference. From these assumptions, we build out a set of important causal inference techniques, which we do so by categorizing them into two buckets; active and passive approaches. We describe and discuss randomized controlled trials and bandit-based approaches from the active category. We then describe classical approaches, such as matching and inverse probability weighting, in the passive category, followed by more recent deep learning based algorithms. By finishing the paper with some of the missing aspects of causal inference from this paper, such as collider biases, we expect this paper to provide readers with a diverse set of starting points for further reading and research in causal inference and discovery.},
  journal={arXiv}
}

@article{rizomiliotis2022partially,
  title={Partially Oblivious Neural Network Inference},
  author={Panagiotis Rizomiliotis and Christos Diou and Aikaterini Triakosia and Ilias Kyrannas and Konstantinos Tserpes},
  year={2022},
  url={http://arxiv.org/abs/2210.15189v1},
  abstract={Oblivious inference is the task of outsourcing a ML model, like neural-networks, without disclosing critical and sensitive information, like the model's parameters. One of the most prominent solutions for secure oblivious inference is based on a powerful cryptographic tools, like Homomorphic Encryption (HE) and/or multi-party computation (MPC). Even though the implementation of oblivious inference systems schemes has impressively improved the last decade, there are still significant limitations on the ML models that they can practically implement. Especially when both the ML model and the input data's confidentiality must be protected. In this paper, we introduce the notion of partially oblivious inference. We empirically show that for neural network models, like CNNs, some information leakage can be acceptable. We therefore propose a novel trade-off between security and efficiency. In our research, we investigate the impact on security and inference runtime performance from the CNN model's weights partial leakage. We experimentally demonstrate that in a CIFAR-10 network we can leak up to $80\%$ of the model's weights with practically no security impact, while the necessary HE-mutliplications are performed four times faster.},
  doi={10.5220/0011272500003283},
  journal={arXiv}
}

@article{schmitt2002frequency,
  title={The Frequency of Active and Quiescent Galaxies with Companions},
  author={Henrique R. Schmitt},
  year={2002},
  url={http://arxiv.org/abs/astro-ph/0211038v1},
  abstract={We study the percentage of active, HII and quiescent galaxies with companions in the Palomar survey. We find that when we separate the galaxies by their morphological types (ellipticals or spirals), to avoid morphology-density effects, there is no difference in the percentage of galaxies with companions among the different activity types.},
  journal={arXiv}
}

@article{caticha2003relative,
  title={Relative Entropy and Inductive Inference},
  author={Ariel Caticha},
  year={2003},
  url={http://arxiv.org/abs/physics/0311093v1},
  abstract={We discuss how the method of maximum entropy, MaxEnt, can be extended beyond its original scope, as a rule to assign a probability distribution, to a full-fledged method for inductive inference. The main concept is the (relative) entropy S[p|q] which is designed as a tool to update from a prior probability distribution q to a posterior probability distribution p when new information in the form of a constraint becomes available. The extended method goes beyond the mere selection of a single posterior p, but also addresses the question of how much less probable other distributions might be. Our approach clarifies how the entropy S[p|q] is used while avoiding the question of its meaning. Ultimately, entropy is a tool for induction which needs no interpretation. Finally, being a tool for generalization from special examples, we ask whether the functional form of the entropy depends on the choice of the examples and we find that it does. The conclusion is that there is no single general theory of inductive inference and that alternative expressions for the entropy are possible.},
  doi={10.1063/1.1751358},
  journal={arXiv}
}

@article{cacciarelli2022online,
  title={Online Active Learning for Soft Sensor Development using Semi-Supervised Autoencoders},
  author={Davide Cacciarelli and Murat Kulahci and John Tyssedal},
  year={2022},
  url={http://arxiv.org/abs/2212.13067v3},
  abstract={Data-driven soft sensors are extensively used in industrial and chemical processes to predict hard-to-measure process variables whose real value is difficult to track during routine operations. The regression models used by these sensors often require a large number of labeled examples, yet obtaining the label information can be very expensive given the high time and cost required by quality inspections. In this context, active learning methods can be highly beneficial as they can suggest the most informative labels to query. However, most of the active learning strategies proposed for regression focus on the offline setting. In this work, we adapt some of these approaches to the stream-based scenario and show how they can be used to select the most informative data points. We also demonstrate how to use a semi-supervised architecture based on orthogonal autoencoders to learn salient features in a lower dimensional space. The Tennessee Eastman Process is used to compare the predictive performance of the proposed approaches.},
  journal={arXiv}
}

@article{kolluru2025comparative,
  title={Comparative Analysis of Large Language Model Inference Serving Systems: A Performance Study of vLLM and HuggingFace TGI},
  author={Saicharan Kolluru},
  year={2025},
  url={http://arxiv.org/abs/2511.17593v1},
  abstract={The deployment of Large Language Models (LLMs) in production environments requires efficient inference serving systems that balance throughput, latency, and resource utilization. This paper presents a comprehensive empirical evaluation of two prominent open-source LLM serving frameworks: vLLM and HuggingFace Text Generation Inference (TGI). We benchmark these systems across multiple dimensions including throughput performance, end-to-end latency, GPU memory utilization, and scalability characteristics using LLaMA-2 models ranging from 7B to 70B parameters. Our experiments reveal that vLLM achieves up to 24x higher throughput than TGI under high-concurrency workloads through its novel PagedAttention mechanism, while TGI demonstrates lower tail latencies for interactive single-user scenarios. We provide detailed performance profiles for different deployment scenarios and offer practical recommendations for system selection based on workload characteristics. Our findings indicate that the choice between these frameworks should be guided by specific use-case requirements: vLLM excels in high-throughput batch processing scenarios, while TGI is better suited for latency-sensitive interactive applications with moderate concurrency.},
  journal={arXiv}
}

@article{peng2022active,
  title={Active Reconfigurable Intelligent Surface for Mobile Edge Computing},
  author={Zhangjie Peng and Ruisong Weng and Zhenkun Zhang and Cunhua Pan and Jiangzhou Wang},
  year={2022},
  url={http://arxiv.org/abs/2209.01438v2},
  abstract={This paper investigates an active reconfigurable intelligent surface (RIS)-aided mobile edge computing (MEC) system. Compared with passive RIS, the active RIS is equipped with active reflective amplifier, which can effectively circumvent the "double path loss" attenuation. We propose a joint computing and communication design to minimize the maximum computational latency (MCL), subject to both the phase shift constraints and the edge computing capability constraints. Specifically, the original problem is decoupled into four subproblems, and then the block coordinate descent (BCD) method and the successive convex approximation (SCA) method are applied to alternately optimize the subproblems. The simulation results show that with the same power budget, the performance gain achieved by the active RIS is much larger than that by the passive RIS.},
  journal={arXiv}
}

@article{werner2024crossdomain,
  title={A Cross-Domain Benchmark for Active Learning},
  author={Thorben Werner and Johannes Burchert and Maximilian Stubbemann and Lars Schmidt-Thieme},
  year={2024},
  url={http://arxiv.org/abs/2408.00426v2},
  abstract={Active Learning (AL) deals with identifying the most informative samples for labeling to reduce data annotation costs for supervised learning tasks. AL research suffers from the fact that lifts from literature generalize poorly and that only a small number of repetitions of experiments are conducted. To overcome these obstacles, we propose CDALBench, the first active learning benchmark which includes tasks in computer vision, natural language processing and tabular learning. Furthermore, by providing an efficient, greedy oracle, CDALBench can be evaluated with 50 runs for each experiment. We show, that both the cross-domain character and a large amount of repetitions are crucial for sophisticated evaluation of AL research. Concretely, we show that the superiority of specific methods varies over the different domains, making it important to evaluate Active Learning with a cross-domain benchmark. Additionally, we show that having a large amount of runs is crucial. With only conducting three runs as often done in the literature, the superiority of specific methods can strongly vary with the specific runs. This effect is so strong, that, depending on the seed, even a well-established method's performance can be significantly better and significantly worse than random for the same dataset.},
  journal={arXiv}
}

@article{poppenhaeger2017tidal,
  title={Tidal effects on stellar activity},
  author={K. Poppenhaeger},
  year={2017},
  url={http://arxiv.org/abs/1707.03906v1},
  abstract={The architecture of many exoplanetary systems is different from the solar system, with exoplanets being in close orbits around their host stars and having orbital periods of only a few days. We can expect interactions between the star and the exoplanet for such systems that are similar to the tidal interactions observed in close stellar binary systems. For the exoplanet, tidal interaction can lead to circularization of its orbit and the synchronization of its rotational and orbital period. For the host star, it has long been speculated if significant angular momentum transfer can take place between the planetary orbit and the stellar rotation. In the case of the Earth-Moon system, such tidal interaction has led to an increasing distance between Earth and Moon. For stars with Hot Jupiters, where the orbital period of the exoplanet is typically shorter than the stellar rotation period, one expects a decreasing semimajor axis for the planet and enhanced stellar rotation, leading to increased stellar activity. Also excess turbulence in the stellar convective zone due to rising and subsiding tidal bulges may change the magnetic activity we observe for the host star. Here I review recent observational results on stellar activity and tidal interaction in the presence of close-in exoplanets, and discuss the effects of enhanced stellar activity on the exoplanets in such systems.},
  doi={10.1017/S1743921317004045},
  journal={arXiv}
}

@article{ajao2017location,
  title={Location Inference from Tweets using Grid-based Classification},
  author={Oluwaseun Ajao and Deepak P and Jun Hong},
  year={2017},
  url={http://arxiv.org/abs/1701.03855v1},
  abstract={The impact of social media and its growing association with the sharing of ideas and propagation of messages remains vital in everyday communication. Twitter is one effective platform for the dissemination of news and stories about recent events happening around the world. It has a continually growing database currently adopted by over 300 million users. In this paper we propose a novel grid-based approach employing supervised Multinomial Naive Bayes while extracting geographic entities from relevant user descriptions metadata which gives a spatial indication of the user location. To the best of our knowledge our approach is the first to make location inference from tweets using geo-enriched grid-based classification. Our approach performs better than existing baselines achieving more than 57% accuracy at city-level granularity. In addition we present a novel framework for content-based estimation of user locations by specifying levels of granularity required in pre-defined location grids.},
  journal={arXiv}
}

@article{allahverdyan2014active,
  title={Active Inference for Binary Symmetric Hidden Markov Models},
  author={Armen E. Allahverdyan and Aram Galstyan},
  year={2014},
  url={http://arxiv.org/abs/1411.0630v1},
  abstract={We consider active maximum a posteriori (MAP) inference problem for Hidden Markov Models (HMM), where, given an initial MAP estimate of the hidden sequence, we select to label certain states in the sequence to improve the estimation accuracy of the remaining states. We develop an analytical approach to this problem for the case of binary symmetric HMMs, and obtain a closed form solution that relates the expected error reduction to model parameters under the specified active inference scheme. We then use this solution to determine most optimal active inference scheme in terms of error reduction, and examine the relation of those schemes to heuristic principles of uncertainty reduction and solution unicity.},
  doi={10.1007/s10955-015-1321-y},
  journal={arXiv}
}

@article{elitzur2008toroidal,
  title={The Toroidal Obscuration of Active Galactic Nuclei},
  author={Moshe Elitzur},
  year={2008},
  url={http://arxiv.org/abs/0805.3699v1},
  abstract={Observations give strong support for the unification scheme of active galactic nuclei. The scheme is premised on toroidal obscuration of the central engine by dusty clouds that are individually very optically thick. These lectures summarize the torus properties, describe the handling and implications of its clumpy nature and present speculations about its dynamic origin.},
  doi={10.1016/j.newar.2008.06.010},
  journal={arXiv}
}

@article{maele2023objectcentric,
  title={Object-Centric Scene Representations using Active Inference},
  author={Toon Van de Maele and Tim Verbelen and Pietro Mazzaglia and Stefano Ferraro and Bart Dhoedt},
  year={2023},
  url={http://arxiv.org/abs/2302.03288v1},
  abstract={Representing a scene and its constituent objects from raw sensory data is a core ability for enabling robots to interact with their environment. In this paper, we propose a novel approach for scene understanding, leveraging a hierarchical object-centric generative model that enables an agent to infer object category and pose in an allocentric reference frame using active inference, a neuro-inspired framework for action and perception. For evaluating the behavior of an active vision agent, we also propose a new benchmark where, given a target viewpoint of a particular object, the agent needs to find the best matching viewpoint given a workspace with randomly positioned objects in 3D. We demonstrate that our active inference agent is able to balance epistemic foraging and goal-driven behavior, and outperforms both supervised and reinforcement learning baselines by a large margin.},
  journal={arXiv}
}

@article{zhang2025inferencetime,
  title={Inference-time Scaling of Diffusion Models through Classical Search},
  author={Xiangcheng Zhang and Haowei Lin and Haotian Ye and James Zou and Jianzhu Ma and Yitao Liang and Yilun Du},
  year={2025},
  url={http://arxiv.org/abs/2505.23614v2},
  abstract={Classical search algorithms have long underpinned modern artificial intelligence. In this work, we tackle the challenge of inference-time control in diffusion models -- adapting generated outputs to meet diverse test-time objectives -- using principles from classical search. We propose a general framework that orchestrates local and global search to efficiently navigate the generative space. It employs a theoretically grounded local search via annealed Langevin MCMC and performs compute-efficient global exploration using breadth-first and depth-first tree search. We evaluate our approach on a range of challenging domains, including planning, offline reinforcement learning, and image generation. Across all tasks, we observe significant gains in both performance and efficiency. These results show that classical search provides a principled and practical foundation for inference-time scaling in diffusion models. Project page at https://diffusion-inference-scaling.github.io/.},
  journal={arXiv}
}

@article{çatal2019bayesian,
  title={Bayesian policy selection using active inference},
  author={Ozan Çatal and Johannes Nauta and Tim Verbelen and Pieter Simoens and Bart Dhoedt},
  year={2019},
  url={http://arxiv.org/abs/1904.08149v2},
  abstract={Learning to take actions based on observations is a core requirement for artificial agents to be able to be successful and robust at their task. Reinforcement Learning (RL) is a well-known technique for learning such policies. However, current RL algorithms often have to deal with reward shaping, have difficulties generalizing to other environments and are most often sample inefficient. In this paper, we explore active inference and the free energy principle, a normative theory from neuroscience that explains how self-organizing biological systems operate by maintaining a model of the world and casting action selection as an inference problem. We apply this concept to a typical problem known to the RL community, the mountain car problem, and show how active inference encompasses both RL and learning from demonstrations.},
  journal={arXiv}
}

@article{glazer2022robust,
  title={Robust inference for matching under rolling enrollment},
  author={Amanda K. Glazer and Samuel D. Pimentel},
  year={2022},
  url={http://arxiv.org/abs/2205.01061v3},
  abstract={Matching in observational studies faces complications when units enroll in treatment on a rolling basis. While each treated unit has a specific time of entry into the study, control units each have many possible comparison, or "pseudo-treatment," times. The recent GroupMatch framework (Pimentel et al., 2020) solves this problem by searching over all possible pseudo-treatment times for each control and selecting those permitting the closest matches based on covariate histories. However, valid methods of inference have been described only for special cases of the general GroupMatch design, and these rely on strong assumptions. We provide three important innovations to address these problems. First, we introduce a new design, GroupMatch with instance replacement, that allows additional flexibility in control selection and proves more amenable to analysis. Second, we propose a block bootstrap approach for inference in GroupMatch with instance replacement and demonstrate that it accounts properly for complex correlations across matched sets. Third, we develop a permutation-based falsification test to detect possible violations of the important timepoint agnosticism assumption underpinning GroupMatch, which requires homogeneity of potential outcome means across time. Via simulation and a case study of the impact of short-term injuries on batting performance in major league baseball, we demonstrate the effectiveness of our methods for data analysis in practice.},
  journal={arXiv}
}

@article{champion2023deconstructing,
  title={Deconstructing deep active inference},
  author={Théophile Champion and Marek Grześ and Lisa Bonheme and Howard Bowman},
  year={2023},
  url={http://arxiv.org/abs/2303.01618v2},
  abstract={Active inference is a theory of perception, learning and decision making, which can be applied to neuroscience, robotics, and machine learning. Recently, reasearch has been taking place to scale up this framework using Monte-Carlo tree search and deep learning. The goal of this activity is to solve more complicated tasks using deep active inference. First, we review the existing literature, then, we progresively build a deep active inference agent. For two agents, we have experimented with five definitions of the expected free energy and three different action selection strategies. According to our experiments, the models able to solve the dSprites environment are the ones that maximise rewards. Finally, we compare the similarity of the representation learned by the layers of various agents using centered kernel alignment. Importantly, the agent maximising reward and the agent minimising expected free energy learn very similar representations except for the last layer of the critic network (reflecting the difference in learning objective), and the variance layers of the transition and encoder networks. We found that the reward maximising agent is a lot more certain than the agent minimising expected free energy. This is because the agent minimising expected free energy always picks the action down, and does not gather enough data for the other actions. In contrast, the agent maximising reward, keeps on selecting the actions left and right, enabling it to successfully solve the task. The only difference between those two agents is the epistemic value, which aims to make the outputs of the transition and encoder networks as close as possible. Thus, the agent minimising expected free energy picks a single action (down), and becomes an expert at predicting the future when selecting this action. This makes the KL divergence between the output of the transition and encoder networks small.},
  journal={arXiv}
}

@article{lin2023ensemble,
  title={Ensemble Kalman Filtering Meets Gaussian Process SSM for Non-Mean-Field and Online Inference},
  author={Zhidi Lin and Yiyong Sun and Feng Yin and Alexandre Hoang Thiéry},
  year={2023},
  url={http://arxiv.org/abs/2312.05910v5},
  abstract={The Gaussian process state-space models (GPSSMs) represent a versatile class of data-driven nonlinear dynamical system models. However, the presence of numerous latent variables in GPSSM incurs unresolved issues for existing variational inference approaches, particularly under the more realistic non-mean-field (NMF) assumption, including extensive training effort, compromised inference accuracy, and infeasibility for online applications, among others. In this paper, we tackle these challenges by incorporating the ensemble Kalman filter (EnKF), a well-established model-based filtering technique, into the NMF variational inference framework to approximate the posterior distribution of the latent states. This novel marriage between EnKF and GPSSM not only eliminates the need for extensive parameterization in learning variational distributions, but also enables an interpretable, closed-form approximation of the evidence lower bound (ELBO). Moreover, owing to the streamlined parameterization via the EnKF, the new GPSSM model can be easily accommodated in online learning applications. We demonstrate that the resulting EnKF-aided online algorithm embodies a principled objective function by ensuring data-fitting accuracy while incorporating model regularizations to mitigate overfitting. We also provide detailed analysis and fresh insights for the proposed algorithms. Comprehensive evaluation across diverse real and synthetic datasets corroborates the superior learning and inference performance of our EnKF-aided variational inference algorithms compared to existing methods.},
  journal={arXiv}
}

@article{pezzato2019novel,
  title={A Novel Adaptive Controller for Robot Manipulators based on Active Inference},
  author={Corrado Pezzato and Riccardo Ferrari and Carlos Hernandez},
  year={2019},
  url={http://arxiv.org/abs/1909.12768v2},
  abstract={More adaptive controllers for robot manipulators are needed, which can deal with large model uncertainties. This paper presents a novel active inference controller (AIC) as an adaptive control scheme for industrial robots. This scheme is easily scalable to high degrees-of-freedom, and it maintains high performance even in the presence of large unmodeled dynamics. The proposed method is based on active inference, a promising neuroscientific theory of the brain, which describes a biologically plausible algorithm for perception and action. In this work, we formulate active inference from a control perspective, deriving a model-free control law which is less sensitive to unmodeled dynamics. The performance and the adaptive properties of the algorithm are compared to a state-of-the-art model reference adaptive controller (MRAC) in an experimental setup with a real 7-DOF robot arm. The results showed that the AIC outperformed the MRAC in terms of adaptability, providing a more general control law. This confirmed the relevance of active inference for robot control.},
  doi={10.1109/LRA.2020.2974451},
  journal={arXiv}
}

@article{margolis2023learning,
  title={Learning to See Physical Properties with Active Sensing Motor Policies},
  author={Gabriel B. Margolis and Xiang Fu and Yandong Ji and Pulkit Agrawal},
  year={2023},
  url={http://arxiv.org/abs/2311.01405v1},
  abstract={Knowledge of terrain's physical properties inferred from color images can aid in making efficient robotic locomotion plans. However, unlike image classification, it is unintuitive for humans to label image patches with physical properties. Without labeled data, building a vision system that takes as input the observed terrain and predicts physical properties remains challenging. We present a method that overcomes this challenge by self-supervised labeling of images captured by robots during real-world traversal with physical property estimators trained in simulation. To ensure accurate labeling, we introduce Active Sensing Motor Policies (ASMP), which are trained to explore locomotion behaviors that increase the accuracy of estimating physical parameters. For instance, the quadruped robot learns to swipe its foot against the ground to estimate the friction coefficient accurately. We show that the visual system trained with a small amount of real-world traversal data accurately predicts physical parameters. The trained system is robust and works even with overhead images captured by a drone despite being trained on data collected by cameras attached to a quadruped robot walking on the ground.},
  journal={arXiv}
}

@article{zuiden2016spatiotemporal,
  title={Spatiotemporal order and emergent edge currents in active spinner materials},
  author={Benjamin C. van Zuiden and Jayson Paulose and William T. M. Irvine and Denis Bartolo and Vincenzo Vitelli},
  year={2016},
  url={http://arxiv.org/abs/1606.03934v3},
  abstract={Collections of interacting, self-propelled particles have been extensively studied as minimal models of many living and synthetic systems from bird flocks to active colloids. However, the influence of active rotations in the absence of self-propulsion i.e. spinning without walking) remains less explored. Here, we numerically and theoretically investigate the behaviour of ensembles of self-spinning dimers. We find that geometric frustration of dimer rotation by interactions yields spatiotemporal order and active melting with no equilibrium counterparts. At low density, the spinning dimers self-assemble into a triangular lattice with their orientations phase-locked into spatially periodic phases. The phase-locked patterns form dynamical analogues of the ground states of various spin models, transitioning from the 3-state Potts antiferromagnet at low densities to the striped herringbone phase of planar quadrupoles at higher densities. As the density is raised further, the competition between active rotations and interactions leads to melting of the active spinner crystal. Emergent edge currents, whose direction is set by the chirality of the active spinning, arise as a non-equilibrium signature of the transition to the active spinner liquid and vanish when the system eventually undergoes kinetic arrest at very high densities. Our findings may be realized in systems ranging from liquid crystal and colloidal experiments to tabletop realizations using macroscopic chiral grains.},
  doi={10.1073/pnas.1609572113},
  journal={arXiv}
}

@article{jiang2020inferring,
  title={Inferring Degrees from Incomplete Networks and Nonlinear Dynamics},
  author={Chunheng Jiang and Jianxi Gao and Malik Magdon-Ismail},
  year={2020},
  url={http://arxiv.org/abs/2004.10546v2},
  abstract={Inferring topological characteristics of complex networks from observed data is critical to understand the dynamical behavior of networked systems, ranging from the Internet and the World Wide Web to biological networks and social networks. Prior studies usually focus on the structure-based estimation to infer network sizes, degree distributions, average degrees, and more. Little effort attempted to estimate the specific degree of each vertex from a sampled induced graph, which prevents us from measuring the lethality of nodes in protein networks and influencers in social networks. The current approaches dramatically fail for a tiny sampled induced graph and require a specific sampling method and a large sample size. These approaches neglect information of the vertex state, representing the dynamical behavior of the networked system, such as the biomass of species or expression of a gene, which is useful for degree estimation. We fill this gap by developing a framework to infer individual vertex degrees using both information of the sampled topology and vertex state. We combine the mean-field theory with combinatorial optimization to learn vertex degrees. Experimental results on real networks with a variety of dynamics demonstrate that our framework can produce reliable degree estimates and dramatically improve existing link prediction methods by replacing the sampled degrees with our estimated degrees.},
  journal={arXiv}
}

@article{bergen2022objectbased,
  title={Object-based active inference},
  author={Ruben S. van Bergen and Pablo L. Lanillos},
  year={2022},
  url={http://arxiv.org/abs/2209.01258v1},
  abstract={The world consists of objects: distinct entities possessing independent properties and dynamics. For agents to interact with the world intelligently, they must translate sensory inputs into the bound-together features that describe each object. These object-based representations form a natural basis for planning behavior. Active inference (AIF) is an influential unifying account of perception and action, but existing AIF models have not leveraged this important inductive bias. To remedy this, we introduce 'object-based active inference' (OBAI), marrying AIF with recent deep object-based neural networks. OBAI represents distinct objects with separate variational beliefs, and uses selective attention to route inputs to their corresponding object slots. Object representations are endowed with independent action-based dynamics. The dynamics and generative model are learned from experience with a simple environment (active multi-dSprites). We show that OBAI learns to correctly segment the action-perturbed objects from video input, and to manipulate these objects towards arbitrary goals.},
  journal={arXiv}
}

@article{kuhn2025addressing,
  title={Addressing the Subsumption Thesis: A Formal Bridge between Microeconomics and Active Inference},
  author={Noe Kuhn},
  year={2025},
  url={http://arxiv.org/abs/2503.05048v1},
  abstract={As a unified theory of sentient behaviour, active inference is formally intertwined with multiple normative theories of optimal behaviour. Specifically, we address what we call the subsumption thesis: The claim that expected utility from economics, as an account of agency, is subsumed by active inference. To investigate this claim, we present multiple examples that challenge the subsumption thesis. To formally compare these two accounts of agency, we analyze the objective functions for MDPs and POMDPs. By imposing information-theoretic rationality bounds (ITBR) on the expected utility agent, we find that the resultant agency is equivalent to that of active inference in MDPs, but slightly different in POMDPs. Rather than being strictly resolved, the subsumption thesis motivates the construction of a formal bridge between active inference and expected utility. This highlights the necessary formal assumptions and frameworks to make these disparate accounts of agency commensurable.},
  journal={arXiv}
}

@article{maisto2021active,
  title={Active Inference Tree Search in Large POMDPs},
  author={Domenico Maisto and Francesco Gregoretti and Karl Friston and Giovanni Pezzulo},
  year={2021},
  url={http://arxiv.org/abs/2103.13860v6},
  abstract={The ability to plan ahead efficiently is key for both living organisms and artificial systems. Model-based planning and prospection are widely studied in cognitive neuroscience and artificial intelligence (AI), but from different perspectives--and with different desiderata in mind (biological realism versus scalability) that are difficult to reconcile. Here, we introduce a novel method to plan in POMDPs--Active Inference Tree Search (AcT)--that combines the normative character and biological realism of a leading planning theory in neuroscience (Active Inference) and the scalability of tree search methods in AI. This unification enhances both approaches. On the one hand, tree searches enable the biologically grounded, first principle method of active inference to be applied to large-scale problems. On the other hand, active inference provides a principled solution to the exploration-exploitation dilemma, which is often addressed heuristically in tree search methods. Our simulations show that AcT successfully navigates binary trees that are challenging for sampling-based methods, problems that require adaptive exploration, and the large POMDP problem 'RockSample'--in which AcT reproduces state-of-the-art POMDP solutions. Furthermore, we illustrate how AcT can be used to simulate neurophysiological responses (e.g., in the hippocampus and prefrontal cortex) of humans and other animals that solve large planning problems. These numerical analyses show that Active Tree Search is a principled realisation of neuroscientific and AI planning theories, which offer both biological realism and scalability.},
  journal={arXiv}
}

@article{tsoumas2025positiveunlabeled,
  title={Positive-Unlabeled Learning for Control Group Construction in Observational Causal Inference},
  author={Ilias Tsoumas and Dimitrios Bormpoudakis and Vasileios Sitokonstantinou and Athanasios Askitopoulos and Andreas Kalogeras and Charalampos Kontoes and Ioannis Athanasiadis},
  year={2025},
  url={http://arxiv.org/abs/2507.14528v1},
  abstract={In causal inference, whether through randomized controlled trials or observational studies, access to both treated and control units is essential for estimating the effect of a treatment on an outcome of interest. When treatment assignment is random, the average treatment effect (ATE) can be estimated directly by comparing outcomes between groups. In non-randomized settings, various techniques are employed to adjust for confounding and approximate the counterfactual scenario to recover an unbiased ATE. A common challenge, especially in observational studies, is the absence of units clearly labeled as controls-that is, units known not to have received the treatment. To address this, we propose positive-unlabeled (PU) learning as a framework for identifying, with high confidence, control units from a pool of unlabeled ones, using only the available treated (positive) units. We evaluate this approach using both simulated and real-world data. We construct a causal graph with diverse relationships and use it to generate synthetic data under various scenarios, assessing how reliably the method recovers control groups that allow estimates of true ATE. We also apply our approach to real-world data on optimal sowing and fertilizer treatments in sustainable agriculture. Our findings show that PU learning can successfully identify control (negative) units from unlabeled data based only on treated units and, through the resulting control group, estimate an ATE that closely approximates the true value. This work has important implications for observational causal inference, especially in fields where randomized experiments are difficult or costly. In domains such as earth, environmental, and agricultural sciences, it enables a plethora of quasi-experiments by leveraging available earth observation and climate data, particularly when treated units are available but control units are lacking.},
  journal={arXiv}
}

@article{gadginmath2025active,
  title={Active Probing with Multimodal Predictions for Motion Planning},
  author={Darshan Gadginmath and Farhad Nawaz and Minjun Sung and Faizan M Tariq and Sangjae Bae and David Isele and Fabio Pasqualetti and Jovin D'sa},
  year={2025},
  url={http://arxiv.org/abs/2507.09822v4},
  abstract={Navigation in dynamic environments requires autonomous systems to reason about uncertainties in the behavior of other agents. In this paper, we introduce a unified framework that combines trajectory planning with multimodal predictions and active probing to enhance decision-making under uncertainty. We develop a novel risk metric that seamlessly integrates multimodal prediction uncertainties through mixture models. When these uncertainties follow a Gaussian mixture distribution, we prove that our risk metric admits a closed-form solution, and is always finite, thus ensuring analytical tractability. To reduce prediction ambiguity, we incorporate an active probing mechanism that strategically selects actions to improve its estimates of behavioral parameters of other agents, while simultaneously handling multimodal uncertainties. We extensively evaluate our framework in autonomous navigation scenarios using the MetaDrive simulation environment. Results demonstrate that our active probing approach successfully navigates complex traffic scenarios with uncertain predictions. Additionally, our framework shows robust performance across diverse traffic agent behavior models, indicating its broad applicability to real-world autonomous navigation challenges. Code and videos are available at https://darshangm.github.io/papers/active-probing-multimodal-predictions/.},
  journal={arXiv}
}

@article{toner2018giant,
  title={Giant number fluctuations in dry active polar fluids: A shocking analogy with lightning rods},
  author={John Toner},
  year={2018},
  url={http://arxiv.org/abs/1812.04532v1},
  abstract={The hydrodynamic equations of dry active polar fluids (i.e., moving flocks without momentum conservation) are shown to imply giant number fluctuations. Specifically, the rms fluctuations $\sqrt {<(δN)^2>}$ of the number $N$ of active particles in a region containing a mean number of active particles $<N>$ scales according to the law $\sqrt {<(δN)^2>} = K'<N>^{φ(d)}$ with $φ(d)=\frac{7}{10}+\frac{1}{5d}$ in $d\le4$ spatial dimensions. This is much larger the "law of large numbers" scaling $\sqrt {<(δN)^2>} = K\sqrt{<N>}$ found in most equilibrium and non-equilibrium systems. In further contrast to most other systems, the coefficient $K'$ also depends singularly on the shape of the box in which one counts the particles, vanishing in the limit of very thin boxes. These fluctuations arise {\it not} from large density fluctuations - indeed, the density fluctuations in \dry s are not in general particularly large - but from long ranged spatial correlations between those fluctuations. These are shown to be closely related in two spatial dimensions to the electrostatic potential near a sharp upward pointing conducting wedge of opening angle ${3π\over8}=67.5^\circ$, and in three dimensions to the electrostatic potential near a sharp upward pointing charged cone of opening angle $37.16^\circ$. This very precise prediction can be stringently tested by alternative box counting experiments that directly measure this density-density correlation function.},
  doi={10.1063/1.5081742},
  journal={arXiv}
}

@article{toth2022active,
  title={Active Bayesian Causal Inference},
  author={Christian Toth and Lars Lorch and Christian Knoll and Andreas Krause and Franz Pernkopf and Robert Peharz and Julius von Kügelgen},
  year={2022},
  url={http://arxiv.org/abs/2206.02063v2},
  abstract={Causal discovery and causal reasoning are classically treated as separate and consecutive tasks: one first infers the causal graph, and then uses it to estimate causal effects of interventions. However, such a two-stage approach is uneconomical, especially in terms of actively collected interventional data, since the causal query of interest may not require a fully-specified causal model. From a Bayesian perspective, it is also unnatural, since a causal query (e.g., the causal graph or some causal effect) can be viewed as a latent quantity subject to posterior inference -- other unobserved quantities that are not of direct interest (e.g., the full causal model) ought to be marginalized out in this process and contribute to our epistemic uncertainty. In this work, we propose Active Bayesian Causal Inference (ABCI), a fully-Bayesian active learning framework for integrated causal discovery and reasoning, which jointly infers a posterior over causal models and queries of interest. In our approach to ABCI, we focus on the class of causally-sufficient, nonlinear additive noise models, which we model using Gaussian processes. We sequentially design experiments that are maximally informative about our target causal query, collect the corresponding interventional data, and update our beliefs to choose the next experiment. Through simulations, we demonstrate that our approach is more data-efficient than several baselines that only focus on learning the full causal graph. This allows us to accurately learn downstream causal queries from fewer samples while providing well-calibrated uncertainty estimates for the quantities of interest.},
  journal={arXiv}
}

@article{palacci2014light,
  title={Light Activated Self-Propelled Colloids},
  author={J. Palacci and S. Sacanna and S. -H. Kim and G. -R. Yi and D. J. Pine and P. M. Chaikin},
  year={2014},
  url={http://arxiv.org/abs/1410.7278v1},
  abstract={Light-activated self-propelled colloids are synthesized and their active motion is studied using optical microscopy. We propose a versatile route using different photoactive materials, and demonstrate a multiwavelength activation and propulsion. Thanks to the photoelectrochemical properties of two semiconductor materials (αFe2 O3 and TiO2 ), a light with an energy higher than the bandgap triggers the reaction of decomposition of hydrogen peroxide and produces a chemical cloud around the particle. It induces a phoretic attraction with neighbouring colloids as well as an osmotic self- propulsion of the particle on the substrate. We use these mechanisms to form colloidal cargos as well as self-propelled particles where the light-activated component is embedded into a dielectric sphere. The particles are self-propelled along a direction otherwise randomized by thermal fluctuations, and exhibit a persistent random walk. For sufficient surface density, the particles spontaneously form "living crystals" which are mobile, break apart and reform. Steering the particle with an external magnetic field, we show that the formation of the dense phase results from the collisions heads-on of the particles. This effect is intrinsically non-equilibrium and a novel principle of organization for systems without detailed balance. Engineering families of particles self-propelled by different wavelength demonstrate a good understanding of both the physics and the chemistry behind the system and points to a general route for designing new families of self-propelled particles.},
  doi={10.1098/rsta.2013.0372},
  journal={arXiv}
}

@article{huang2025aline,
  title={ALINE: Joint Amortization for Bayesian Inference and Active Data Acquisition},
  author={Daolang Huang and Xinyi Wen and Ayush Bharti and Samuel Kaski and Luigi Acerbi},
  year={2025},
  url={http://arxiv.org/abs/2506.07259v2},
  abstract={Many critical applications, from autonomous scientific discovery to personalized medicine, demand systems that can both strategically acquire the most informative data and instantaneously perform inference based upon it. While amortized methods for Bayesian inference and experimental design offer part of the solution, neither approach is optimal in the most general and challenging task, where new data needs to be collected for instant inference. To tackle this issue, we introduce the Amortized Active Learning and Inference Engine (ALINE), a unified framework for amortized Bayesian inference and active data acquisition. ALINE leverages a transformer architecture trained via reinforcement learning with a reward based on self-estimated information gain provided by its own integrated inference component. This allows it to strategically query informative data points while simultaneously refining its predictions. Moreover, ALINE can selectively direct its querying strategy towards specific subsets of model parameters or designated predictive tasks, optimizing for posterior estimation, data prediction, or a mixture thereof. Empirical results on regression-based active learning, classical Bayesian experimental design benchmarks, and a psychometric model with selectively targeted parameters demonstrate that ALINE delivers both instant and accurate inference along with efficient selection of informative points.},
  journal={arXiv}
}

@article{stamps2024active,
  title={Active Inference Demonstrated with Artificial Spin Ice},
  author={Robert L. Stamps and Rehana Begum Popy and Johan van Lierop},
  year={2024},
  url={http://arxiv.org/abs/2401.12211v4},
  abstract={A numerical model of interacting nanomagnetic elements is used to demonstrate active inference with a three dimensional Artificial Spin Ice structure. It is shown that thermal fluctuations can drive this magnetic spin system to evolve under dynamic constraints imposed through interactions with an external environment as predicted by the neurological free energy principle and active inference. The structure is defined by two layers of magnetic nanoelements where one layer is a square Artificial Spin Ice geometry. The other magnetic layer functions as a sensory filter that mediates interaction between the external environment and the hidden Artificial Spin Ice layer. Spin dynamics displayed by the bilayer structure are shown to be well described using a continuous form of a neurological free energy principle that has been previously proposed as a high level description of certain biological neural processes. Numerical simulations demonstrate that this proposed bilayer geometry is able to reproduce theoretical results derived previously for examples of active inference in neurological contexts.},
  journal={arXiv}
}

@article{sevilla2019generalized,
  title={Generalized persistence dynamics for active motion},
  author={Francisco J. Sevilla and Pavel Castro-Villarreal},
  year={2019},
  url={http://arxiv.org/abs/1912.03425v2},
  abstract={We analyze the statistical physics of self-propelled particles from a general theoretical framework that properly describes the most salient characteristic of active motion, $persistence$, in arbitrary spatial dimensions. Such a framework allows the development of a Smoluchowski-like equation for the probability density of finding a particle at a given position and time, without assuming an explicit orientational dynamics of the self-propelling velocity as Langevin-like equation-based models do. Also, the Brownian motion due to thermal fluctuations and the active one due to a general intrinsic persistent motion of the particle are taken into consideration on an equal footing. The persistence of motion is introduced in our formalism in the form of a \emph{two-time memory function}, $K(t,t^{\prime})$. We focus on the consequences when $K(t,t^{\prime})\sim (t/t^{\prime})^{-η}\exp[-Γ(t-t^{\prime})]$, $Γ$ being the characteristic persistence time, and show that it precisely describes a variety of active motion patterns characterized by $η$. We find analytical expressions for the experimentally obtainable intermediate scattering function, the time dependence of the mean-squared displacement, and the kurtosis.},
  doi={10.1103/PhysRevE.104.064601},
  journal={arXiv}
}

@article{champion2021branching,
  title={Branching Time Active Inference with Bayesian Filtering},
  author={Théophile Champion and Marek Grześ and Howard Bowman},
  year={2021},
  url={http://arxiv.org/abs/2112.07406v1},
  abstract={Branching Time Active Inference (Champion et al., 2021b,a) is a framework proposing to look at planning as a form of Bayesian model expansion. Its root can be found in Active Inference (Friston et al., 2016; Da Costa et al., 2020; Champion et al., 2021c), a neuroscientific framework widely used for brain modelling, as well as in Monte Carlo Tree Search (Browne et al., 2012), a method broadly applied in the Reinforcement Learning literature. Up to now, the inference of the latent variables was carried out by taking advantage of the flexibility offered by Variational Message Passing (Winn and Bishop, 2005), an iterative process that can be understood as sending messages along the edges of a factor graph (Forney, 2001). In this paper, we harness the efficiency of an alternative method for inference called Bayesian Filtering (Fox et al., 2003), which does not require the iteration of the update equations until convergence of the Variational Free Energy. Instead, this scheme alternates between two phases: integration of evidence and prediction of future states. Both of those phases can be performed efficiently and this provides a seventy times speed up over the state-of-the-art.},
  journal={arXiv}
}

@article{tull2023active,
  title={Active Inference in String Diagrams: A Categorical Account of Predictive Processing and Free Energy},
  author={Sean Tull and Johannes Kleiner and Toby St Clere Smithe},
  year={2023},
  url={http://arxiv.org/abs/2308.00861v1},
  abstract={We present a categorical formulation of the cognitive frameworks of Predictive Processing and Active Inference, expressed in terms of string diagrams interpreted in a monoidal category with copying and discarding. This includes diagrammatic accounts of generative models, Bayesian updating, perception, planning, active inference, and free energy. In particular we present a diagrammatic derivation of the formula for active inference via free energy minimisation, and establish a compositionality property for free energy, allowing free energy to be applied at all levels of an agent's generative model. Aside from aiming to provide a helpful graphical language for those familiar with active inference, we conversely hope that this article may provide a concise formulation and introduction to the framework.},
  journal={arXiv}
}

@article{peng2023energy,
  title={Energy Minimization for Active RIS-Aided UAV-Enabled SWIPT Systems},
  author={Zhangjie Peng and Ruijing Liu and Cunhua Pan and Zhenkun Zhang and Jiangzhou Wang},
  year={2023},
  url={http://arxiv.org/abs/2306.10233v2},
  abstract={In this paper, we consider an active reconfigurable intelligent surface (RIS)-aided unmanned aerial vehicle(UAV)-enabled simultaneous wireless information and power transfer(SWIPT) system with multiple ground users. Compared with the conventional passive RIS, the active RIS deploying the internally integrated amplifiers can offset part of the multiplicative fading. In this system, we deal with an optimization problem of minimizing the total energy cost of the UAV. Specifically, we alternately optimize the trajectories, the hovering time, and the reflection vectors at the active RIS by using the successive convex approximation (SCA) method. Simulation results show that the active RIS performs better in energy saving than the conventional passive RIS.},
  journal={arXiv}
}

@article{champion2021branching2,
  title={Branching Time Active Inference: the theory and its generality},
  author={Théophile Champion and Lancelot Da Costa and Howard Bowman and Marek Grześ},
  year={2021},
  url={http://arxiv.org/abs/2111.11107v2},
  abstract={Over the last 10 to 15 years, active inference has helped to explain various brain mechanisms from habit formation to dopaminergic discharge and even modelling curiosity. However, the current implementations suffer from an exponential (space and time) complexity class when computing the prior over all the possible policies up to the time-horizon. Fountas et al (2020) used Monte Carlo tree search to address this problem, leading to impressive results in two different tasks. In this paper, we present an alternative framework that aims to unify tree search and active inference by casting planning as a structure learning problem. Two tree search algorithms are then presented. The first propagates the expected free energy forward in time (i.e., towards the leaves), while the second propagates it backward (i.e., towards the root). Then, we demonstrate that forward and backward propagations are related to active inference and sophisticated inference, respectively, thereby clarifying the differences between those two planning strategies.},
  journal={arXiv}
}

@article{ren2023transmission,
  title={Transmission Design for Active RIS-Aided Simultaneous Wireless Information and Power Transfer},
  author={Hong Ren and Zhiwei Chen and Guosheng Hu and Zhangjie Peng and Cunhua Pan and Jiangzhou Wang},
  year={2023},
  url={http://arxiv.org/abs/2301.03822v1},
  abstract={Reconfigurable intelligent surface (RIS) is a revolutionary technology to enhance both the spectral efficiency and energy efficiency of wireless communication systems. However, most of the existing contributions mainly focused on the study of passive RIS, which suffers from the ``double fading'' effect. On the other hand, active RIS, which is equipped with amplifiers, can effectively address this issue. In this paper, we propose an active RIS-aided simultaneous wireless information and power transfer (SWIPT) system. Specifically, we maximize the weighted sum rate of the information receivers, subject to the minimum power received at all energy receivers, amplification power constraint at the active RIS, and the maximum transmit power constraint at the base station (BS). By adopting alternating optimization framework, suboptimal solutions are obtained. Simulation results show that the active RIS-aided SWIPT system has higher performance gain with the same power budget.},
  journal={arXiv}
}

@article{reiter2021threedimensional,
  title={Three-dimensional assessment of susceptibility-induced signal voids caused by active cardiac implants in the setting of 3.0T CMR},
  author={Theresa Reiter and Ingo Weiss and Oliver M. Weber and Wolfgang R. Bauer},
  year={2021},
  url={http://arxiv.org/abs/2108.00437v2},
  abstract={Recent technical advancements allow cardiac MRI (CMR) examinations in the presence of so-called MRI conditional active cardiac implants at 3.0T. However, the artifact burden caused by susceptibility effects remain an obstacle. All measurements were obtained at a clinical 3.0T scanner using an in-house designed cubic phantom and optimized sequences for artifact evaluation (3D gradient echo sequence, multi-slice 2D turbo spin echo sequence), as well as reference sequences according to the ASTM were applied. Four representative active cardiac devices and a generic setup were analysed regarding volume and shape of the signal void. For analysis, a threshold operation applied to the grey value profle of each data data set was used. The presented approach allows the evaluation of signal void and shape even for larger implants such as ICDs. The void shape is influenced by the orientation of the B0-field and the chosen sequence type, as well as the distribution of magnetic material within the implants. The void volume depends both on the device itself, and the sequence type. Disturbances in the B0 and B1 fields exceed the visual signal void. This work presents a reproducible and highly defined approach towards characterising both signal void artifacts at 3.0T and their influencing factors.},
  journal={arXiv}
}

@article{serov2019statistical,
  title={Statistical Tests for Force Inference in Heterogeneous Environments},
  author={Alexander S. Serov and François Laurent and Charlotte Floderer and Karen Perronet and Cyril Favard and Delphine Muriaux and Christian L. Vestergaard and Jean-Baptiste Masson},
  year={2019},
  url={http://arxiv.org/abs/1903.03048v3},
  abstract={We devise a method to detect and estimate forces in a heterogeneous environment based on experimentally recorded stochastic trajectories. In particular, we focus on systems modeled by the heterogeneous overdamped Langevin equation. Here, the observed drift includes a "spurious" force term when the diffusivity varies in space. We show how Bayesian inference can be leveraged to reliably infer forces by taking into account such spurious forces of unknown amplitude as well as experimental sources of error. The method is based on marginalizing the force posterior over all possible spurious force contributions. The approach is combined with a Bayes factor statistical test for the presence of forces. The performance of our method is investigated analytically, numerically and tested on experimental data sets. The main results are obtained in a closed form allowing for direct exploration of their properties and fast computation. The method is incorporated into TRamWAy, an open-source software platform for automated analysis of biomolecule trajectories.},
  journal={arXiv}
}

@article{shang2023active,
  title={Active Vision Reinforcement Learning under Limited Visual Observability},
  author={Jinghuan Shang and Michael S. Ryoo},
  year={2023},
  url={http://arxiv.org/abs/2306.00975v2},
  abstract={In this work, we investigate Active Vision Reinforcement Learning (ActiveVision-RL), where an embodied agent simultaneously learns action policy for the task while also controlling its visual observations in partially observable environments. We denote the former as motor policy and the latter as sensory policy. For example, humans solve real world tasks by hand manipulation (motor policy) together with eye movements (sensory policy). ActiveVision-RL poses challenges on coordinating two policies given their mutual influence. We propose SUGARL, Sensorimotor Understanding Guided Active Reinforcement Learning, a framework that models motor and sensory policies separately, but jointly learns them using with an intrinsic sensorimotor reward. This learnable reward is assigned by sensorimotor reward module, incentivizes the sensory policy to select observations that are optimal to infer its own motor action, inspired by the sensorimotor stage of humans. Through a series of experiments, we show the effectiveness of our method across a range of observability conditions and its adaptability to existed RL algorithms. The sensory policies learned through our method are observed to exhibit effective active vision strategies.},
  journal={arXiv}
}

@article{desai2022steady,
  title={Steady state propulsion of isotropic active colloids along a wall},
  author={Nikhil Desai and Sebastien Michelin},
  year={2022},
  url={http://arxiv.org/abs/2209.07371v1},
  abstract={Active drops emit/absorb chemical solutes, whose concentration gradients cause interfacial flows driving their own transport and the propulsion of the droplet. Such non-linear coupling enables active drops to achieve directed self-propulsion despite their isotropy, if the ratio of advective-to-diffusive solute transport, i.e. the Peclet number Pe, is larger than a finite critical threshold. In most experimental situations, active drops are non-neutrally buoyant and thus swim along rigid surfaces; yet theoretical descriptions of their non-linear motion focus almost exclusively on unbounded domains to circumvent geometric complexity. To overcome this gap in understanding, we investigate the spontaneous emergence and nonlinear saturation of propulsion of an isotropic phoretic colloid along a rigid wall, to which it is confined by a constant external force (e.g., gravity). This phoretic particle model is considered here as a limiting case for a viscous active drop. We show that, for moderate Pe, the particle motion and associated chemical transport reduce the chemically-induced wall repulsion, thereby causing the particle to swim progressively closer to the wall as Pe increases. Far from hindering self-propulsion, this reduction in the particle-wall separation is accompanied by a wall-induced efficient rearrangement of the solute concentration gradients driving the particle, thus augmenting its swimming speed.},
  doi={10.1103/PhysRevFluids.7.100501},
  journal={arXiv}
}

@article{nikulin2011evaluation,
  title={On the Evaluation Criterions for the Active Learning Processes},
  author={Vladimir Nikulin},
  year={2011},
  url={http://arxiv.org/abs/1108.0453v1},
  abstract={In many data mining applications collection of sufficiently large datasets is the most time consuming and expensive. On the other hand, industrial methods of data collection create huge databases, and make difficult direct applications of the advanced machine learning algorithms. To address the above problems, we consider active learning (AL), which may be very efficient either for the experimental design or for the data filtering. In this paper we demonstrate using the online evaluation opportunity provided by the AL Challenge that quite competitive results may be produced using a small percentage of the available data. Also, we present several alternative criteria, which may be useful for the evaluation of the active learning processes. The author of this paper attended special presentation in Barcelona, where results of the WCCI 2010 AL Challenge were discussed.},
  journal={arXiv}
}

@article{thomas2025attack,
  title={An Attack to Break Permutation-Based Private Third-Party Inference Schemes for LLMs},
  author={Rahul Thomas and Louai Zahran and Erica Choi and Akilesh Potti and Micah Goldblum and Arka Pal},
  year={2025},
  url={http://arxiv.org/abs/2505.18332v1},
  abstract={Recent advances in Large Language Models (LLMs) have led to the widespread adoption of third-party inference services, raising critical privacy concerns. Existing methods of performing private third-party inference, such as Secure Multiparty Computation (SMPC), often rely on cryptographic methods. However, these methods are thousands of times slower than standard unencrypted inference, and fail to scale to large modern LLMs. Therefore, recent lines of work have explored the replacement of expensive encrypted nonlinear computations in SMPC with statistical obfuscation methods - in particular, revealing permuted hidden states to the third parties, with accompanying strong claims of the difficulty of reversal into the unpermuted states. In this work, we begin by introducing a novel reconstruction technique that can recover original prompts from hidden states with nearly perfect accuracy across multiple state-of-the-art LLMs. We then show that extensions of our attack are nearly perfectly effective in reversing permuted hidden states of LLMs, demonstrating the insecurity of three recently proposed privacy schemes. We further dissect the shortcomings of prior theoretical `proofs' of permuation security which allow our attack to succeed. Our findings highlight the importance of rigorous security analysis in privacy-preserving LLM inference.},
  journal={arXiv}
}

@article{kostecki2011principles,
  title={On principles of inductive inference},
  author={Ryszard Paweł Kostecki},
  year={2011},
  url={http://arxiv.org/abs/1109.3142v4},
  abstract={We propose an intersubjective epistemic approach to foundations of probability theory and statistical inference, based on relative entropy and category theory, and aimed to bypass the mathematical and conceptual problems of existing foundational approaches.},
  journal={arXiv}
}

@article{lu2023bayesian,
  title={Bayesian inference with finitely wide neural networks},
  author={Chi-Ken Lu},
  year={2023},
  url={http://arxiv.org/abs/2303.02859v2},
  abstract={The analytic inference, e.g. predictive distribution being in closed form, may be an appealing benefit for machine learning practitioners when they treat wide neural networks as Gaussian process in Bayesian setting. The realistic widths, however, are finite and cause weak deviation from the Gaussianity under which partial marginalization of random variables in a model is straightforward. On the basis of multivariate Edgeworth expansion, we propose a non-Gaussian distribution in differential form to model a finite set of outputs from a random neural network, and derive the corresponding marginal and conditional properties. Thus, we are able to derive the non-Gaussian posterior distribution in Bayesian regression task. In addition, in the bottlenecked deep neural networks, a weight space representation of deep Gaussian process, the non-Gaussianity is investigated through the marginal kernel.},
  doi={10.1103/PhysRevE.108.014311},
  journal={arXiv}
}

@article{champion2021realising,
  title={Realising Active Inference in Variational Message Passing: the Outcome-blind Certainty Seeker},
  author={Théophile Champion and Marek Grześ and Howard Bowman},
  year={2021},
  url={http://arxiv.org/abs/2104.11798v1},
  abstract={Active inference is a state-of-the-art framework in neuroscience that offers a unified theory of brain function. It is also proposed as a framework for planning in AI. Unfortunately, the complex mathematics required to create new models -- can impede application of active inference in neuroscience and AI research. This paper addresses this problem by providing a complete mathematical treatment of the active inference framework -- in discrete time and state spaces -- and the derivation of the update equations for any new model. We leverage the theoretical connection between active inference and variational message passing as describe by John Winn and Christopher M. Bishop in 2005. Since, variational message passing is a well-defined methodology for deriving Bayesian belief update equations, this paper opens the door to advanced generative models for active inference. We show that using a fully factorized variational distribution simplifies the expected free energy -- that furnishes priors over policies -- so that agents seek unambiguous states. Finally, we consider future extensions that support deep tree searches for sequential policy optimisation -- based upon structure learning and belief propagation.},
  journal={arXiv}
}

@article{noroozizadeh2025impact,
  title={The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis},
  author={Shahriar Noroozizadeh and Pim Welle and Jeremy C. Weiss and George H. Chen},
  year={2025},
  url={http://arxiv.org/abs/2506.18187v1},
  abstract={This study quantifies the association between non-adherence to antipsychotic medications and adverse outcomes in individuals with schizophrenia. We frame the problem using survival analysis, focusing on the time to the earliest of several adverse events (early death, involuntary hospitalization, jail booking). We extend standard causal inference methods (T-learner, S-learner, nearest neighbor matching) to utilize various survival models to estimate individual and average treatment effects, where treatment corresponds to medication non-adherence. Analyses are repeated using different amounts of longitudinal information (3, 6, 9, and 12 months). Using data from Allegheny County in western Pennsylvania, we find strong evidence that non-adherence advances adverse outcomes by approximately 1 to 4 months. Ablation studies confirm that county-provided risk scores adjust for key confounders, as their removal amplifies the estimated effects. Subgroup analyses by medication formulation (injectable vs. oral) and medication type consistently show that non-adherence is associated with earlier adverse events. These findings highlight the clinical importance of adherence in delaying psychiatric crises and show that integrating survival analysis with causal inference tools can yield policy-relevant insights. We caution that although we apply causal inference, we only make associative claims and discuss assumptions needed for causal interpretation.},
  journal={arXiv}
}

@article{ferianc2021causal,
  title={On Causal Inference for Data-free Structured Pruning},
  author={Martin Ferianc and Anush Sankaran and Olivier Mastropietro and Ehsan Saboori and Quentin Cappart},
  year={2021},
  url={http://arxiv.org/abs/2112.10229v1},
  abstract={Neural networks (NNs) are making a large impact both on research and industry. Nevertheless, as NNs' accuracy increases, it is followed by an expansion in their size, required number of compute operations and energy consumption. Increase in resource consumption results in NNs' reduced adoption rate and real-world deployment impracticality. Therefore, NNs need to be compressed to make them available to a wider audience and at the same time decrease their runtime costs. In this work, we approach this challenge from a causal inference perspective, and we propose a scoring mechanism to facilitate structured pruning of NNs. The approach is based on measuring mutual information under a maximum entropy perturbation, sequentially propagated through the NN. We demonstrate the method's performance on two datasets and various NNs' sizes, and we show that our approach achieves competitive performance under challenging conditions.},
  journal={arXiv}
}

@article{paul2024predictive,
  title={On Predictive planning and counterfactual learning in active inference},
  author={Aswin Paul and Takuya Isomura and Adeel Razi},
  year={2024},
  url={http://arxiv.org/abs/2403.12417v1},
  abstract={Given the rapid advancement of artificial intelligence, understanding the foundations of intelligent behaviour is increasingly important. Active inference, regarded as a general theory of behaviour, offers a principled approach to probing the basis of sophistication in planning and decision-making. In this paper, we examine two decision-making schemes in active inference based on 'planning' and 'learning from experience'. Furthermore, we also introduce a mixed model that navigates the data-complexity trade-off between these strategies, leveraging the strengths of both to facilitate balanced decision-making. We evaluate our proposed model in a challenging grid-world scenario that requires adaptability from the agent. Additionally, our model provides the opportunity to analyze the evolution of various parameters, offering valuable insights and contributing to an explainable framework for intelligent decision-making.},
  doi={10.3390/e26060484},
  journal={arXiv}
}

@article{lanillos2021active,
  title={Active Inference in Robotics and Artificial Agents: Survey and Challenges},
  author={Pablo Lanillos and Cristian Meo and Corrado Pezzato and Ajith Anil Meera and Mohamed Baioumy and Wataru Ohata and Alexander Tschantz and Beren Millidge and Martijn Wisse and Christopher L. Buckley and Jun Tani},
  year={2021},
  url={http://arxiv.org/abs/2112.01871v1},
  abstract={Active inference is a mathematical framework which originated in computational neuroscience as a theory of how the brain implements action, perception and learning. Recently, it has been shown to be a promising approach to the problems of state-estimation and control under uncertainty, as well as a foundation for the construction of goal-driven behaviours in robotics and artificial agents in general. Here, we review the state-of-the-art theory and implementations of active inference for state-estimation, control, planning and learning; describing current achievements with a particular focus on robotics. We showcase relevant experiments that illustrate its potential in terms of adaptation, generalization and robustness. Furthermore, we connect this approach with other frameworks and discuss its expected benefits and challenges: a unified framework with functional biological plausibility using variational Bayesian inference.},
  journal={arXiv}
}

@article{drémeau2014statistical,
  title={Statistical inference with probabilistic graphical models},
  author={Angélique Drémeau and Christophe Schülke and Yingying Xu and Devavrat Shah},
  year={2014},
  url={http://arxiv.org/abs/1409.4928v1},
  abstract={These are notes from the lecture of Devavrat Shah given at the autumn school "Statistical Physics, Optimization, Inference, and Message-Passing Algorithms", that took place in Les Houches, France from Monday September 30th, 2013, till Friday October 11th, 2013. The school was organized by Florent Krzakala from UPMC & ENS Paris, Federico Ricci-Tersenghi from La Sapienza Roma, Lenka Zdeborova from CEA Saclay & CNRS, and Riccardo Zecchina from Politecnico Torino. This lecture of Devavrat Shah (MIT) covers the basics of inference and learning. It explains how inference problems are represented within structures known as graphical models. The theoretical basis of the belief propagation algorithm is then explained and derived. This lecture sets the stage for generalizations and applications of message passing algorithms.},
  journal={arXiv}
}

@article{park2020largescale,
  title={Large-Scale Gravitational Lens Modeling with Bayesian Neural Networks for Accurate and Precise Inference of the Hubble Constant},
  author={Ji Won Park and Sebastian Wagner-Carena and Simon Birrer and Philip J. Marshall and Joshua Yao-Yu Lin and Aaron Roodman},
  year={2020},
  url={http://arxiv.org/abs/2012.00042v2},
  abstract={We investigate the use of approximate Bayesian neural networks (BNNs) in modeling hundreds of time-delay gravitational lenses for Hubble constant ($H_0$) determination. Our BNN was trained on synthetic HST-quality images of strongly lensed active galactic nuclei (AGN) with lens galaxy light included. The BNN can accurately characterize the posterior PDFs of model parameters governing the elliptical power-law mass profile in an external shear field. We then propagate the BNN-inferred posterior PDFs into ensemble $H_0$ inference, using simulated time delay measurements from a plausible dedicated monitoring campaign. Assuming well-measured time delays and a reasonable set of priors on the environment of the lens, we achieve a median precision of $9.3$\% per lens in the inferred $H_0$. A simple combination of 200 test-set lenses results in a precision of 0.5 $\textrm{km s}^{-1} \textrm{ Mpc}^{-1}$ ($0.7\%$), with no detectable bias in this $H_0$ recovery test. The computation time for the entire pipeline -- including the training set generation, BNN training, and $H_0$ inference -- translates to 9 minutes per lens on average for 200 lenses and converges to 6 minutes per lens as the sample size is increased. Being fully automated and efficient, our pipeline is a promising tool for exploring ensemble-level systematics in lens modeling for $H_0$ inference.},
  doi={10.3847/1538-4357/abdfc4},
  journal={arXiv}
}

@article{wauthier2022learning,
  title={Learning Generative Models for Active Inference using Tensor Networks},
  author={Samuel T. Wauthier and Bram Vanhecke and Tim Verbelen and Bart Dhoedt},
  year={2022},
  url={http://arxiv.org/abs/2208.08713v2},
  abstract={Active inference provides a general framework for behavior and learning in autonomous agents. It states that an agent will attempt to minimize its variational free energy, defined in terms of beliefs over observations, internal states and policies. Traditionally, every aspect of a discrete active inference model must be specified by hand, i.e. by manually defining the hidden state space structure, as well as the required distributions such as likelihood and transition probabilities. Recently, efforts have been made to learn state space representations automatically from observations using deep neural networks. In this paper, we present a novel approach of learning state spaces using quantum physics-inspired tensor networks. The ability of tensor networks to represent the probabilistic nature of quantum states as well as to reduce large state spaces makes tensor networks a natural candidate for active inference. We show how tensor networks can be used as a generative model for sequential data. Furthermore, we show how one can obtain beliefs from such a generative model and how an active inference agent can use these to compute the expected free energy. Finally, we demonstrate our method on the classic T-maze environment.},
  journal={arXiv}
}

@article{singh2021guided,
  title={Guided run-and-tumble active particles: wall accumulation and preferential deposition},
  author={Chamkor Singh},
  year={2021},
  url={http://arxiv.org/abs/2112.02697v1},
  abstract={Bacterial biofilms cost an enormous amount of resources in the health, medical, and industrial sectors. To understand early biofilm formation, beginning from planktonic states of active bacterial suspensions (such as Escherichia coli) to microcolonization, it is vital to study the mechanics of accumulation near surfaces and subsequent deposition. In this study, analytical expressions for the mean orientation, density and angular distributions, and deposition rates in such bacterial suspensions are derived, with and without the effects of external guiding or taxis fields. Simulations of confined active particles, using the run-and-tumble statistics from well-established three-dimensional tracking experiments and a preferential sticking probability model for deposition, closely verify the derived mean orientation, density profiles, angular distributions, and deposition rates. It is found that the size distribution of deposited microcolonies remains unaffected when guiding fields are applied, however, the pair correlation function of deposited structures relatively spreads out. The factor behind the changes in the accumulation patterns, and the changes in the architecture of deposited biomass, turns out to be an asymmetrical rotational drift caused by the guiding fields, and is an important physical mechanism behind the organization in confined active particle suspensions.},
  doi={10.1039/d1sm00775k},
  journal={arXiv}
}

@article{heckerman2018accounting,
  title={Accounting for hidden common causes when inferring cause and effect from observational data},
  author={David Heckerman},
  year={2018},
  url={http://arxiv.org/abs/1801.00727v2},
  abstract={Identifying causal relationships from observation data is difficult, in large part, due to the presence of hidden common causes. In some cases, where just the right patterns of conditional independence and dependence lie in the data---for example, Y-structures---it is possible to identify cause and effect. In other cases, the analyst deliberately makes an uncertain assumption that hidden common causes are absent, and infers putative causal relationships to be tested in a randomized trial. Here, we consider a third approach, where there are sufficient clues in the data such that hidden common causes can be inferred.},
  journal={arXiv}
}

@article{fountas2020deep,
  title={Deep active inference agents using Monte-Carlo methods},
  author={Zafeirios Fountas and Noor Sajid and Pedro A. M. Mediano and Karl Friston},
  year={2020},
  url={http://arxiv.org/abs/2006.04176v2},
  abstract={Active inference is a Bayesian framework for understanding biological intelligence. The underlying theory brings together perception and action under one single imperative: minimizing free energy. However, despite its theoretical utility in explaining intelligence, computational implementations have been restricted to low-dimensional and idealized situations. In this paper, we present a neural architecture for building deep active inference agents operating in complex, continuous state-spaces using multiple forms of Monte-Carlo (MC) sampling. For this, we introduce a number of techniques, novel to active inference. These include: i) selecting free-energy-optimal policies via MC tree search, ii) approximating this optimal policy distribution via a feed-forward `habitual' network, iii) predicting future parameter belief updates using MC dropouts and, finally, iv) optimizing state transition precision (a high-end form of attention). Our approach enables agents to learn environmental dynamics efficiently, while maintaining task performance, in relation to reward-based counterparts. We illustrate this in a new toy environment, based on the dSprites data-set, and demonstrate that active inference agents automatically create disentangled representations that are apt for modeling state transitions. In a more complex Animal-AI environment, our agents (using the same neural architecture) are able to simulate future state transitions and actions (i.e., plan), to evince reward-directed navigation - despite temporary suspension of visual input. These results show that deep active inference - equipped with MC methods - provides a flexible framework to develop biologically-inspired intelligent agents, with applications in both machine learning and cognitive science.},
  journal={arXiv}
}

@article{meo2021adaptation,
  title={Adaptation through prediction: multisensory active inference torque control},
  author={Cristian Meo and Giovanni Franzese and Corrado Pezzato and Max Spahn and Pablo Lanillos},
  year={2021},
  url={http://arxiv.org/abs/2112.06752v1},
  abstract={Adaptation to external and internal changes is major for robotic systems in uncertain environments. Here we present a novel multisensory active inference torque controller for industrial arms that shows how prediction can be used to resolve adaptation. Our controller, inspired by the predictive brain hypothesis, improves the capabilities of current active inference approaches by incorporating learning and multimodal integration of low and high-dimensional sensor inputs (e.g., raw images) while simplifying the architecture. We performed a systematic evaluation of our model on a 7DoF Franka Emika Panda robot arm by comparing its behavior with previous active inference baselines and classic controllers, analyzing both qualitatively and quantitatively adaptation capabilities and control accuracy. Results showed improved control accuracy in goal-directed reaching with high noise rejection due to multimodal filtering, and adaptability to dynamical inertial changes, elasticity constraints and human disturbances without the need to relearn the model nor parameter retuning.},
  journal={arXiv}
}

@article{schöpp2022inferring,
  title={Inferring Region Types via an Abstract Notion of Environment Transformation},
  author={Ulrich Schöpp and Chuangjie Xu},
  year={2022},
  url={http://arxiv.org/abs/2209.02147v2},
  abstract={Region-based type systems are a powerful tool for various kinds of program analysis. We introduce a new inference algorithm for region types based on an abstract notion of environment transformation. It analyzes the code of a method only once, even when there are multiple invocations of the method of different region types in the program. Elements of such an abstract transformation are essentially constraints for equality and subtyping that capture flow information of the program. In particular, we work with access graphs in the definition of abstract transformations to guarantee the termination of the inference algorithm, because they provide a finite representation of field access paths.},
  journal={arXiv}
}

@article{prakki2024demonstrating,
  title={Demonstrating the Continual Learning Capabilities and Practical Application of Discrete-Time Active Inference},
  author={Rithvik Prakki},
  year={2024},
  url={http://arxiv.org/abs/2410.00240v1},
  abstract={Active inference is a mathematical framework for understanding how agents (biological or artificial) interact with their environments, enabling continual adaptation and decision-making. It combines Bayesian inference and free energy minimization to model perception, action, and learning in uncertain and dynamic contexts. Unlike reinforcement learning, active inference integrates exploration and exploitation seamlessly by minimizing expected free energy. In this paper, we present a continual learning framework for agents operating in discrete time environments, using active inference as the foundation. We derive the mathematical formulations of variational and expected free energy and apply them to the design of a self-learning research agent. This agent updates its beliefs and adapts its actions based on new data without manual intervention. Through experiments in changing environments, we demonstrate the agent's ability to relearn and refine its models efficiently, making it suitable for complex domains like finance and healthcare. The paper concludes by discussing how the proposed framework generalizes to other systems, positioning active inference as a flexible approach for adaptive AI.},
  journal={arXiv}
}

@article{forneron2022estimation,
  title={Estimation and Inference by Stochastic Optimization},
  author={Jean-Jacques Forneron},
  year={2022},
  url={http://arxiv.org/abs/2205.03254v1},
  abstract={In non-linear estimations, it is common to assess sampling uncertainty by bootstrap inference. For complex models, this can be computationally intensive. This paper combines optimization with resampling: turning stochastic optimization into a fast resampling device. Two methods are introduced: a resampled Newton-Raphson (rNR) and a resampled quasi-Newton (rqN) algorithm. Both produce draws that can be used to compute consistent estimates, confidence intervals, and standard errors in a single run. The draws are generated by a gradient and Hessian (or an approximation) computed from batches of data that are resampled at each iteration. The proposed methods transition quickly from optimization to resampling when the objective is smooth and strictly convex. Simulated and empirical applications illustrate the properties of the methods on large scale and computationally intensive problems. Comparisons with frequentist and Bayesian methods highlight the features of the algorithms.},
  journal={arXiv}
}

@article{gentile2022fast,
  title={Fast Rates in Pool-Based Batch Active Learning},
  author={Claudio Gentile and Zhilei Wang and Tong Zhang},
  year={2022},
  url={http://arxiv.org/abs/2202.05448v2},
  abstract={We consider a batch active learning scenario where the learner adaptively issues batches of points to a labeling oracle. Sampling labels in batches is highly desirable in practice due to the smaller number of interactive rounds with the labeling oracle (often human beings). However, batch active learning typically pays the price of a reduced adaptivity, leading to suboptimal results. In this paper we propose a solution which requires a careful trade off between the informativeness of the queried points and their diversity. We theoretically investigate batch active learning in the practically relevant scenario where the unlabeled pool of data is available beforehand ({\em pool-based} active learning). We analyze a novel stage-wise greedy algorithm and show that, as a function of the label complexity, the excess risk of this algorithm matches the known minimax rates in standard statistical learning settings. Our results also exhibit a mild dependence on the batch size. These are the first theoretical results that employ careful trade offs between informativeness and diversity to rigorously quantify the statistical performance of batch active learning in the pool-based scenario.},
  journal={arXiv}
}

@article{zhang2022active,
  title={Active RISs: Signal Modeling, Asymptotic Analysis, and Beamforming Design},
  author={Zijian Zhang and Linglong Dai and Xibi Chen and Changhao Liu and Fan Yang and Robert Schober and H. Vincent Poor},
  year={2022},
  url={http://arxiv.org/abs/2301.00161v1},
  abstract={Reconfigurable intelligent surfaces (RISs) have emerged as a candidate technology for future 6G networks. However, due to the "multiplicative fading" effect, the existing passive RISs only achieve a negligible capacity gain in environments with strong direct links. In this paper, the concept of active RISs is studied to overcome this fundamental limitation. Unlike the existing passive RISs that reflect signals without amplification, active RISs can amplify the reflected signals via amplifiers integrated into their elements. To characterize the signal amplification and incorporate the noise introduced by the active components, we verify the signal model of active RISs through the experimental measurements on a fabricated active RIS element. Based on the verified signal model, we formulate the sum-rate maximization problem for an active RIS aided multi-user multiple-input single-output (MU-MISO) system and a joint transmit precoding and reflect beamforming algorithm is proposed to solve this problem. Simulation results show that, in a typical wireless system, the existing passive RISs can realize only a negligible sum-rate gain of 3%, while the active RISs can achieve a significant sum-rate gain of 62%, thus overcoming the "multiplicative fading" effect. Finally, we develop a 64-element active RIS aided wireless communication prototype, and the significant gain of active RISs is validated by field test.},
  doi={10.1109/GLOBECOM48099.2022.10001687},
  journal={arXiv}
}

@article{mackinnon2024clusterrobust,
  title={Cluster-robust jackknife and bootstrap inference for logistic regression models},
  author={James G. MacKinnon and Morten Ørregaard Nielsen and Matthew D. Webb},
  year={2024},
  url={http://arxiv.org/abs/2406.00650v2},
  abstract={We study cluster-robust inference for logistic regression (logit) models. Inference based on the most commonly-used cluster-robust variance matrix estimator (CRVE) can be very unreliable. We study several alternatives. Conceptually the simplest of these, but also the most computationally demanding, involves jackknifing at the cluster level. We also propose a linearized version of the cluster-jackknife variance matrix estimator as well as linearized versions of the wild cluster bootstrap. The linearizations are based on empirical scores and are computationally efficient. Our results can readily be generalized to other binary response models. We also discuss a new Stata software package called logitjack which implements these procedures. Simulation results strongly favor the new methods, and two empirical examples suggest that it can be important to use them in practice.},
  journal={arXiv}
}

@article{liu2023neural,
  title={A Neural Network Implementation for Free Energy Principle},
  author={Jingwei Liu},
  year={2023},
  url={http://arxiv.org/abs/2306.06792v1},
  abstract={The free energy principle (FEP), as an encompassing framework and a unified brain theory, has been widely applied to account for various problems in fields such as cognitive science, neuroscience, social interaction, and hermeneutics. As a computational model deeply rooted in math and statistics, FEP posits an optimization problem based on variational Bayes, which is solved either by dynamic programming or expectation maximization in practice. However, there seems to be a bottleneck in extending the FEP to machine learning and implementing such models with neural networks. This paper gives a preliminary attempt at bridging FEP and machine learning, via a classical neural network model, the Helmholtz machine. As a variational machine learning model, the Helmholtz machine is optimized by minimizing its free energy, the same objective as FEP. Although the Helmholtz machine is not temporal, it gives an ideal parallel to the vanilla FEP and the hierarchical model of the brain, under which the active inference and predictive coding could be formulated coherently. Besides a detailed theoretical discussion, the paper also presents a preliminary experiment to validate the hypothesis. By fine-tuning the trained neural network through active inference, the model performance is promoted to accuracy above 99\%. In the meantime, the data distribution is continuously deformed to a salience that conforms to the model representation, as a result of active sampling.},
  journal={arXiv}
}

@article{parisot2021property,
  title={Property Inference Attacks on Convolutional Neural Networks: Influence and Implications of Target Model's Complexity},
  author={Mathias P. M. Parisot and Balazs Pejo and Dayana Spagnuelo},
  year={2021},
  url={http://arxiv.org/abs/2104.13061v1},
  abstract={Machine learning models' goal is to make correct predictions for specific tasks by learning important properties and patterns from data. By doing so, there is a chance that the model learns properties that are unrelated to its primary task. Property Inference Attacks exploit this and aim to infer from a given model (\ie the target model) properties about the training dataset seemingly unrelated to the model's primary goal. If the training data is sensitive, such an attack could lead to privacy leakage. This paper investigates the influence of the target model's complexity on the accuracy of this type of attack, focusing on convolutional neural network classifiers. We perform attacks on models that are trained on facial images to predict whether someone's mouth is open. Our attacks' goal is to infer whether the training dataset is balanced gender-wise. Our findings reveal that the risk of a privacy breach is present independently of the target model's complexity: for all studied architectures, the attack's accuracy is clearly over the baseline. We discuss the implication of the property inference on personal data in the light of Data Protection Regulations and Guidelines.},
  journal={arXiv}
}

@article{kenny2025active,
  title={Active Inference in Discrete State Spaces from First Principles},
  author={Patrick Kenny},
  year={2025},
  url={http://arxiv.org/abs/2511.20321v1},
  abstract={We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.},
  journal={arXiv}
}

@article{baltieri2020predictions,
  title={Predictions in the eye of the beholder: an active inference account of Watt governors},
  author={Manuel Baltieri and Christopher L. Buckley and Jelle Bruineberg},
  year={2020},
  url={http://arxiv.org/abs/2006.11495v2},
  abstract={Active inference introduces a theory describing action-perception loops via the minimisation of variational (and expected) free energy or, under simplifying assumptions, (weighted) prediction error. Recently, active inference has been proposed as part of a new and unifying framework in the cognitive sciences: predictive processing. Predictive processing is often associated with traditional computational theories of the mind, strongly relying on internal representations presented in the form of generative models thought to explain different functions of living and cognitive systems. In this work, we introduce an active inference formulation of the Watt centrifugal governor, a system often portrayed as the canonical "anti-representational" metaphor for cognition. We identify a generative model of a steam engine for the governor, and derive a set of equations describing "perception" and "action" processes as a form of prediction error minimisation. In doing so, we firstly challenge the idea of generative models as explicit internal representations for cognitive systems, suggesting that such models serve only as implicit descriptions for an observer. Secondly, we consider current proposals of predictive processing as a theory of cognition, focusing on some of its potential shortcomings and in particular on the idea that virtually any system admits a description in terms of prediction error minimisation, suggesting that this theory may offer limited explanatory power for cognitive systems. Finally, as a silver lining we emphasise the instrumental role this framework can nonetheless play as a mathematical tool for modelling cognitive architectures interpreted in terms of Bayesian (active) inference.},
  doi={10.1162/isal_a_00288},
  journal={arXiv}
}

@article{atchadé2021fast,
  title={A fast asynchronous MCMC sampler for sparse Bayesian inference},
  author={Yves Atchadé and Liwei Wang},
  year={2021},
  url={http://arxiv.org/abs/2108.06446v1},
  abstract={We propose a very fast approximate Markov Chain Monte Carlo (MCMC) sampling framework that is applicable to a large class of sparse Bayesian inference problems, where the computational cost per iteration in several models is of order $O(ns)$, where $n$ is the sample size, and $s$ the underlying sparsity of the model. This cost can be further reduced by data sub-sampling when stochastic gradient Langevin dynamics are employed. The algorithm is an extension of the asynchronous Gibbs sampler of Johnson et al. (2013), but can be viewed from a statistical perspective as a form of Bayesian iterated sure independent screening (Fan et al. (2009)). We show that in high-dimensional linear regression problems, the Markov chain generated by the proposed algorithm admits an invariant distribution that recovers correctly the main signal with high probability under some statistical assumptions. Furthermore we show that its mixing time is at most linear in the number of regressors. We illustrate the algorithm with several models.},
  journal={arXiv}
}

@article{dey2023dietcnn,
  title={DietCNN: Multiplication-free Inference for Quantized CNNs},
  author={Swarnava Dey and Pallab Dasgupta and Partha P Chakrabarti},
  year={2023},
  url={http://arxiv.org/abs/2305.05274v2},
  abstract={The rising demand for networked embedded systems with machine intelligence has been a catalyst for sustained attempts by the research community to implement Convolutional Neural Networks (CNN) based inferencing on embedded resource-limited devices. Redesigning a CNN by removing costly multiplication operations has already shown promising results in terms of reducing inference energy usage. This paper proposes a new method for replacing multiplications in a CNN by table look-ups. Unlike existing methods that completely modify the CNN operations, the proposed methodology preserves the semantics of the major CNN operations. Conforming to the existing mechanism of the CNN layer operations ensures that the reliability of a standard CNN is preserved. It is shown that the proposed multiplication-free CNN, based on a single activation codebook, can achieve 4.7x, 5.6x, and 3.5x reduction in energy per inference in an FPGA implementation of MNIST-LeNet-5, CIFAR10-VGG-11, and Tiny ImageNet-ResNet-18 respectively. Our results show that the DietCNN approach significantly improves the resource consumption and latency of deep inference for smaller models, often used in embedded systems. Our code is available at: https://github.com/swadeykgp/DietCNN},
  doi={10.1109/IJCNN54540.2023.10191771},
  journal={arXiv}
}

@article{ofner2018hybrid,
  title={Hybrid Active Inference},
  author={André Ofner and Sebastian Stober},
  year={2018},
  url={http://arxiv.org/abs/1810.02647v1},
  abstract={We describe a framework of hybrid cognition by formulating a hybrid cognitive agent that performs hierarchical active inference across a human and a machine part. We suggest that, in addition to enhancing human cognitive functions with an intelligent and adaptive interface, integrated cognitive processing could accelerate emergent properties within artificial intelligence. To establish this, a machine learning part learns to integrate into human cognition by explaining away multi-modal sensory measurements from the environment and physiology simultaneously with the brain signal. With ongoing training, the amount of predictable brain signal increases. This lends the agent the ability to self-supervise on increasingly high levels of cognitive processing in order to further minimize surprise in predicting the brain signal. Furthermore, with increasing level of integration, the access to sensory information about environment and physiology is substituted with access to their representation in the brain. While integrating into a joint embodiment of human and machine, human action and perception are treated as the machine's own. The framework can be implemented with invasive as well as non-invasive sensors for environment, body and brain interfacing. Online and offline training with different machine learning approaches are thinkable. Building on previous research on shared representation learning, we suggest a first implementation leading towards hybrid active inference with non-invasive brain interfacing and state of the art probabilistic deep learning methods. We further discuss how implementation might have effect on the meta-cognitive abilities of the described agent and suggest that with adequate implementation the machine part can continue to execute and build upon the learned cognitive processes autonomously.},
  journal={arXiv}
}

@article{marghi2020active,
  title={Active recursive Bayesian inference using Rényi information measures},
  author={Yeganeh M. Marghi and Aziz Kocanaogullari and Murat Akcakaya and Deniz Erdogmus},
  year={2020},
  url={http://arxiv.org/abs/2004.03139v2},
  abstract={Recursive Bayesian inference (RBI) provides optimal Bayesian latent variable estimates in real-time settings with streaming noisy observations. Active RBI attempts to effectively select queries that lead to more informative observations to rapidly reduce uncertainty until a confident decision is made. However, typically the optimality objectives of inference and query mechanisms are not jointly selected. Furthermore, conventional active querying methods stagger due to misleading prior information. Motivated by information theoretic approaches, we propose an active RBI framework with unified inference and query selection steps through Renyi entropy and $α$-divergence. We also propose a new objective based on Renyi entropy and its changes called Momentum that encourages exploration for misleading prior cases. The proposed active RBI framework is applied to the trajectory of the posterior changes in the probability simplex that provides a coordinated active querying and decision making with specified confidence. Under certain assumptions, we analytically demonstrate that the proposed approach outperforms conventional methods such as mutual information by allowing the selections of unlikely events. We present empirical and experimental performance evaluations on two applications: restaurant recommendation and brain-computer interface (BCI) typing systems.},
  journal={arXiv}
}

@article{storchibergmann2007observational,
  title={Observational Overview of the Feeding of Active Galactic Nuclei},
  author={Thaisa Storchi-Bergmann},
  year={2007},
  url={http://arxiv.org/abs/0712.3747v1},
  abstract={I present an overview of the observational signatures of feeding of Active Galactic Nuclei, discussing briefly the role of interactions among galaxies on extragalactic scales, and of non-axisymmetric gravitational potentials -- such as bars -- on galactic scales. Then I discuss at larger length the feeding signatures on hundred of parsec scales, for which new results include: (1) recent star formation surrounding the active nucleus on tens of parsec scales; (2) excess of gas and dust in active galaxies relative to non-active ones, in the form of nuclear spirals and disks; (3) new kinematic signatures of gas inflow along nuclear spiral arms, which may be the long sought mechanism to bring gas from kiloparsec scales down to the nucleus to feed the supermassive black hole.},
  journal={arXiv}
}

@article{sabato2014active,
  title={Active Regression by Stratification},
  author={Sivan Sabato and Remi Munos},
  year={2014},
  url={http://arxiv.org/abs/1410.5920v1},
  abstract={We propose a new active learning algorithm for parametric linear regression with random design. We provide finite sample convergence guarantees for general distributions in the misspecified model. This is the first active learner for this setting that provably can improve over passive learning. Unlike other learning settings (such as classification), in regression the passive learning rate of $O(1/ε)$ cannot in general be improved upon. Nonetheless, the so-called `constant' in the rate of convergence, which is characterized by a distribution-dependent risk, can be improved in many cases. For a given distribution, achieving the optimal risk requires prior knowledge of the distribution. Following the stratification technique advocated in Monte-Carlo function integration, our active learner approaches the optimal risk using piecewise constant approximations.},
  journal={arXiv}
}

@article{delavari2024towards,
  title={Towards Human-Like Driving: Active Inference in Autonomous Vehicle Control},
  author={Elahe Delavari and John Moore and Junho Hong and Jaerock Kwon},
  year={2024},
  url={http://arxiv.org/abs/2407.07684v2},
  abstract={This paper presents a novel approach to Autonomous Vehicle (AV) control through the application of active inference, a theory derived from neuroscience that conceptualizes the brain as a predictive machine. Traditional autonomous driving systems rely heavily on Modular Pipelines, Imitation Learning, or Reinforcement Learning, each with inherent limitations in adaptability, generalization, and computational efficiency. Active inference addresses these challenges by minimizing prediction error (termed "surprise") through a dynamic model that balances perception and action. Our method integrates active inference with deep learning to manage lateral control in AVs, enabling them to perform lane following maneuvers within a simulated urban environment. We demonstrate that our model, despite its simplicity, effectively learns and generalizes from limited data without extensive retraining, significantly reducing computational demands. The proposed approach not only enhances the adaptability and performance of AVs in dynamic scenarios but also aligns closely with human-like driving behavior, leveraging a generative model to predict and adapt to environmental changes. Results from extensive experiments in the CARLA simulator show promising outcomes, outperforming traditional methods in terms of adaptability and efficiency, thereby advancing the potential of active inference in real-world autonomous driving applications.},
  journal={arXiv}
}

@article{champion2021branching3,
  title={Branching Time Active Inference: empirical study and complexity class analysis},
  author={Théophile Champion and Howard Bowman and Marek Grześ},
  year={2021},
  url={http://arxiv.org/abs/2111.11276v2},
  abstract={Active inference is a state-of-the-art framework for modelling the brain that explains a wide range of mechanisms such as habit formation, dopaminergic discharge and curiosity. However, recent implementations suffer from an exponential complexity class when computing the prior over all the possible policies up to the time horizon. Fountas et al (2020) used Monte Carlo tree search to address this problem, leading to very good results in two different tasks. Additionally, Champion et al (2021a) proposed a tree search approach based on (temporal) structure learning. This was enabled by the development of a variational message passing approach to active inference, which enables compositional construction of Bayesian networks for active inference. However, this message passing tree search approach, which we call branching-time active inference (BTAI), has never been tested empirically. In this paper, we present an experimental study of BTAI in the context of a maze solving agent. In this context, we show that both improved prior preferences and deeper search help mitigate the vulnerability to local minima. Then, we compare BTAI to standard active inference (AcI) on a graph navigation task. We show that for small graphs, both BTAI and AcI successfully solve the task. For larger graphs, AcI exhibits an exponential (space) complexity class, making the approach intractable. However, BTAI explores the space of policies more efficiently, successfully scaling to larger graphs. Then, BTAI was compared to the POMCP algorithm on the frozen lake environment. The experiments suggest that BTAI and the POMCP algorithm accumulate a similar amount of reward. Also, we describe when BTAI receives more rewards than the POMCP agent, and when the opposite is true. Finally, we compared BTAI to the approach of Fountas et al (2020) on the dSprites dataset, and we discussed the pros and cons of each approach.},
  journal={arXiv}
}

@article{vassend2019justifying,
  title={Justifying the Norms of Inductive Inference},
  author={Olav Benjamin Vassend},
  year={2019},
  url={http://arxiv.org/abs/1909.06523v1},
  abstract={Bayesian inference is limited in scope because it cannot be applied in idealized contexts where none of the hypotheses under consideration is true and because it is committed to always using the likelihood as a measure of evidential favoring, even when that is inappropriate. The purpose of this paper is to study inductive inference in a very general setting where finding the truth is not necessarily the goal and where the measure of evidential favoring is not necessarily the likelihood. I use an accuracy argument to argue for probabilism and I develop a new kind of argument to argue for two general updating rules, both of which are reasonable in different contexts. One of the updating rules has standard Bayesian updating, Bissiri et al's (2016) general Bayesian updating, Douven's (2016) IBE-based updating, and Vassend's (2019a) quasi-Bayesian updating as special cases. The other updating rule is novel.},
  journal={arXiv}
}

@article{singh2023semisupervised,
  title={Semi-supervised Active Learning for Video Action Detection},
  author={Ayush Singh and Aayush J Rana and Akash Kumar and Shruti Vyas and Yogesh Singh Rawat},
  year={2023},
  url={http://arxiv.org/abs/2312.07169v3},
  abstract={In this work, we focus on label efficient learning for video action detection. We develop a novel semi-supervised active learning approach which utilizes both labeled as well as unlabeled data along with informative sample selection for action detection. Video action detection requires spatio-temporal localization along with classification, which poses several challenges for both active learning informative sample selection as well as semi-supervised learning pseudo label generation. First, we propose NoiseAug, a simple augmentation strategy which effectively selects informative samples for video action detection. Next, we propose fft-attention, a novel technique based on high-pass filtering which enables effective utilization of pseudo label for SSL in video action detection by emphasizing on relevant activity region within a video. We evaluate the proposed approach on three different benchmark datasets, UCF-101-24, JHMDB-21, and Youtube-VOS. First, we demonstrate its effectiveness on video action detection where the proposed approach outperforms prior works in semi-supervised and weakly-supervised learning along with several baseline approaches in both UCF101-24 and JHMDB-21. Next, we also show its effectiveness on Youtube-VOS for video object segmentation demonstrating its generalization capability for other dense prediction tasks in videos. The code and models is publicly available at: \url{https://github.com/AKASH2907/semi-sup-active-learning}.},
  journal={arXiv}
}

@article{gunapati2018variational,
  title={Variational Inference as an alternative to MCMC for parameter estimation and model selection},
  author={Geetakrishnasai Gunapati and Anirudh Jain and P. K. Srijith and Shantanu Desai},
  year={2018},
  url={http://arxiv.org/abs/1803.06473v4},
  abstract={Most applications of Bayesian Inference for parameter estimation and model selection in astrophysics involve the use of Monte Carlo techniques such as Markov Chain Monte Carlo (MCMC) and nested sampling. However, these techniques are time consuming and their convergence to the posterior could be difficult to determine. In this work, we advocate Variational inference as an alternative to solve the above problems, and demonstrate its usefulness for parameter estimation and model selection in Astrophysics. Variational inference converts the inference problem into an optimization problem by approximating the posterior from a known family of distributions and using Kullback-Leibler divergence to characterize the difference. It takes advantage of fast optimization techniques, which make it ideal to deal with large datasets and makes it trivial to parallelize on a multicore platform. We also derive a new approximate evidence estimation based on variational posterior, and importance sampling technique called posterior weighted importance sampling for the calculation of evidence (PWISE), which is useful to perform Bayesian model selection. As a proof of principle, we apply variational inference to five different problems in astrophysics, where Monte Carlo techniques were previously used. These include assessment of significance of annual modulation in the COSINE-100 dark matter experiment, measuring exoplanet orbital parameters from radial velocity data, tests of periodicities in measurements of Newton's constant $G$, assessing the significance of a turnover in the spectral lag data of GRB 160625B and estimating the mass of a galaxy cluster using weak gravitational lensing. We find that variational inference is much faster than MCMC and nested sampling techniques for most of these problems while providing competitive results. All our analysis codes have been made publicly available.},
  doi={10.1017/pasa.2021.64},
  journal={arXiv}
}

@article{baltieri2020kalmanbucy,
  title={On Kalman-Bucy filters, linear quadratic control and active inference},
  author={Manuel Baltieri and Christopher L. Buckley},
  year={2020},
  url={http://arxiv.org/abs/2005.06269v1},
  abstract={Linear Quadratic Gaussian (LQG) control is a framework first introduced in control theory that provides an optimal solution to linear problems of regulation in the presence of uncertainty. This framework combines Kalman-Bucy filters for the estimation of hidden states with Linear Quadratic Regulators for the control of their dynamics. Nowadays, LQG is also a common paradigm in neuroscience, where it is used to characterise different approaches to sensorimotor control based on state estimators, forward and inverse models. According to this paradigm, perception can be seen as a process of Bayesian inference and action as a process of optimal control. Recently, active inference has been introduced as a process theory derived from a variational approximation of Bayesian inference problems that describes, among others, perception and action in terms of (variational and expected) free energy minimisation. Active inference relies on a mathematical formalism similar to LQG, but offers a rather different perspective on problems of sensorimotor control in biological systems based on a process of biased perception. In this note we compare the mathematical treatments of these two frameworks for linear systems, focusing on their respective assumptions and highlighting their commonalities and technical differences.},
  journal={arXiv}
}

@article{dauchot2022collective,
  title={Collective Motion in Active Materials: Model Experiments},
  author={Olivier Dauchot},
  year={2022},
  url={http://arxiv.org/abs/2211.01045v1},
  abstract={In these lecture notes from the Les Houches School, we discuss collective motion in model experiments of active systems. We specifically discuss walking grains and colloidal rollers experiments. In both cases, we focus on the theoretical tools one can use to relate the knowledge of the dynamics at the particle scale to the large scale physics.},
  doi={10.1093/oso/9780192858313.003.0003},
  journal={arXiv}
}

@article{wei2024value,
  title={Value of Information and Reward Specification in Active Inference and POMDPs},
  author={Ran Wei},
  year={2024},
  url={http://arxiv.org/abs/2408.06542v1},
  abstract={Expected free energy (EFE) is a central quantity in active inference which has recently gained popularity due to its intuitive decomposition of the expected value of control into a pragmatic and an epistemic component. While numerous conjectures have been made to justify EFE as a decision making objective function, the most widely accepted is still its intuitiveness and resemblance to variational free energy in approximate Bayesian inference. In this work, we take a bottom up approach and ask: taking EFE as given, what's the resulting agent's optimality gap compared with a reward-driven reinforcement learning (RL) agent, which is well understood? By casting EFE under a particular class of belief MDP and using analysis tools from RL theory, we show that EFE approximates the Bayes optimal RL policy via information value. We discuss the implications for objective specification of active inference agents.},
  journal={arXiv}
}

@article{friston2023active,
  title={Active Inference and Intentional Behaviour},
  author={Karl J. Friston and Tommaso Salvatori and Takuya Isomura and Alexander Tschantz and Alex Kiefer and Tim Verbelen and Magnus Koudahl and Aswin Paul and Thomas Parr and Adeel Razi and Brett Kagan and Christopher L. Buckley and Maxwell J. D. Ramstead},
  year={2023},
  url={http://arxiv.org/abs/2312.07547v2},
  abstract={Recent advances in theoretical biology suggest that basal cognition and sentient behaviour are emergent properties of in vitro cell cultures and neuronal networks, respectively. Such neuronal networks spontaneously learn structured behaviours in the absence of reward or reinforcement. In this paper, we characterise this kind of self-organisation through the lens of the free energy principle, i.e., as self-evidencing. We do this by first discussing the definitions of reactive and sentient behaviour in the setting of active inference, which describes the behaviour of agents that model the consequences of their actions. We then introduce a formal account of intentional behaviour, that describes agents as driven by a preferred endpoint or goal in latent state-spaces. We then investigate these forms of (reactive, sentient, and intentional) behaviour using simulations. First, we simulate the aforementioned in vitro experiments, in which neuronal cultures spontaneously learn to play Pong, by implementing nested, free energy minimising processes. The simulations are then used to deconstruct the ensuing predictive behaviour, leading to the distinction between merely reactive, sentient, and intentional behaviour, with the latter formalised in terms of inductive planning. This distinction is further studied using simple machine learning benchmarks (navigation in a grid world and the Tower of Hanoi problem), that show how quickly and efficiently adaptive behaviour emerges under an inductive form of active inference.},
  journal={arXiv}
}

@article{giebels2010active,
  title={Active Galactic Nuclei and gamma rays},
  author={Berrie Giebels and Felix Aharonian and Hélène Sol},
  year={2010},
  url={http://arxiv.org/abs/1005.2330v1},
  abstract={The supermassive black holes harboured in active galactic nuclei are at the origin of powerful jets which can emit copious amounts of gamma-rays. The exact interplay between the infalling matter, the black hole and the relativistic outflow is still poorly known, and this parallel session of the 12th Marcel Grossman meeting intended to offer the most up to date status of observational results with the latest generation of ground and space-based instruments, as well as the theoretical developments relevant for the field.},
  journal={arXiv}
}

@article{li2022inferring,
  title={Inferring Topology of Networked Dynamical Systems by Active Excitations},
  author={Yushan Li and Jianping He and Cailian Chen and Xinping Guan},
  year={2022},
  url={http://arxiv.org/abs/2208.11276v1},
  abstract={Topology inference for networked dynamical systems (NDSs) has received considerable attention in recent years. The majority of pioneering works have dealt with inferring the topology from abundant observations of NDSs, so as to approximate the real one asymptotically. Leveraging the characteristic that NDSs will react to various disturbances and the disturbance's influence will consistently spread, this paper focuses on inferring the topology by a few active excitations. The key challenge is to distinguish different influences of system noises and excitations from the exhibited state deviations, where the influences will decay with time and the exciatation cannot be arbitrarily large. To practice, we propose a one-shot excitation based inference method to infer $h$-hop neighbors of a node. The excitation conditions for accurate one-hop neighbor inference are first derived with probability guarantees. Then, we extend the results to $h$-hop neighbor inference and multiple excitations cases, providing the explicit relationships between the inference accuracy and excitation magnitude. Specifically, the excitation based inference method is not only suitable for scenarios where abundant observations are unavailable, but also can be leveraged as auxiliary means to improve the accuracy of existing methods. Simulations are conducted to verify the analytical results.},
  journal={arXiv}
}

@article{sancaktar2019endtoend,
  title={End-to-End Pixel-Based Deep Active Inference for Body Perception and Action},
  author={Cansu Sancaktar and Marcel van Gerven and Pablo Lanillos},
  year={2019},
  url={http://arxiv.org/abs/2001.05847v3},
  abstract={We present a pixel-based deep active inference algorithm (PixelAI) inspired by human body perception and action. Our algorithm combines the free-energy principle from neuroscience, rooted in variational inference, with deep convolutional decoders to scale the algorithm to directly deal with raw visual input and provide online adaptive inference. Our approach is validated by studying body perception and action in a simulated and a real Nao robot. Results show that our approach allows the robot to perform 1) dynamical body estimation of its arm using only monocular camera images and 2) autonomous reaching to "imagined" arm poses in the visual space. This suggests that robot and human body perception and action can be efficiently solved by viewing both as an active inference problem guided by ongoing sensory input.},
  doi={10.1109/ICDL-EpiRob48136.2020.9278105},
  journal={arXiv}
}

@article{commeford2021characterizing,
  title={Characterizing active learning environments in physics using latent profile analysis},
  author={Kelley Commeford and Eric Brewe and Adrienne Traxler},
  year={2021},
  url={http://arxiv.org/abs/2105.02897v1},
  abstract={The vast majority of research involving active learning pedagogies uses passive lecture methods as a baseline. We propose to move beyond such comparisons to understand the mechanisms that make different active learning styles unique. Here, we use COPUS observations to record student and instructor activities in six known styles of active learning in physics, and use latent profile analysis to classify these observations. Latent profile analysis using two profiles successfully groups COPUS profiles into interactive lecture-like and other. Five latent profiles successfully sorts observations into interactive lecture-like, Modeling Instruction, ISLE labs, Context-Rich problems labs, and recitation/discussion-like. This analysis serves as a proof of concept, and suggests instructional differences across pedagogies that can be further investigated using this method.},
  journal={arXiv}
}

@article{campbell2014approximate,
  title={Approximate Decentralized Bayesian Inference},
  author={Trevor Campbell and Jonathan P. How},
  year={2014},
  url={http://arxiv.org/abs/1403.7471v3},
  abstract={This paper presents an approximate method for performing Bayesian inference in models with conditional independence over a decentralized network of learning agents. The method first employs variational inference on each individual learning agent to generate a local approximate posterior, the agents transmit their local posteriors to other agents in the network, and finally each agent combines its set of received local posteriors. The key insight in this work is that, for many Bayesian models, approximate inference schemes destroy symmetry and dependencies in the model that are crucial to the correct application of Bayes' rule when combining the local posteriors. The proposed method addresses this issue by including an additional optimization step in the combination procedure that accounts for these broken dependencies. Experiments on synthetic and real data demonstrate that the decentralized method provides advantages in computational performance and predictive test likelihood over previous batch and distributed methods.},
  journal={arXiv}
}

@article{chesneau2010high,
  title={High spatial resolution monitoring of the activity of BA supergiant winds},
  author={Olivier Chesneau and Luc Dessart and A. Kaufer and D. Mourard and O. Stahl and R. Prinja and S. Owocki},
  year={2010},
  url={http://arxiv.org/abs/1010.6228v1},
  abstract={There are currently two optical interferometry recombiners that can provide spectral resolutions better than 10000, AMBER/VLTI operating in the H-K bands, and VEGA/CHARA, recently commissioned, operating in the visible. These instruments are well suited to study the wind activity of the brightest AB supergiants in our vicinity, in lines such as H$α$ or BrGamma. We present here the first observations of this kind, performed on Rigel (B8Ia) and Deneb (A2Ia). Rigel was monitored by AMBER in two campaigns, in 2006-2007 and 2009-2010, and observed in 2009 by VEGA; whereas Deneb was monitored in 2008-2009 by VEGA. The extension of the Halpha and BrGamma line forming regions were accurately measured and compared with CMFGEN models of both stars. Moreover, clear signs of activity were observed in the differential visibility and phases. These pioneer observations are still limited, but show the path for a better understanding of the spatial structure and temporal evolution of localized ejections using optical interferometry.},
  doi={10.1017/S1743921311010751},
  journal={arXiv}
}

@article{paul2023efficient,
  title={On efficient computation in active inference},
  author={Aswin Paul and Noor Sajid and Lancelot Da Costa and Adeel Razi},
  year={2023},
  url={http://arxiv.org/abs/2307.00504v1},
  abstract={Despite being recognized as neurobiologically plausible, active inference faces difficulties when employed to simulate intelligent behaviour in complex environments due to its computational cost and the difficulty of specifying an appropriate target distribution for the agent. This paper introduces two solutions that work in concert to address these limitations. First, we present a novel planning algorithm for finite temporal horizons with drastically lower computational complexity. Second, inspired by Z-learning from control theory literature, we simplify the process of setting an appropriate target distribution for new and existing active inference planning schemes. Our first approach leverages the dynamic programming algorithm, known for its computational efficiency, to minimize the cost function used in planning through the Bellman-optimality principle. Accordingly, our algorithm recursively assesses the expected free energy of actions in the reverse temporal order. This improves computational efficiency by orders of magnitude and allows precise model learning and planning, even under uncertain conditions. Our method simplifies the planning process and shows meaningful behaviour even when specifying only the agent's final goal state. The proposed solutions make defining a target distribution from a goal state straightforward compared to the more complicated task of defining a temporally informed target distribution. The effectiveness of these methods is tested and demonstrated through simulations in standard grid-world tasks. These advances create new opportunities for various applications.},
  doi={10.1016/j.eswa.2024.124315},
  journal={arXiv}
}

@article{schumann2025active,
  title={Active inference as a unified model of collision avoidance behavior in human drivers},
  author={Julian F. Schumann and Johan Engström and Leif Johnson and Matthew O'Kelly and Joao Messias and Jens Kober and Arkady Zgonnikov},
  year={2025},
  url={http://arxiv.org/abs/2506.02215v4},
  abstract={Collision avoidance -- involving a rapid threat detection and quick execution of the appropriate evasive maneuver -- is a critical aspect of driving. However, existing models of human collision avoidance behavior are fragmented, focusing on specific scenarios or only describing certain aspects of the avoidance behavior, such as response times. This paper addresses these gaps by proposing a novel computational cognitive model of human collision avoidance behavior based on active inference. Active inference provides a unified approach to modeling human behavior: the minimization of free energy. Building on prior active inference work, our model incorporates established cognitive mechanisms such as evidence accumulation to simulate human responses in two distinct collision avoidance scenarios: front-to-rear lead vehicle braking and lateral incursion by an oncoming vehicle. We demonstrate that our model explains a wide range of previous empirical findings on human collision avoidance behavior. Specifically, the model closely reproduces both aggregate results from meta-analyses previously reported in the literature and detailed, scenario-specific effects observed in a recent driving simulator study, including response timing, maneuver selection, and execution. Our results highlight the potential of active inference as a unified framework for understanding and modeling human behavior in complex real-life driving tasks.},
  journal={arXiv}
}

@article{pöppel2021resonating,
  title={Resonating Minds -- Emergent Collaboration Through Hierarchical Active Inference},
  author={Jan Pöppel and Sebastian Kahl and Stefan Kopp},
  year={2021},
  url={http://arxiv.org/abs/2112.01210v1},
  abstract={Working together on complex collaborative tasks requires agents to coordinate their actions. Doing this explicitly or completely prior to the actual interaction is not always possible nor sufficient. Agents also need to continuously understand the current actions of others and quickly adapt their own behavior appropriately. Here we investigate how efficient, automatic coordination processes at the level of mental states (intentions, goals), which we call belief resonance, can lead to collaborative situated problem-solving. We present a model of hierarchical active inference for collaborative agents (HAICA). It combines efficient Bayesian Theory of Mind processes with a perception-action system based on predictive processing and active inference. Belief resonance is realized by letting the inferred mental states of one agent influence another agent's predictive beliefs about its own goals and intentions. This way, the inferred mental states influence the agent's own task behavior without explicit collaborative reasoning. We implement and evaluate this model in the Overcooked domain, in which two agents with varying degrees of belief resonance team up to fulfill meal orders. Our results demonstrate that agents based on HAICA achieve a team performance comparable to recent state of the art approaches, while incurring much lower computational costs. We also show that belief resonance is especially beneficial in settings were the agents have asymmetric knowledge about the environment. The results indicate that belief resonance and active inference allow for quick and efficient agent coordination, and thus can serve as a building block for collaborative cognitive agents.},
  doi={10.1007/s12559-021-09960-4},
  journal={arXiv}
}

@article{delavari2025perceptual,
  title={Perceptual Motor Learning with Active Inference Framework for Robust Lateral Control},
  author={Elahe Delavari and John Moore and Junho Hong and Jaerock Kwon},
  year={2025},
  url={http://arxiv.org/abs/2503.01676v2},
  abstract={This paper presents a novel Perceptual Motor Learning (PML) framework integrated with Active Inference (AIF) to enhance lateral control in Highly Automated Vehicles (HAVs). PML, inspired by human motor learning, emphasizes the seamless integration of perception and action, enabling efficient decision-making in dynamic environments. Traditional autonomous driving approaches--including modular pipelines, imitation learning, and reinforcement learning--struggle with adaptability, generalization, and computational efficiency. In contrast, PML with AIF leverages a generative model to minimize prediction error ("surprise") and actively shape vehicle control based on learned perceptual-motor representations. Our approach unifies deep learning with active inference principles, allowing HAVs to perform lane-keeping maneuvers with minimal data and without extensive retraining across different environments. Extensive experiments in the CARLA simulator demonstrate that PML with AIF enhances adaptability without increasing computational overhead while achieving performance comparable to conventional methods. These findings highlight the potential of PML-driven active inference as a robust alternative for real-world autonomous driving applications.},
  journal={arXiv}
}

@article{wilhelm2021conditional,
  title={Conditional Inference and Activation of Knowledge Entities in ACT-R},
  author={Marco Wilhelm and Diana Howey and Gabriele Kern-Isberner and Kai Sauerwald and Christoph Beierle},
  year={2021},
  url={http://arxiv.org/abs/2110.15214v1},
  abstract={Activation-based conditional inference applies conditional reasoning to ACT-R, a cognitive architecture developed to formalize human reasoning. The idea of activation-based conditional inference is to determine a reasonable subset of a conditional belief base in order to draw inductive inferences in time. Central to activation-based conditional inference is the activation function which assigns to the conditionals in the belief base a degree of activation mainly based on the conditional's relevance for the current query and its usage history. Therewith, our approach integrates several aspects of human reasoning into expert systems such as focusing, forgetting, and remembering.},
  journal={arXiv}
}

@article{song2023ace,
  title={ACE: Active Learning for Causal Inference with Expensive Experiments},
  author={Difan Song and Simon Mak and C. F. Jeff Wu},
  year={2023},
  url={http://arxiv.org/abs/2306.07480v1},
  abstract={Experiments are the gold standard for causal inference. In many applications, experimental units can often be recruited or chosen sequentially, and the adaptive execution of such experiments may offer greatly improved inference of causal quantities over non-adaptive approaches, particularly when experiments are expensive. We thus propose a novel active learning method called ACE (Active learning for Causal inference with Expensive experiments), which leverages Gaussian process modeling of the conditional mean functions to guide an informed sequential design of costly experiments. In particular, we develop new acquisition functions for sequential design via the minimization of the posterior variance of a desired causal estimand. Our approach facilitates targeted learning of a variety of causal estimands, such as the average treatment effect (ATE), the average treatment effect on the treated (ATTE), and individualized treatment effects (ITE), and can be used for adaptive selection of an experimental unit and/or the applied treatment. We then demonstrate in a suite of numerical experiments the improved performance of ACE over baseline methods for estimating causal estimands given a limited number of experiments.},
  journal={arXiv}
}

@article{svendsen2019active,
  title={Active emulation of computer codes with Gaussian processes -- Application to remote sensing},
  author={Daniel Heestermans Svendsen and Luca Martino and Gustau Camps-Valls},
  year={2019},
  url={http://arxiv.org/abs/1912.06552v1},
  abstract={Many fields of science and engineering rely on running simulations with complex and computationally expensive models to understand the involved processes in the system of interest. Nevertheless, the high cost involved hamper reliable and exhaustive simulations. Very often such codes incorporate heuristics that ironically make them less tractable and transparent. This paper introduces an active learning methodology for adaptively constructing surrogate models, i.e. emulators, of such costly computer codes in a multi-output setting. The proposed technique is sequential and adaptive, and is based on the optimization of a suitable acquisition function. It aims to achieve accurate approximations, model tractability, as well as compact and expressive simulated datasets. In order to achieve this, the proposed Active Multi-Output Gaussian Process Emulator (AMOGAPE) combines the predictive capacity of Gaussian Processes (GPs) with the design of an acquisition function that favors sampling in low density and fluctuating regions of the approximation functions. Comparing different acquisition functions, we illustrate the promising performance of the method for the construction of emulators with toy examples, as well as for a widely used remote sensing transfer code.},
  doi={10.1016/j.patcog.2019.107103},
  journal={arXiv}
}

@article{mcelwee2019cyber,
  title={Cyber Situation Awareness with Active Learning for Intrusion Detection},
  author={Steven McElwee and James Cannady},
  year={2019},
  url={http://arxiv.org/abs/1912.12673v1},
  abstract={Intrusion detection has focused primarily on detecting cyberattacks at the event-level. Since there is such a large volume of network data and attacks are minimal, machine learning approaches have focused on improving accuracy and reducing false positives, but this has frequently resulted in overfitting. In addition, the volume of intrusion detection alerts is large and creates fatigue in the human analyst who must review them. This research addresses the problems associated with event-level intrusion detection and the large volumes of intrusion alerts by applying active learning and cyber situation awareness. This paper includes the results of two experiments using the UNSW-NB15 dataset. The first experiment evaluated sampling approaches for querying the oracle, as part of active learning. It then trained a Random Forest classifier using the samples and evaluated its results. The second experiment applied cyber situation awareness by aggregating the detection results of the first experiment and calculating the probability that a computer system was part of a cyberattack. This research showed that moving the perspective of event-level alerts to the probability that a computer system was part of an attack improved the accuracy of detection and reduced the volume of alerts that a human analyst would need to review.},
  doi={10.1109/SoutheastCon42311.2019.9020599},
  journal={arXiv}
}

@article{bhattacharya2020gibbs,
  title={Gibbs posterior inference on multivariate quantiles},
  author={Indrabati Bhattacharya and Ryan Martin},
  year={2020},
  url={http://arxiv.org/abs/2002.01052v3},
  abstract={Bayesian and other likelihood-based methods require specification of a statistical model and may not be fully satisfactory for inference on quantities, such as quantiles, that are not naturally defined as model parameters. In this paper, we construct a direct and model-free Gibbs posterior distribution for multivariate quantiles. Being model-free means that inferences drawn from the Gibbs posterior are not subject to model misspecification bias, and being direct means that no priors for or marginalization over nuisance parameters are required. We show here that the Gibbs posterior enjoys a root-$n$ convergence rate and a Bernstein--von Mises property, i.e., for large n, the Gibbs posterior distribution can be approximated by a Gaussian. Moreover, we present numerical results showing the validity and efficiency of credible sets derived from a suitably scaled Gibbs posterior.},
  doi={10.1016/j.jspi.2021.10.003},
  journal={arXiv}
}

@article{albarracin2023designing,
  title={Designing explainable artificial intelligence with active inference: A framework for transparent introspection and decision-making},
  author={Mahault Albarracin and Inês Hipólito and Safae Essafi Tremblay and Jason G. Fox and Gabriel René and Karl Friston and Maxwell J. D. Ramstead},
  year={2023},
  url={http://arxiv.org/abs/2306.04025v1},
  abstract={This paper investigates the prospect of developing human-interpretable, explainable artificial intelligence (AI) systems based on active inference and the free energy principle. We first provide a brief overview of active inference, and in particular, of how it applies to the modeling of decision-making, introspection, as well as the generation of overt and covert actions. We then discuss how active inference can be leveraged to design explainable AI systems, namely, by allowing us to model core features of ``introspective'' processes and by generating useful, human-interpretable models of the processes involved in decision-making. We propose an architecture for explainable AI systems using active inference. This architecture foregrounds the role of an explicit hierarchical generative model, the operation of which enables the AI system to track and explain the factors that contribute to its own decisions, and whose structure is designed to be interpretable and auditable by human users. We outline how this architecture can integrate diverse sources of information to make informed decisions in an auditable manner, mimicking or reproducing aspects of human-like consciousness and introspection. Finally, we discuss the implications of our findings for future research in AI, and the potential ethical considerations of developing AI systems with (the appearance of) introspective capabilities.},
  journal={arXiv}
}

@article{donta2025resilient,
  title={Resilient by Design -- Active Inference for Distributed Continuum Intelligence},
  author={Praveen Kumar Donta and Alfreds Lapkovskis and Enzo Mingozzi and Schahram Dustdar},
  year={2025},
  url={http://arxiv.org/abs/2511.07202v2},
  abstract={Failures are the norm in highly complex and heterogeneous devices spanning the distributed computing continuum (DCC), from resource-constrained IoT and edge nodes to high-performance computing systems. Ensuring reliability and global consistency across these layers remains a major challenge, especially for AI-driven workloads requiring real-time, adaptive coordination. This work-in-progress paper introduces a Probabilistic Active Inference Resilience Agent (PAIR-Agent) to achieve resilience in DCC systems. PAIR-Agent performs three core operations: (i) constructing a causal fault graph from device logs, (ii) identifying faults while managing certainties and uncertainties using Markov blankets and the free energy principle, and (iii) autonomously healing issues through active inference. Through continuous monitoring and adaptive reconfiguration, the agent maintains service continuity and stability under diverse failure conditions. Theoretical validations confirm the reliability and effectiveness of the proposed framework.},
  journal={arXiv}
}

@article{krayani2022novel,
  title={A Novel Resource Allocation for Anti-jamming in Cognitive-UAVs: an Active Inference Approach},
  author={Ali Krayani and Atm S. Alam and Lucio Marcenaro and Arumugam Nallanathan and Carlo Regazzoni},
  year={2022},
  url={http://arxiv.org/abs/2208.05269v1},
  abstract={This work proposes a novel resource allocation strategy for anti-jamming in Cognitive Radio using Active Inference ($\textit{AIn}$), and a cognitive-UAV is employed as a case study. An Active Generalized Dynamic Bayesian Network (Active-GDBN) is proposed to represent the external environment that jointly encodes the physical signal dynamics and the dynamic interaction between UAV and jammer in the spectrum. We cast the action and planning as a Bayesian inference problem that can be solved by avoiding surprising states (minimizing abnormality) during online learning. Simulation results verify the effectiveness of the proposed $\textit{AIn}$ approach in minimizing abnormalities (maximizing rewards) and has a high convergence speed by comparing it with the conventional Frequency Hopping and Q-learning.},
  doi={10.1109/LCOMM.2022.3190971},
  journal={arXiv}
}

@article{akitsu2025cosmology,
  title={Cosmology inference with perturbative forward modeling at the field level: a comparison with joint power spectrum and bispectrum analyses},
  author={Kazuyuki Akitsu and Marko Simonović and Shi-Fan Chen and Giovanni Cabass and Matias Zaldarriaga},
  year={2025},
  url={http://arxiv.org/abs/2509.09673v2},
  abstract={We extend field-level inference to jointly constrain the cosmological parameters $\{A,ω_{\rm cdm},H_0\}$, in both real and redshift space. Our analyses are based on mock data generated using a perturbative forward model, with noise drawn from a Gaussian distribution with a constant power spectrum. This idealized setting, where the field-level likelihood is exactly Gaussian, allows us to precisely quantify the information content in the nonlinear field on large scales. We find that field-level inference accurately recovers all cosmological parameters in both real and redshift space, with uncertainties consistent with perturbation theory expectations. We show that these error bars are comparable to those obtained from a joint power spectrum and bispectrum analysis using the same perturbative model. Finally, we perform several tests using the Gaussian field-level likelihood to fit the mock data where the true noise model is non-Gaussian, and find significant biases in the inferred cosmological parameters. These results highlight that the success of field-level inference critically depends on using the correct likelihood, which may be the primary challenge for applying this method to smaller scales even in the perturbative regime.},
  journal={arXiv}
}

@article{netzer2007conference,
  title={Conference Summary: The Central Engine of Active Galactic Nuclei},
  author={Hagai Netzer and Joseph C. Shields},
  year={2007},
  url={http://arxiv.org/abs/0705.2192v1},
  abstract={The 2006 meeting in Xi'an on the Central Engine of Active Galactic Nuclei covered the enormous and continuously expanding area of AGN research, from theory to the most sophisticated observations and from gamma-ray energies to long radio wavelengths. This short summary gives some, but definitely not all, highlights and new results presented by the participants.},
  journal={arXiv}
}

@article{sosnowski2022active,
  title={Active TLS Stack Fingerprinting: Characterizing TLS Server Deployments at Scale},
  author={Markus Sosnowski and Johannes Zirngibl and Patrick Sattler and Georg Carle and Claas Grohnfeldt and Michele Russo and Daniele Sgandurra},
  year={2022},
  url={http://arxiv.org/abs/2206.13230v3},
  abstract={Active measurements can be used to collect server characteristics on a large scale. This kind of metadata can help discovering hidden relations and commonalities among server deployments offering new possibilities to cluster and classify them. As an example, identifying a previously-unknown cybercriminal infrastructures can be a valuable source for cyber-threat intelligence. We propose herein an active measurement-based methodology for acquiring Transport Layer Security (TLS) metadata from servers and leverage it for their fingerprinting. Our fingerprints capture the characteristic behavior of the TLS stack primarily caused by the implementation, configuration, and hardware support of the underlying server. Using an empirical optimization strategy that maximizes information gain from every handshake to minimize measurement costs, we generated 10 general-purpose Client Hellos used as scanning probes to create a large database of TLS configurations used for classifying servers. We fingerprinted 28 million servers from the Alexa and Majestic toplists and two Command and Control (C2) blocklists over a period of 30 weeks with weekly snapshots as foundation for two long-term case studies: classification of Content Delivery Network and C2 servers. The proposed methodology shows a precision of more than 99 % and enables a stable identification of new servers over time. This study describes a new opportunity for active measurements to provide valuable insights into the Internet that can be used in security-relevant use cases.},
  journal={arXiv}
}

@article{peterson2002masses,
  title={Masses of Black Holes in Active Galactic Nuclei},
  author={Bradley M. Peterson},
  year={2002},
  url={http://arxiv.org/abs/astro-ph/0210639v1},
  abstract={We present a progress report on a project whose goal is to improve both the precision and accuracy of everberation-based black-hole masses. Reverberation masses appear to be accurate to a factor of about three, and the black-hole mass/bulge velocity dispersion relationship appears to be the same in active and quiescent galaxies.},
  journal={arXiv}
}

@article{griesemer2024active,
  title={Active Sequential Posterior Estimation for Sample-Efficient Simulation-Based Inference},
  author={Sam Griesemer and Defu Cao and Zijun Cui and Carolina Osorio and Yan Liu},
  year={2024},
  url={http://arxiv.org/abs/2412.05590v1},
  abstract={Computer simulations have long presented the exciting possibility of scientific insight into complex real-world processes. Despite the power of modern computing, however, it remains challenging to systematically perform inference under simulation models. This has led to the rise of simulation-based inference (SBI), a class of machine learning-enabled techniques for approaching inverse problems with stochastic simulators. Many such methods, however, require large numbers of simulation samples and face difficulty scaling to high-dimensional settings, often making inference prohibitive under resource-intensive simulators. To mitigate these drawbacks, we introduce active sequential neural posterior estimation (ASNPE). ASNPE brings an active learning scheme into the inference loop to estimate the utility of simulation parameter candidates to the underlying probabilistic model. The proposed acquisition scheme is easily integrated into existing posterior estimation pipelines, allowing for improved sample efficiency with low computational overhead. We further demonstrate the effectiveness of the proposed method in the travel demand calibration setting, a high-dimensional inverse problem commonly requiring computationally expensive traffic simulators. Our method outperforms well-tuned benchmarks and state-of-the-art posterior estimation methods on a large-scale real-world traffic network, as well as demonstrates a performance advantage over non-active counterparts on a suite of SBI benchmark environments.},
  journal={arXiv}
}

@article{borah2013common,
  title={Common Radiative Origin of Active and Sterile Neutrino Masses},
  author={Debasish Borah and Rathin Adhikari},
  year={2013},
  url={http://arxiv.org/abs/1310.5419v2},
  abstract={Sterile neutrinos with sub-electron volt (eV) masses have recently received serious attention due to the tantalizing hints from reactor neutrino experiments as well as cosmology. While the nine year old Wilkinson Mass Anisotropy Probe experiment suggests the effective number of relativistic degrees of freedom to be $N_{\text{eff}} = 3.84 \pm 0.40$, recently reported Planck collaboration results show more preference towards the standard three light neutrino scenario $ N_{\text{eff}} = 3.30^{+0.54}_{-0.51}$. Keeping in mind that the issue of existence or non-existence of sub-eV scale sterile neutrinos is not yet settled, here we outline a mechanism to generate sub-eV scale masses for three active and one sterile neutrinos simultaneously. The model is based on an abelian extension of standard model where the fermion and scalar fields are charged under the additional $U(1)$ gauge group in such an anomaly free way that it allows one eV scale neutrino and three massless neutrinos at tree level. However, at one loop level, this model naturally allows three active and one sterile neutrino with mass at the sub-eV scale. The model also allows for mixing between active and sterile neutrinos at one loop level which can have interesting signatures in reactor neutrino experiments.},
  doi={10.1016/j.physletb.2014.01.018},
  journal={arXiv}
}

@article{gregory2016longterm,
  title={The long-term evolution of stellar activity},
  author={Scott G. Gregory},
  year={2016},
  url={http://arxiv.org/abs/1612.04587v1},
  abstract={I review the evolution of low-mass stars with outer convective zones over timescales of millions-to-billions of years, from the pre-main sequence to solar-age, ~4.6 Gyr (Bahcall et al. 1995; Amelin et al. 2010), and beyond. I discuss the evolution of high-energy coronal and chromospheric emission, the links with stellar rotation and magnetism, and the emergence of the rotation-activity relation for stars within young clusters.},
  doi={10.1017/S1743921317003891},
  journal={arXiv}
}

@article{stillman2023graphinformed,
  title={Graph-informed simulation-based inference for models of active matter},
  author={Namid R. Stillman and Silke Henkes and Roberto Mayor and Gilles Louppe},
  year={2023},
  url={http://arxiv.org/abs/2304.06806v1},
  abstract={Many collective systems exist in nature far from equilibrium, ranging from cellular sheets up to flocks of birds. These systems reflect a form of active matter, whereby individual material components have internal energy. Under specific parameter regimes, these active systems undergo phase transitions whereby small fluctuations of single components can lead to global changes to the rheology of the system. Simulations and methods from statistical physics are typically used to understand and predict these phase transitions for real-world observations. In this work, we demonstrate that simulation-based inference can be used to robustly infer active matter parameters from system observations. Moreover, we demonstrate that a small number (from one to three) snapshots of the system can be used for parameter inference and that this graph-informed approach outperforms typical metrics such as the average velocity or mean square displacement of the system. Our work highlights that high-level system information is contained within the relational structure of a collective system and that this can be exploited to better couple models to data.},
  journal={arXiv}
}

@article{lee2020empowering,
  title={Empowering Active Learning to Jointly Optimize System and User Demands},
  author={Ji-Ung Lee and Christian M. Meyer and Iryna Gurevych},
  year={2020},
  url={http://arxiv.org/abs/2005.04470v2},
  abstract={Existing approaches to active learning maximize the system performance by sampling unlabeled instances for annotation that yield the most efficient training. However, when active learning is integrated with an end-user application, this can lead to frustration for participating users, as they spend time labeling instances that they would not otherwise be interested in reading. In this paper, we propose a new active learning approach that jointly optimizes the seemingly counteracting objectives of the active learning system (training efficiently) and the user (receiving useful instances). We study our approach in an educational application, which particularly benefits from this technique as the system needs to rapidly learn to predict the appropriateness of an exercise to a particular user, while the users should receive only exercises that match their skills. We evaluate multiple learning strategies and user types with data from real users and find that our joint approach better satisfies both objectives when alternative methods lead to many unsuitable exercises for end users.},
  journal={arXiv}
}

@article{smithe2021compositional,
  title={Compositional Active Inference I: Bayesian Lenses. Statistical Games},
  author={Toby St. Clere Smithe},
  year={2021},
  url={http://arxiv.org/abs/2109.04461v2},
  abstract={We introduce the concepts of Bayesian lens, characterizing the bidirectional structure of exact Bayesian inference, and statistical game, formalizing the optimization objectives of approximate inference problems. We prove that Bayesian inversions compose according to the compositional lens pattern, and exemplify statistical games with a number of classic statistical concepts, from maximum likelihood estimation to generalized variational Bayesian methods. This paper is the first in a series laying the foundations for a compositional account of the theory of active inference, and we therefore pay particular attention to statistical games with a free-energy objective.},
  journal={arXiv}
}

@article{saldutti2019coupled,
  title={Coupled Bloch-Wave Analysis of Active PhC Waveguides and Cavities},
  author={Marco Saldutti and Jesper Moerk and Paolo Bardella and Ivo Montrosset and Mariangela Gioannini},
  year={2019},
  url={http://arxiv.org/abs/1906.03638v1},
  abstract={A coupled Bloch-wave approach is employed to analyze active photonic-crystal (PhC) waveguides and cavities. Gain couples the otherwise independent counter-propagating Bloch modes. This coupling is shown to limit the maximum attainable slow-light enhancement of gain itself and to strongly affect the mode selection in PhC lasers.},
  doi={10.1109/NUSOD.2018.8570231},
  journal={arXiv}
}

@article{malik2023batchgfn,
  title={BatchGFN: Generative Flow Networks for Batch Active Learning},
  author={Shreshth A. Malik and Salem Lahlou and Andrew Jesson and Moksh Jain and Nikolay Malkin and Tristan Deleu and Yoshua Bengio and Yarin Gal},
  year={2023},
  url={http://arxiv.org/abs/2306.15058v1},
  abstract={We introduce BatchGFN -- a novel approach for pool-based active learning that uses generative flow networks to sample sets of data points proportional to a batch reward. With an appropriate reward function to quantify the utility of acquiring a batch, such as the joint mutual information between the batch and the model parameters, BatchGFN is able to construct highly informative batches for active learning in a principled way. We show our approach enables sampling near-optimal utility batches at inference time with a single forward pass per point in the batch in toy regression problems. This alleviates the computational complexity of batch-aware algorithms and removes the need for greedy approximations to find maximizers for the batch reward. We also present early results for amortizing training across acquisition steps, which will enable scaling to real-world tasks.},
  journal={arXiv}
}

@article{kim2025inferencetime,
  title={Inference-Time Scaling for Flow Models via Stochastic Generation and Rollover Budget Forcing},
  author={Jaihoon Kim and Taehoon Yoon and Jisung Hwang and Minhyuk Sung},
  year={2025},
  url={http://arxiv.org/abs/2503.19385v5},
  abstract={We propose an inference-time scaling approach for pretrained flow models. Recently, inference-time scaling has gained significant attention in LLMs and diffusion models, improving sample quality or better aligning outputs with user preferences by leveraging additional computation. For diffusion models, particle sampling has allowed more efficient scaling due to the stochasticity at intermediate denoising steps. On the contrary, while flow models have gained popularity as an alternative to diffusion models--offering faster generation and high-quality outputs in state-of-the-art image and video generative models--efficient inference-time scaling methods used for diffusion models cannot be directly applied due to their deterministic generative process. To enable efficient inference-time scaling for flow models, we propose three key ideas: 1) SDE-based generation, enabling particle sampling in flow models, 2) Interpolant conversion, broadening the search space and enhancing sample diversity, and 3) Rollover Budget Forcing (RBF), an adaptive allocation of computational resources across timesteps to maximize budget utilization. Our experiments show that SDE-based generation, particularly variance-preserving (VP) interpolant-based generation, improves the performance of particle sampling methods for inference-time scaling in flow models. Additionally, we demonstrate that RBF with VP-SDE achieves the best performance, outperforming all previous inference-time scaling approaches.},
  journal={arXiv}
}

@article{fields2023control,
  title={Control flow in active inference systems},
  author={Chris Fields and Filippo Fabrocini and Karl Friston and James F. Glazebrook and Hananel Hazan and Michael Levin and Antonino Marciano},
  year={2023},
  url={http://arxiv.org/abs/2303.01514v1},
  abstract={Living systems face both environmental complexity and limited access to free-energy resources. Survival under these conditions requires a control system that can activate, or deploy, available perception and action resources in a context specific way. We show here that when systems are described as executing active inference driven by the free-energy principle (and hence can be considered Bayesian prediction-error minimizers), their control flow systems can always be represented as tensor networks (TNs). We show how TNs as control systems can be implmented within the general framework of quantum topological neural networks, and discuss the implications of these results for modeling biological systems at multiple scales.},
  journal={arXiv}
}

@article{huang2022sparse,
  title={Sparse inference and active learning of stochastic differential equations from data},
  author={Yunfei Huang and Youssef Mabrouk and Gerhard Gompper and Benedikt Sabass},
  year={2022},
  url={http://arxiv.org/abs/2203.11010v3},
  abstract={Automatic machine learning of empirical models from experimental data has recently become possible as a result of increased availability of computational power and dedicated algorithms. Despite the successes of non-parametric inference and neural-network-based inference for empirical modelling, a physical interpretation of the results often remains challenging. Here, we focus on direct inference of governing differential equations from data, which can be formulated as a linear inverse problem. A Bayesian framework with a Laplacian prior distribution is employed for finding sparse solutions efficiently. The superior accuracy and robustness of the method is demonstrated for various cases, including ordinary, partial, and stochastic differential equations. Furthermore, we develop an active learning procedure for the automated discovery of stochastic differential equations. In this procedure, learning of the unknown dynamical equations is coupled to the application of perturbations to the measured system in a feedback loop. We demonstrate with simulations that the active learning procedure improves the inference of empirical, Langevin-type descriptions of stochastic processes.},
  doi={10.1038/s41598-022-25638-9},
  journal={arXiv}
}

@article{kajdanowicz2015learning,
  title={Learning in Unlabeled Networks - An Active Learning and Inference Approach},
  author={Tomasz Kajdanowicz and Radosław Michalski and Katarzyna Musiał and Przemysław Kazienko},
  year={2015},
  url={http://arxiv.org/abs/1510.01270v1},
  abstract={The task of determining labels of all network nodes based on the knowledge about network structure and labels of some training subset of nodes is called the within-network classification. It may happen that none of the labels of the nodes is known and additionally there is no information about number of classes to which nodes can be assigned. In such a case a subset of nodes has to be selected for initial label acquisition. The question that arises is: "labels of which nodes should be collected and used for learning in order to provide the best classification accuracy for the whole network?". Active learning and inference is a practical framework to study this problem.   A set of methods for active learning and inference for within network classification is proposed and validated. The utility score calculation for each node based on network structure is the first step in the process. The scores enable to rank the nodes. Based on the ranking, a set of nodes, for which the labels are acquired, is selected (e.g. by taking top or bottom N from the ranking). The new measure-neighbour methods proposed in the paper suggest not obtaining labels of nodes from the ranking but rather acquiring labels of their neighbours. The paper examines 29 distinct formulations of utility score and selection methods reporting their impact on the results of two collective classification algorithms: Iterative Classification Algorithm and Loopy Belief Propagation.   We advocate that the accuracy of presented methods depends on the structural properties of the examined network. We claim that measure-neighbour methods will work better than the regular methods for networks with higher clustering coefficient and worse than regular methods for networks with low clustering coefficient. According to our hypothesis, based on clustering coefficient we are able to recommend appropriate active learning and inference method.},
  journal={arXiv}
}

@article{heller2023simultaneous,
  title={Simultaneous directional inference},
  author={Ruth Heller and Aldo Solari},
  year={2023},
  url={http://arxiv.org/abs/2301.01653v2},
  abstract={We consider the problem of inference on the signs of $n>1$ parameters. We aim to provide $1-α$ post-hoc confidence bounds on the number of positive and negative (or non-positive) parameters. The guarantee is simultaneous, for all subsets of parameters. Our suggestion is as follows: start by using the data to select the direction of the hypothesis test for each parameter; then, adjust the $p$-values of the one-sided hypotheses for the selection, and use the adjusted $p$-values for simultaneous inference on the selected $n$ one-sided hypotheses. The adjustment is straightforward assuming that the $p$-values of one-sided hypotheses have densities with monotone likelihood ratio, and are mutually independent. We show that the bounds we provide are tighter (often by a great margin) than existing alternatives, and that they can be obtained by at most a polynomial time. We demonstrate the usefulness of our simultaneous post-hoc bounds in the evaluation of treatment effects across studies or subgroups. Specifically, we provide a tight lower bound on the number of studies which are beneficial, as well as on the number of studies which are harmful (or non-beneficial), and in addition conclude on the effect direction of individual studies, while guaranteeing that the probability of at least one wrong inference is at most 0.05.},
  doi={10.1093/jrsssb/qkad137},
  journal={arXiv}
}

@article{maier2025from,
  title={From Artificial Intelligence to Active Inference: The Key to True AI and 6G World Brain [Invited]},
  author={Martin Maier},
  year={2025},
  url={http://arxiv.org/abs/2505.10569v1},
  abstract={In his opening OFC plenary talk back in 2021, Alibaba Group's Yiqun Cai notably added in the follow-up Q&A that today's complex networks are more than computer science - they grow, they are life. This entails that future networks may be better viewed as techno-social systems that resemble biological superorganisms with brain-like cognitive capabilities. Fast-forwarding, there is now growing awareness that we have to completely change our networks from being static into being a living entity that would act as an AI-powered network `brain', as recently stated by Bruno Zerbib, Chief Technology and Innovation Officer of France's Orange, at the Mobile World Congress (MWC) 2025. Even though AI was front and center at both MWC and OFC 2025 and has been widely studied in the context of optical networks, there are currently no publications on active inference in optical (and less so mobile) networks available. Active inference is an ideal methodology for developing more advanced AI systems by biomimicking the way living intelligent systems work, while overcoming the limitations of today's AI related to training, learning, and explainability. Active inference is considered the key to true AI: Less artificial, more intelligent. The goal of this paper is twofold. First, we aim at enabling optical network researchers to conceptualize new research lines for future optical networks with human-AI interaction capabilities by introducing them to the main mathematical concepts of the active inference framework. Second, we demonstrate how to move AI research beyond the human brain toward the 6G world brain by exploring the role of mycorrhizal networks, the largest living organism on planet Earth, in the AI vision and R&D roadmap for the next decade and beyond laid out by Karl Friston, the father of active inference.},
  journal={arXiv}
}

@article{chittyvenkata2025lexi,
  title={LExI: Layer-Adaptive Active Experts for Efficient MoE Model Inference},
  author={Krishna Teja Chitty-Venkata and Sandeep Madireddy and Murali Emani and Venkatram Vishwanath},
  year={2025},
  url={http://arxiv.org/abs/2509.02753v1},
  abstract={Mixture-of-Experts (MoE) models scale efficiently by activating only a subset of experts per token, offering a computationally sparse alternative to dense architectures. While prior post-training optimizations, such as inter- and intra-expert pruning, reduce memory usage they provide limited gains in inference-time compute efficiency. Moreover, existing MoE architectures typically activate a fixed number of experts uniformly across all layers, resulting in redundant computation and suboptimal performance. In this work, we first demonstrate that MoE pruning strategies improve only the memory footprint but do not significantly improve inference performance on GPU using optimized frameworks such as vLLM. To address this, we introduce LExI, a data-free optimization technique that determines the optimal number of active experts per layer in a pretrained MoE model. LExI leverages only the model weights to estimate the relative importance of each layer and adaptively assigns the number of active experts accordingly per layer. Experiments on state-of-the-art language and vision MoE benchmarks demonstrate that LExI significantly outperforms traditional MoE pruning approaches in terms of inference efficiency with negligible accuracy loss. For example, using LExI, Qwen1.5-MoE achieves the same throughput on Nvidia H100 GPU with 10% better accuracy than traditional expert pruning.},
  journal={arXiv}
}

@article{habrard2006using,
  title={Using Pseudo-Stochastic Rational Languages in Probabilistic Grammatical Inference},
  author={Amaury Habrard and Francois Denis and Yann Esposito},
  year={2006},
  url={http://arxiv.org/abs/cs/0607085v2},
  abstract={In probabilistic grammatical inference, a usual goal is to infer a good approximation of an unknown distribution P called a stochastic language. The estimate of P stands in some class of probabilistic models such as probabilistic automata (PA). In this paper, we focus on probabilistic models based on multiplicity automata (MA). The stochastic languages generated by MA are called rational stochastic languages; they strictly include stochastic languages generated by PA; they also admit a very concise canonical representation. Despite the fact that this class is not recursively enumerable, it is efficiently identifiable in the limit by using the algorithm DEES, introduced by the authors in a previous paper. However, the identification is not proper and before the convergence of the algorithm, DEES can produce MA that do not define stochastic languages. Nevertheless, it is possible to use these MA to define stochastic languages. We show that they belong to a broader class of rational series, that we call pseudo-stochastic rational languages. The aim of this paper is twofold. First we provide a theoretical study of pseudo-stochastic rational languages, the languages output by DEES, showing for example that this class is decidable within polynomial time. Second, we have carried out a lot of experiments in order to compare DEES to classical inference algorithms such as ALERGIA and MDI. They show that DEES outperforms them in most cases.},
  journal={arXiv}
}

@article{du2020compositional,
  title={Compositional Visual Generation and Inference with Energy Based Models},
  author={Yilun Du and Shuang Li and Igor Mordatch},
  year={2020},
  url={http://arxiv.org/abs/2004.06030v3},
  abstract={A vital aspect of human intelligence is the ability to compose increasingly complex concepts out of simpler ideas, enabling both rapid learning and adaptation of knowledge. In this paper we show that energy-based models can exhibit this ability by directly combining probability distributions. Samples from the combined distribution correspond to compositions of concepts. For example, given a distribution for smiling faces, and another for male faces, we can combine them to generate smiling male faces. This allows us to generate natural images that simultaneously satisfy conjunctions, disjunctions, and negations of concepts. We evaluate compositional generation abilities of our model on the CelebA dataset of natural faces and synthetic 3D scene images. We also demonstrate other unique advantages of our model, such as the ability to continually learn and incorporate new concepts, or infer compositions of concept properties underlying an image.},
  journal={arXiv}
}

@article{mullen2021communicating,
  title={Communicating Inferred Goals with Passive Augmented Reality and Active Haptic Feedback},
  author={James F. Mullen and Josh Mosier and Sounak Chakrabarti and Anqi Chen and Tyler White and Dylan P. Losey},
  year={2021},
  url={http://arxiv.org/abs/2109.01747v1},
  abstract={Robots learn as they interact with humans. Consider a human teleoperating an assistive robot arm: as the human guides and corrects the arm's motion, the robot gathers information about the human's desired task. But how does the human know what their robot has inferred? Today's approaches often focus on conveying intent: for instance, upon legible motions or gestures to indicate what the robot is planning. However, closing the loop on robot inference requires more than just revealing the robot's current policy: the robot should also display the alternatives it thinks are likely, and prompt the human teacher when additional guidance is necessary. In this paper we propose a multimodal approach for communicating robot inference that combines both passive and active feedback. Specifically, we leverage information-rich augmented reality to passively visualize what the robot has inferred, and attention-grabbing haptic wristbands to actively prompt and direct the human's teaching. We apply our system to shared autonomy tasks where the robot must infer the human's goal in real-time. Within this context, we integrate passive and active modalities into a single algorithmic framework that determines when and which type of feedback to provide. Combining both passive and active feedback experimentally outperforms single modality baselines; during an in-person user study, we demonstrate that our integrated approach increases how efficiently humans teach the robot while simultaneously decreasing the amount of time humans spend interacting with the robot. Videos here: https://youtu.be/swq_u4iIP-g},
  doi={10.1109/LRA.2021.3111055},
  journal={arXiv}
}

@article{syring2015gibbs,
  title={Gibbs posterior inference on the minimum clinically important difference},
  author={Nick Syring and Ryan Martin},
  year={2015},
  url={http://arxiv.org/abs/1501.01840v4},
  abstract={IIt is known that a statistically significant treatment may not be clinically significant. A quantity that can be used to assess clinical significance is called the minimum clinically important difference (MCID), and inference on the MCID is an important and challenging problem. Modeling for the purpose of inference on the MCID is non-trivial, and concerns about bias from a misspecified parametric model or inefficiency from a nonparametric model motivate an alternative approach to balance robustness and efficiency. In particular, a recently proposed representation of the MCID as the minimizer of a suitable risk function makes it possible to construct a Gibbs posterior distribution for the MCID without specifying a model. We establish the posterior convergence rate and show, numerically, that an appropriately scaled version of this Gibbs posterior yields interval estimates for the MCID which are both valid and efficient even for relatively small sample sizes.},
  doi={10.1016/j.jspi.2017.03.001},
  journal={arXiv}
}

@article{wei2025active,
  title={Active Inference through Incentive Design in Markov Decision Processes},
  author={Xinyi Wei and Chongyang Shi and Shuo Han and Ahmed H. Hemida and Charles A. Kamhoua and Jie Fu},
  year={2025},
  url={http://arxiv.org/abs/2502.07065v1},
  abstract={We present a method for active inference with partial observations in stochastic systems through incentive design, also known as the leader-follower game. Consider a leader agent who aims to infer a follower agent's type given a finite set of possible types. Different types of followers differ in either the dynamical model, the reward function, or both. We assume the leader can partially observe a follower's behavior in the stochastic system modeled as a Markov decision process, in which the follower takes an optimal policy to maximize a total reward. To improve inference accuracy and efficiency, the leader can offer side payments (incentives) to the followers such that different types of them, under the incentive design, can exhibit diverging behaviors that facilitate the leader's inference task. We show the problem of active inference through incentive design can be formulated as a special class of leader-follower games, where the leader's objective is to balance the information gain and cost of incentive design. The information gain is measured by the entropy of the estimated follower's type given partial observations. Furthermore, we demonstrate that this problem can be solved by reducing a single-level optimization through softmax temporal consistency between followers' policies and value functions. This reduction allows us to develop an efficient gradient-based algorithm. We utilize observable operators in the hidden Markov model (HMM) to compute the necessary gradients and demonstrate the effectiveness of our approach through experiments in stochastic grid world environments.},
  journal={arXiv}
}

@article{orihara2025bayesian,
  title={Bayesian Doubly Robust Causal Inference via Posterior Coupling},
  author={Shunichiro Orihara and Tomotaka Momozaki and Shonosuke Sugasawa},
  year={2025},
  url={http://arxiv.org/abs/2506.04868v2},
  abstract={Bayesian doubly robust (DR) causal inference faces a fundamental dilemma: joint modeling of outcome and propensity score suffers from the feedback problem where outcome information contaminates propensity score estimation, while two-step analysis sacrifices valid posterior distributions for computational convenience. We resolve this dilemma through posterior coupling via entropic tilting. Our framework constructs independent posteriors for propensity score and outcome models, then couples them using entropic tilting to enforce the DR moment condition. This yields the first fully Bayesian DR estimator with an explicit posterior distribution. Theoretically, we establish three key properties: (i) when the outcome model is correctly specified, the tilted posterior coincides with the original; (ii) under propensity score model correctness, the posterior mean remains consistent despite outcome model misspecification; (iii) convergence rates improve for nonparametric outcome models. Simulations demonstrate superior bias reduction and efficiency compared to existing methods. We illustrate practical advantages of the proposed method through two applications: sensitivity analysis for unmeasured confounding in antihypertensive treatment effects on dementia, and high-dimensional confounder selection combining shrinkage priors with modified moment conditions for right heart catheterization mortality. We provide an R package implementing the proposed method.},
  journal={arXiv}
}

@article{goeman2022cluster,
  title={Cluster extent inference revisited: quantification and localization of brain activity},
  author={Jelle J. Goeman and Paweł\ Górecki and Ramin Monajemi and Xu Chen and Thomas E. Nichols and Wouter Weeda},
  year={2022},
  url={http://arxiv.org/abs/2208.04780v1},
  abstract={Cluster inference based on spatial extent thresholding is the most popular analysis method for finding activated brain areas in neuroimaging. However, the method has several well-known issues. While powerful for finding brain regions with some activation, the method as currently defined does not allow any further quantification or localization of signal. In this paper we repair this gap. We show that cluster-extent inference can be used (1.) to infer the presence of signal in anatomical regions of interest and (2.) to quantify the percentage of active voxels in any cluster or region of interest. These additional inferences come for free, i.e. they do not require any further adjustment of the alpha-level of tests, while retaining full familywise error control. We achieve this extension of the possibilities of cluster inference by an embedding of the method into a closed testing procedure, and solving the graph-theoretic k-separator problem that results from this embedding. The new method can be used in combination with random field theory or permutations. We demonstrate the usefulness of the method in a large-scale application to neuroimaging data from the Neurovault database.},
  journal={arXiv}
}

@article{nabi2020causal,
  title={Causal Inference in the Presence of Interference in Sponsored Search Advertising},
  author={Razieh Nabi and Joel Pfeiffer and Murat Ali Bayir and Denis Charles and Emre Kıcıman},
  year={2020},
  url={http://arxiv.org/abs/2010.07458v1},
  abstract={In classical causal inference, inferring cause-effect relations from data relies on the assumption that units are independent and identically distributed. This assumption is violated in settings where units are related through a network of dependencies. An example of such a setting is ad placement in sponsored search advertising, where the clickability of a particular ad is potentially influenced by where it is placed and where other ads are placed on the search result page. In such scenarios, confounding arises due to not only the individual ad-level covariates but also the placements and covariates of other ads in the system. In this paper, we leverage the language of causal inference in the presence of interference to model interactions among the ads. Quantification of such interactions allows us to better understand the click behavior of users, which in turn impacts the revenue of the host search engine and enhances user satisfaction. We illustrate the utility of our formalization through experiments carried out on the ad placement system of the Bing search engine.},
  doi={10.3389/fdata.2022.888592},
  journal={arXiv}
}

@article{oliver2019active,
  title={Active inference body perception and action for humanoid robots},
  author={Guillermo Oliver and Pablo Lanillos and Gordon Cheng},
  year={2019},
  url={http://arxiv.org/abs/1906.03022v3},
  abstract={Providing artificial agents with the same computational models of biological systems is a way to understand how intelligent behaviours may emerge. We present an active inference body perception and action model working for the first time in a humanoid robot. The model relies on the free energy principle proposed for the brain, where both perception and action goal is to minimise the prediction error through gradient descent on the variational free energy bound. The body state (latent variable) is inferred by minimising the difference between the observed (visual and proprioceptive) sensor values and the predicted ones. Simultaneously, the action makes sensory data sampling to better correspond to the prediction made by the inner model. We formalised and implemented the algorithm on the iCub robot and tested in 2D and 3D visual spaces for online adaptation to visual changes, sensory noise and discrepancies between the model and the real robot. We also compared our approach with classical inverse kinematics in a reaching task, analysing the suitability of such a neuroscience-inspired approach for real-world interaction. The algorithm gave the robot adaptive body perception and upper body reaching with head object tracking (toddler-like), and was able to incorporate visual features online (in a closed-loop manner) without increasing the computational complexity. Moreover, our model predicted involuntary actions in the presence of sensorimotor conflicts showing the path for a potential proof of active inference in humans.},
  doi={10.1109/TCDS.2021.3049907},
  journal={arXiv}
}

@article{lambert2024bayesian,
  title={Bayesian inference of wall torques for active Brownian particles},
  author={Sascha Lambert and Merle Duchene and Stefan Klumpp},
  year={2024},
  url={http://arxiv.org/abs/2409.03533v1},
  abstract={The motility of living things and synthetic self-propelled objects is often described using Active Brownian particles. To capture the interaction of these particles with their often complex environment, this model can be augmented with empirical forces or torques, for example, to describe their alignment with an obstacle or wall after a collision. Here, we assess the quality of these empirical models by comparing their output predictions with trajectories of rod-shaped active particles that scatter sterically at a flat wall. We employ a classical least-squares method to evaluate the instantaneous torque. In addition, we lay out a Bayesian inference procedure to construct the posterior distribution of plausible model parameters. In contrast to the least squares fit, the Bayesian approach does not require orientational data of the active particle and can readily be applied to experimental tracking data.},
  journal={arXiv}
}

@article{surrao2024constraining,
  title={Constraining Cosmological Parameters with Needlet Internal Linear Combination Maps II: Likelihood-Free Inference on NILC Power Spectra},
  author={Kristen M. Surrao and J. Colin Hill},
  year={2024},
  url={http://arxiv.org/abs/2406.16811v1},
  abstract={Standard cosmic microwave background (CMB) analyses constrain cosmological and astrophysical parameters by fitting parametric models to multifrequency power spectra (MFPS). However, such methods do not optimally weight maps in power spectrum (PS) measurements for non-Gaussian CMB foregrounds. We propose needlet internal linear combination (NILC), operating on wavelets with compact support in pixel and harmonic space, as a weighting scheme to yield more optimal parameter constraints. In a companion paper, we derived an analytic formula for NILC map PS, which is physically insightful but computationally difficult to use in parameter inference pipelines. In this work, we analytically show that fitting parametric templates to MFPS and harmonic ILC PS yields identical parameter constraints when the number of sky components equals or exceeds the number of frequency channels. We numerically show that, for Gaussian random fields, the same holds for NILC PS. This suggests that NILC can reduce parameter error bars in the presence of non-Gaussian fields since it uses non-Gaussian information. As Gaussian likelihoods may be inaccurate, we use likelihood-free inference (LFI) with neural posterior estimation. We show that performing inference with auto- and cross-PS of NILC component maps as summary statistics yields smaller parameter error bars than inference with MFPS. For a model with CMB, an amplified thermal Sunyaev--Zel'dovich (tSZ) signal, and noise, we find a 60% reduction in the area of the 2D 68% confidence region for component amplitude parameters inferred from NILC PS, as compared to inference from MFPS. Primordial $B$-mode searches are a promising application for our new method, as the amplitude of the non-Gaussian dust foreground is known to be larger than a potential signal. Our code is available in https://github.com/kmsurrao/NILC-Inference-Pipeline.},
  journal={arXiv}
}

@article{murugesan2022deep,
  title={Deep Surrogate of Modular Multi Pump using Active Learning},
  author={Malathi Murugesan and Kanika Goyal and Laure Barriere and Maura Pasquotti and Giacomo Veneri and Giovanni De Magistris},
  year={2022},
  url={http://arxiv.org/abs/2208.02840v1},
  abstract={Due to the high cost and reliability of sensors, the designers of a pump reduce the needed number of sensors for the estimation of the feasible operating point as much as possible. The major challenge to obtain a good estimation is the low amount of data available. Using this amount of data, the performance of the estimation method is not enough to satisfy the client requests. To solve this problem of scarcity of data, getting high quality data is important to obtain a good estimation. Based on these considerations, we develop an active learning framework for estimating the operating point of a Modular Multi Pump used in energy field. In particular we focus on the estimation of the surge distance. We apply Active learning to estimate the surge distance with minimal dataset. Results report that active learning is a valuable technique also for real application.},
  journal={arXiv}
}

@article{perrinet2016active,
  title={Active inference, eye movements and oculomotor delays},
  author={Laurent Perrinet and Rick Adams and Karl Friston},
  year={2016},
  url={http://arxiv.org/abs/1610.05564v1},
  abstract={This paper considers the problem of sensorimotor delays in the optimal control of (smooth) eye movements under uncertainty. Specifically, we consider delays in the visuo-oculomotor loop and their implications for active inference. Active inference uses a generalisation of Kalman filtering to provide Bayes optimal estimates of hidden states and action in generalized coordinates of motion. Representing hidden states in generalized coordinates provides a simple way of compensating for both sensory and oculomotor delays. The efficacy of this scheme is illustrated using neuronal simulations of pursuit initiation responses, with and without compensation. We then consider an extension of the gener-ative model to simulate smooth pursuit eye movements - in which the visuo-oculomotor system believes both the target and its centre of gaze are attracted to a (hidden) point moving in the visual field. Finally, the generative model is equipped with a hierarchical structure, so that it can recognise and remember unseen (occluded) trajectories and emit anticipatory responses. These simulations speak to a straightforward and neurobiologically plausible solution to the generic problem of integrating information from different sources with different temporal delays and the particular difficulties encountered when a system - like the oculomotor system - tries to control its environment with delayed signals.},
  doi={10.1007/s00422-014-0620-8},
  journal={arXiv}
}

@article{noel2021online,
  title={Online reinforcement learning with sparse rewards through an active inference capsule},
  author={Alejandro Daniel Noel and Charel van Hoof and Beren Millidge},
  year={2021},
  url={http://arxiv.org/abs/2106.02390v1},
  abstract={Intelligent agents must pursue their goals in complex environments with partial information and often limited computational capacity. Reinforcement learning methods have achieved great success by creating agents that optimize engineered reward functions, but which often struggle to learn in sparse-reward environments, generally require many environmental interactions to perform well, and are typically computationally very expensive. Active inference is a model-based approach that directs agents to explore uncertain states while adhering to a prior model of their goal behaviour. This paper introduces an active inference agent which minimizes the novel free energy of the expected future. Our model is capable of solving sparse-reward problems with a very high sample efficiency due to its objective function, which encourages directed exploration of uncertain states. Moreover, our model is computationally very light and can operate in a fully online manner while achieving comparable performance to offline RL methods. We showcase the capabilities of our model by solving the mountain car problem, where we demonstrate its superior exploration properties and its robustness to observation noise, which in fact improves performance. We also introduce a novel method for approximating the prior model from the reward function, which simplifies the expression of complex objectives and improves performance over previous active inference approaches.},
  journal={arXiv}
}

@article{obite2023active,
  title={Active Inference for Sum Rate Maximization in UAV-Assisted Cognitive NOMA Networks},
  author={Felix Obite and Ali Krayani and Atm S. Alam and Lucio Marcenaro and Arumugam Nallanathan and Carlo Regazzoni},
  year={2023},
  url={http://arxiv.org/abs/2309.11263v1},
  abstract={Given the surge in wireless data traffic driven by the emerging Internet of Things (IoT), unmanned aerial vehicles (UAVs), cognitive radio (CR), and non-orthogonal multiple access (NOMA) have been recognized as promising techniques to overcome massive connectivity issues. As a result, there is an increasing need to intelligently improve the channel capacity of future wireless networks. Motivated by active inference from cognitive neuroscience, this paper investigates joint subchannel and power allocation for an uplink UAV-assisted cognitive NOMA network. Maximizing the sum rate is often a highly challenging optimization problem due to dynamic network conditions and power constraints. To address this challenge, we propose an active inference-based algorithm. We transform the sum rate maximization problem into abnormality minimization by utilizing a generalized state-space model to characterize the time-changing network environment. The problem is then solved using an Active Generalized Dynamic Bayesian Network (Active-GDBN). The proposed framework consists of an offline perception stage, in which a UAV employs a hierarchical GDBN structure to learn an optimal generative model of discrete subchannels and continuous power allocation. In the online active inference stage, the UAV dynamically selects discrete subchannels and continuous power to maximize the sum rate of secondary users. By leveraging the errors in each episode, the UAV can adapt its resource allocation policies and belief updating to improve its performance over time. Simulation results demonstrate the effectiveness of our proposed algorithm in terms of cumulative sum rate compared to benchmark schemes.},
  journal={arXiv}
}

@article{singh2019hydrodynamically,
  title={Hydrodynamically interrupted droplet growth in scalar active matter},
  author={Rajesh Singh and M. E. Cates},
  year={2019},
  url={http://arxiv.org/abs/1907.04819v2},
  abstract={Suspensions of spherical active particles often show microphase separation. At a continuum level, coupling their scalar density to fluid flow, there are two distinct explanations. Each involves an effective interfacial tension: the first mechanical (causing flow) and the second diffusive (causing Ostwald ripening). Here we show how the negative mechanical tension of contractile swimmers creates, via a self-shearing instability, a steady-state life cycle of droplet growth interrupted by division whose scaling behavior we predict. When the diffusive tension is also negative, this is replaced by an arrested regime (mechanistically distinct, but with similar scaling) where division of small droplets is prevented by reverse Ostwald ripening.},
  doi={10.1103/PhysRevLett.123.148005},
  journal={arXiv}
}

@article{safa2023active,
  title={Active Inference in Hebbian Learning Networks},
  author={Ali Safa and Tim Verbelen and Lars Keuninckx and Ilja Ocket and André Bourdoux and Francky Catthoor and Georges Gielen and Gert Cauwenberghs},
  year={2023},
  url={http://arxiv.org/abs/2306.05053v2},
  abstract={This work studies how brain-inspired neural ensembles equipped with local Hebbian plasticity can perform active inference (AIF) in order to control dynamical agents. A generative model capturing the environment dynamics is learned by a network composed of two distinct Hebbian ensembles: a posterior network, which infers latent states given the observations, and a state transition network, which predicts the next expected latent state given current state-action pairs. Experimental studies are conducted using the Mountain Car environment from the OpenAI gym suite, to study the effect of the various Hebbian network parameters on the task performance. It is shown that the proposed Hebbian AIF approach outperforms the use of Q-learning, while not requiring any replay buffer, as in typical reinforcement learning systems. These results motivate further investigations of Hebbian learning for the design of AIF networks that can learn environment dynamics without the need for revisiting past buffered experiences.},
  journal={arXiv}
}

@article{fisch2020efficient,
  title={Efficient Conformal Prediction via Cascaded Inference with Expanded Admission},
  author={Adam Fisch and Tal Schuster and Tommi Jaakkola and Regina Barzilay},
  year={2020},
  url={http://arxiv.org/abs/2007.03114v3},
  abstract={In this paper, we present a novel approach for conformal prediction (CP), in which we aim to identify a set of promising prediction candidates -- in place of a single prediction. This set is guaranteed to contain a correct answer with high probability, and is well-suited for many open-ended classification tasks. In the standard CP paradigm, the predicted set can often be unusably large and also costly to obtain. This is particularly pervasive in settings where the correct answer is not unique, and the number of total possible answers is high. We first expand the CP correctness criterion to allow for additional, inferred "admissible" answers, which can substantially reduce the size of the predicted set while still providing valid performance guarantees. Second, we amortize costs by conformalizing prediction cascades, in which we aggressively prune implausible labels early on by using progressively stronger classifiers -- again, while still providing valid performance guarantees. We demonstrate the empirical effectiveness of our approach for multiple applications in natural language processing and computational chemistry for drug discovery.},
  journal={arXiv}
}

@article{kimhi2024hysteresis,
  title={Hysteresis Activation Function for Efficient Inference},
  author={Moshe Kimhi and Idan Kashani and Avi Mendelson and Chaim Baskin},
  year={2024},
  url={http://arxiv.org/abs/2411.10573v3},
  abstract={The widely used ReLU is favored for its hardware efficiency, {as the implementation at inference is a one bit sign case,} yet suffers from issues such as the ``dying ReLU'' problem, where during training, neurons fail to activate and constantly remain at zero, as highlighted by Lu et al. Traditional approaches to mitigate this issue often introduce more complex and less hardware-friendly activation functions. In this work, we propose a Hysteresis Rectified Linear Unit (HeLU), an efficient activation function designed to address the ``dying ReLU'' problem with minimal complexity. Unlike traditional activation functions with fixed thresholds for training and inference, HeLU employs a variable threshold that refines the backpropagation. This refined mechanism allows simpler activation functions to achieve competitive performance comparable to their more complex counterparts without introducing unnecessary complexity or requiring inductive biases. Empirical evaluations demonstrate that HeLU enhances model generalization across diverse datasets, offering a promising solution for efficient and effective inference suitable for a wide range of neural network architectures.},
  journal={arXiv}
}

@article{scholz2022inference,
  title={Inference of Affordances and Active Motor Control in Simulated Agents},
  author={Fedor Scholz and Christian Gumbsch and Sebastian Otte and Martin V. Butz},
  year={2022},
  url={http://arxiv.org/abs/2202.11532v3},
  abstract={Flexible, goal-directed behavior is a fundamental aspect of human life. Based on the free energy minimization principle, the theory of active inference formalizes the generation of such behavior from a computational neuroscience perspective. Based on the theory, we introduce an output-probabilistic, temporally predictive, modular artificial neural network architecture, which processes sensorimotor information, infers behavior-relevant aspects of its world, and invokes highly flexible, goal-directed behavior. We show that our architecture, which is trained end-to-end to minimize an approximation of free energy, develops latent states that can be interpreted as affordance maps. That is, the emerging latent states signal which actions lead to which effects dependent on the local context. In combination with active inference, we show that flexible, goal-directed behavior can be invoked, incorporating the emerging affordance maps. As a result, our simulated agent flexibly steers through continuous spaces, avoids collisions with obstacles, and prefers pathways that lead to the goal with high certainty. Additionally, we show that the learned agent is highly suitable for zero-shot generalization across environments: After training the agent in a handful of fixed environments with obstacles and other terrains affecting its behavior, it performs similarly well in procedurally generated environments containing different amounts of obstacles and terrains of various sizes at different locations.},
  doi={10.3389/fnbot.2022.881673},
  journal={arXiv}
}

@article{kontorovich2016active,
  title={Active Nearest-Neighbor Learning in Metric Spaces},
  author={Aryeh Kontorovich and Sivan Sabato and Ruth Urner},
  year={2016},
  url={http://arxiv.org/abs/1605.06792v3},
  abstract={We propose a pool-based non-parametric active learning algorithm for general metric spaces, called MArgin Regularized Metric Active Nearest Neighbor (MARMANN), which outputs a nearest-neighbor classifier. We give prediction error guarantees that depend on the noisy-margin properties of the input sample, and are competitive with those obtained by previously proposed passive learners. We prove that the label complexity of MARMANN is significantly lower than that of any passive learner with similar error guarantees. MARMANN is based on a generalized sample compression scheme, and a new label-efficient active model-selection procedure.},
  journal={arXiv}
}

@article{asghar2016deep,
  title={Deep Active Learning for Dialogue Generation},
  author={Nabiha Asghar and Pascal Poupart and Xin Jiang and Hang Li},
  year={2016},
  url={http://arxiv.org/abs/1612.03929v5},
  abstract={We propose an online, end-to-end, neural generative conversational model for open-domain dialogue. It is trained using a unique combination of offline two-phase supervised learning and online human-in-the-loop active learning. While most existing research proposes offline supervision or hand-crafted reward functions for online reinforcement, we devise a novel interactive learning mechanism based on hamming-diverse beam search for response generation and one-character user-feedback at each step. Experiments show that our model inherently promotes the generation of semantically relevant and interesting responses, and can be used to train agents with customized personas, moods and conversational styles.},
  journal={arXiv}
}

@article{peixoto2016nonparametric,
  title={Nonparametric Bayesian inference of the microcanonical stochastic block model},
  author={Tiago P. Peixoto},
  year={2016},
  url={http://arxiv.org/abs/1610.02703v4},
  abstract={A principled approach to characterize the hidden structure of networks is to formulate generative models, and then infer their parameters from data. When the desired structure is composed of modules or "communities", a suitable choice for this task is the stochastic block model (SBM), where nodes are divided into groups, and the placement of edges is conditioned on the group memberships. Here, we present a nonparametric Bayesian method to infer the modular structure of empirical networks, including the number of modules and their hierarchical organization. We focus on a microcanonical variant of the SBM, where the structure is imposed via hard constraints, i.e. the generated networks are not allowed to violate the patterns imposed by the model. We show how this simple model variation allows simultaneously for two important improvements over more traditional inference approaches: 1. Deeper Bayesian hierarchies, with noninformative priors replaced by sequences of priors and hyperpriors, that not only remove limitations that seriously degrade the inference on large networks, but also reveal structures at multiple scales; 2. A very efficient inference algorithm that scales well not only for networks with a large number of nodes and edges, but also with an unlimited number of modules. We show also how this approach can be used to sample modular hierarchies from the posterior distribution, as well as to perform model selection. We discuss and analyze the differences between sampling from the posterior and simply finding the single parameter estimate that maximizes it. Furthermore, we expose a direct equivalence between our microcanonical approach and alternative derivations based on the canonical SBM.},
  doi={10.1103/PhysRevE.95.012317},
  journal={arXiv}
}

@article{lee2025efficient,
  title={Efficient LLM Inference with Activation Checkpointing and Hybrid Caching},
  author={Sanghyeon Lee and Hongbeen Kim and Soojin Hwang and Guseul Heo and Minwoo Noh and Jaehyuk Huh},
  year={2025},
  url={http://arxiv.org/abs/2501.01792v1},
  abstract={Recent large language models (LLMs) with enormous model sizes use many GPUs to meet memory capacity requirements incurring substantial costs for token generation. To provide cost-effective LLM inference with relaxed latency constraints, extensive research has focused on expanding GPU memory by leveraging the host memory. However, LLM inference engines that utilize the host memory often face underutilization of GPU compute units, as a considerable portion of inference time is spent in loading the model onto the GPU via host-GPU interconnect. To tackle these challenges of the host memory offloading for LLM, we introduce HybridServe, an LLM inference system with activation checkpointing based on activation caching. The activation cache stores activation checkpoints generated during intermediate inference stages, allowing the fast recomputation of KV cache while model parameters are transferred to GPU from host memory. Unlike conventional methods that recompute the KV cache from scratch using token IDs, the activation cache allows bypassing projection and FFN operations. To balance between the activation recomputation and parameter loading overhead, this study proposes a KV-activation hybrid caching scheme which finds the best ratio of the key-value and activation caches to adjust the recomputation time. Our system achieves 2.19x throughput improvement over the state-of-the-art prior work for offloading both model weights and KV cache.},
  journal={arXiv}
}

@article{mohapatra2025inferring,
  title={Inferring activity from the flow field around active colloidal particles using deep learning},
  author={Aditya Mohapatra and Aditya Kumar and Mayurakshi Deb and Siddharth Dhomkar and Rajesh Singh},
  year={2025},
  url={http://arxiv.org/abs/2505.10270v3},
  abstract={Active colloidal particles create flow around them due to non-equilibrium process on their surfaces. In this paper, we infer the activity of such colloidal particles from the flow field created by them via deep learning. We first explain our method for one active particle, inferring the $2s$ mode (or the stresslet) and the $3t$ mode (or the source dipole) from the flow field data, along with the position and orientation of the particle. We then apply the method to a system of many active particles. We find excellent agreements between the predictions and the true values of activity. Our method presents a principled way to predict arbitrary activity from the flow field created by active particles.},
  doi={10.1017/jfm.2025.10502},
  journal={arXiv}
}

@article{annicchiarico2025active,
  title={An Active Inference perspective on Neurofeedback Training},
  author={Côme Annicchiarico and Fabien Lotte and Jérémie Mattout},
  year={2025},
  url={http://arxiv.org/abs/2505.03308v1},
  abstract={Neurofeedback training (NFT) aims to teach self-regulation of brain activity through real-time feedback, but suffers from highly variable outcomes and poorly understood mechanisms, hampering its validation. To address these issues, we propose a formal computational model of the NFT closed loop. Using Active Inference, a Bayesian framework modelling perception, action, and learning, we simulate agents interacting with an NFT environment. This enables us to test the impact of design choices (e.g., feedback quality, biomarker validity) and subject factors (e.g., prior beliefs) on training. Simulations show that training effectiveness is sensitive to feedback noise or bias, and to prior beliefs (highlighting the importance of guiding instructions), but also reveal that perfect feedback is insufficient to guarantee high performance. This approach provides a tool for assessing and predicting NFT variability, interpret empirical data, and potentially develop personalized training protocols.},
  journal={arXiv}
}

@article{gafarov2019simple,
  title={Simple subvector inference on sharp identified set in affine models},
  author={Bulat Gafarov},
  year={2019},
  url={http://arxiv.org/abs/1904.00111v3},
  abstract={This paper studies a regularized support function estimator for bounds on components of the parameter vector in the case in which the identified set is a polygon. The proposed regularized estimator has three important properties: (i) it has a uniform asymptotic Gaussian limit in the presence of flat faces in the absence of redundant (or overidentifying) constraints (or vice versa); (ii) the bias from regularization does not enter the first-order limiting distribution; (iii) the estimator remains consistent for sharp (non-enlarged) identified set for the individual components even in the non-regualar case. These properties are used to construct \emph{uniformly valid} confidence sets for an element $θ_{1}$ of a parameter vector $θ\in\mathbb{R}^{d}$ that is partially identified by affine moment equality and inequality conditions. The proposed confidence sets can be computed as a solution to a small number of linear and convex quadratic programs, leading to a substantial decrease in computation time and guarantees a global optimum. As a result, the method provides a uniformly valid inference in applications in which the dimension of the parameter space, $d$, and the number of inequalities, $k$, were previously computationally unfeasible ($d,k=100$). The proposed approach can be extended to construct confidence sets for intersection bounds, to construct joint polygon-shaped confidence sets for multiple components of $θ$, and to find the set of solutions to a linear program. Inference for coefficients in the linear IV regression model with an interval outcome is used as an illustrative example.},
  journal={arXiv}
}

@article{virgo2021interpreting,
  title={Interpreting Dynamical Systems as Bayesian Reasoners},
  author={Nathaniel Virgo and Martin Biehl and Simon McGregor},
  year={2021},
  url={http://arxiv.org/abs/2112.13523v1},
  abstract={A central concept in active inference is that the internal states of a physical system parametrise probability measures over states of the external world. These can be seen as an agent's beliefs, expressed as a Bayesian prior or posterior. Here we begin the development of a general theory that would tell us when it is appropriate to interpret states as representing beliefs in this way. We focus on the case in which a system can be interpreted as performing either Bayesian filtering or Bayesian inference. We provide formal definitions of what it means for such an interpretation to exist, using techniques from category theory.},
  journal={arXiv}
}

@article{stassun2012empirical,
  title={An Empirical Correction for Activity Effects on the Temperatures, Radii, and Estimated Masses of Low-Mass Stars and Brown Dwarfs},
  author={Keivan G. Stassun and Kaitlin M. Kratter and Aleks Scholz and Trent J. Dupuy},
  year={2012},
  url={http://arxiv.org/abs/1206.4930v2},
  abstract={We present empirical relations for determining the amount by which the effective temperatures and radii -- and therefore the estimated masses -- of low-mass stars and brown dwarfs are altered due to chromospheric activity. We base our relations on a large set of low-mass stars in the field with Halpha activity measurements, and on a set of low-mass eclipsing binaries with X-ray activity measurements from which we indirectly infer the Halpha activity. Both samples yield consistent relations linking the amount by which an active object's temperature is suppressed, and its radius inflated, to the strength of its Halpha emission. These relations are found to approximately preserve bolometric luminosity. We apply these relations to the peculiar brown-dwarf eclipsing binary 2M0535-05, in which the active, higher-mass brown dwarf has a cooler temperature than its inactive, lower-mass companion. The relations correctly reproduce the observed temperatures and radii of 2M0535-05 after accounting for the Halpha emission; 2M0535-05 would be in precise agreement with theoretical isochrones were it inactive. The relations that we present are applicable to brown dwarfs and low-mass stars with masses below 0.8 Msun and for which the activity, as measured by the fractional Halpha luminosity, is in the range -4.6 < log LHa/Lbol < -3.3. We expect these relations to be most useful for correcting radius and mass estimates of low-mass stars and brown dwarfs over their active lifetimes (few Gyr) and when the ages or distances (and therefore luminosities) are unknown. We also discuss the implications of this work for improved determinations of young cluster initial mass functions.},
  doi={10.1088/0004-637X/756/1/47},
  journal={arXiv}
}

@article{maisto2025what,
  title={What the flock knows that the birds do not: exploring the emergence of joint agency in multi-agent active inference},
  author={Domenico Maisto and Davide Nuzzi and Giovanni Pezzulo},
  year={2025},
  url={http://arxiv.org/abs/2511.10835v1},
  abstract={Collective behavior pervades biological systems, from flocks of birds to neural assemblies and human societies. Yet, how such collectives acquire functional properties -- such as joint agency or knowledge -- that transcend those of their individual components remains an open question. Here, we combine active inference and information-theoretic analyses to explore how a minimal system of interacting agents can give rise to joint agency and collective knowledge. We model flocking dynamics using multiple active inference agents, each minimizing its own free energy while coupling reciprocally with its neighbors. We show that as agents self-organize, their interactions define higher-order statistical boundaries (Markov blankets) enclosing a ``flock'' that can be treated as an emergent agent with its own sensory, active, and internal states. When exposed to external perturbations (a ``predator''), the flock exhibits faster, coordinated responses than individual agents, reflecting collective sensitivity to environmental change. Crucially, analyses of synergistic information reveal that the flock encodes information about the predator's location that is not accessible to every individual bird, demonstrating implicit collective knowledge. Together, these results show how informational coupling among active inference agents can generate new levels of autonomy and inference, providing a framework for understanding the emergence of (implicit) collective knowledge and joint agency.},
  journal={arXiv}
}

@article{han2021goaldirected,
  title={Goal-Directed Planning by Reinforcement Learning and Active Inference},
  author={Dongqi Han and Kenji Doya and Jun Tani},
  year={2021},
  url={http://arxiv.org/abs/2106.09938v2},
  abstract={What is the difference between goal-directed and habitual behavior? We propose a novel computational framework of decision making with Bayesian inference, in which everything is integrated as an entire neural network model. The model learns to predict environmental state transitions by self-exploration and generating motor actions by sampling stochastic internal states ${z}$. Habitual behavior, which is obtained from the prior distribution of ${z}$, is acquired by reinforcement learning. Goal-directed behavior is determined from the posterior distribution of ${z}$ by planning, using active inference which optimizes the past, current and future ${z}$ by minimizing the variational free energy for the desired future observation constrained by the observed sensory sequence. We demonstrate the effectiveness of the proposed framework by experiments in a sensorimotor navigation task with camera observations and continuous motor actions.},
  journal={arXiv}
}

@article{meng2025study,
  title={A study on audio synchronous steganography detection and distributed guide inference model based on sliding spectral features and intelligent inference drive},
  author={Wei Meng},
  year={2025},
  url={http://arxiv.org/abs/2505.03193v1},
  abstract={With the rise of short video platforms in global communication, embedding steganographic data in audio synchronization streams has emerged as a new covert communication method. To address the limitations of traditional techniques in detecting synchronized steganography, this paper proposes a detection and distributed guidance reconstruction model based on short video "Yupan" samples released by China's South Sea Fleet on TikTok. The method integrates sliding spectrum feature extraction and intelligent inference mechanisms. A 25 ms sliding window with short-time Fourier transform (STFT) is used to extract the main frequency trajectory and construct the synchronization frame detection model (M1), identifying a frame flag "FFFFFFFFFFFFFFFFFF80". The subsequent 32-byte payload is decoded by a structured model (M2) to infer distributed guidance commands. Analysis reveals a low-entropy, repetitive byte sequence in the 36 to 45 second audio segment with highly concentrated spectral energy, confirming the presence of synchronization frames. Although plaintext semantics are not restored, the consistency in command field layout suggests features of military communication protocols. The multi-segment splicing model further shows cross-video embedding and centralized decoding capabilities. The proposed framework validates the effectiveness of sliding spectral features for synchronized steganography detection and builds an extensible inference model for covert communication analysis and tactical guidance simulation on open platforms.},
  journal={arXiv}
}

@article{zhang2025rsparse,
  title={R-Sparse: Rank-Aware Activation Sparsity for Efficient LLM Inference},
  author={Zhenyu Zhang and Zechun Liu and Yuandong Tian and Harshit Khaitan and Zhangyang Wang and Steven Li},
  year={2025},
  url={http://arxiv.org/abs/2504.19449v1},
  abstract={Large Language Models (LLMs), while demonstrating remarkable capabilities across various applications, present significant challenges during inference due to their substantial model size, especially when deployed on edge devices. Activation sparsity offers a promising solution to reduce computation and memory movement, enabling more efficient inference, particularly for small-batch on-device applications. However, current approaches face limitations with non-ReLU activation function, which are foundational to most advanced LLMs, or require heavy continual training. Additionally, the difficulty in predicting active channels and limited achievable sparsity ratios constrain the effectiveness of activation sparsity-based methods. In this paper, we introduce R-Sparse, a training-free activation sparsity approach capable of achieving high sparsity levels in advanced LLMs. We conducted two preliminary investigations into how different components contribute to the output within a single linear layer and found two key observations: (i) the non-sparse components of the input function can be regarded as a few bias terms, and (ii) The full computation can be effectively approximated by an appropriate combination of input channels and weight singular values. Building on this, we replace the linear layers in LLMs with a rank-aware sparse inference method that leverages the sparsity of input channels and singular value components, eliminating the need for active channel prediction like the output sparsity based approaches. Experiments on Llama-2/3 and Mistral models across ten diverse tasks demonstrate that R-Sparse achieves comparable performance at 50% model-level sparsity, resulting in a significant 43% end-to-end efficient improvements with customized kernels.},
  journal={arXiv}
}

@article{prakki2024active,
  title={Active Inference for Self-Organizing Multi-LLM Systems: A Bayesian Thermodynamic Approach to Adaptation},
  author={Rithvik Prakki},
  year={2024},
  url={http://arxiv.org/abs/2412.10425v3},
  abstract={This paper introduces a novel approach to creating adaptive language agents by integrating active inference with large language models (LLMs). While LLMs demonstrate remarkable capabilities, their reliance on static prompts limits adaptation to new information and changing environments. We address this by implementing an active inference framework that acts as a cognitive layer above an LLM-based agent, dynamically adjusting prompts and search strategies through principled information-seeking behavior. Our framework models the environment using three state factors (prompt, search, and information states) with seven observation modalities capturing quality metrics. By framing the agent's learning through the free energy principle, we enable systematic exploration of prompt combinations and search strategies. Experimental results demonstrate the effectiveness of this approach, with the agent developing accurate models of environment dynamics evidenced by emergent structure in observation matrices. Action selection patterns reveal sophisticated exploration-exploitation behavior, transitioning from initial information-gathering to targeted prompt testing. The integration of thermodynamic principles with language model capabilities provides a principled framework for creating robust, adaptable agents, extending active inference beyond traditional low-dimensional control problems to high-dimensional, language-driven environments.},
  journal={arXiv}
}

@article{wei2023learning,
  title={Learning An Active Inference Model of Driver Perception and Control: Application to Vehicle Car-Following},
  author={Ran Wei and Anthony D. McDonald and Alfredo Garcia and Gustav Markkula and Johan Engstrom and Matthew O'Kelly},
  year={2023},
  url={http://arxiv.org/abs/2303.15201v2},
  abstract={In this paper we introduce a general estimation methodology for learning a model of human perception and control in a sensorimotor control task based upon a finite set of demonstrations. The model's structure consists of i the agent's internal representation of how the environment and associated observations evolve as a result of control actions and ii the agent's preferences over observable outcomes. We consider a model's structure specification consistent with active inference, a theory of human perception and behavior from cognitive science. According to active inference, the agent acts upon the world so as to minimize surprise defined as a measure of the extent to which an agent's current sensory observations differ from its preferred sensory observations. We propose a bi-level optimization approach to estimation which relies on a structural assumption on prior distributions that parameterize the statistical accuracy of the human agent's model of the environment. To illustrate the proposed methodology, we present the estimation of a model for car-following behavior based upon a naturalistic dataset. Overall, the results indicate that learning active inference models of human perception and control from data is a promising alternative to black-box models of driving.},
  journal={arXiv}
}

@article{mladenović2018active,
  title={Active Inference for Adaptive BCI: application to the P300 Speller},
  author={Jelena Mladenović and Jérémy Frey and Emmanuel Maby and Mateus Joffily and Fabien Lotte and Jeremie Mattout},
  year={2018},
  url={http://arxiv.org/abs/1805.09109v1},
  abstract={Adaptive Brain-Computer interfaces (BCIs) have shown to improve performance, however a general and flexible framework to implement adaptive features is still lacking. We appeal to a generic Bayesian approach, called Active Inference (AI), to infer user's intentions or states and act in a way that optimizes performance. In realistic P300-speller simulations, AI outperforms traditional algorithms with an increase in bit rate between 18% and 59%, while offering a possibility of unifying various adaptive implementations within one generic framework.},
  journal={arXiv}
}

@article{peng2022multipair,
  title={Multi-Pair D2D Communications Aided by An Active RIS over Spatially Correlated Channels with Phase Noise},
  author={Zhangjie Peng and Xue Liu and Cunhua Pan and Li Li and Jiangzhou Wang},
  year={2022},
  url={http://arxiv.org/abs/2208.07840v1},
  abstract={This paper investigates a multi-pair device-to-device (D2D) communication system aided by an active reconfigurable intelligent surface (RIS) with phase noise and direct link. The approximate closed-form expression of the ergodic sum rate is derived over spatially correlated Rician fading channels with statistical channel state information (CSI). When the Rician factors go to infinity, the asymptotic expressions of the ergodic sum rates are presented to give insights in poor scattering environment. The power scaling law for the special case of a single D2D pair is presented without phase noise under uncorrelated Rician fading condition. Then, to solve the ergodic sum rate maximization problem, a method based on genetic algorithm (GA) is proposed for joint power control and discrete phase shifts optimization. Simulation results verify the accuracy of our derivations, and also show that the active RIS outperforms the passive RIS.},
  doi={10.1109/LWC.2022.3193868},
  journal={arXiv}
}

@article{rodriguez2012submodular,
  title={Submodular Inference of Diffusion Networks from Multiple Trees},
  author={Manuel Gomez Rodriguez and Bernhard Schölkopf},
  year={2012},
  url={http://arxiv.org/abs/1205.1671v1},
  abstract={Diffusion and propagation of information, influence and diseases take place over increasingly larger networks. We observe when a node copies information, makes a decision or becomes infected but networks are often hidden or unobserved. Since networks are highly dynamic, changing and growing rapidly, we only observe a relatively small set of cascades before a network changes significantly. Scalable network inference based on a small cascade set is then necessary for understanding the rapidly evolving dynamics that govern diffusion. In this article, we develop a scalable approximation algorithm with provable near-optimal performance based on submodular maximization which achieves a high accuracy in such scenario, solving an open problem first introduced by Gomez-Rodriguez et al (2010). Experiments on synthetic and real diffusion data show that our algorithm in practice achieves an optimal trade-off between accuracy and running time.},
  journal={arXiv}
}

@article{nagao2006metallicity,
  title={Metallicity Evolution of Active Galactic Nuclei},
  author={Tohru Nagao and Roberto Maiolino and Alessandro Marconi},
  year={2006},
  url={http://arxiv.org/abs/astro-ph/0612570v1},
  abstract={In this contribution we report our recent investigation of the gas metallicity in active galactic nuclei and its dependence on luminosity and redshift. We compile large spectroscopic datasets of broad-line and narrow-line AGNs, and compare them with the results of our photoionization models. Through the analysis of both the broad and the narrow emission-line regions, we find that: (1) for a given luminosity, there is no redshift dependence of the gas metallicity; (2) for a given redshift, there is a significant correlation between gas metallicity and luminosity; (3) the luminosity-metallicity relation does no show any evolution in the redshift range 2 < z < 4.},
  journal={arXiv}
}

@article{khan2019approximate,
  title={Approximate Inference Turns Deep Networks into Gaussian Processes},
  author={Mohammad Emtiyaz Khan and Alexander Immer and Ehsan Abedi and Maciej Korzepa},
  year={2019},
  url={http://arxiv.org/abs/1906.01930v3},
  abstract={Deep neural networks (DNN) and Gaussian processes (GP) are two powerful models with several theoretical connections relating them, but the relationship between their training methods is not well understood. In this paper, we show that certain Gaussian posterior approximations for Bayesian DNNs are equivalent to GP posteriors. This enables us to relate solutions and iterations of a deep-learning algorithm to GP inference. As a result, we can obtain a GP kernel and a nonlinear feature map while training a DNN. Surprisingly, the resulting kernel is the neural tangent kernel. We show kernels obtained on real datasets and demonstrate the use of the GP marginal likelihood to tune hyperparameters of DNNs. Our work aims to facilitate further research on combining DNNs and GPs in practical settings.},
  journal={arXiv}
}

@article{dultzin2008activity,
  title={Activity induced by Gravitational Interaction in Galaxy Pairs},
  author={D. Dultzin and J. J. Gonzalez and Y. Krongold and H. Hernandez-Toledo and E. M. Huerta and I. Cruz-Gonzalez and L. Olguin and P. Marziani and F. Hernandez-Ibarra},
  year={2008},
  url={http://arxiv.org/abs/0809.1680v1},
  abstract={A systematic study of the nuclear emission of a sample of 97 spirals in isolated galaxy pairs with mixed morphology (E+S) shows that: 1) AGN activity is found in 40% of the spiral galaxies in these pairs, 2) Only one out of the 39 AGN found has type 1 (Broad line Component) activity, and 3) AGN tend to have closer companions than star forming galaxies. These results are at odds with a simple Unified Model for Seyferts, where only obscuration/orientation effects are of relevance, and neatly support an evolutionary scenario where interactions trigger nuclear activity, and obscuration/orientation effects may be complementary in a certain evolutionary phase.},
  journal={arXiv}
}

@article{baioumy2021faulttolerant,
  title={Fault-tolerant Control of Robot Manipulators with Sensory Faults using Unbiased Active Inference},
  author={Mohamed Baioumy and Corrado Pezzato and Riccardo Ferrari and Carlos Hernandez Corbato and Nick Hawes},
  year={2021},
  url={http://arxiv.org/abs/2104.01817v1},
  abstract={This work presents a novel fault-tolerant control scheme based on active inference. Specifically, a new formulation of active inference which, unlike previous solutions, provides unbiased state estimation and simplifies the definition of probabilistically robust thresholds for fault-tolerant control of robotic systems using the free-energy. The proposed solution makes use of the sensory prediction errors in the free-energy for the generation of residuals and thresholds for fault detection and isolation of sensory faults, and it does not require additional controllers for fault recovery. Results validating the benefits in a simulated 2-DOF manipulator are presented, and future directions to improve the current fault recovery approach are discussed.},
  journal={arXiv}
}

@article{piriyakulkij2023active,
  title={Active Preference Inference using Language Models and Probabilistic Reasoning},
  author={Wasu Top Piriyakulkij and Volodymyr Kuleshov and Kevin Ellis},
  year={2023},
  url={http://arxiv.org/abs/2312.12009v2},
  abstract={Actively inferring user preferences, for example by asking good questions, is important for any human-facing decision-making system. Active inference allows such systems to adapt and personalize themselves to nuanced individual preferences. To enable this ability for instruction-tuned large language models (LLMs), one may prompt them to ask users questions to infer their preferences, transforming the language models into more robust, interactive systems. However, out of the box, these models are not efficient at extracting preferences: the questions they generate are not informative, requiring a high number of user interactions and impeding the usability of the downstream system. In this work, we introduce an inference-time algorithm that helps LLMs quickly infer preferences by using more informative questions. Our algorithm uses a probabilistic model whose conditional distributions are defined by prompting an LLM, and returns questions that optimize expected entropy and expected model change. Results in a simplified interactive web shopping setting with real product items show that an LLM equipped with our entropy reduction algorithm outperforms baselines with the same underlying LLM on task performance while using fewer user interactions.},
  journal={arXiv}
}

@article{luo2011inference,
  title={Inference with interference between units in an fMRI experiment of motor inhibition},
  author={Xi Luo and Dylan S. Small and Chiang-shan R. Li and Paul R. Rosenbaum},
  year={2011},
  url={http://arxiv.org/abs/1110.6560v2},
  abstract={An experimental unit is an opportunity to randomly apply or withhold a treatment. There is interference between units if the application of the treatment to one unit may also affect other units. In cognitive neuroscience, a common form of experiment presents a sequence of stimuli or requests for cognitive activity at random to each experimental subject and measures biological aspects of brain activity that follow these requests. Each subject is then many experimental units, and interference between units within an experimental subject is likely, in part because the stimuli follow one another quickly and in part because human subjects learn or become experienced or primed or bored as the experiment proceeds. We use a recent fMRI experiment concerned with the inhibition of motor activity to illustrate and further develop recently proposed methodology for inference in the presence of interference. A simulation evaluates the power of competing procedures.},
  doi={10.1080/01621459.2012.655954},
  journal={arXiv}
}

@article{wakayama2022active,
  title={Active Inference for Autonomous Decision-Making with Contextual Multi-Armed Bandits},
  author={Shohei Wakayama and Nisar Ahmed},
  year={2022},
  url={http://arxiv.org/abs/2209.09185v2},
  abstract={In autonomous robotic decision-making under uncertainty, the tradeoff between exploitation and exploration of available options must be considered. If secondary information associated with options can be utilized, such decision-making problems can often be formulated as contextual multi-armed bandits (CMABs). In this study, we apply active inference, which has been actively studied in the field of neuroscience in recent years, as an alternative action selection strategy for CMABs. Unlike conventional action selection strategies, it is possible to rigorously evaluate the uncertainty of each option when calculating the expected free energy (EFE) associated with the decision agent's probabilistic model, as derived from the free-energy principle. We specifically address the case where a categorical observation likelihood function is used, such that EFE values are analytically intractable. We introduce new approximation methods for computing the EFE based on variational and Laplace approximations. Extensive simulation study results demonstrate that, compared to other strategies, active inference generally requires far fewer iterations to identify optimal options and generally achieves superior cumulative regret, for relatively low extra computational cost.},
  journal={arXiv}
}

@article{costa2020neural,
  title={Neural dynamics under active inference: plausibility and efficiency of information processing},
  author={Lancelot Da Costa and Thomas Parr and Biswa Sengupta and Karl Friston},
  year={2020},
  url={http://arxiv.org/abs/2001.08028v2},
  abstract={Active inference is a normative framework for explaining behaviour under the free energy principle -- a theory of self-organisation originating in neuroscience. It specifies neuronal dynamics for state-estimation in terms of a descent on (variational) free energy -- a measure of the fit between an internal (generative) model and sensory observations. The free energy gradient is a prediction error -- plausibly encoded in the average membrane potentials of neuronal populations. Conversely, the expected probability of a state can be expressed in terms of neuronal firing rates. We show that this is consistent with current models of neuronal dynamics and establish face validity by synthesising plausible electrophysiological responses. We then show that these neuronal dynamics approximate natural gradient descent, a well-known optimisation algorithm from information geometry that follows the steepest descent of the objective in information space. We compare the information length of belief updating in both schemes, a measure of the distance traveled in information space that has a direct interpretation in terms of metabolic cost. We show that neural dynamics under active inference are metabolically efficient and suggest that neural representations in biological agents may evolve by approximating steepest descent in information space towards the point of optimal inference.},
  doi={10.3390/e23040454},
  journal={arXiv}
}

@article{chen2022adaptive,
  title={Adaptive Cluster Thresholding with Spatial Activation Guarantees Using All-resolutions Inference},
  author={Xu Chen and Jelle J. Goeman and Thijmen J. P. Krebs and Rosa J. Meijer and Wouter D. Weeda},
  year={2022},
  url={http://arxiv.org/abs/2206.13587v3},
  abstract={Classical cluster inference is hampered by the spatial specificity paradox. Given the null-hypothesis of no active voxels, the alternative hypothesis states that there is at least one active voxel in a cluster. Hence, the larger the cluster the less we know about where activation in the cluster is. Rosenblatt et al. (2018) proposed a post-hoc inference method, All-resolutions Inference (ARI), that addresses this paradox by estimating the number of active voxels of any brain region. ARI allows users to choose arbitrary brain regions and returns a simultaneous lower confidence bound of the true discovery proportion (TDP) for each of them, retaining control of the family-wise error rate. ARI does not, however, guide users to regions with high enough TDP. In this paper, we propose an efficient algorithm that outputs all maximal supra-threshold clusters, for which ARI gives a TDP lower confidence bound that is at least a chosen threshold, for any number of thresholds that need not be chosen a priori nor all at once. After a preprocessing step in linearithmic time, the algorithm only takes linear time in the size of its output. We demonstrate the algorithm with an application to two fMRI datasets. For both datasets, we found several clusters whose TDP confidently meets or exceeds a given threshold in less than a second.},
  journal={arXiv}
}

@article{mukherjee2024experimental,
  title={Experimental Design for Active Transductive Inference in Large Language Models},
  author={Subhojyoti Mukherjee and Anusha Lalitha and Aniket Deshmukh and Ge Liu and Yifei Ma and Branislav Kveton},
  year={2024},
  url={http://arxiv.org/abs/2404.08846v2},
  abstract={One emergent ability of large language models (LLMs) is that query-specific examples can be included in the prompt at inference time. In this work, we use active learning for adaptive prompt design and call it Active In-context Prompt Design (AIPD). We design the LLM prompt by adaptively choosing few-shot examples from a training set to optimize performance on a test set. The training examples are initially unlabeled and we obtain the label of the most informative ones, which maximally reduces uncertainty in the LLM prediction. We propose two algorithms, GO and SAL, which differ in how the few-shot examples are chosen. We analyze these algorithms in linear models: first GO and then use its equivalence with SAL. We experiment with many different tasks in small, medium-sized, and large language models; and show that GO and SAL outperform other methods for choosing few-shot examples in the LLM prompt at inference time.},
  journal={arXiv}
}

@article{zhang2020privacy,
  title={Privacy for All: Demystify Vulnerability Disparity of Differential Privacy against Membership Inference Attack},
  author={Bo Zhang and Ruotong Yu and Haipei Sun and Yanying Li and Jun Xu and Hui Wang},
  year={2020},
  url={http://arxiv.org/abs/2001.08855v1},
  abstract={Machine learning algorithms, when applied to sensitive data, pose a potential threat to privacy. A growing body of prior work has demonstrated that membership inference attack (MIA) can disclose specific private information in the training data to an attacker. Meanwhile, the algorithmic fairness of machine learning has increasingly caught attention from both academia and industry. Algorithmic fairness ensures that the machine learning models do not discriminate a particular demographic group of individuals (e.g., black and female people). Given that MIA is indeed a learning model, it raises a serious concern if MIA ``fairly'' treats all groups of individuals equally. In other words, whether a particular group is more vulnerable against MIA than the other groups. This paper examines the algorithmic fairness issue in the context of MIA and its defenses. First, for fairness evaluation, it formalizes the notation of vulnerability disparity (VD) to quantify the difference of MIA treatment on different demographic groups. Second, it evaluates VD on four real-world datasets, and shows that VD indeed exists in these datasets. Third, it examines the impacts of differential privacy, as a defense mechanism of MIA, on VD. The results show that although DP brings significant change on VD, it cannot eliminate VD completely. Therefore, fourth, it designs a new mitigation algorithm named FAIRPICK to reduce VD. An extensive set of experimental results demonstrate that FAIRPICK can effectively reduce VD for both with and without the DP deployment.},
  journal={arXiv}
}

@article{jordan2022datadriven,
  title={Data-Driven Influence Functions for Optimization-Based Causal Inference},
  author={Michael I. Jordan and Yixin Wang and Angela Zhou},
  year={2022},
  url={http://arxiv.org/abs/2208.13701v4},
  abstract={We study a constructive algorithm that approximates Gateaux derivatives for statistical functionals by finite differencing, with a focus on functionals that arise in   causal inference. We study the case where probability distributions are not known a priori but need to be estimated from data. These estimated distributions lead to empirical Gateaux derivatives, and we study the relationships between empirical, numerical, and analytical Gateaux derivatives. Starting with a case study of the interventional mean (average potential outcome), we delineate the relationship between finite differences and the analytical Gateaux derivative. We then derive requirements on the rates of numerical approximation in perturbation and smoothing that preserve the statistical benefits of one-step adjustments, such as rate double robustness. We then study more complicated functionals such as dynamic treatment regimes, the linear-programming formulation for policy optimization in infinite-horizon Markov decision processes, and sensitivity analysis in causal inference. More broadly, we study optimization-based estimators, since this begets a class of estimands where identification via regression adjustment is straightforward but obtaining influence functions under minor variations thereof is not. The ability to approximate bias adjustments in the presence of arbitrary constraints illustrates the usefulness of constructive approaches for Gateaux derivatives. We also find that the statistical structure of the functional (rate double robustness) can permit less conservative rates for finite-difference approximation. This property, however, can be specific to particular functionals; e.g., it occurs for the average potential outcome (hence average treatment effect) but not the infinite-horizon MDP policy value.},
  journal={arXiv}
}

@article{goosmann2007modeling,
  title={Modeling the Polarization of Dusty Scattering Cones in Active Galactic Nuclei},
  author={Rene W. Goosmann and C. Martin Gaskell and M. Shoji},
  year={2007},
  url={http://arxiv.org/abs/astro-ph/0701163v1},
  abstract={We have used the STOKES radiative transfer code, to model polarization induced by dust scattering in the polar regions of Active Galactic Nuclei (AGN). We discuss the wavelength-dependence of the spectral intensity and polarization over the optical/UV range at different viewing angles for two different types of dust: a Galactic dust model, and a dust model inferred from extinction properties of AGN. The STOKES code and documentation are freely available at http://www.stokes-program.info/.},
  journal={arXiv}
}

@article{sattari2010active,
  title={Active Topology Inference using Network Coding},
  author={Pegah Sattari and Christina Fragouli and Athina Markopoulou},
  year={2010},
  url={http://arxiv.org/abs/1007.3336v2},
  abstract={Our goal is to infer the topology of a network when (i) we can send probes between sources and receivers at the edge of the network and (ii) intermediate nodes can perform simple network coding operations, i.e., additions. Our key intuition is that network coding introduces topology-dependent correlation in the observations at the receivers, which can be exploited to infer the topology. For undirected tree topologies, we design hierarchical clustering algorithms, building on our prior work. For directed acyclic graphs (DAGs), first we decompose the topology into a number of two-source, two-receiver (2-by-2) subnetwork components and then we merge these components to reconstruct the topology. Our approach for DAGs builds on prior work on tomography, and improves upon it by employing network coding to accurately distinguish among all different 2-by-2 components. We evaluate our algorithms through simulation of a number of realistic topologies and compare them to active tomographic techniques without network coding. We also make connections between our approach and alternatives, including passive inference, traceroute, and packet marking.},
  doi={10.1016/j.phycom.2012.02.006},
  journal={arXiv}
}

@article{uy2021active,
  title={Active operator inference for learning low-dimensional dynamical-system models from noisy data},
  author={Wayne Isaac Tan Uy and Yuepeng Wang and Yuxiao Wen and Benjamin Peherstorfer},
  year={2021},
  url={http://arxiv.org/abs/2107.09256v2},
  abstract={Noise poses a challenge for learning dynamical-system models because already small variations can distort the dynamics described by trajectory data. This work builds on operator inference from scientific machine learning to infer low-dimensional models from high-dimensional state trajectories polluted with noise. The presented analysis shows that, under certain conditions, the inferred operators are unbiased estimators of the well-studied projection-based reduced operators from traditional model reduction. Furthermore, the connection between operator inference and projection-based model reduction enables bounding the mean-squared errors of predictions made with the learned models with respect to traditional reduced models. The analysis also motivates an active operator inference approach that judiciously samples high-dimensional trajectories with the aim of achieving a low mean-squared error by reducing the effect of noise. Numerical experiments with high-dimensional linear and nonlinear state dynamics demonstrate that predictions obtained with active operator inference have orders of magnitude lower mean-squared errors than operator inference with traditional, equidistantly sampled trajectory data.},
  journal={arXiv}
}

@article{shields2006emissionline,
  title={Emission-Line versus Continuum Correlations in Active Galactic Nuclei},
  author={Joseph C. Shields},
  year={2006},
  url={http://arxiv.org/abs/astro-ph/0612613v1},
  abstract={The Baldwin Effect, a negative correlation between emission-line equivalent width and luminosity in active galactic nuclei, is still of interest as a diagnostic of accretion physics nearly thirty years after its discovery. This review examines recent developments in the study of correlations between line and continuum emission in AGNs, as measured both in ensembles and in individual sources.},
  journal={arXiv}
}

@article{lanzieri2024optimal,
  title={Optimal Neural Summarisation for Full-Field Weak Lensing Cosmological Implicit Inference},
  author={Denise Lanzieri and Justine Zeghal and T. Lucas Makinen and Alexandre Boucaud and Jean-Luc Starck and François Lanusse},
  year={2024},
  url={http://arxiv.org/abs/2407.10877v2},
  abstract={Traditionally, weak lensing cosmological surveys have been analyzed using summary statistics motivated by their analytically tractable likelihoods, or by their ability to access higher-order information, at the cost of requiring Simulation-Based Inference (SBI) approaches. While informative, these statistics are neither designed nor guaranteed to be statistically sufficient. With the rise of deep learning, it becomes possible to create summary statistics optimized to extract the full data information. We compare different neural summarization strategies proposed in the weak lensing literature, to assess which loss functions lead to theoretically optimal summary statistics to perform full-field inference. In doing so, we aim to provide guidelines and insights to the community to help guide future neural-based inference analyses. We design an experimental setup to isolate the impact of the loss function used to train neural networks. We have developed the sbi_lens JAX package, which implements an automatically differentiable lognormal wCDM LSST-Y10 weak lensing simulator. The explicit full-field posterior obtained using the Hamiltonian Monte Carlo sampler gives us a ground truth to which to compare different compression strategies. We provide theoretical insight into the loss functions used in the literature and show that some do not necessarily lead to sufficient statistics (e.g. Mean Square Error (MSE)), while those motivated by information theory (e.g. Variational Mutual Information Maximization (VMIM)) can. Our numerical experiments confirm these insights and show, in our simulated wCDM scenario, that the Figure of Merit (FoM) of an analysis using neural summaries optimized under VMIM achieves 100% of the reference Omega_c - sigma_8 full-field FoM, while an analysis using neural summaries trained under MSE achieves only 81% of the same reference FoM.},
  doi={10.1051/0004-6361/202451535},
  journal={arXiv}
}

@article{caretta2009galaxy,
  title={Galaxy activity influenced by the environment in the cluster of galaxies Abell 85},
  author={C. A. Caretta and J. M. Islas-Islas and J. P. Torres-Papaqui and R. Coziol and H. Bravo-Alfaro and H. Andernach},
  year={2009},
  url={http://arxiv.org/abs/0902.2293v1},
  abstract={We analyse the relation between the dynamical state of a cluster of galaxies and the activity (star formation and AGN) of its members. For the case of Abell 85 we find some evidence for an enhanced activity of both types in substructures which are in the early stage of merging with the cluster.},
  journal={arXiv}
}

@article{selig2014nifty,
  title={The NIFTY way of Bayesian signal inference},
  author={Marco Selig},
  year={2014},
  url={http://arxiv.org/abs/1412.7160v1},
  abstract={We introduce NIFTY, "Numerical Information Field Theory", a software package for the development of Bayesian signal inference algorithms that operate independently from any underlying spatial grid and its resolution. A large number of Bayesian and Maximum Entropy methods for 1D signal reconstruction, 2D imaging, as well as 3D tomography, appear formally similar, but one often finds individualized implementations that are neither flexible nor easily transferable. Signal inference in the framework of NIFTY can be done in an abstract way, such that algorithms, prototyped in 1D, can be applied to real world problems in higher-dimensional settings. NIFTY as a versatile library is applicable and already has been applied in 1D, 2D, 3D and spherical settings. A recent application is the D3PO algorithm targeting the non-trivial task of denoising, deconvolving, and decomposing photon observations in high energy astronomy.},
  doi={10.1063/1.4903712},
  journal={arXiv}
}

@article{joseph2021anomaly,
  title={Anomaly Detection via Controlled Sensing and Deep Active Inference},
  author={Geethu Joseph and Chen Zhong and M. Cenk Gursoy and Senem Velipasalar and Pramod K. Varshney},
  year={2021},
  url={http://arxiv.org/abs/2105.06288v1},
  abstract={In this paper, we address the anomaly detection problem where the objective is to find the anomalous processes among a given set of processes. To this end, the decision-making agent probes a subset of processes at every time instant and obtains a potentially erroneous estimate of the binary variable which indicates whether or not the corresponding process is anomalous. The agent continues to probe the processes until it obtains a sufficient number of measurements to reliably identify the anomalous processes. In this context, we develop a sequential selection algorithm that decides which processes to be probed at every instant to detect the anomalies with an accuracy exceeding a desired value while minimizing the delay in making the decision and the total number of measurements taken. Our algorithm is based on active inference which is a general framework to make sequential decisions in order to maximize the notion of free energy. We define the free energy using the objectives of the selection policy and implement the active inference framework using a deep neural network approximation. Using numerical experiments, we compare our algorithm with the state-of-the-art method based on deep actor-critic reinforcement learning and demonstrate the superior performance of our algorithm.},
  journal={arXiv}
}

@article{yan2018unified,
  title={A Unified Framework for Inference in Network Models with Degree Heterogeneity and Homophily},
  author={Ting Yan},
  year={2018},
  url={http://arxiv.org/abs/1806.02550v2},
  abstract={The degree heterogeneity and homophily are two typical features in network data. In this paper, we formulate a general model for undirected networks with these two features and present the moment estimation for inferring the degree and homophily parameters. The binary or nonbinary network edges are simultaneously considered. We establish a unified theoretical framework under which the consistency of the moment estimator holds as the size of networks goes to infinity. We also derive the asymptotic representation of the moment estimator that can be used to characterize its limiting distribution. The asymptotic representation of the moment estimator of the homophily parameter contains a bias term. Two applications are provided to illustrate the theoretical result. Numerical studies and a real data analysis demonstrate our theoretical findings.},
  journal={arXiv}
}

@article{tinguy2022home,
  title={Home Run: Finding Your Way Home by Imagining Trajectories},
  author={Daria de Tinguy and Pietro Mazzaglia and Tim Verbelen and Bart Dhoedt},
  year={2022},
  url={http://arxiv.org/abs/2208.10914v1},
  abstract={When studying unconstrained behaviour and allowing mice to leave their cage to navigate a complex labyrinth, the mice exhibit foraging behaviour in the labyrinth searching for rewards, returning to their home cage now and then, e.g. to drink. Surprisingly, when executing such a ``home run'', the mice do not follow the exact reverse path, in fact, the entry path and home path have very little overlap. Recent work proposed a hierarchical active inference model for navigation, where the low level model makes inferences about hidden states and poses that explain sensory inputs, whereas the high level model makes inferences about moving between locations, effectively building a map of the environment. However, using this ``map'' for planning, only allows the agent to find trajectories that it previously explored, far from the observed mice's behaviour. In this paper, we explore ways of incorporating before-unvisited paths in the planning algorithm, by using the low level generative model to imagine potential, yet undiscovered paths. We demonstrate a proof of concept in a grid-world environment, showing how an agent can accurately predict a new, shorter path in the map leading to its starting point, using a generative model learnt from pixel-based observations.},
  journal={arXiv}
}

@article{mozafari2012active,
  title={Active Learning for Crowd-Sourced Databases},
  author={Barzan Mozafari and Purnamrita Sarkar and Michael J. Franklin and Michael I. Jordan and Samuel Madden},
  year={2012},
  url={http://arxiv.org/abs/1209.3686v4},
  abstract={Crowd-sourcing has become a popular means of acquiring labeled data for a wide variety of tasks where humans are more accurate than computers, e.g., labeling images, matching objects, or analyzing sentiment. However, relying solely on the crowd is often impractical even for data sets with thousands of items, due to time and cost constraints of acquiring human input (which cost pennies and minutes per label). In this paper, we propose algorithms for integrating machine learning into crowd-sourced databases, with the goal of allowing crowd-sourcing applications to scale, i.e., to handle larger datasets at lower costs. The key observation is that, in many of the above tasks, humans and machine learning algorithms can be complementary, as humans are often more accurate but slow and expensive, while algorithms are usually less accurate, but faster and cheaper.   Based on this observation, we present two new active learning algorithms to combine humans and algorithms together in a crowd-sourced database. Our algorithms are based on the theory of non-parametric bootstrap, which makes our results applicable to a broad class of machine learning models. Our results, on three real-life datasets collected with Amazon's Mechanical Turk, and on 15 well-known UCI data sets, show that our methods on average ask humans to label one to two orders of magnitude fewer items to achieve the same accuracy as a baseline that labels random images, and two to eight times fewer questions than previous active learning schemes.},
  journal={arXiv}
}

@article{pitliya2025theory,
  title={Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation},
  author={Riddhi J. Pitliya and Ozan Çatal and Toon Van de Maele and Corrado Pezzato and Tim Verbelen},
  year={2025},
  url={http://arxiv.org/abs/2508.00401v2},
  abstract={Theory of Mind (ToM) -- the ability to understand that others can have differing knowledge and goals -- enables agents to reason about others' beliefs while planning their own actions. We present a novel approach to multi-agent cooperation by implementing ToM within active inference. Unlike previous active inference approaches to multi-agent cooperation, our method neither relies on task-specific shared generative models nor requires explicit communication. In our framework, ToM-equipped agents maintain distinct representations of their own and others' beliefs and goals. ToM agents then use an extended and adapted version of the sophisticated inference tree-based planning algorithm to systematically explore joint policy spaces through recursive reasoning. We evaluate our approach through collision avoidance and foraging simulations. Results suggest that ToM agents cooperate better compared to non-ToM counterparts by being able to avoid collisions and reduce redundant efforts. Crucially, ToM agents accomplish this by inferring others' beliefs solely from observable behaviour and considering them when planning their own actions. Our approach shows potential for generalisable and scalable multi-agent systems while providing computational insights into ToM mechanisms.},
  journal={arXiv}
}

@article{nouioua2006using,
  title={Using Answer Set Programming in an Inference-Based approach to Natural Language Semantics},
  author={Farid Nouioua and Pascal Nicolas},
  year={2006},
  url={http://arxiv.org/abs/cs/0607088v1},
  abstract={Using Answer Set Programming in an Inference-Based approach to Natural Language Semantics},
  journal={arXiv}
}

@article{tinguy2025navigation,
  title={Navigation and Exploration with Active Inference: from Biology to Industry},
  author={Daria de Tinguy and Tim Verbelen and Bart Dhoedt},
  year={2025},
  url={http://arxiv.org/abs/2508.07269v2},
  abstract={By building and updating internal cognitive maps, animals exhibit extraordinary navigation abilities in complex, dynamic environments. Inspired by these biological mechanisms, we present a real time robotic navigation system grounded in the Active Inference Framework (AIF). Our model incrementally constructs a topological map, infers the agent's location, and plans actions by minimising expected uncertainty and fulfilling perceptual goals without any prior training. Integrated into the ROS2 ecosystem, we validate its adaptability and efficiency across both 2D and 3D environments (simulated and real world), demonstrating competitive performance with traditional and state of the art exploration approaches while offering a biologically inspired navigation approach.},
  journal={arXiv}
}

@article{nasr2018comprehensive,
  title={Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning},
  author={Milad Nasr and Reza Shokri and Amir Houmansadr},
  year={2018},
  url={http://arxiv.org/abs/1812.00910v2},
  abstract={Deep neural networks are susceptible to various inference attacks as they remember information about their training data. We design white-box inference attacks to perform a comprehensive privacy analysis of deep learning models. We measure the privacy leakage through parameters of fully trained models as well as the parameter updates of models during training. We design inference algorithms for both centralized and federated learning, with respect to passive and active inference attackers, and assuming different adversary prior knowledge.   We evaluate our novel white-box membership inference attacks against deep learning algorithms to trace their training data records. We show that a straightforward extension of the known black-box attacks to the white-box setting (through analyzing the outputs of activation functions) is ineffective. We therefore design new algorithms tailored to the white-box setting by exploiting the privacy vulnerabilities of the stochastic gradient descent algorithm, which is the algorithm used to train deep neural networks. We investigate the reasons why deep learning models may leak information about their training data. We then show that even well-generalized models are significantly susceptible to white-box membership inference attacks, by analyzing state-of-the-art pre-trained and publicly available models for the CIFAR dataset. We also show how adversarial participants, in the federated learning setting, can successfully run active membership inference attacks against other participants, even when the global model achieves high prediction accuracies.},
  doi={10.1109/SP.2019.00065},
  journal={arXiv}
}

@article{roversi2010linear,
  title={Linear lambda Calculus with Explicit Substitutions as Proof-Search in Deep Inference},
  author={Luca Roversi},
  year={2010},
  url={http://arxiv.org/abs/1011.3668v4},
  abstract={SBV is a deep inference system that extends the set of logical operators of multiplicative linear logic with the non commutative operator Seq. We introduce the logical system SBVr which extends SBV by adding a self-dual atom-renaming operator to it. We prove that the cut elimination holds on SBVr. SBVr and its cut free subsystem BVr are complete and sound with respect to linear lambda calculus with explicit substitutions. Under any strategy, a sequence of evaluation steps of any linear lambda-term M becomes a process of proof-search in SBVr (BVr) once M is mapped into a formula of SBVr. Completeness and soundness follow from simulating linear beta-reduction with explicit substitutions as processes. The role of the new renaming operator of SBVr is to rename channel-names on-demand. This simulates the substitution that occurs in a beta-reduction. Despite SBVr is a minimal extension of SBV its proof-search can compute all boolean functions, as linear lambda-calculus with explicit substitutions can compute all boolean functions as well. So, proof search of SBVr and BVr is at least ptime-complete.},
  journal={arXiv}
}

@article{dette2016optimal,
  title={Optimal designs for active controlled dose finding trials with efficacy-toxicity outcomes},
  author={Holger Dette and Katrin Kettelhake and Kirsten Schorning and Weng Kee Wong and Frank Bretz},
  year={2016},
  url={http://arxiv.org/abs/1601.00797v1},
  abstract={Nonlinear regression models addressing both efficacy and toxicity outcomes are increasingly used in dose-finding trials, such as in pharmaceutical drug development. However, research on related experimental design problems for corresponding active controlled trials is still scarce. In this paper we derive optimal designs to estimate efficacy and toxicity in an active controlled clinical dose finding trial when the bivariate continuous outcomes are modeled either by polynomials up to degree 2, the Michaelis- Menten model, the Emax model, or a combination thereof. We determine upper bounds on the number of different doses levels required for the optimal design and provide conditions under which the boundary points of the design space are included in the optimal design. We also provide an analytical description of the minimally supported $D$-optimal designs and show that they do not depend on the correlation between the bivariate outcomes. We illustrate the proposed methods with numerical examples and demonstrate the advantages of the $D$-optimal design for a trial, which has recently been considered in the literature.},
  journal={arXiv}
}

@article{dawid2020fiducial,
  title={Fiducial inference then and now},
  author={Philip Dawid},
  year={2020},
  url={http://arxiv.org/abs/2012.10689v1},
  abstract={We conduct a review of the fiducial approach to statistical inference, following its journey from its initiation by R. A. Fisher, through various problems and criticisms, on to its general neglect, and then to its more recent resurgence. Emphasis is laid on the functional model formulation, which helps clarify the very limited conditions under which fiducial inference can be conducted in an unambiguous and self-consistent way.},
  journal={arXiv}
}

@article{tang2025is,
  title={Is Active Persona Inference Necessary for Aligning Small Models to Personal Preferences?},
  author={Zilu Tang and Afra Feyza Akyürek and Ekin Akyürek and Derry Wijaya},
  year={2025},
  url={http://arxiv.org/abs/2505.13257v2},
  abstract={A prominent issue in aligning language models (LMs) to personalized preferences is underspecification -- the lack of information from users about their preferences. A popular trend of injecting such specification is adding a prefix (e.g. prior relevant conversations) to the current user's conversation to steer preference distribution. Most methods passively model personal preferences with prior example preferences pairs. We ask whether models benefit from actively inferring preference descriptions, and address this question by creating a synthetic personalized alignment dataset based on famous people with known public preferences. We then test how effective finetuned 1-8B size models are at inferring and aligning to personal preferences. Results show that higher-quality active prefixes lead to better generalization, more contextually faithful models, and less systematic biases across different protected attributes. All our results suggest active alignment can lead to a more controllable and efficient path for personalized alignment.},
  journal={arXiv}
}

@article{athreya2017statistical,
  title={Statistical inference on random dot product graphs: a survey},
  author={Avanti Athreya and Donniell E. Fishkind and Keith Levin and Vince Lyzinski and Youngser Park and Yichen Qin and Daniel L. Sussman and Minh Tang and Joshua T. Vogelstein and Carey E. Priebe},
  year={2017},
  url={http://arxiv.org/abs/1709.05454v1},
  abstract={The random dot product graph (RDPG) is an independent-edge random graph that is analytically tractable and, simultaneously, either encompasses or can successfully approximate a wide range of random graphs, from relatively simple stochastic block models to complex latent position graphs. In this survey paper, we describe a comprehensive paradigm for statistical inference on random dot product graphs, a paradigm centered on spectral embeddings of adjacency and Laplacian matrices. We examine the analogues, in graph inference, of several canonical tenets of classical Euclidean inference: in particular, we summarize a body of existing results on the consistency and asymptotic normality of the adjacency and Laplacian spectral embeddings, and the role these spectral embeddings can play in the construction of single- and multi-sample hypothesis tests for graph data. We investigate several real-world applications, including community detection and classification in large social networks and the determination of functional and biologically relevant network properties from an exploratory data analysis of the Drosophila connectome. We outline requisite background and current open problems in spectral graph inference.},
  journal={arXiv}
}

@article{hemmer2020deal,
  title={DEAL: Deep Evidential Active Learning for Image Classification},
  author={Patrick Hemmer and Niklas Kühl and Jakob Schöffer},
  year={2020},
  url={http://arxiv.org/abs/2007.11344v2},
  abstract={Convolutional Neural Networks (CNNs) have proven to be state-of-the-art models for supervised computer vision tasks, such as image classification. However, large labeled data sets are generally needed for the training and validation of such models. In many domains, unlabeled data is available but labeling is expensive, for instance when specific expert knowledge is required. Active Learning (AL) is one approach to mitigate the problem of limited labeled data. Through selecting the most informative and representative data instances for labeling, AL can contribute to more efficient learning of the model. Recent AL methods for CNNs propose different solutions for the selection of instances to be labeled. However, they do not perform consistently well and are often computationally expensive. In this paper, we propose a novel AL algorithm that efficiently learns from unlabeled data by capturing high prediction uncertainty. By replacing the softmax standard output of a CNN with the parameters of a Dirichlet density, the model learns to identify data instances that contribute efficiently to improving model performance during training. We demonstrate in several experiments with publicly available data that our method consistently outperforms other state-of-the-art AL approaches. It can be easily implemented and does not require extensive computational resources for training. Additionally, we are able to show the benefits of the approach on a real-world medical use case in the field of automated detection of visual signals for pneumonia on chest radiographs.},
  journal={arXiv}
}

@article{kirsch2022marginal,
  title={Marginal and Joint Cross-Entropies & Predictives for Online Bayesian Inference, Active Learning, and Active Sampling},
  author={Andreas Kirsch and Jannik Kossen and Yarin Gal},
  year={2022},
  url={http://arxiv.org/abs/2205.08766v1},
  abstract={Principled Bayesian deep learning (BDL) does not live up to its potential when we only focus on marginal predictive distributions (marginal predictives). Recent works have highlighted the importance of joint predictives for (Bayesian) sequential decision making from a theoretical and synthetic perspective. We provide additional practical arguments grounded in real-world applications for focusing on joint predictives: we discuss online Bayesian inference, which would allow us to make predictions while taking into account additional data without retraining, and we propose new challenging evaluation settings using active learning and active sampling. These settings are motivated by an examination of marginal and joint predictives, their respective cross-entropies, and their place in offline and online learning. They are more realistic than previously suggested ones, building on work by Wen et al. (2021) and Osband et al. (2022), and focus on evaluating the performance of approximate BNNs in an online supervised setting. Initial experiments, however, raise questions on the feasibility of these ideas in high-dimensional parameter spaces with current BDL inference techniques, and we suggest experiments that might help shed further light on the practicality of current research for these problems. Importantly, our work highlights previously unidentified gaps in current research and the need for better approximate joint predictives.},
  journal={arXiv}
}

@article{wolfe2016inflation,
  title={The Inflation Technique for Causal Inference with Latent Variables},
  author={Elie Wolfe and Robert W. Spekkens and Tobias Fritz},
  year={2016},
  url={http://arxiv.org/abs/1609.00672v5},
  abstract={The problem of causal inference is to determine if a given probability distribution on observed variables is compatible with some causal structure. The difficult case is when the causal structure includes latent variables. We here introduce the $\textit{inflation technique}$ for tackling this problem. An inflation of a causal structure is a new causal structure that can contain multiple copies of each of the original variables, but where the ancestry of each copy mirrors that of the original. To every distribution of the observed variables that is compatible with the original causal structure, we assign a family of marginal distributions on certain subsets of the copies that are compatible with the inflated causal structure. It follows that compatibility constraints for the inflation can be translated into compatibility constraints for the original causal structure. Even if the constraints at the level of inflation are weak, such as observable statistical independences implied by disjoint causal ancestry, the translated constraints can be strong. We apply this method to derive new inequalities whose violation by a distribution witnesses that distribution's incompatibility with the causal structure (of which Bell inequalities and Pearl's instrumental inequality are prominent examples). We describe an algorithm for deriving all such inequalities for the original causal structure that follow from ancestral independences in the inflation. For three observed binary variables with pairwise common causes, it yields inequalities that are stronger in at least some aspects than those obtainable by existing methods. We also describe an algorithm that derives a weaker set of inequalities but is more efficient. Finally, we discuss which inflations are such that the inequalities one obtains from them remain valid even for quantum (and post-quantum) generalizations of the notion of a causal model.},
  doi={10.1515/jci-2017-0020},
  journal={arXiv}
}

@article{sedlak2023active,
  title={Active Inference on the Edge: A Design Study},
  author={Boris Sedlak and Victor Casamayor Pujol and Praveen Kumar Donta and Schahram Dustdar},
  year={2023},
  url={http://arxiv.org/abs/2311.10607v1},
  abstract={Machine Learning (ML) is a common tool to interpret and predict the behavior of distributed computing systems, e.g., to optimize the task distribution between devices. As more and more data is created by Internet of Things (IoT) devices, data processing and ML training are carried out by edge devices in close proximity. To ensure Quality of Service (QoS) throughout these operations, systems are supervised and dynamically adapted with the help of ML. However, as long as ML models are not retrained, they fail to capture gradual shifts in the variable distribution, leading to an inaccurate view of the system state. Moreover, as the prediction accuracy decreases, the reporting device should actively resolve uncertainties to improve the model's precision. Such a level of self-determination could be provided by Active Inference (ACI) -- a concept from neuroscience that describes how the brain constantly predicts and evaluates sensory information to decrease long-term surprise. We encompassed these concepts in a single action-perception cycle, which we implemented for distributed agents in a smart manufacturing use case. As a result, we showed how our ACI agent was able to quickly and traceably solve an optimization problem while fulfilling QoS requirements.},
  journal={arXiv}
}

@article{donnarumma2023integrating,
  title={Integrating large language models and active inference to understand eye movements in reading and dyslexia},
  author={Francesco Donnarumma and Mirco Frosolone and Giovanni Pezzulo},
  year={2023},
  url={http://arxiv.org/abs/2308.04941v3},
  abstract={We present a novel computational model employing hierarchical active inference to simulate reading and eye movements. The model characterizes linguistic processing as inference over a hierarchical generative model, facilitating predictions and inferences at various levels of granularity, from syllables to sentences. Our approach combines the strengths of large language models for realistic textual predictions and active inference for guiding eye movements to informative textual information, enabling the testing of predictions. The model exhibits proficiency in reading both known and unknown words and sentences, adhering to the distinction between lexical and nonlexical routes in dual route theories of reading. Our model therefore provides a novel approach to understand the cognitive processes underlying reading and eye movements, within a predictive processing framework. Furthermore, our model can potentially aid in understanding how maladaptive predictive processing can produce reading deficits associated with dyslexia. As a proof of concept, we show that attenuating the contribution of priors during the reading process leads to incorrect inferences and a more fragmented reading style, characterized by a greater number of shorter saccades, aligning with empirical findings regarding eye movements in dyslexic individuals. In summary, our model represents a significant advancement in comprehending the cognitive processes involved in reading and eye movements, with potential implications for understanding dyslexia in terms of maladaptive inference.},
  journal={arXiv}
}

@article{krishnan2018bar,
  title={BAR: Bayesian Activity Recognition using variational inference},
  author={Ranganath Krishnan and Mahesh Subedar and Omesh Tickoo},
  year={2018},
  url={http://arxiv.org/abs/1811.03305v2},
  abstract={Uncertainty estimation in deep neural networks is essential for designing reliable and robust AI systems. Applications such as video surveillance for identifying suspicious activities are designed with deep neural networks (DNNs), but DNNs do not provide uncertainty estimates. Capturing reliable uncertainty estimates in safety and security critical applications will help to establish trust in the AI system. Our contribution is to apply Bayesian deep learning framework to visual activity recognition application and quantify model uncertainty along with principled confidence. We utilize the stochastic variational inference technique while training the Bayesian DNNs to infer the approximate posterior distribution around model parameters and perform Monte Carlo sampling on the posterior of model parameters to obtain the predictive distribution. We show that the Bayesian inference applied to DNNs provide reliable confidence measures for visual activity recognition task as compared to conventional DNNs. We also show that our method improves the visual activity recognition precision-recall AUC by 6.2% compared to non-Bayesian baseline. We evaluate our models on Moments-In-Time (MiT) activity recognition dataset by selecting a subset of in- and out-of-distribution video samples.},
  journal={arXiv}
}

@article{chernozhukov2009intersection,
  title={Intersection Bounds: Estimation and Inference},
  author={Victor Chernozhukov and Sokbae Lee and Adam M. Rosen},
  year={2009},
  url={http://arxiv.org/abs/0907.3503v5},
  abstract={We develop a practical and novel method for inference on intersection bounds, namely bounds defined by either the infimum or supremum of a parametric or nonparametric function, or equivalently, the value of a linear programming problem with a potentially infinite constraint set. We show that many bounds characterizations in econometrics, for instance bounds on parameters under conditional moment inequalities, can be formulated as intersection bounds. Our approach is especially convenient for models comprised of a continuum of inequalities that are separable in parameters, and also applies to models with inequalities that are non-separable in parameters. Since analog estimators for intersection bounds can be severely biased in finite samples, routinely underestimating the size of the identified set, we also offer a median-bias-corrected estimator of such bounds as a by-product of our inferential procedures. We develop theory for large sample inference based on the strong approximation of a sequence of series or kernel-based empirical processes by a sequence of "penultimate" Gaussian processes. These penultimate processes are generally not weakly convergent, and thus non-Donsker. Our theoretical results establish that we can nonetheless perform asymptotically valid inference based on these processes. Our construction also provides new adaptive inequality/moment selection methods. We provide conditions for the use of nonparametric kernel and series estimators, including a novel result that establishes strong approximation for any general series estimator admitting linearization, which may be of independent interest.},
  doi={10.3982/ECTA8718},
  journal={arXiv}
}

@article{wu2020object,
  title={Object SLAM-Based Active Mapping and Robotic Grasping},
  author={Yanmin Wu and Yunzhou Zhang and Delong Zhu and Xin Chen and Sonya Coleman and Wenkai Sun and Xinggang Hu and Zhiqiang Deng},
  year={2020},
  url={http://arxiv.org/abs/2012.01788v3},
  abstract={This paper presents the first active object mapping framework for complex robotic manipulation and autonomous perception tasks. The framework is built on an object SLAM system integrated with a simultaneous multi-object pose estimation process that is optimized for robotic grasping. Aiming to reduce the observation uncertainty on target objects and increase their pose estimation accuracy, we also design an object-driven exploration strategy to guide the object mapping process, enabling autonomous mapping and high-level perception. Combining the mapping module and the exploration strategy, an accurate object map that is compatible with robotic grasping can be generated. Additionally, quantitative evaluations also indicate that the proposed framework has a very high mapping accuracy. Experiments with manipulation (including object grasping and placement) and augmented reality significantly demonstrate the effectiveness and advantages of our proposed framework.},
  doi={10.1109/3DV53792.2021.00144},
  journal={arXiv}
}

@article{pižurica2025hardwareoriented,
  title={A Hardware-oriented Approach for Efficient Active Inference Computation and Deployment},
  author={Nikola Pižurica and Nikola Milović and Igor Jovančević and Conor Heins and Miguel de Prado},
  year={2025},
  url={http://arxiv.org/abs/2508.13177v1},
  abstract={Active Inference (AIF) offers a robust framework for decision-making, yet its computational and memory demands pose challenges for deployment, especially in resource-constrained environments. This work presents a methodology that facilitates AIF's deployment by integrating pymdp's flexibility and efficiency with a unified, sparse, computational graph tailored for hardware-efficient execution. Our approach reduces latency by over 2x and memory by up to 35%, advancing the deployment of efficient AIF agents for real-time and embedded applications.},
  journal={arXiv}
}

@article{ferraro2023symmetry,
  title={Symmetry and Complexity in Object-Centric Deep Active Inference Models},
  author={Stefano Ferraro and Toon Van de Maele and Tim Verbelen and Bart Dhoedt},
  year={2023},
  url={http://arxiv.org/abs/2304.14493v1},
  abstract={Humans perceive and interact with hundreds of objects every day. In doing so, they need to employ mental models of these objects and often exploit symmetries in the object's shape and appearance in order to learn generalizable and transferable skills. Active inference is a first principles approach to understanding and modeling sentient agents. It states that agents entertain a generative model of their environment, and learn and act by minimizing an upper bound on their surprisal, i.e. their Free Energy. The Free Energy decomposes into an accuracy and complexity term, meaning that agents favor the least complex model, that can accurately explain their sensory observations. In this paper, we investigate how inherent symmetries of particular objects also emerge as symmetries in the latent state space of the generative model learnt under deep active inference. In particular, we focus on object-centric representations, which are trained from pixels to predict novel object views as the agent moves its viewpoint. First, we investigate the relation between model complexity and symmetry exploitation in the state space. Second, we do a principal component analysis to demonstrate how the model encodes the principal axis of symmetry of the object in the latent space. Finally, we also demonstrate how more symmetrical representations can be exploited for better generalization in the context of manipulation.},
  doi={10.1098/rsfs.2022.0077},
  journal={arXiv}
}

@article{laar2021active,
  title={Active Inference and Epistemic Value in Graphical Models},
  author={Thijs van de Laar and Magnus Koudahl and Bart van Erp and Bert de Vries},
  year={2021},
  url={http://arxiv.org/abs/2109.00541v2},
  abstract={The Free Energy Principle (FEP) postulates that biological agents perceive and interact with their environment in order to minimize a Variational Free Energy (VFE) with respect to a generative model of their environment. The inference of a policy (future control sequence) according to the FEP is known as Active Inference (AIF). The AIF literature describes multiple VFE objectives for policy planning that lead to epistemic (information-seeking) behavior. However, most objectives have limited modeling flexibility. This paper approaches epistemic behavior from a constrained Bethe Free Energy (CBFE) perspective. Crucially, variational optimization of the CBFE can be expressed in terms of message passing on free-form generative models. The key intuition behind the CBFE is that we impose a point-mass constraint on predicted outcomes, which explicitly encodes the assumption that the agent will make observations in the future. We interpret the CBFE objective in terms of its constituent behavioral drives. We then illustrate resulting behavior of the CBFE by planning and interacting with a simulated T-maze environment. Simulations for the T-maze task illustrate how the CBFE agent exhibits an epistemic drive, and actively plans ahead to account for the impact of predicted outcomes. Compared to an EFE agent, the CBFE agent incurs expected reward in significantly more environmental scenarios. We conclude that CBFE optimization by message passing suggests a general mechanism for epistemic-aware AIF in free-form generative models.},
  doi={10.3389/frobt.2022.794464},
  journal={arXiv}
}

@article{ghasimi2025new,
  title={A New Approach for Knowledge Generation Using Active Inference},
  author={Jamshid Ghasimi and Nazanin Movarraei},
  year={2025},
  url={http://arxiv.org/abs/2501.15105v1},
  abstract={There are various models proposed on how knowledge is generated in the human brain including the semantic networks model. Although this model has been widely studied and even computational models are presented, but, due to various limits and inefficiencies in the generation of different types of knowledge, its application is limited to semantic knowledge because of has been formed according to semantic memory and declarative knowledge and has many limits in explaining various procedural and conditional knowledge. Given the importance of providing an appropriate model for knowledge generation, especially in the areas of improving human cognitive functions or building intelligent machines, improving existing models in knowledge generation or providing more comprehensive models is of great importance. In the current study, based on the free energy principle of the brain, is the researchers proposed a model for generating three types of declarative, procedural, and conditional knowledge. While explaining different types of knowledge, this model is capable to compute and generate concepts from stimuli based on probabilistic mathematics and the action-perception process (active inference). The proposed model is unsupervised learning that can update itself using a combination of different stimuli as a generative model can generate new concepts of unsupervised received stimuli. In this model, the active inference process is used in the generation of procedural and conditional knowledge and the perception process is used to generate declarative knowledge.},
  journal={arXiv}
}

@article{ioannidis2017kernelbased,
  title={Kernel-based Inference of Functions over Graphs},
  author={Vassilis N. Ioannidis and Meng Ma and Athanasios N. Nikolakopoulos and Georgios B. Giannakis and Daniel Romero},
  year={2017},
  url={http://arxiv.org/abs/1711.10353v2},
  abstract={The study of networks has witnessed an explosive growth over the past decades with several ground-breaking methods introduced. A particularly interesting -- and prevalent in several fields of study -- problem is that of inferring a function defined over the nodes of a network. This work presents a versatile kernel-based framework for tackling this inference problem that naturally subsumes and generalizes the reconstruction approaches put forth recently by the signal processing on graphs community. Both the static and the dynamic settings are considered along with effective modeling approaches for addressing real-world problems. The herein analytical discussion is complemented by a set of numerical examples, which showcase the effectiveness of the presented techniques, as well as their merits related to state-of-the-art methods.},
  journal={arXiv}
}

@article{rajabi2021dynamic,
  title={Dynamic control of speed and trajectories of active droplets in a nematic environment by electric field and focused laser beam},
  author={Mojtaba Rajabi and Hend Baza and Hao Wang and Oleg D. Lavrentovich},
  year={2021},
  url={http://arxiv.org/abs/2111.00413v1},
  abstract={One objective of active matter science is to unveil principles by which chaotic microscale dynamics could be transformed into useful work. A nematic liquid crystal environment offers a number of possibilities, one of which is a directional motion of an active droplet filled with an aqueous dispersion of swimming bacteria. In this work, using the responsiveness of the nematic to the electric field and light, we demonstrate how to control the direction and speed of active droplets. The dielectric response of nematic to the electric field causes two effects: (i) reorientation of the overall director, and (ii) changing the symmetry of the director configuration around the droplet. The first effect redirects the propulsion direction while the second one changes the speed. A laser beam pointed to the vicinity of the droplet can trigger the desired director symmetry around the droplet, by switching between dipolar and quadrupolar configurations, thus affecting the motility and polarity of propulsion. The dynamic tuning of the direction and speed of active droplets represents a step forward in the development of controllable microswimmers.},
  doi={10.3389/fphy.2021.752994},
  journal={arXiv}
}

@article{torresan2025active,
  title={Active inference for action-unaware agents},
  author={Filippo Torresan and Keisuke Suzuki and Ryota Kanai and Manuel Baltieri},
  year={2025},
  url={http://arxiv.org/abs/2508.12027v1},
  abstract={Active inference is a formal approach to study cognition based on the notion that adaptive agents can be seen as engaging in a process of approximate Bayesian inference, via the minimisation of variational and expected free energies. Minimising the former provides an account of perceptual processes and learning as evidence accumulation, while minimising the latter describes how agents select their actions over time. In this way, adaptive agents are able to maximise the likelihood of preferred observations or states, given a generative model of the environment. In the literature, however, different strategies have been proposed to describe how agents can plan their future actions. While they all share the notion that some kind of expected free energy offers an appropriate way to score policies, sequences of actions, in terms of their desirability, there are different ways to consider the contribution of past motor experience to the agent's future behaviour. In some approaches, agents are assumed to know their own actions, and use such knowledge to better plan for the future. In other approaches, agents are unaware of their actions, and must infer their motor behaviour from recent observations in order to plan for the future. This difference reflects a standard point of departure in two leading frameworks in motor control based on the presence, or not, of an efference copy signal representing knowledge about an agent's own actions. In this work we compare the performances of action-aware and action-unaware agents in two navigations tasks, showing how action-unaware agents can achieve performances comparable to action-aware ones while at a severe disadvantage.},
  journal={arXiv}
}

@article{li2021obstructed,
  title={Obstructed surface states as the origin of catalytic activity in inorganic heterogeneous catalysts},
  author={Guowei Li and Yuanfeng Xu and Zhida Song and Qun Yang and Uttam Gupta and Vicky Sü\b{eta} and Yan Sun and Paolo Sessi and Stuart S. P. Parkin and B. Andrei Bernevig and Claudia Felser},
  year={2021},
  url={http://arxiv.org/abs/2111.02435v1},
  abstract={The discovery of new catalysts that are efficient, sustainable, and low-cost is a major research endeavor for many industrial chemical processes. This requires an understanding and determination of the catalytic origins for the given catalysts, which still remains a challenge. Here we describe a novel method to identify new catalysts based on searching for crystalline symmetry-protected obstructed atomic insulators (OAIs) that have metallic surface states on otherwise semiconducting or insulating compounds. The Wannier charge centers in OAIs are pinned by symmetries at some empty Wyckoff positions so that surfaces that accommodate these sites are guaranteed to have metallic obstructed surface states (OSSs). Beyond the well-studied 2H-MoS2, we further verified our theory on the catalysts, 2H-MoTe2, and 1T'-MoTe2, whose catalytic active sites are consistent with our calculations of obstructed Wannier charge centers (OWCCs) and OSSs. In addition, we have predicted the location of catalytic active sites and confirmed these predictions by exploring the hydrogen evolution reaction on NiPS3 bulk single crystals, which we find to be one of the most promising new catalysts with high activity and, moreover, of low cost. Most importantly, we successfully identified several high-efficient catalysts just by considering the number of OWCCs and the crystal symmetry of the OAIs. Using the real space invariant theory and high-throughput computational methods applied to a database of 34013 topologically trivial insulators, we have identified 1788 unique OAIs (3383 ICSDs), of which 465 are potential high-quality catalysts for heterogeneous reactions. The Miller indices of the active surfaces are also obtained. Our new methodology will facilitate and accelerate the discovery of new catalysts for a wide range of heterogeneous redox reactions, where sustainability, toxicity, and cost must be considered.},
  doi={10.1002/adma.202201328},
  journal={arXiv}
}

@article{strieder2023confidence,
  title={Confidence in Causal Inference under Structure Uncertainty in Linear Causal Models with Equal Variances},
  author={David Strieder and Mathias Drton},
  year={2023},
  url={http://arxiv.org/abs/2309.04298v1},
  abstract={Inferring the effect of interventions within complex systems is a fundamental problem of statistics. A widely studied approach employs structural causal models that postulate noisy functional relations among a set of interacting variables. The underlying causal structure is then naturally represented by a directed graph whose edges indicate direct causal dependencies. In a recent line of work, additional assumptions on the causal models have been shown to render this causal graph identifiable from observational data alone. One example is the assumption of linear causal relations with equal error variances that we will take up in this work. When the graph structure is known, classical methods may be used for calculating estimates and confidence intervals for causal effects. However, in many applications, expert knowledge that provides an a priori valid causal structure is not available. Lacking alternatives, a commonly used two-step approach first learns a graph and then treats the graph as known in inference. This, however, yields confidence intervals that are overly optimistic and fail to account for the data-driven model choice. We argue that to draw reliable conclusions, it is necessary to incorporate the remaining uncertainty about the underlying causal structure in confidence statements about causal effects. To address this issue, we present a framework based on test inversion that allows us to give confidence regions for total causal effects that capture both sources of uncertainty: causal structure and numerical size of nonzero effects.},
  doi={10.1515/jci-2023-0030},
  journal={arXiv}
}

@article{donea2003how,
  title={How relevant is the torus activity/geometry for the TeV gamma-rays emitted in the jet of M87 ?},
  author={A. -C. Donea and R. J. Protheroe},
  year={2003},
  url={http://arxiv.org/abs/astro-ph/0301433v1},
  abstract={Motivated by unification schemes of active galactic nuclei, we review evidence for the existence of a small-scale dust torus in M87, a Fanaroff-Riley Class I radio galaxy. Since there is no direct evidence of any thermal emission from its torus we consider indirect evidence, such as BLR activity and ageing arguments to model the cold dust structure of M87. In the context of the jet -- accretion disk -- torus symbiosis we discuss the interactions of GeV and TeV gamma-rays produced in the jet of M87 with the infrared radiation fields external to the jet, produced by a less active torus. A thin and cold torus with less defined outer boundaries could still posses problems to some of the TeV emission from the jet.},
  journal={arXiv}
}

@article{denis2008probability,
  title={On Probability Distributions for Trees: Representations, Inference and Learning},
  author={François Denis and Amaury Habrard and Rémi Gilleron and Marc Tommasi and Édouard Gilbert},
  year={2008},
  url={http://arxiv.org/abs/0807.2983v1},
  abstract={We study probability distributions over free algebras of trees. Probability distributions can be seen as particular (formal power) tree series [Berstel et al 82, Esik et al 03], i.e. mappings from trees to a semiring K . A widely studied class of tree series is the class of rational (or recognizable) tree series which can be defined either in an algebraic way or by means of multiplicity tree automata. We argue that the algebraic representation is very convenient to model probability distributions over a free algebra of trees. First, as in the string case, the algebraic representation allows to design learning algorithms for the whole class of probability distributions defined by rational tree series. Note that learning algorithms for rational tree series correspond to learning algorithms for weighted tree automata where both the structure and the weights are learned. Second, the algebraic representation can be easily extended to deal with unranked trees (like XML trees where a symbol may have an unbounded number of children). Both properties are particularly relevant for applications: nondeterministic automata are required for the inference problem to be relevant (recall that Hidden Markov Models are equivalent to nondeterministic string automata); nowadays applications for Web Information Extraction, Web Services and document processing consider unranked trees.},
  journal={arXiv}
}

@article{sprenger2020towards,
  title={Towards an analytical description of active microswimmers in clean and in surfactant-covered drops},
  author={Alexander R. Sprenger and Vaseem A. Shaik and Arezoo M. Ardekani and Maciej Lisicki and Arnold J. T. M. Mathijssen and Francisca Guzmán-Lastra and Hartmut Löwen and Andreas M. Menzel and Abdallah Daddi-Moussa-Ider},
  year={2020},
  url={http://arxiv.org/abs/2005.14661v2},
  abstract={Geometric confinements are frequently encountered in the biological world and strongly affect the stability, topology, and transport properties of active suspensions in viscous flow. Based on a far-field analytical model, the low-Reynolds-number locomotion of a self-propelled microswimmer moving inside a clean viscous drop or a drop covered with a homogeneously distributed surfactant, is theoretically examined. The interfacial viscous stresses induced by the surfactant are described by the well-established Boussinesq-Scriven constitutive rheological model. Moreover, the active agent is represented by a force dipole and the resulting fluid-mediated hydrodynamic couplings between the swimmer and the confining drop are investigated. We find that the presence of the surfactant significantly alters the dynamics of the encapsulated swimmer by enhancing its reorientation. Exact solutions for the velocity images for the Stokeslet and dipolar flow singularities inside the drop are introduced and expressed in terms of infinite series of harmonic components. Our results offer useful insights into guiding principles for the control of confined active matter systems and support the objective of utilizing synthetic microswimmers to drive drops for targeted drug delivery applications.},
  doi={10.1140/epje/i2020-11980-9},
  journal={arXiv}
}

@article{basbug2015accelerometer,
  title={Accelerometer based Activity Classification with Variational Inference on Sticky HDP-SLDS},
  author={Mehmet Emin Basbug and Koray Ozcan and Senem Velipasalar},
  year={2015},
  url={http://arxiv.org/abs/1510.05477v1},
  abstract={As part of daily monitoring of human activities, wearable sensors and devices are becoming increasingly popular sources of data. With the advent of smartphones equipped with acceloremeter, gyroscope and camera; it is now possible to develop activity classification platforms everyone can use conveniently. In this paper, we propose a fast inference method for an unsupervised non-parametric time series model namely variational inference for sticky HDP-SLDS(Hierarchical Dirichlet Process Switching Linear Dynamical System). We show that the proposed algorithm can differentiate various indoor activities such as sitting, walking, turning, going up/down the stairs and taking the elevator using only the acceloremeter of an Android smartphone Samsung Galaxy S4. We used the front camera of the smartphone to annotate activity types precisely. We compared the proposed method with Hidden Markov Models with Gaussian emission probabilities on a dataset of 10 subjects. We showed that the efficacy of the stickiness property. We further compared the variational inference to the Gibbs sampler on the same model and show that variational inference is faster in one order of magnitude.},
  journal={arXiv}
}

@article{wen2025framework,
  title={A Framework for Inherently Safer AGI through Language-Mediated Active Inference},
  author={Bo Wen},
  year={2025},
  url={http://arxiv.org/abs/2508.05766v1},
  abstract={This paper proposes a novel framework for developing safe Artificial General Intelligence (AGI) by combining Active Inference principles with Large Language Models (LLMs). We argue that traditional approaches to AI safety, focused on post-hoc interpretability and reward engineering, have fundamental limitations. We present an architecture where safety guarantees are integrated into the system's core design through transparent belief representations and hierarchical value alignment. Our framework leverages natural language as a medium for representing and manipulating beliefs, enabling direct human oversight while maintaining computational tractability. The architecture implements a multi-agent system where agents self-organize according to Active Inference principles, with preferences and safety constraints flowing through hierarchical Markov blankets. We outline specific mechanisms for ensuring safety, including: (1) explicit separation of beliefs and preferences in natural language, (2) bounded rationality through resource-aware free energy minimization, and (3) compositional safety through modular agent structures. The paper concludes with a research agenda centered on the Abstraction and Reasoning Corpus (ARC) benchmark, proposing experiments to validate our framework's safety properties. Our approach offers a path toward AGI development that is inherently safer, rather than retrofitted with safety measures.},
  journal={arXiv}
}

@article{bush2002active,
  title={Active Virtual Network Management Prediction: Complexity as a Framework for Prediction, Optimization, and Assurance},
  author={Stephen F. Bush},
  year={2002},
  url={http://arxiv.org/abs/cs/0203014v1},
  abstract={Research into active networking has provided the incentive to re-visit what has traditionally been classified as distinct properties and characteristics of information transfer such as protocol versus service; at a more fundamental level this paper considers the blending of computation and communication by means of complexity. The specific service examined in this paper is network self-prediction enabled by Active Virtual Network Management Prediction. Computation/communication is analyzed via Kolmogorov Complexity. The result is a mechanism to understand and improve the performance of active networking and Active Virtual Network Management Prediction in particular. The Active Virtual Network Management Prediction mechanism allows information, in various states of algorithmic and static form, to be transported in the service of prediction for network management. The results are generally applicable to algorithmic transmission of information. Kolmogorov Complexity is used and experimentally validated as a theory describing the relationship among algorithmic compression, complexity, and prediction accuracy within an active network. Finally, the paper concludes with a complexity-based framework for Information Assurance that attempts to take a holistic view of vulnerability analysis.},
  doi={10.1109/DANCE.2002.1003518},
  journal={arXiv}
}

@article{champion2022multimodal,
  title={Multi-Modal and Multi-Factor Branching Time Active Inference},
  author={Théophile Champion and Marek Grześ and Howard Bowman},
  year={2022},
  url={http://arxiv.org/abs/2206.12503v1},
  abstract={Active inference is a state-of-the-art framework for modelling the brain that explains a wide range of mechanisms such as habit formation, dopaminergic discharge and curiosity. Recently, two versions of branching time active inference (BTAI) based on Monte-Carlo tree search have been developed to handle the exponential (space and time) complexity class that occurs when computing the prior over all possible policies up to the time horizon. However, those two versions of BTAI still suffer from an exponential complexity class w.r.t the number of observed and latent variables being modelled. In the present paper, we resolve this limitation by first allowing the modelling of several observations, each of them having its own likelihood mapping. Similarly, we allow each latent state to have its own transition mapping. The inference algorithm then exploits the factorisation of the likelihood and transition mappings to accelerate the computation of the posterior. Those two optimisations were tested on the dSprites environment in which the metadata of the dSprites dataset was used as input to the model instead of the dSprites images. On this task, $BTAI_{VMP}$ (Champion et al., 2022b,a) was able to solve 96.9\% of the task in 5.1 seconds, and $BTAI_{BF}$ (Champion et al., 2021a) was able to solve 98.6\% of the task in 17.5 seconds. Our new approach ($BTAI_{3MF}$) outperformed both of its predecessors by solving the task completly (100\%) in only 2.559 seconds. Finally, $BTAI_{3MF}$ has been implemented in a flexible and easy to use (python) package, and we developed a graphical user interface to enable the inspection of the model's beliefs, planning process and behaviour.},
  journal={arXiv}
}

@article{pan2025active,
  title={Active Inference Framework for Closed-Loop Sensing, Communication, and Control in UAV Systems},
  author={Guangjin Pan and Liping Bai and Zhuojun Tian and Hui Chen and Mehdi Bennis and Henk Wymeersch},
  year={2025},
  url={http://arxiv.org/abs/2509.14201v1},
  abstract={Integrated sensing and communication (ISAC) is a core technology for 6G, and its application to closed-loop sensing, communication, and control (SCC) enables various services. Existing SCC solutions often treat sensing and control separately, leading to suboptimal performance and resource usage. In this work, we introduce the active inference framework (AIF) into SCC-enabled unmanned aerial vehicle (UAV) systems for joint state estimation, control, and sensing resource allocation. By formulating a unified generative model, the problem reduces to minimizing variational free energy for inference and expected free energy for action planning. Simulation results show that both control cost and sensing cost are reduced relative to baselines.},
  journal={arXiv}
}

@article{pezzato2020active,
  title={Active Inference and Behavior Trees for Reactive Action Planning and Execution in Robotics},
  author={Corrado Pezzato and Carlos Hernandez Corbato and Stefan Bonhof and Martijn Wisse},
  year={2020},
  url={http://arxiv.org/abs/2011.09756v4},
  abstract={We propose a hybrid combination of active inference and behavior trees (BTs) for reactive action planning and execution in dynamic environments, showing how robotic tasks can be formulated as a free-energy minimization problem. The proposed approach allows handling partially observable initial states and improves the robustness of classical BTs against unexpected contingencies while at the same time reducing the number of nodes in a tree. In this work, we specify the nominal behavior offline, through BTs. However, in contrast to previous approaches, we introduce a new type of leaf node to specify the desired state to be achieved rather than an action to execute. The decision of which action to execute to reach the desired state is performed online through active inference. This results in continual online planning and hierarchical deliberation. By doing so, an agent can follow a predefined offline plan while still keeping the ability to locally adapt and take autonomous decisions at runtime, respecting safety constraints. We provide proof of convergence and robustness analysis, and we validate our method in two different mobile manipulators performing similar tasks, both in a simulated and real retail environment. The results showed improved runtime adaptability with a fraction of the hand-coded nodes compared to classical BTs.},
  journal={arXiv}
}

@article{baranes2013active,
  title={Active Learning of Inverse Models with Intrinsically Motivated Goal Exploration in Robots},
  author={Adrien Baranes and Pierre-Yves Oudeyer},
  year={2013},
  url={http://arxiv.org/abs/1301.4862v1},
  abstract={We introduce the Self-Adaptive Goal Generation - Robust Intelligent Adaptive Curiosity (SAGG-RIAC) architecture as an intrinsi- cally motivated goal exploration mechanism which allows active learning of inverse models in high-dimensional redundant robots. This allows a robot to efficiently and actively learn distributions of parameterized motor skills/policies that solve a corresponding distribution of parameterized tasks/goals. The architecture makes the robot sample actively novel parameterized tasks in the task space, based on a measure of competence progress, each of which triggers low-level goal-directed learning of the motor policy pa- rameters that allow to solve it. For both learning and generalization, the system leverages regression techniques which allow to infer the motor policy parameters corresponding to a given novel parameterized task, and based on the previously learnt correspondences between policy and task parameters. We present experiments with high-dimensional continuous sensorimotor spaces in three different robotic setups: 1) learning the inverse kinematics in a highly-redundant robotic arm, 2) learning omnidirectional locomotion with motor primitives in a quadruped robot, 3) an arm learning to control a fishing rod with a flexible wire. We show that 1) exploration in the task space can be a lot faster than exploration in the actuator space for learning inverse models in redundant robots; 2) selecting goals maximizing competence progress creates developmental trajectories driving the robot to progressively focus on tasks of increasing complexity and is statistically significantly more efficient than selecting tasks randomly, as well as more efficient than different standard active motor babbling methods; 3) this architecture allows the robot to actively discover which parts of its task space it can learn to reach and which part it cannot.},
  doi={10.1016/j.robot.2012.05.008},
  journal={arXiv}
}

@article{chen2024long,
  title={The Long Way to Deforestation (Technical Report): A Type Inference and Elaboration Technique for Removing Intermediate Data Structures},
  author={Yijia Chen and Lionel Parreaux},
  year={2024},
  url={http://arxiv.org/abs/2410.02232v2},
  abstract={Deforestation is a compiler optimization that removes intermediate data structure allocations from functional programs to improve their efficiency. This is an old idea, but previous approaches have proved limited or impractical: they either only worked on compositions of predefined combinators (shortcut fusion), or involved the aggressive unfolding of recursive definitions until a depth limit was reached or a reoccurring pattern was found to tie the recursive knot, resulting in impractical algorithmic complexity and large amounts of code duplication. We present Lumberhack, a general-purpose deforestation approach for purely functional call-by-value programs. Lumberhack uses subtype inference to reason about data structure production and consumption and uses an elaboration pass to fuse the corresponding recursive definitions. It fuses large classes of mutually recursive definitions while avoiding much of the unproductive (and sometimes counter-productive) code duplication inherent in previous approaches. We prove the soundness of Lumberhack using logical relations and experimentally demonstrate significant speedups in the standard nofib benchmark suite.},
  doi={10.1145/3674634},
  journal={arXiv}
}

@article{kawakami2025finding,
  title={Finding Similar Objects and Active Inference for Surprise in Numenta Neocortex Model},
  author={Hajime Kawakami},
  year={2025},
  url={http://arxiv.org/abs/2506.21554v1},
  abstract={Jeff Hawkins and his colleagues in Numenta have proposed the thousand-brains system. This is a model of the structure and operation of the neocortex and is under investigation as a new form of artificial intelligence. In their study, learning and inference algorithms running on the system are proposed, where the prediction is an important function. The author believes that one of the most important capabilities of the neocortex in addition to prediction is the ability to make association, that is, to find the relationships between objects. Similarity is an important example of such relationships. In our study, algorithms that run on the thousand-brains system to find similarities are proposed. Although the setting for these algorithms is restricted, the author believes that the case it covers is fundamental. Karl Friston and his colleagues have studied the free-energy principle that explains how the brain actively infers the cause of a Shannon surprise. In our study, an algorithm is proposed for the thousand-brains system to make this inference. The problem of inferring what is being observed from the sensory data is a type of inverse problem, and the inference algorithms of the thousand-brains system and free-energy principle solve this problem in a Bayesian manner. Our inference algorithms can also be interpreted as Bayesian or non-Bayesian updating processes.},
  journal={arXiv}
}

@article{seifner2025incontext,
  title={In-Context Learning of Stochastic Differential Equations with Foundation Inference Models},
  author={Patrick Seifner and Kostadin Cvejoski and David Berghaus and Cesar Ojeda and Ramses J. Sanchez},
  year={2025},
  url={http://arxiv.org/abs/2502.19049v2},
  abstract={Stochastic differential equations (SDEs) describe dynamical systems where deterministic flows, governed by a drift function, are superimposed with random fluctuations, dictated by a diffusion function. The accurate estimation (or discovery) of these functions from data is a central problem in machine learning, with wide application across the natural and social sciences. Yet current solutions either rely heavily on prior knowledge of the dynamics or involve intricate training procedures. We introduce FIM-SDE (Foundation Inference Model for SDEs), a pretrained recognition model that delivers accurate in-context (or zero-shot) estimation of the drift and diffusion functions of low-dimensional SDEs, from noisy time series data, and allows rapid finetuning to target datasets. Leveraging concepts from amortized inference and neural operators, we (pre)train FIM-SDE in a supervised fashion to map a large set of noisy, discretely observed SDE paths onto the space of drift and diffusion functions. We demonstrate that FIM-SDE achieves robust in-context function estimation across a wide range of synthetic and real-world processes -- from canonical SDE systems (e.g., double-well dynamics or weakly perturbed Lorenz attractors) to stock price recordings and oil-price and wind-speed fluctuations -- while matching the performance of symbolic, Gaussian process and Neural SDE baselines trained on the target datasets. When finetuned to the target processes, we show that FIM-SDE consistently outperforms all these baselines.},
  journal={arXiv}
}

@article{baioumy2020active,
  title={Active Inference for Integrated State-Estimation, Control, and Learning},
  author={Mohamed Baioumy and Paul Duckworth and Bruno Lacerda and Nick Hawes},
  year={2020},
  url={http://arxiv.org/abs/2005.05894v2},
  abstract={This work presents an approach for control, state-estimation and learning model (hyper)parameters for robotic manipulators. It is based on the active inference framework, prominent in computational neuroscience as a theory of the brain, where behaviour arises from minimizing variational free-energy. The robotic manipulator shows adaptive and robust behaviour compared to state-of-the-art methods. Additionally, we show the exact relationship to classic methods such as PID control. Finally, we show that by learning a temporal parameter and model variances, our approach can deal with unmodelled dynamics, damps oscillations, and is robust against disturbances and poor initial parameters. The approach is validated on the `Franka Emika Panda' 7 DoF manipulator.},
  journal={arXiv}
}

@article{vasil2019world,
  title={A World unto Itself: Human Communication as Active Inference},
  author={Jared Vasil and Paul B. Badcock and Axel Constant and Karl Friston and Maxwell J. D. Ramstead},
  year={2019},
  url={http://arxiv.org/abs/1906.10538v2},
  abstract={Work in developmental psychology suggests that humans are predisposed to align their mental states with other individuals. This manifests principally in cooperative communication, that is, intentional communication geared towards aligning mental states. This viewpoint has received ample empirical support. However, this view lacks a formal grounding, and provides no precise neuroscientific hypotheses. To remedy this, we suggest an active inference approach to cooperative communication. We suggest that humans appear to possess an evolved adaptive prior belief that their mental states are aligned with those of conspecifics. Cooperative communication emerges as the principal means to gather evidence for this belief. Our approach has implications for the study of the usage, ontogeny, and cultural evolution of human communication.},
  journal={arXiv}
}

@article{kyrkou2021c3net,
  title={C^3Net: End-to-End deep learning for efficient real-time visual active camera control},
  author={Christos Kyrkou},
  year={2021},
  url={http://arxiv.org/abs/2107.13233v1},
  abstract={The need for automated real-time visual systems in applications such as smart camera surveillance, smart environments, and drones necessitates the improvement of methods for visual active monitoring and control. Traditionally, the active monitoring task has been handled through a pipeline of modules such as detection, filtering, and control. However, such methods are difficult to jointly optimize and tune their various parameters for real-time processing in resource constraint systems. In this paper a deep Convolutional Camera Controller Neural Network is proposed to go directly from visual information to camera movement to provide an efficient solution to the active vision problem. It is trained end-to-end without bounding box annotations to control a camera and follow multiple targets from raw pixel values. Evaluation through both a simulation framework and real experimental setup, indicate that the proposed solution is robust to varying conditions and able to achieve better monitoring performance than traditional approaches both in terms of number of targets monitored as well as in effective monitoring time. The advantage of the proposed approach is that it is computationally less demanding and can run at over 10 FPS (~4x speedup) on an embedded smart camera providing a practical and affordable solution to real-time active monitoring.},
  doi={10.1007/s11554-021-01077-z},
  journal={arXiv}
}

@article{baldi2004chandra,
  title={Chandra discovery of activity in the quiescent nuclear black hole of NGC821},
  author={A. Baldi and G. Fabbiano and S. Pellegrini and A. Siemiginowska and M. Elvis and A. Zezas and J. C. McDowell},
  year={2004},
  url={http://arxiv.org/abs/astro-ph/0410169v1},
  abstract={We report the results of the Chandra ACIS-S observations of the elliptical galaxy NGC 821, which harbors a supermassive nuclear black hole (of 3.5x10^7 solar masses), but does not show sign of AGN activity. A small, 8.5" long (~1 kpc at the galaxy's distance of 23 Mpc), S-shaped, jet-like feature centered on the nucleus is detected in the 38 ksec ACIS-S integrated exposure of this region. The luminosity of this feature is L_X ~ 2.6 x 10^39 erg/s (0.3-10 keV), and its spectrum is hard (described by a power-law of Gamma = 1.8^{+0.7}_{-0.6}; or by thermal emission with kT > 2 keV). We discuss two possibilities for the origin of this feature: (1) a low-luminosity X-ray jet, or (2) a hot shocked gas. In either case, it is a clear indication of nuclear activity, detectable only in the X-ray band. Steady spherical accretion of the mass losses from the central stellar cusp within the accretion radius, when coupled to a high radiative efficiency, already provides a power source exceeding the observed radiative losses from the nuclear region.},
  journal={arXiv}
}

@article{rupke2007uncovering,
  title={Uncovering the Active Galactic Nuclei in Low-Ionization Nuclear Emission-Line Regions with Spitzer},
  author={David Rupke and Sylvain Veilleux and DongChan Kim and Eckhard Sturm and Alessandra Contursi and Dieter Lutz and Hagai Netzer and Amiel Sternberg and Dan Maoz},
  year={2007},
  url={http://arxiv.org/abs/0708.1907v1},
  abstract={The impact of active galactic nuclei on low-ionization nuclear emission-line regions (LINERs) remains a vigorous field of study. We present preliminary results from a study of the mid-infrared atomic emission lines of LINERs with the Spitzer Space Telescope. We assess the ubiquity and properties of AGN in LINERs using this data. We discuss what powers the mid-infrared emission lines and conclude that the answer depends unsurprisingly on the emission line ionization state and, more interestingly, on the infrared luminosity.},
  journal={arXiv}
}

@article{zhang2020statistical,
  title={Statistical inference of assortative community structures},
  author={Lizhi Zhang and Tiago P. Peixoto},
  year={2020},
  url={http://arxiv.org/abs/2006.14493v3},
  abstract={We develop a principled methodology to infer assortative communities in networks based on a nonparametric Bayesian formulation of the planted partition model. We show that this approach succeeds in finding statistically significant assortative modules in networks, unlike alternatives such as modularity maximization, which systematically overfits both in artificial as well as in empirical examples. In addition, we show that our method is not subject to a resolution limit, and can uncover an arbitrarily large number of communities, as long as there is statistical evidence for them. Our formulation is amenable to model selection procedures, which allow us to compare it to more general approaches based on the stochastic block model, and in this way reveal whether assortativity is in fact the dominating large-scale mixing pattern. We perform this comparison with several empirical networks, and identify numerous cases where the network's assortativity is exaggerated by traditional community detection methods, and we show how a more faithful degree of assortativity can be identified.},
  doi={10.1103/PhysRevResearch.2.043271},
  journal={arXiv}
}

@article{chen2025wina,
  title={WINA: Weight Informed Neuron Activation for Accelerating Large Language Model Inference},
  author={Sihan Chen and Dan Zhao and Jongwoo Ko and Colby Banbury and Huiping Zhuang and Luming Liang and Tianyi Chen},
  year={2025},
  url={http://arxiv.org/abs/2505.19427v1},
  abstract={The growing computational demands of large language models (LLMs) make efficient inference and activation strategies increasingly critical. While recent approaches, such as Mixture-of-Experts (MoE), leverage selective activation but require specialized training, training-free sparse activation methods offer broader applicability and superior resource efficiency through their plug-and-play design. However, many existing methods rely solely on hidden state magnitudes to determine activation, resulting in high approximation errors and suboptimal inference accuracy. To address these limitations, we propose WINA (Weight Informed Neuron Activation), a novel, simple, and training-free sparse activation framework that jointly considers hidden state magnitudes and the column-wise $\ell_2$-norms of weight matrices. We show that this leads to a sparsification strategy that obtains optimal approximation error bounds with theoretical guarantees tighter than existing techniques. Empirically, WINA also outperforms state-of-the-art methods (e.g., TEAL) by up to $2.94\%$ in average performance at the same sparsity levels, across a diverse set of LLM architectures and datasets. These results position WINA as a new performance frontier for training-free sparse activation in LLM inference, advancing training-free sparse activation methods and setting a robust baseline for efficient inference. The source code is available at https://github.com/microsoft/wina.},
  journal={arXiv}
}

@article{terada2019selective,
  title={Selective inference after feature selection via multiscale bootstrap},
  author={Yoshikazu Terada and Hidetoshi Shimodaira},
  year={2019},
  url={http://arxiv.org/abs/1905.10573v5},
  abstract={It is common to show the confidence intervals or $p$-values of selected features, or predictor variables in regression, but they often involve selection bias. The selective inference approach solves this bias by conditioning on the selection event. Most existing studies of selective inference consider a specific algorithm, such as Lasso, for feature selection, and thus they have difficulties in handling more complicated algorithms. Moreover, existing studies often consider unnecessarily restrictive events, leading to over-conditioning and lower statistical power. Our novel and widely-applicable resampling method via multiscale bootstrap addresses these issues to compute an approximately unbiased selective $p$-value for the selected features. As a simplification of the proposed method, we also develop a simpler method via the classical bootstrap. We prove that the $p$-value computed by our multiscale bootstrap method is more accurate than the classical bootstrap method. Furthermore, numerical experiments demonstrate that our algorithm works well even for more complicated feature selection methods such as non-convex regularization.},
  journal={arXiv}
}

@article{haziza2025accelerating,
  title={Accelerating Transformer Inference and Training with 2:4 Activation Sparsity},
  author={Daniel Haziza and Timothy Chou and Dhruv Choudhary and Luca Wehrstedt and Francisco Massa and Jiecao Yu and Geonhwa Jeong and Supriya Rao and Patrick Labatut and Jesse Cai},
  year={2025},
  url={http://arxiv.org/abs/2503.16672v1},
  abstract={In this paper, we demonstrate how to leverage 2:4 sparsity, a popular hardware-accelerated GPU sparsity pattern, to activations to accelerate large language model training and inference. Crucially we exploit the intrinsic sparsity found in Squared-ReLU activations to provide this acceleration with no accuracy loss. Our approach achieves up to 1.3x faster Feed Forward Network (FFNs) in both the forwards and backwards pass. This work highlights the potential for sparsity to play a key role in accelerating large language model training and inference.},
  journal={arXiv}
}

@article{ichbiah2023inverse,
  title={Inverse 3D Microscopy Rendering for Cell Shape Inference with Active Mesh},
  author={Sacha Ichbiah and Anshuman Sinha and Fabrice Delbary and Hervé Turlier},
  year={2023},
  url={http://arxiv.org/abs/2303.10440v3},
  abstract={Traditional methods for biological shape inference, such as deep learning (DL) and active contour models, face important limitations in 3D. DL approaches require large annotated datasets, which are often impractical to obtain, while active contour methods depend on carefully tuned heuristics for intensity attraction and shape regularization. We introduce deltaMic, a novel differentiable 3D renderer for fluorescence microscopy that formulates shape inference as an inverse problem. By leveraging differentiable convolutions, deltaMic simulates the image formation process, integrating a parameterized point spread function (PSF) with a triangle mesh-based representation of biological structures. Unlike DL- or contour-based segmentation, deltaMic directly optimizes both shape and optical parameters to align synthetic and real microscopy images, removing the need for large datasets or sample-specific fine-tuning. To ensure scalability, we implement a GPU-accelerated Fourier transform for triangle meshes along with narrow-band spectral filtering. We show that deltaMic accurately reconstructs cell geometries from both synthetic and diverse experimental 3D microscopy data, while remaining robust to noise and initialization. This establishes a new physics-informed framework for biophysical image analysis and inverse modeling.},
  journal={arXiv}
}

@article{shin2024sparseinfer,
  title={SparseInfer: Training-free Prediction of Activation Sparsity for Fast LLM Inference},
  author={Jiho Shin and Hoeseok Yang and Youngmin Yi},
  year={2024},
  url={http://arxiv.org/abs/2411.12692v2},
  abstract={Leveraging sparsity is crucial for optimizing large language model inference. however, modern LLMs employing SiLU as their activation function exhibit minimal activation sparsity. Recent research has proposed replacing SiLU with ReLU to induce significant activation sparsity and showed no downstream task accuracy degradation through fine tuning. However, taking full advantage of it required training a predictor to estimate this sparsity. In this paper, we introduce SparseInfer, a simple, light weight, and training free predictor for activation sparsity of ReLU field LLMs, in which activation sparsity is predicted by comparing only the sign bits of inputs and weights. To compensate for possible prediction inaccuracy, an adaptive tuning of the predictor's conservativeness is enabled, which can also serve as a control knob for optimizing LLM inference. The proposed method achieves approximately faster inference speed over the state of the art, with negligible accuracy loss of within 1%p.},
  journal={arXiv}
}

@article{nuijten2024reactive,
  title={Reactive Environments for Active Inference Agents with RxEnvironments.jl},
  author={Wouter W. L. Nuijten and Bert de Vries},
  year={2024},
  url={http://arxiv.org/abs/2409.11087v1},
  abstract={Active Inference is a framework that emphasizes the interaction between agents and their environment. While the framework has seen significant advancements in the development of agents, the environmental models are often borrowed from reinforcement learning problems, which may not fully capture the complexity of multi-agent interactions or allow complex, conditional communication. This paper introduces Reactive Environments, a comprehensive paradigm that facilitates complex multi-agent communication. In this paradigm, both agents and environments are defined as entities encapsulated by boundaries with interfaces. This setup facilitates a robust framework for communication in nonequilibrium-Steady-State systems, allowing for complex interactions and information exchange. We present a Julia package RxEnvironments.jl, which is a specific implementation of Reactive Environments, where we utilize a Reactive Programming style for efficient implementation. The flexibility of this paradigm is demonstrated through its application to several complex, multi-agent environments. These case studies highlight the potential of Reactive Environments in modeling sophisticated systems of interacting agents.},
  journal={arXiv}
}

@article{mohammaddjafari2023deep,
  title={Deep Learning and Bayesian inference for Inverse Problems},
  author={Ali Mohammad-Djafari and Ning Chu and Li Wang and Liang Yu},
  year={2023},
  url={http://arxiv.org/abs/2308.15492v1},
  abstract={Inverse problems arise anywhere we have indirect measurement. As, in general they are ill-posed, to obtain satisfactory solutions for them needs prior knowledge. Classically, different regularization methods and Bayesian inference based methods have been proposed. As these methods need a great number of forward and backward computations, they become costly in computation, in particular, when the forward or generative models are complex and the evaluation of the likelihood becomes very costly. Using Deep Neural Network surrogate models and approximate computation can become very helpful. However, accounting for the uncertainties, we need first understand the Bayesian Deep Learning and then, we can see how we can use them for inverse problems. In this work, we focus on NN, DL and more specifically the Bayesian DL particularly adapted for inverse problems. We first give details of Bayesian DL approximate computations with exponential families, then we will see how we can use them for inverse problems. We consider two cases: First the case where the forward operator is known and used as physics constraint, the second more general data driven DL methods. keyword: Neural Network, Variational Bayesian inference, Bayesian Deep Learning (DL), Inverse problems, Physics based DL.},
  journal={arXiv}
}

@article{kamijo2023tactilebased,
  title={Tactile-based Active Inference for Force-Controlled Peg-in-Hole Insertions},
  author={Tatsuya Kamijo and Ixchel G. Ramirez-Alpizar and Enrique Coronado and Gentiane Venture},
  year={2023},
  url={http://arxiv.org/abs/2309.15681v1},
  abstract={Reinforcement Learning (RL) has shown great promise for efficiently learning force control policies in peg-in-hole tasks. However, robots often face difficulties due to visual occlusions by the gripper and uncertainties in the initial grasping pose of the peg. These challenges often restrict force-controlled insertion policies to situations where the peg is rigidly fixed to the end-effector. While vision-based tactile sensors offer rich tactile feedback that could potentially address these issues, utilizing them to learn effective tactile policies is both computationally intensive and difficult to generalize. In this paper, we propose a robust tactile insertion policy that can align the tilted peg with the hole using active inference, without the need for extensive training on large datasets. Our approach employs a dual-policy architecture: one policy focuses on insertion, integrating force control and RL to guide the object into the hole, while the other policy performs active inference based on tactile feedback to align the tilted peg with the hole. In real-world experiments, our dual-policy architecture achieved 90% success rate into a hole with a clearance of less than 0.1 mm, significantly outperforming previous methods that lack tactile sensory feedback (5%). To assess the generalizability of our alignment policy, we conducted experiments with five different pegs, demonstrating its effective adaptation to multiple objects.},
  journal={arXiv}
}

@article{tufino2024exploring,
  title={Exploring active learning in physics with ISLE-based modules in high school},
  author={Eugenio Tufino and Pasquale Onorato and Stefano Oss},
  year={2024},
  url={http://arxiv.org/abs/2403.11583v2},
  abstract={This study presents a case study of active learning within the Investigative Science Learning Environment (ISLE), using the iOLab digital devices. We designed a pilot lab format to enhance student engagement and understanding through direct experimentation, taking advantage of the multifunctional capabilities of the iOLab devices. This paper evaluates the pedagogical effectiveness of integrating ISLE with digital tools for data collection and analysis in physics experiments. The initial findings provide insights into the pedagogical benefits and logistical considerations of using such technologies in a laboratory setting. Although no direct comparison with traditional teaching methods has been made, the observed student engagement and feedback suggest a positive impact on learning outcomes, even within the constraints of the short duration of the interventions.},
  doi={10.1088/1742-6596/2950/1/012021},
  journal={arXiv}
}

@article{gatterbauer2013dissociation,
  title={Dissociation and Propagation for Approximate Lifted Inference with Standard Relational Database Management Systems},
  author={Wolfgang Gatterbauer and Dan Suciu},
  year={2013},
  url={http://arxiv.org/abs/1310.6257v4},
  abstract={Probabilistic inference over large data sets is a challenging data management problem since exact inference is generally #P-hard and is most often solved approximately with sampling-based methods today. This paper proposes an alternative approach for approximate evaluation of conjunctive queries with standard relational databases: In our approach, every query is evaluated entirely in the database engine by evaluating a fixed number of query plans, each providing an upper bound on the true probability, then taking their minimum. We provide an algorithm that takes into account important schema information to enumerate only the minimal necessary plans among all possible plans. Importantly, this algorithm is a strict generalization of all known PTIME self-join-free conjunctive queries: A query is in PTIME if and only if our algorithm returns one single plan. Furthermore, our approach is a generalization of a family of efficient ranking methods from graphs to hypergraphs. We also adapt three relational query optimization techniques to evaluate all necessary plans very fast. We give a detailed experimental evaluation of our approach and, in the process, provide a new way of thinking about the value of probabilistic methods over non-probabilistic methods for ranking query answers. We also note that the techniques developed in this paper apply immediately to lifted inference from statistical relational models since lifted inference corresponds to PTIME plans in probabilistic databases.},
  journal={arXiv}
}

@article{hassan2021hiflow,
  title={HIFlow: Generating Diverse HI Maps and Inferring Cosmology while Marginalizing over Astrophysics using Normalizing Flows},
  author={Sultan Hassan and Francisco Villaescusa-Navarro and Benjamin Wandelt and David N. Spergel and Daniel Anglés-Alcázar and Shy Genel and Miles Cranmer and Greg L. Bryan and Romeel Davé and Rachel S. Somerville and Michael Eickenberg and Desika Narayanan and Shirley Ho and Sambatra Andrianomena},
  year={2021},
  url={http://arxiv.org/abs/2110.02983v3},
  abstract={A wealth of cosmological and astrophysical information is expected from many ongoing and upcoming large-scale surveys. It is crucial to prepare for these surveys now and develop tools that can efficiently extract most information. We present HIFlow: a fast generative model of the neutral hydrogen (HI) maps that is conditioned only on cosmology ($Ω_{m}$ and $σ_{8}$) and designed using a class of normalizing flow models, the Masked Autoregressive Flow (MAF). HIFlow is trained on the state-of-the-art simulations from the Cosmology and Astrophysics with MachinE Learning Simulations (CAMELS) project. HIFlow has the ability to generate realistic diverse maps without explicitly incorporating the expected 2D maps structure into the flow as an inductive bias. We find that HIFlow is able to reproduce the CAMELS average and standard deviation HI power spectrum (Pk) within a factor of $\lesssim$ 2, scoring a very high $R^{2} > 90\%$. By inverting the flow, HIFlow provides a tractable high-dimensional likelihood for efficient parameter inference. We show that the conditional HIFlow on cosmology is successfully able to marginalize over astrophysics at the field level, regardless of the stellar and AGN feedback strengths. This new tool represents a first step toward a more powerful parameter inference, maximizing the scientific return of future HI surveys, and opening a new avenue to minimize the loss of complex information due to data compression down to summary statistics.},
  doi={10.3847/1538-4357/ac8b09},
  journal={arXiv}
}

@article{ravichandran2023optimal,
  title={Optimal allocation of sample size for randomization-based inference from $2^K$ factorial designs},
  author={Arun Ravichandran and Nicole E. Pashley and Brian Libgober and Tirthankar Dasgupta},
  year={2023},
  url={http://arxiv.org/abs/2306.12394v1},
  abstract={Optimizing the allocation of units into treatment groups can help researchers improve the precision of causal estimators and decrease costs when running factorial experiments. However, existing optimal allocation results typically assume a super-population model and that the outcome data comes from a known family of distributions. Instead, we focus on randomization-based causal inference for the finite-population setting, which does not require model specifications for the data or sampling assumptions. We propose exact theoretical solutions for optimal allocation in $2^K$ factorial experiments under complete randomization with A-, D- and E-optimality criteria. We then extend this work to factorial designs with block randomization. We also derive results for optimal allocations when using cost-based constraints. To connect our theory to practice, we provide convenient integer-constrained programming solutions using a greedy optimization approach to find integer optimal allocation solutions for both complete and block randomization. The proposed methods are demonstrated using two real-life factorial experiments conducted by social scientists.},
  doi={10.1515/jci-2023-0046},
  journal={arXiv}
}

@article{laar2021chanceconstrained,
  title={Chance-Constrained Active Inference},
  author={Thijs van de Laar and Ismail Senoz and Ayça Özçelikkale and Henk Wymeersch},
  year={2021},
  url={http://arxiv.org/abs/2102.08792v2},
  abstract={Active Inference (ActInf) is an emerging theory that explains perception and action in biological agents, in terms of minimizing a free energy bound on Bayesian surprise. Goal-directed behavior is elicited by introducing prior beliefs on the underlying generative model. In contrast to prior beliefs, which constrain all realizations of a random variable, we propose an alternative approach through chance constraints, which allow for a (typically small) probability of constraint violation, and demonstrate how such constraints can be used as intrinsic drivers for goal-directed behavior in ActInf. We illustrate how chance-constrained ActInf weights all imposed (prior) constraints on the generative model, allowing e.g., for a trade-off between robust control and empirical chance constraint violation. Secondly, we interpret the proposed solution within a message passing framework. Interestingly, the message passing interpretation is not only relevant to the context of ActInf, but also provides a general purpose approach that can account for chance constraints on graphical models. The chance constraint message updates can then be readily combined with other pre-derived message update rules, without the need for custom derivations. The proposed chance-constrained message passing framework thus accelerates the search for workable models in general, and can be used to complement message-passing formulations on generative neural models.},
  doi={10.1162/neco_a_01427},
  journal={arXiv}
}

@article{lin2022exploring,
  title={Exploring Diversity-based Active Learning for 3D Object Detection in Autonomous Driving},
  author={Jinpeng Lin and Zhihao Liang and Shengheng Deng and Lile Cai and Tao Jiang and Tianrui Li and Kui Jia and Xun Xu},
  year={2022},
  url={http://arxiv.org/abs/2205.07708v3},
  abstract={3D object detection has recently received much attention due to its great potential in autonomous vehicle (AV). The success of deep learning based object detectors relies on the availability of large-scale annotated datasets, which is time-consuming and expensive to compile, especially for 3D bounding box annotation. In this work, we investigate diversity-based active learning (AL) as a potential solution to alleviate the annotation burden. Given limited annotation budget, only the most informative frames and objects are automatically selected for human to annotate. Technically, we take the advantage of the multimodal information provided in an AV dataset, and propose a novel acquisition function that enforces spatial and temporal diversity in the selected samples. We benchmark the proposed method against other AL strategies under realistic annotation cost measurement, where the realistic costs for annotating a frame and a 3D bounding box are both taken into consideration. We demonstrate the effectiveness of the proposed method on the nuScenes dataset and show that it outperforms existing AL strategies significantly. Code is available at https://github.com/Linkon87/Exploring-Diversity-based-Active-Learning-for-3D-Object-Detection-in-Autonomous-Driving},
  journal={arXiv}
}

@article{niekerk2022new,
  title={A new avenue for Bayesian inference with INLA},
  author={Janet van Niekerk and Elias Krainski and Denis Rustand and Haavard Rue},
  year={2022},
  url={http://arxiv.org/abs/2204.06797v1},
  abstract={Integrated Nested Laplace Approximations (INLA) has been a successful approximate Bayesian inference framework since its proposal by Rue et al. (2009). The increased computational efficiency and accuracy when compared with sampling-based methods for Bayesian inference like MCMC methods, are some contributors to its success. Ongoing research in the INLA methodology and implementation thereof in the R package R-INLA, ensures continued relevance for practitioners and improved performance and applicability of INLA. The era of big data and some recent research developments, presents an opportunity to reformulate some aspects of the classic INLA formulation, to achieve even faster inference, improved numerical stability and scalability. The improvement is especially noticeable for data-rich models. We demonstrate the efficiency gains with various examples of data-rich models, like Cox's proportional hazards model, an item-response theory model, a spatial model including prediction, and a 3-dimensional model for fMRI data.},
  journal={arXiv}
}

@article{snijders2023investigating,
  title={Investigating Multi-source Active Learning for Natural Language Inference},
  author={Ard Snijders and Douwe Kiela and Katerina Margatina},
  year={2023},
  url={http://arxiv.org/abs/2302.06976v1},
  abstract={In recent years, active learning has been successfully applied to an array of NLP tasks. However, prior work often assumes that training and test data are drawn from the same distribution. This is problematic, as in real-life settings data may stem from several sources of varying relevance and quality. We show that four popular active learning schemes fail to outperform random selection when applied to unlabelled pools comprised of multiple data sources on the task of natural language inference. We reveal that uncertainty-based strategies perform poorly due to the acquisition of collective outliers, i.e., hard-to-learn instances that hamper learning and generalization. When outliers are removed, strategies are found to recover and outperform random baselines. In further analysis, we find that collective outliers vary in form between sources, and show that hard-to-learn data is not always categorically harmful. Lastly, we leverage dataset cartography to introduce difficulty-stratified testing and find that different strategies are affected differently by example learnability and difficulty.},
  journal={arXiv}
}

@article{pazem2024free,
  title={Free Energy Projective Simulation (FEPS): Active inference with interpretability},
  author={Joséphine Pazem and Marius Krumm and Alexander Q. Vining and Lukas J. Fiderer and Hans J. Briegel},
  year={2024},
  url={http://arxiv.org/abs/2411.14991v1},
  abstract={In the last decade, the free energy principle (FEP) and active inference (AIF) have achieved many successes connecting conceptual models of learning and cognition to mathematical models of perception and action. This effort is driven by a multidisciplinary interest in understanding aspects of self-organizing complex adaptive systems, including elements of agency. Various reinforcement learning (RL) models performing active inference have been proposed and trained on standard RL tasks using deep neural networks. Recent work has focused on improving such agents' performance in complex environments by incorporating the latest machine learning techniques. In this paper, we take an alternative approach. Within the constraints imposed by the FEP and AIF, we attempt to model agents in an interpretable way without deep neural networks by introducing Free Energy Projective Simulation (FEPS). Using internal rewards only, FEPS agents build a representation of their partially observable environments with which they interact. Following AIF, the policy to achieve a given task is derived from this world model by minimizing the expected free energy. Leveraging the interpretability of the model, techniques are introduced to deal with long-term goals and reduce prediction errors caused by erroneous hidden state estimation. We test the FEPS model on two RL environments inspired from behavioral biology: a timed response task and a navigation task in a partially observable grid. Our results show that FEPS agents fully resolve the ambiguity of both environments by appropriately contextualizing their observations based on prediction accuracy only. In addition, they infer optimal policies flexibly for any target observation in the environment.},
  journal={arXiv}
}

@article{bayati2025inferring,
  title={Inferring Surface Slip in Active Colloids from Flow Fields Using Physics-Informed Neural Networks},
  author={Parvin Bayati and Stewart A. Mallory},
  year={2025},
  url={http://arxiv.org/abs/2511.22723v1},
  abstract={The directed motion of active colloids is governed by spatial variations in surface chemistry and interfacial stress, yet these properties remain extremely difficult to measure directly. We introduce a physics-informed neural network framework that infers the slip distribution driving propulsion from partial observations of the surrounding flow. By combining sparse fluid velocity measurements with the Stokes equations and boundary constraints, the method reconstructs both the near-surface slip and the full velocity and pressure fields. Validation against analytical solutions and Boundary Element Method calculations for canonical active colloid models shows quantitative agreement in both unbounded and confined geometries. Crucially, the framework recovers the surface slip even when no flow data are available near the particle, demonstrating that accessible bulk measurements encode the interfacial stresses responsible for active motion. These results establish physics-informed inference as a powerful tool for characterizing and ultimately controlling interfacially driven transport in colloidal active matter.},
  journal={arXiv}
}

@article{group1999evaluation,
  title={Evaluation of the LEP Centre-of-Mass Energy Above the W-Pair Production Threshold},
  author={ The LEP Energy Working Group},
  year={1999},
  url={http://arxiv.org/abs/hep-ex/9901002v2},
  abstract={Knowledge of the centre-of-mass energy at LEP2 is of primary importance to set the absolute energy scale for the measurement of the W-boson mass. The beam energy above 80 GeV is derived from continuous measurements of the magnetic bending field by 16 NMR probes situated in a number of the LEP dipoles. The relationship between the fields measured by the probes and the beam energy is calibrated against precise measurements of the average beam energy between 41 and 55 GeV made using the resonant depolarisation technique. The linearity of the relationship is tested by comparing the fields measured by the probes with the total bending field measured by a flux loop. This test results in the largest contribution to the systematic uncertainty. Several further corrections are applied to derive the the centre-of-mass energies at each interaction point. In addition the centre-of-mass energy spread is evaluated. The beam energy has been determined with a precision of 25 MeV for the data taken in 1997, corresponding to a relative precision of 2.7x10^{-4}. This is small in comparison to the present uncertainty on the W mass measurement at LEP. However, the ultimate statistical precision on the W mass with the full LEP2 data sample should be around 25 MeV, and a smaller uncertainty on the beam energy is desirable. Prospects for improvements are outlined.},
  doi={10.1007/s100520050657},
  journal={arXiv}
}

@article{group2004calibration,
  title={Calibration of centre-of-mass energies at LEP 2 for a precise measurement of the W boson mass},
  author={ LEP Energy Working Group and R. Assmann},
  year={2004},
  url={http://arxiv.org/abs/hep-ex/0410026v1},
  abstract={The determination of the centre-of-mass energies for all LEP 2 running is presented. Accurate knowledge of these energies is of primary importance to set the absolute energy scale for the measurement of the W boson mass. The beam energy between 80 and 104 GeV is derived from continuous measurements of the magnetic bending field by 16 NMR probes situated in a number of the LEP dipoles. The relationship between the fields measured by the probes and the beam energy is defined in the NMR model, which is calibrated against precise measurements of the average beam energy between 41 and 61 GeV made using the resonant depolarisation technique. The validity of the NMR model is verified by three independent methods: the flux-loop, which is sensitive to the bending field of all the dipoles of LEP; the spectrometer, which determines the energy through measurements of the deflection of the beam in a magnet of known integrated field; and an analysis of the variation of the synchrotron tune with the total RF voltage. To obtain the centre-of-mass energies, corrections are then applied to account for sources of bending field external to the dipoles, and variations in the local beam energy at each interaction point. The relative error on the centre-of-mass energy determination for the majority of LEP 2 running is 1.2 x 10^{-4}, which is sufficiently precise so as not to introduce a dominant uncertainty on the W mass measurement.},
  doi={10.1140/epjc/s2004-02108-8},
  journal={arXiv}
}

@article{dobbs2015free,
  title={Free energy and equilibrium states for families of interval maps},
  author={Neil Dobbs and Mike Todd},
  year={2015},
  url={http://arxiv.org/abs/1512.09245v3},
  abstract={We study continuity, and lack thereof, of thermodynamical properties for one-dimensional dynamical systems. Under quite general hypotheses, the free energy is shown to be almost upper-semicontinuous: some normalised component of a limit measure will have free energy at least that of the limit of the free energies. From this, we deduce results concerning existence and continuity of equilibrium states (statistical stability). Counterexamples to statistical stability in the absence of strong hypotheses are provided.},
  journal={arXiv}
}

@article{ahmad2021free,
  title={Free energy calculation of crystalline solids using normalizing flow},
  author={Rasool Ahmad and Wei Cai},
  year={2021},
  url={http://arxiv.org/abs/2111.01292v2},
  abstract={Taking advantage of the advances in generative deep learning, particularly normalizing flow, a framework, called Boltzmann Generator, has recently been proposed for the purpose of generating equilibrium atomic configurations from the canonical ensemble and determining the associated free energy. In this work, we revisit Boltzmann Generator to motivate the construction of the loss function from the statistical mechanical point of view, and to cast the training of the neural networks in a purely unsupervised manner that requires no samples of the atomic configurations from the equilibrium ensemble. We further show that the normalizing flow framework furnishes a reference thermodynamic system, very close to the real thermodynamic system under consideration, that is suitable for the well-established free energy perturbation methods to determine accurate free energy of solids. We then apply the normalizing flow to two problems: temperature-dependent Gibbs free energy of perfect crystal and formation free energy of monovacancy defect in a model system of diamond cubic Si. The results obtained from the normalizing flow are shown to be in good agreement with that obtained from independent well-established free energy methods.},
  doi={10.1088/1361-651X/ac7f4b},
  journal={arXiv}
}

@article{fritzsch2014quantum,
  title={Quantum Haplodynamics, Dark Matter and Dark Energy},
  author={Harald Fritzsch and Joan Sola},
  year={2014},
  url={http://arxiv.org/abs/1402.4106v2},
  abstract={In quantum haplodynamics (QHD) the weak bosons, quarks and leptons are bound states of fundamental constituents, denoted as haplons. The confinement scale of the associated gauge group SU(2)_h is of the order of $Λ_h\simeq 0.3$ TeV. One scalar state has zero haplon number and is the resonance observed at the LHC. In addition, there exist new bound states of haplons with no counterpart in the SM, having a mass of the order of 0.5 TeV up to a few TeV. In particular, a neutral scalar state with haplon number 4 is stable and can provide the dark matter in the universe. The QHD, QCD and QED couplings can unify at the Planck scale. If this scale changes slowly with cosmic time, all of the fundamental couplings, the masses of the nucleons and of the DM particles, including the cosmological term (or vacuum energy density), will evolve with time. This could explain the dark energy of the universe.},
  doi={10.1155/2014/361587},
  journal={arXiv}
}

@article{pezzulo2024active,
  title={Active inference as a theory of sentient behavior},
  author={Giovanni Pezzulo and Thomas Parr and Karl J. Friston},
  year={2024},
  url={https://www.semanticscholar.org/paper/0d598b16582e344ee621f469787af85b467c78a8},
  doi={10.1016/j.biopsycho.2023.108741},
  journal={Biological Psychology}
}

@article{barrett2017theory,
  title={The theory of constructed emotion: an active inference account of interoception and categorization},
  author={L. F. Barrett},
  year={2017},
  url={https://www.semanticscholar.org/paper/b705c2afd6d7cc9218fdf985a70b3967e1165540},
  abstract={The science of emotion has been using folk psychology categories derived from philosophy to search for the brain basis of emotion. The last two decades of neuroscience research have brought us to the brink of a paradigm shift in understanding the workings of the brain, however, setting the stage to revolutionize our understanding of what emotions are and how they work. In this article, we begin with the structure and function of the brain, and from there deduce what the biological basis of emotions might be. The answer is a brain-based, computational account called the theory of constructed emotion.},
  doi={10.1093/scan/nsx060},
  journal={Social Cognitive and Affective Neuroscience}
}

@article{friston2017active,
  title={Active Inference: A Process Theory},
  author={Karl J. Friston and Thomas H. B. FitzGerald and Francesco Rigoli and P. Schwartenbeck and G. Pezzulo},
  year={2017},
  url={https://www.semanticscholar.org/paper/0fdd66fcf6b9bc04428e337df66fd510a659eb2f},
  doi={10.1162/NECO_a_00912},
  journal={Neural Computation}
}

@article{albarracin2024shared,
  title={Shared Protentions in Multi-Agent Active Inference},
  author={Mahault Albarracin and R. J. Pitliya and T. S. C. Smithe and D. Friedman and K. Friston and M. Ramstead},
  year={2024},
  url={https://www.semanticscholar.org/paper/7b2aca8cb0f297c53c539ece9c36fe9a06554f4d},
  abstract={In this paper, we unite concepts from Husserlian phenomenology, the active inference framework in theoretical biology, and category theory in mathematics to develop a comprehensive framework for understanding social action premised on shared goals. We begin with an overview of Husserlian phenomenology, focusing on aspects of inner time-consciousness, namely, retention, primal impression, and protention. We then review active inference as a formal approach to modeling agent behavior based on variational (approximate Bayesian) inference. Expanding upon Husserl’s model of time consciousness, we consider collective goal-directed behavior, emphasizing shared protentions among agents and their connection to the shared generative models of active inference. This integrated framework aims to formalize shared goals in terms of shared protentions, and thereby shed light on the emergence of group intentionality. Building on this foundation, we incorporate mathematical tools from category theory, in particular, sheaf and topos theory, to furnish a mathematical image of individual and group interactions within a stochastic environment. Specifically, we employ morphisms between polynomial representations of individual agent models, allowing predictions not only of their own behaviors but also those of other agents and environmental responses. Sheaf and topos theory facilitates the construction of coherent agent worldviews and provides a way of representing consensus or shared understanding. We explore the emergence of shared protentions, bridging the phenomenology of temporal structure, multi-agent active inference systems, and category theory. Shared protentions are highlighted as pivotal for coordination and achieving common objectives. We conclude by acknowledging the intricacies stemming from stochastic systems and uncertainties in realizing shared goals.},
  doi={10.3390/e26040303},
  journal={Entropy}
}

@article{jacques2023active,
  title={Active Inference: The Free Energy Principle in Mind, Brain, and Behaviour by Thomas Parr, Giovanni Pezzulo, and Karl J. Friston (review)},
  author={David Jacques},
  year={2023},
  url={https://www.semanticscholar.org/paper/dded71d2681fb42c1d149286b636b066ab6a0910}
}

@article{jacques2023active2,
  title={Active Inference: The Free Energy Principle in Mind, Brain, and Behaviour},
  author={David Jacques},
  year={2023},
  url={https://www.semanticscholar.org/paper/e5de43f98bfd367690e3787f130dadc02beb80dc},
  doi={10.3368/lj.42.2.175},
  journal={Landscape Journal}
}

@article{pezzulo2023generating,
  title={Generating meaning: active inference and the scope and limits of passive AI},
  author={Giovanni Pezzulo and Thomas Parr and Paul Cisek and Andy Clark and Karl J. Friston},
  year={2023},
  url={https://www.semanticscholar.org/paper/abcf8d2585334dfd1575e9b0778e907cde1e25c8},
  doi={10.1016/j.tics.2023.10.002},
  journal={Trends in Cognitive Sciences}
}

@article{costa2023reward,
  title={Reward Maximization Through Discrete Active Inference},
  author={Lancelot Da Costa and Noor Sajid and Thomas Parr and K. Friston and Ryan Smith},
  year={2023},
  url={https://www.semanticscholar.org/paper/abbef3f050f2381c88fbd4dd8a7818d9ba989b38},
  abstract={Abstract Active inference is a probabilistic framework for modeling the behavior of biological and artificial agents, which derives from the principle of minimizing free energy. In recent years, this framework has been applied successfully to a variety of situations where the goal was to maximize reward, often offering comparable and sometimes superior performance to alternative approaches. In this article, we clarify the connection between reward maximization and active inference by demonstrating how and when active inference agents execute actions that are optimal for maximizing reward. Precisely, we show the conditions under which active inference produces the optimal solution to the Bellman equation, a formulation that underlies several approaches to model-based reinforcement learning and control. On partially observed Markov decision processes, the standard active inference scheme can produce Bellman optimal actions for planning horizons of 1 but not beyond. In contrast, a recently developed recursive active inference scheme (sophisticated inference) can produce Bellman optimal actions on any finite temporal horizon. We append the analysis with a discussion of the broader relationship between active inference and reinforcement learning.},
  doi={10.1162/neco_a_01574},
  journal={Neural Computation}
}

@article{lehmann2023activeinference,
  title={An Active-Inference Approach to Second-Person Neuroscience},
  author={K. Lehmann and Dimitris Bolis and K. Friston and L. Schilbach and M. Ramstead and Philipp Kanske},
  year={2023},
  url={https://www.semanticscholar.org/paper/2f5411605691f79a69a84ab0b7c0599678725484},
  abstract={Social neuroscience has often been criticized for approaching the investigation of the neural processes that enable social interaction and cognition from a passive, detached, third-person perspective, without involving any real-time social interaction. With the emergence of second-person neuroscience, investigators have uncovered the unique complexity of neural-activation patterns in actual, real-time interaction. Social cognition that occurs during social interaction is fundamentally different from that unfolding during social observation. However, it remains unclear how the neural correlates of social interaction are to be interpreted. Here, we leverage the active-inference framework to shed light on the mechanisms at play during social interaction in second-person neuroscience studies. Specifically, we show how counterfactually rich mutual predictions, real-time bodily adaptation, and policy selection explain activation in components of the default mode, salience, and frontoparietal networks of the brain, as well as in the basal ganglia. We further argue that these processes constitute the crucial neural processes that underwrite bona fide social interaction. By placing the experimental approach of second-person neuroscience on the theoretical foundation of the active-inference framework, we inform the field of social neuroscience about the mechanisms of real-life interactions. We thereby contribute to the theoretical foundations of empirical second-person neuroscience.},
  doi={10.1177/17456916231188000},
  journal={Perspectives on Psychological Science}
}

@article{hodson2023empirical,
  title={The empirical status of predictive coding and active inference},
  author={Rowan Hodson and M. Mehta and Ryan Smith},
  year={2023},
  url={https://www.semanticscholar.org/paper/ad407c66679cc67ffa10917fcb64c76be79eb084},
  doi={10.1016/j.neubiorev.2023.105473},
  journal={Neuroscience and Biobehavioral Reviews}
}

@article{cruys2023order,
  title={Order and change in art: towards an active inference account of aesthetic experience},
  author={Sander Van de Cruys and Jacopo Frascaroli and K. Friston},
  year={2023},
  url={https://www.semanticscholar.org/paper/8ce0437b44f92b14e304c861f1fc1158304a6156},
  abstract={How to account for the power that art holds over us? Why do artworks touch us deeply, consoling, transforming or invigorating us in the process? In this paper, we argue that an answer to this question might emerge from a fecund framework in cognitive science known as predictive processing (a.k.a. active inference). We unpack how this approach connects sense-making and aesthetic experiences through the idea of an ‘epistemic arc’, consisting of three parts (curiosity, epistemic action and aha experiences), which we cast as aspects of active inference. We then show how epistemic arcs are built and sustained by artworks to provide us with those satisfying experiences that we tend to call ‘aesthetic’. Next, we defuse two key objections to this approach; namely, that it places undue emphasis on the cognitive component of our aesthetic encounters—at the expense of affective aspects—and on closure and uncertainty minimization (order)—at the expense of openness and lingering uncertainty (change). We show that the approach offers crucial resources to account for the open-ended, free and playful behaviour inherent in aesthetic experiences. The upshot is a promising but deflationary approach, both philosophically informed and psychologically sound, that opens new empirical avenues for understanding our aesthetic encounters. This article is part of the theme issue ‘Art, aesthetics and predictive processing: theoretical and empirical perspectives’.},
  doi={10.1098/rstb.2022.0411},
  journal={Philosophical Transactions of the Royal Society of London. Biological Sciences}
}

@article{parr2023cognitive,
  title={Cognitive effort and active inference},
  author={Thomas Parr and E. Holmes and K. Friston and G. Pezzulo},
  year={2023},
  url={https://www.semanticscholar.org/paper/dc02375b9e4f4f92f40f21cc4449fef0d9a78e47},
  doi={10.1016/j.neuropsychologia.2023.108562},
  journal={Neuropsychologia}
}

@article{fang2023large,
  title={Large Language Models (LLMs) Inference Offloading and Resource Allocation in Cloud-Edge Networks: An Active Inference Approach},
  author={Jingcheng Fang and Ying He and F. Yu and Jianqiang Li and Victor C.M. Leung},
  year={2023},
  url={https://www.semanticscholar.org/paper/c803b2236136fe7c59ea3619bc7520d331568d32},
  abstract={As the research and applications of large language model (LLM) become increasingly sophisticated, it is difficult for resource-limited mobile terminals to run large-model inference tasks efficiently. Traditional deep reinforcement learning (DRL) based approaches have been used to offload LLM inference tasks to servers. However, existing solutions suffer from data inefficiency, insensitivity to latency requirements, and non-adaptability to task load variations. In this paper, we propose an active inference with rewardless guidance algorithm using expected future free energy for offloading decisions and allocating resources for the LLM inference task offloading and resource allocation problem of cloud-edge networks systems. Experimental results show that our proposed method has superior performance over mainstream DRLs, improves in data utilization efficiency, and is more adaptable to changing task load scenarios.},
  doi={10.1109/VTC2023-Fall60731.2023.10333824},
  journal={IEEE Vehicular Technology Conference}
}

@article{limongi2023active,
  title={Active Inference, Epistemic Value, and Uncertainty in Conceptual Disorganization in First-Episode Schizophrenia.},
  author={R. Limongi and Angelica M Silva and M. Mackinley and S. Ford and L. Palaniyappan},
  year={2023},
  url={https://www.semanticscholar.org/paper/91dbdca2ca3421402f99b0cbe3ee5a5c52451003},
  abstract={BACKGROUND AND HYPOTHESIS
Active inference has become an influential concept in psychopathology. We apply active inference to investigate conceptual disorganization in first-episode schizophrenia. We conceptualize speech production as a decision-making process affected by the latent "conceptual organization"-as a special case of uncertainty about the causes of sensory information. Uncertainty is both minimized via speech production-in which function words index conceptual organization in terms of analytic thinking-and tracked by a domain-general salience network. We hypothesize that analytic thinking depends on conceptual organization. Therefore, conceptual disorganization in schizophrenia would be both indexed by low conceptual organization and reflected in the effective connectivity within the salience network.


STUDY DESIGN
With 1-minute speech samples from a picture description task and resting state fMRI from 30 patients and 30 healthy subjects, we employed dynamic causal and probabilistic graphical models to investigate if the effective connectivity of the salience network underwrites conceptual organization.


STUDY RESULTS
Low analytic thinking scores index low conceptual organization which affects diagnostic status. The influence of the anterior insula on the anterior cingulate cortex and the self-inhibition within the anterior cingulate cortex are elevated given low conceptual organization (ie, conceptual disorganization).


CONCLUSIONS
Conceptual organization, a construct that explains formal thought disorder, can be modeled in an active inference framework and studied in relation to putative neural substrates of disrupted language in schizophrenia. This provides a critical advance to move away from rating-scale scores to deeper constructs in the pursuit of the pathophysiology of formal thought disorder.},
  doi={10.1093/schbul/sbac125},
  journal={Schizophrenia bulletin}
}

@article{waugh2023resilience,
  title={Resilience as the Ability to Maintain Well-Being: An Allostatic Active Inference Model},
  author={Christian E. Waugh and Anthony W. Sali},
  year={2023},
  url={https://www.semanticscholar.org/paper/75b897b1af5b266cd6b1a1146e5205aa7bf0ae90},
  abstract={Resilience is often characterized as the outcome of well-being maintenance despite threats to that well-being. We suggest that resilience can also be characterized as an emotional-intelligence-related ability to obtain this outcome. We formulate an allostatic active inference model that outlines the primary tools of this resilience ability as monitoring well-being, maintaining stable well-being beliefs while updating situational beliefs and flexibly prioritizing actions that are expected to lead to well-being maintenance or gathering the information needed to discern what those actions could be. This model helps to explain the role of positive emotions in resilience as well as how people high in resilience ability use regulatory flexibility in the service of maintaining well-being and provides a starting point for assessing resilience as an ability.},
  doi={10.3390/jintelligence11080158},
  journal={Journal of Intelligence}
}

@article{sedlak2023equilibrium,
  title={Equilibrium in the Computing Continuum through Active Inference},
  author={Boris Sedlak and Víctor Casamayor-Pujol and Praveen Kumar Donta and S. Dustdar},
  year={2023},
  url={https://www.semanticscholar.org/paper/adc674f67d74cfe2ea01d0f2c67280139081c742},
  doi={10.1016/j.future.2024.05.056},
  journal={Future generations computer systems}
}

@article{fields2023control2,
  title={Control Flow in Active Inference Systems—Part I: Classical and Quantum Formulations of Active Inference},
  author={C. Fields and Filippo Fabrocini and K. Friston and J. Glazebrook and Hananel Hazan and M. Levin and A. Marcianò},
  year={2023},
  url={https://www.semanticscholar.org/paper/c5919327d94883e86d1c24b055c341f6640bfc17},
  abstract={Living systems face both environmental complexity and limited access to free-energy resources. Survival under these conditions requires a control system that can activate, or deploy, available perception and action resources in a context specific way. In this Part I, we introduce the free-energy principle (FEP) and the idea of active inference as Bayesian prediction-error minimization, and show how the control problem arises in active inference systems. We then review classical and quantum formulations of the FEP, with the former being the classical limit of the latter. In the accompanying Part II, we show that when systems are described as executing active inference driven by the FEP, their control flow systems can always be represented as tensor networks (TNs). We show how TNs as control systems can be implemented within the general framework of quantum topological neural networks, and discuss the implications of these results for modeling biological systems at multiple scales.},
  doi={10.1109/TMBMC.2023.3272150},
  journal={IEEE Transactions on Molecular Biological and Multi-Scale Communications}
}

@article{bogotá2023timeconsciousness,
  title={Time-consciousness in computational phenomenology: a temporal analysis of active inference},
  author={Juan Diego Bogotá and Z. Djebbara},
  year={2023},
  url={https://www.semanticscholar.org/paper/b649509581d72c0d29a1ff08de9d0e025a86d446},
  abstract={Abstract Time plays a significant role in science and everyday life. Despite being experienced as a continuous flow, computational models of consciousness are typically restricted to a sequential temporal structure. This difference poses a serious challenge for computational phenomenology—a novel field combining phenomenology and computational modelling. By analysing the temporal structure of the active inference framework, we show that an integrated continuity of time can be achieved by merging Husserlian temporality with a sequential order of time. We also show that a Markov blanket of the present moment integrates past and future moments of both subjective temporality and objective time in an asynchronous manner. By applying the integrated continuity, it is clear that active inference makes use of both subjective temporality and objective time in an integrated fashion. We conclude that active inference, on a temporal note, qualifies as a computational model for phenomenological investigations.},
  doi={10.1093/nc/niad004},
  journal={Neuroscience of Consciousness}
}

@article{sparavigna2012distortional,
  title={Distortional Lifshitz Vectors and Helicity in Nematic Free Energy Density},
  author={Amelia Carolina Sparavigna},
  year={2012},
  url={http://arxiv.org/abs/1207.2918v2},
  abstract={Here we discuss the free energy of nematic liquid crystals using two vectors and the helicity, with the aim of having a compact form of its density. The two vectors are due to the splay and bend distortions of the director field. They have a polar nature, whereas the helicity is a pseudoscalar.},
  doi={10.18483/ijSci.211},
  journal={arXiv}
}

@article{duan2024extracting,
  title={On Extracting Thermal Parameters and Scenario in High-Energy Collisions},
  author={Ting-Ting Duan and Sahanaa Büriechin and Hai-Ling Lao and Fu-Hu Liu and Khusniddin K. Olimov},
  year={2024},
  url={http://arxiv.org/abs/2410.20945v3},
  abstract={In this minireview article, we examine the inconsistent results of thermal parameters derived from various models in high-energy collisions. Through a comprehensive literature review and based on the average transverse momentum or the root-mean-square transverse momentum, we propose model-independent parameters to address these inconsistencies. The relevant parameters include: the initial temperature, the effective temperature, the kinetic freeze-out temperature, and the average transverse velocity. Our findings indicate that these four parameters are larger in central collisions, within central rapidity regions, at higher energies, and in larger collision systems. As collision energy increases, excitation functions for all four parameters rise rapidly (slowly) within ranges below (above) approximately 7.7 GeV. At higher energies (>39) GeV, fluctuations occur in trends for these excitation functions, with only slight changes observed in their growth rates. Additionally, this work reveals a mass-dependent multi-temperature scenario pertaining to both initial states and kinetic freeze-out processes.},
  doi={10.1155/ahep/7766862},
  journal={arXiv}
}

@article{tai2020analysis,
  title={An analysis of transverse momentum spectra of various jets produced in high energy collisions},
  author={Yang-Ming Tai and Pei-Pin Yang and Fu-Hu Liu},
  year={2020},
  url={http://arxiv.org/abs/2008.12554v2},
  abstract={With the framework of the multi-source thermal model, we analyze the experimental transverse momentum spectra of various jets produced in different collisions at high energies. Two energy sources, a projectile participant quark and a target participant quark, are considered. Each energy source (each participant quark) is assumed to contribute to the transverse momentum distribution to be the TP-like function, i.e. a revised Tsallis--Pareto-type function. The contribution of the two participant quarks to the transverse momentum distribution is then the convolution of two TP-like functions. The model distribution can be used to fit the experimental spectra measured by different collaborations. The related parameters such as the entropy index-related, effective temperature, and revised index are then obtained. The trends of these parameters are useful to understand the characteristic of high energy collisions.},
  doi={10.1155/2021/8832892},
  journal={arXiv}
}

@article{majumder2013fr,
  title={f(R) in Holographic and Agegraphic Dark Energy Models and the Generalized Uncertainty Principle},
  author={Barun Majumder},
  year={2013},
  url={http://arxiv.org/abs/1307.4448v1},
  abstract={We studied a unified approach with the holographic, new agegraphic and the $f(R)$ dark energy model to construct the form of $f(R)$ which in general responsible for the curvature driven explanation of the very early inflation along with presently observed late time acceleration. We considered the generalized uncertainty principle in our approach which incorporated the corrections in the entropy area relation and thereby modified the energy densities for the cosmological dark energy models considered. We found that holographic and new agegraphic $f(R)$ gravity models can behave like phantom or quintessence models in the spatially flat FRW universe. We also found a distinct term in the form of $f(R)$ which goes as $R^{\frac{3}{2}}$ due to the consideration of the GUP modified energy densities. Although the presence of this term in the action can have its importance in explaining the early inflationary scenario but Capozziello {\it et.al.} recently showed that $f(R) \sim R^{\frac{3}{2}}$ leads to an accelerated expansion, {\it i.e.}, a negative value for the deceleration parameter $q$ which fit well with SNeIa and WMAP data.},
  doi={10.1155/2013/143195},
  journal={arXiv}
}

@article{liu2015searching,
  title={Searching for minimum in dependence of squared speed-of-sound on collision energy},
  author={Fu-Hu Liu and Li-Na Gao and Roy A. Lacey},
  year={2015},
  url={http://arxiv.org/abs/1511.06839v4},
  abstract={Experimental results of the rapidity distributions of negatively charged pions produced in proton-proton ($p$-$p$) and beryllium-beryllium (Be-Be) collisions at different beam momentums, measured by the NA61/SHINE Collaboration at the super proton synchrotron (SPS), are described by a revised (three-source) Landau hydrodynamic model. The squared speed-of-sound parameter $c^2_s$ is then extracted from the width of rapidity distribution. There is a local minimum (knee point) which indicates a softest point in the equation of state (EoS) appearing at about 40$A$ GeV/$c$ (or 8.8 GeV) in $c^2_s$ excitation function [the dependence of $c^2_s$ on incident beam momentum (or center-of-mass energy)]. This knee point should be related to the searching for the onset of quark deconfinement and the critical point of quark-gluon plasma (QGP) phase transition.},
  doi={10.1155/2016/9467194},
  journal={arXiv}
}

@article{duan2024square,
  title={On the Square Speed of Sound in High-Energy Collisions: Range of Values and How to Understand It},
  author={Ting-Ting Duan and Fu-Hu Liu and Khusniddin K. Olimov},
  year={2024},
  url={http://arxiv.org/abs/2412.01467v3},
  abstract={After reviewing the sound speeds in various forms and conditions of matter, we investigate the sound speed of hadronic matter that has decoupled from the hot and dense system formed during high-energy collisions. We comprehensively consider factors such as energy loss of the incident beam, rapidity shift of leading nucleons, and the Landau hydrodynamic model for hadron production. The sound speed is related to the width or standard deviation of the Gaussian rapidity distribution of hadrons. The extracted square speed of sound lies within a range from 0 to 1/3 in most cases. For scenarios exceeding this limit, we also provide an explanation.},
  doi={10.1155/ahep/9976575},
  journal={arXiv}
}

@article{zhang2021thermal,
  title={Thermal freeze-out parameters and pseudo-entropy from charged hadron spectra in high energy collisions},
  author={Xu-Hong Zhang and Ya-Qin Gao and Fu-Hu Liu and Khusniddin K. Olimov},
  year={2021},
  url={http://arxiv.org/abs/2112.09473v3},
  abstract={We collected the transverse momentum (mass) spectra of charged hadrons ($π^{-}$, $π^{+}$, $K^{-}$, $K^{+}$, $\overline{p}$, and $p$) produced in collisions over a center-of-mass energy range from 2.70 to 200 GeV (per nucleon pair). The modified Tsallis--Pareto-type function (the TP-like function) with average transverse flow velocity is used to describe the contribution of participant or constituent quarks to transverse momentum of considered hadron. The experimental spectra of $π^{\mp}$ and $K^{\mp}$ (or $\overline{p}$ and $p$) are fitted by the convolution of two (or three) TP-like functions due to the fact that two (or three) constituent quarks are regarded as two (or three) energy resources in the formation of considered hadron. From the reasonable fits to the spectra, the thermal freeze-out parameters are extracted, and the pseudo-entropy is newly defined and extracted. Some parameters quickly change in the energy range of less than 7.7 GeV, and slowly change in the energy range of greater than 7.7 GeV, indicating the variation of collision mechanism at around 7.7 GeV.},
  doi={10.1155/2022/7499093},
  journal={arXiv}
}

@article{qi2024longterm,
  title={Long-Term Energy Management for Microgrid with Hybrid Hydrogen-Battery Energy Storage: A Prediction-Free Coordinated Optimization Framework},
  author={Ning Qi and Kaidi Huang and Zhiyuan Fan and Bolun Xu},
  year={2024},
  url={http://arxiv.org/abs/2407.21698v1},
  abstract={This paper studies the long-term energy management of a microgrid coordinating hybrid hydrogen-battery energy storage. We develop an approximate semi-empirical hydrogen storage model to accurately capture the power-dependent efficiency of hydrogen storage. We introduce a prediction-free two-stage coordinated optimization framework, which generates the annual state-of-charge (SoC) reference for hydrogen storage offline. During online operation, it updates the SoC reference online using kernel regression and makes operation decisions based on the proposed adaptive virtual-queue-based online convex optimization (OCO) algorithm. We innovatively incorporate penalty terms for long-term pattern tracking and expert-tracking for step size updates. We provide theoretical proof to show that the proposed OCO algorithm achieves a sublinear bound of dynamic regret without using prediction information. Numerical studies based on the Elia and North China datasets show that the proposed framework significantly outperforms the existing online optimization approaches by reducing the operational costs and loss of load by around 30% and 80%, respectively. These benefits can be further enhanced with optimized settings for the penalty coefficient and step size of OCO, as well as more historical references.},
  doi={10.1016/j.apenergy.2024.124485},
  journal={arXiv}
}

@article{gasperini2021gravity,
  title={Gravity at Finite Temperature, Equivalence Principle,and Local Lorentz Invariance},
  author={M. Gasperini},
  year={2021},
  url={http://arxiv.org/abs/2101.00458v2},
  abstract={In this Chapter we illustrate the close connection between the violation of the weak equivalence principle typical of gravitational interactions at finite temperature, and similar violations induced by a breaking of the local Lorentz symmetry. We also discuss the physical implications of the effective repulsive forces possibly arising in such a generalized gravitational context, by considering, for an illustrative purpose, a quasi-Riemannian model of gravity with rotational symmetry as the local gauge group in tangent space.},
  doi={10.1142/9789811253591_fmatter},
  journal={arXiv}
}

@article{li2019excitation,
  title={Excitation functions of related parameters from transverse momentum (mass) spectra in high energy collisions},
  author={Li-Li Li and Fu-Hu Liu and Muhammad Waqas and Rasha Al-Yusufi and Altaf Mujear},
  year={2019},
  url={http://arxiv.org/abs/1911.07419v2},
  abstract={Transverse momentum (mass) spectra of positively and negatively charged pions, positively and negatively charged kaons, protons and antiprotons produced at mid-(pseudo)rapidity in various collisions at high energies are analyzed in this work. The experimental data measured in central gold-gold, central lead-lead, and inelastic proton-proton collisions by several international collaborations are studied. The (two-component) standard distribution is used to fit the data and extract the excitation function of effective temperature. Then, the excitation functions of kinetic freeze-out temperature, transverse flow velocity, and initial temperature are obtained. In the considered collisions, the four parameters increase with the increase of collision energy in general, and the kinetic freeze-out temperature appears the trend of saturation at the top Relativistic Heavy Ion Collider and the Large Hadron Collider.},
  doi={10.1155/2020/5356705},
  journal={arXiv}
}

@article{ogurtani2010generic,
  title={Generic role of the anisotropic surface free energy on the morphological evolution in a strained-heteroepitaxial solid droplet on a rigid substrate},
  author={Tarik Omer Ogurtani and Aytac Celik and Ersin Emre Oren},
  year={2010},
  url={http://arxiv.org/abs/1010.5363v1},
  abstract={A systematic study based on the self-consistent dynamical simulations is presented for the spontaneous evolution of an isolated thin solid droplet on a rigid substrate, which is driven by the surface drift diffusion induced by the anisotropic capillary forces (surface stiffness) and mismatch stresses. In this work, we studied the affect of surface free energy anisotropies on the development kinetics of the 'Stranski-Krastanow' island type morphology. The anisotropic surface free energy and the surface stiffness were treated with well accepted trigonometric functions. Although, various tilt angles and anisotropy constants were considered during simulations, the main emphasis was given on the effect of rotational symmetries associated with the surface Helmholtz free energy topography in 2D space. Our computer simulations revealed the formation of an extremely thin wetting layer during the development of the bell-shaped Stranski-Krastanow island through the mass accumulation at the central region of the droplet via surface drift-diffusion. In the strong (anomalous) anisotropy constant domain, we demonstrated the existence of two distinct morphological modes: i) the complete stability of the initial Cosine-shaped droplet just above a certain anisotropy constant threshold level by spontaneous slight readjustments of the base and the height of the cluster; ii) the Frank-van der Merwe mode of thin film formation for very large values of the anisotropy constant by the spreading and coalescence of the droplets over the substrate surface. During the course of the simulations, we have continuously tracked both the morphology (i.e., the peak height, the extension of the wetting layer beyond the domain boundaries, and the triple junction contact angle) and energetic (the global Helmholtz free energy changes associated with the total strain and surface energy variations) of the system.},
  doi={10.1063/1.3512970},
  journal={arXiv}
}

@article{lopezcorredoira2016against,
  title={Against free will in the contemporary natural sciences},
  author={Martin Lopez-Corredoira},
  year={2016},
  url={http://arxiv.org/abs/1612.01466v1},
  abstract={The claim of the freedom of the will (understood as an individual who is transcendent to Nature) in the name of XXth century scientific knowledge, against the perspective of XVIIIth-XIXth century scientific materialism, is analysed and refuted in the present paper. The hypothesis of reductionism finds no obstacle within contemporary natural sciences. Determinism in classical physics is irrefutable, unless classical physics is itself refuted. From quantum mechanics, some authors argue that free will is possible because there is an ontological indeterminism in the natural laws, and that the mind is responsible for the wave function collapse of matter, which leads to a choice among the different possibilities for the body. However, here I defend the opposite thesis because indeterminism does not imply free will, and because the considerations about an autonomous mind sending orders to the body is against neuroscience or evolutionary theories about human beings. The quantum theory of measurement can be interpreted without the intervention of human minds, but other fields of science cannot contemplate the mentalist scenario. A fatalistic or materialist view, which denies the possibility of a free will, makes much more sense in scientific terms.},
  journal={arXiv}
}

@article{zhang2022random,
  title={Random statistical analysis of transverse momentum spectra of strange particles and dependence of related parameters on centrality in high energy collisions at the LHC},
  author={Xu-Hong Zhang and Fu-Hu Liu and Khusniddin K. Olimov and Airton Deppman},
  year={2022},
  url={http://arxiv.org/abs/2209.03894v2},
  abstract={We have studied the transverse momentum ($p_T$) spectra of the final-state strange particles, including $K^{\pm}$, $φ$, $\itΞ$, and $\itΩ$, produced in high energy lead-lead (Pb-Pb), proton-lead ($p$-Pb), xenon-xenon (Xe-Xe) collisions at the Large Hadron Collider (LHC). Taking into account the contribution of multi-quark composition, whose probability density distribution is described by the modified Tsallis-Pareto-type function, we simulate the $p_T$ spectra of the final-state strange particles by a Monte Carlo method, which is shown to be in good agreement with the experimental data in most the cases. The kinetic freeze-out parameters are obtained. The present method provides a new tool for studying the spectra of various particles produced in high energy collisions, reflecting more realistically the collision process, which is of great significance to study the formation and properties of the produced particles.},
  doi={10.1155/2022/5949610},
  journal={arXiv}
}

@article{yang2019new,
  title={A new description of transverse momentum spectra of identified particles produced in proton-proton collisions at high energies},
  author={Pei-Pin Yang and Fu-Hu Liu and Raghunath Sahoo},
  year={2019},
  url={http://arxiv.org/abs/1909.13235v5},
  abstract={The transverse momentum spectra of identified particles produced in high energy proton-proton ($p+p$) collisions are empirically described by a new method with the framework of participant quark model or the multisource model at the quark level, in which the source itself is exactly the participant quark. Each participant (constituent) quark contributes to the transverse momentum spectrum, which is described by the TP-like function, a revised Tsallis--Pareto-type function. The transverse momentum spectrum of the hadron is the convolution of two or more TP-like functions. For a lepton, the transverse momentum spectrum is the convolution of two TP-like functions due to two participant quarks, e.g. projectile and target quarks, taking part in the collisions. A discussed theoretical approach seems to describe the $p+p$ collisions data at center-of-mass energy $\sqrt{s}=200$ GeV, 2.76 TeV, and 13 TeV very well.},
  doi={10.1155/2020/6742578},
  journal={arXiv}
}

@article{johnson2021quenched,
  title={On the Quenched Free Energy of JT Gravity and Supergravity},
  author={Clifford V. Johnson},
  year={2021},
  url={http://arxiv.org/abs/2104.02733v3},
  abstract={The quenched free energy, $F_Q(T){=}{-}T\langle \ln Z(T)\rangle$, of various JT gravity and supergravity theories is explored, taking into account the key non-perturbative physics that is accessible using their matrix model formulations. The leading low energy physics of these systems can be modelled by the Airy and (a family of) Bessel models, which arise from scaling limits of matrix ensembles. The $F_Q(T)$s of these models are directly computed by explicit sampling of the matrix ensembles, and how their properties are connected to the statistical mechanics of the underlying discrete spectrum of the ensembles is elucidated. Some of the low temperature ($T$) features of the results confirm recent observations by Jassen and Mirbabayi. The results are then used as benchmarks for exploring an intriguing formula proposed by Okuyama for computing $F_Q(T)$ in terms of the connected correlators of its partition function, the wormholes of the gravity theory. A low $T$ truncation of the correlators helps render the formula practical, but it is shown that this is at the expense of much of its accuracy. The significance of the statistical interpretation of $F_Q(T)$ for black hole microphysics is discussed.},
  journal={arXiv}
}

@article{friston2010freeenergy,
  title={The free-energy principle: a unified brain theory?},
  author={Karl J. Friston},
  year={2010},
  url={https://www.semanticscholar.org/paper/1ed6a4a10589618d4f26350f1a296ee767ceff6b},
  doi={10.1038/nrn2787},
  journal={Nature Reviews Neuroscience}
}

@article{friston2009freeenergy,
  title={The free-energy principle: a rough guide to the brain?},
  author={Karl J. Friston},
  year={2009},
  url={https://www.semanticscholar.org/paper/a878886efacc6a5d742bf98bfc25c0734ce502b1},
  doi={10.1016/j.tics.2009.04.005},
  journal={Trends in Cognitive Sciences}
}

@article{friston2019free,
  title={A free energy principle for a particular physics},
  author={Karl J. Friston},
  year={2019},
  url={https://www.semanticscholar.org/paper/a44cf961a4495f5a789dfa240e2675f7fffa615e},
  abstract={This monograph attempts a theory of every 'thing' that can be distinguished from other things in a statistical sense. The ensuing statistical independencies, mediated by Markov blankets, speak to a recursive composition of ensembles (of things) at increasingly higher spatiotemporal scales. This decomposition provides a description of small things; e.g., quantum mechanics - via the Schrodinger equation, ensembles of small things - via statistical mechanics and related fluctuation theorems, through to big things - via classical mechanics. These descriptions are complemented with a Bayesian mechanics for autonomous or active things. Although this work provides a formulation of every thing, its main contribution is to examine the implications of Markov blankets for self-organisation to nonequilibrium steady-state. In brief, we recover an information geometry and accompanying free energy principle that allows one to interpret the internal states of something as representing or making inferences about its external states. The ensuing Bayesian mechanics is compatible with quantum, statistical and classical mechanics and may offer a formal description of lifelike particles.}
}

@article{wiese2024artificial,
  title={Artificial consciousness: a perspective from the free energy principle},
  author={Wanja Wiese},
  year={2024},
  url={https://www.semanticscholar.org/paper/b0f34f92009dbeb1b1300fb4945603f4c09c22bc},
  abstract={Does the assumption of a weak form of computational functionalism, according to which the right form of neural computation is sufficient for consciousness, entail that a digital computational simulation of such neural computations is conscious? Or must this computational simulation be implemented in the right way, in order to replicate consciousness? From the perspective of Karl Friston’s free energy principle, self-organising systems (such as living organisms) share a set of properties that could be realised in artificial systems, but are not instantiated by computers with a classical (von Neumann) architecture. I argue that at least one of these properties, viz. a certain kind of causal flow, can be used to draw a distinction between systems that merely simulate, and those that actually replicate consciousness.},
  doi={10.1007/s11098-024-02182-y},
  journal={Philosophical Studies}
}

@article{zhang2024overview,
  title={An Overview of the Free Energy Principle and Related Research},
  author={Zhengquan Zhang and Feng Xu},
  year={2024},
  url={https://www.semanticscholar.org/paper/0d0ec3a44ed0c66b96c3da7cbc3a34568ae6ae0f},
  abstract={Abstract The free energy principle and its corollary, the active inference framework, serve as theoretical foundations in the domain of neuroscience, explaining the genesis of intelligent behavior. This principle states that the processes of perception, learning, and decision making—within an agent—are all driven by the objective of “minimizing free energy,” evincing the following behaviors: learning and employing a generative model of the environment to interpret observations, thereby achieving perception, and selecting actions to maintain a stable preferred state and minimize the uncertainty about the environment, thereby achieving decision making. This fundamental principle can be used to explain how the brain processes perceptual information, learns about the environment, and selects actions. Two pivotal tenets are that the agent employs a generative model for perception and planning and that interaction with the world (and other agents) enhances the performance of the generative model and augments perception. With the evolution of control theory and deep learning tools, agents based on the FEP have been instantiated in various ways across different domains, guiding the design of a multitude of generative models and decision-making algorithms. This letter first introduces the basic concepts of the FEP, followed by its historical development and connections with other theories of intelligence, and then delves into the specific application of the FEP to perception and decision making, encompassing both low-dimensional simple situations and high-dimensional complex situations. It compares the FEP with model-based reinforcement learning to show that the FEP provides a better objective function. We illustrate this using numerical studies of Dreamer3 by adding expected information gain into the standard objective function. In a complementary fashion, existing reinforcement learning, and deep learning algorithms can also help implement the FEP-based agents. Finally, we discuss the various capabilities that agents need to possess in complex environments and state that the FEP can aid agents in acquiring these capabilities.},
  doi={10.1162/neco_a_01642},
  journal={Neural Computation}
}

@article{friston2022free,
  title={The free energy principle made simpler but not too simple},
  author={K. Friston and Lancelot Da Costa and Noor Sajid and Conor Heins and Kai Ueltzhoffer and G. Pavliotis and Thomas Parr},
  year={2022},
  url={https://www.semanticscholar.org/paper/e54427100b2de8187fe3b96303653b6220aaad44},
  doi={10.1016/j.physrep.2023.07.001},
  journal={Physics reports}
}

@article{ramstead2023inner,
  title={The inner screen model of consciousness: applying the free energy principle directly to the study of conscious experience},
  author={M. Ramstead and Mahault Albarracin and Alex B. Kiefer and Brennan Klein and C. Fields and K. Friston and A. Safron},
  year={2023},
  url={https://www.semanticscholar.org/paper/8a21c792f07f6e016fb8ee0e7c05ee375a31fab3},
  abstract={This paper presents a model of consciousness that follows directly from the free-energy principle (FEP). We first rehearse the classical and quantum formulations of the FEP. In particular, we consider the inner screen hypothesis that follows from the quantum information theoretic version of the FEP. We then review applications of the FEP to the known sparse (nested and hierarchical) neuro-anatomy of the brain. We focus on the holographic structure of the brain, and how this structure supports (overt and covert) action.}
}

@article{paolo2022laying,
  title={Laying down a forking path: Tensions between enaction and the free energy principle},
  author={E. D. Di Paolo and Evan Thompson and R. Beer},
  year={2022},
  url={https://www.semanticscholar.org/paper/16356bdd79f46ec6f1152c67fa6a8485d0b3bcb8},
  abstract={


Several authors have made claims about the compatibility between the Free Energy Principle (FEP) and theories of autopoiesis and enaction. Many see these theories as natural partners or as making similar statements about the nature of biological and cognitive systems. We critically examine these claims and identify a series of misreadings and misinterpretations of key enactive concepts. In particular, we notice a tendency to disregard the operational definition of autopoiesis and the distinction between a system’s structure and its organization. Other misreadings concern the conflation of processes of self-distinction in operationally closed systems and Markov blankets. Deeper theoretical tensions underlie some of these misinterpretations. FEP assumes systems that reach a non-equilibrium steady state and are enveloped by a Markov blanket. We argue that these assumptions contradict the historicity of sense-making that is explicit in the enactive approach. Enactive concepts such as adaptivity and agency are defined in terms of the modulation of parameters and constraints of the agent-environment coupling, which entail the possibility of changes in variable and parameter sets, constraints, and in the dynamical laws affecting the system. This allows enaction to address the path-dependent diversity of human bodies and minds. We argue that these ideas are incompatible with the time invariance of non-equilibrium steady states assumed by the FEP. In addition, the enactive perspective foregrounds the enabling and constitutive roles played by the world in sense-making, agency, development. We argue that this view of transactional and constitutive relations between organisms and environments is a challenge to the FEP. Once we move beyond superficial similarities, identify misreadings, and examine the theoretical commitments of the two approaches, we reach the conclusion that far from being easily integrated, the FEP, as it stands formulated today, is in tension with the theories of autopoiesis and enaction.


},
  doi={10.33735/phimisci.2022.9187},
  journal={Philosophy and the Mind Sciences}
}

@article{wirkuttis2023turntaking,
  title={Turn-Taking Mechanisms in Imitative Interaction: Robotic Social Interaction Based on the Free Energy Principle},
  author={Nadine Wirkuttis and Wataru Ohata and J. Tani},
  year={2023},
  url={https://www.semanticscholar.org/paper/72cfd94737ca87a635b5b5a40beaa25cc97c805c},
  abstract={This study explains how the leader-follower relationship and turn-taking could develop in a dyadic imitative interaction by conducting robotic simulation experiments based on the free energy principle. Our prior study showed that introducing a parameter during the model training phase can determine leader and follower roles for subsequent imitative interactions. The parameter is defined as w, the so-called meta-prior, and is a weighting factor used to regulate the complexity term versus the accuracy term when minimizing the free energy. This can be read as sensory attenuation, in which the robot’s prior beliefs about action are less sensitive to sensory evidence. The current extended study examines the possibility that the leader-follower relationship shifts depending on changes in w during the interaction phase. We identified a phase space structure with three distinct types of behavioral coordination using comprehensive simulation experiments with sweeps of w of both robots during the interaction. Ignoring behavior in which the robots follow their own intention was observed in the region in which both ws were set to large values. One robot leading, followed by the other robot was observed when one w was set larger and the other was set smaller. Spontaneous, random turn-taking between the leader and the follower was observed when both ws were set at smaller or intermediate values. Finally, we examined a case of slowly oscillating w in anti-phase between the two agents during the interaction. The simulation experiment resulted in turn-taking in which the leader-follower relationship switched during determined sequences, accompanied by periodic shifts of ws. An analysis using transfer entropy found that the direction of information flow between the two agents also shifted along with turn-taking. Herein, we discuss qualitative differences between random/spontaneous turn-taking and agreed-upon sequential turn-taking by reviewing both synthetic and empirical studies.},
  doi={10.3390/e25020263},
  journal={Entropy}
}

@article{isomura2022experimental,
  title={Experimental validation of the free-energy principle with in vitro neural networks},
  author={Takuya Isomura and K. Kotani and Y. Jimbo and K. Friston},
  year={2022},
  url={https://www.semanticscholar.org/paper/0cad9da7488896c9e2d2a7df23b822497f24860c},
  abstract={Empirical applications of the free-energy principle are not straightforward because they entail a commitment to a particular process theory, especially at the cellular and synaptic levels. Using a recently established reverse engineering technique, we confirm the quantitative predictions of the free-energy principle using in vitro networks of rat cortical neurons that perform causal inference. Upon receiving electrical stimuli—generated by mixing two hidden sources—neurons self-organised to selectively encode the two sources. Pharmacological up- and downregulation of network excitability disrupted the ensuing inference, consistent with changes in prior beliefs about hidden sources. As predicted, changes in effective synaptic connectivity reduced variational free energy, where the connection strengths encoded parameters of the generative model. In short, we show that variational free energy minimisation can quantitatively predict the self-organisation of neuronal networks, in terms of their responses and plasticity. These results demonstrate the applicability of the free-energy principle to in vitro neural networks and establish its predictive validity in this setting.},
  doi={10.1038/s41467-023-40141-z},
  journal={bioRxiv}
}

@article{friston2009predictive,
  title={Predictive coding under the free-energy principle},
  author={Karl J. Friston and S. Kiebel},
  year={2009},
  url={https://www.semanticscholar.org/paper/6927ea92b0d759a75f0f696fa028155d6d9ee2ca},
  doi={10.1098/rstb.2008.0300},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences}
}

@article{carl2023models,
  title={Models of the Translation Process and the Free Energy Principle},
  author={M. Carl},
  year={2023},
  url={https://www.semanticscholar.org/paper/f700a47ad70f9dfe0a614b54b648f43ed2cbd28d},
  abstract={Translation process research (TPR) has generated a large number of models that aim at explaining human translation processes. In this paper, I suggest an extension of the monitor model to incorporate aspects of relevance theory (RT) and to adopt the free energy principle (FEP) as a generative model to elucidate translational behaviour. The FEP—and its corollary, active inference—provide a general, mathematical framework to explain how organisms resist entropic erosion so as to remain within their phenotypic bounds. It posits that organisms reduce the gap between their expectations and observations by minimising a quantity called free energy. I map these concepts on the translation process and exemplify them with behavioural data. The analysis is based on the notion of translation units (TUs) which exhibit observable traces of the translator’s epistemic and pragmatic engagement with their translation environment, (i.e., the text) that can be measured in terms of translation effort and effects. Sequences of TUs cluster into translation states (steady state, orientation, and hesitation). Drawing on active inference, sequences of translation states combine into translation policies that reduce expected free energy. I show how the notion of free energy is compatible with the concept of relevance, as developed in RT, and how essential concepts of the monitor model and RT can be formalised as deep temporal generative models that can be interpreted under a representationalist view, but also support a non-representationalist account.},
  doi={10.3390/e25060928},
  journal={Entropy}
}

@article{sasaki2023quantification,
  title={Quantification of “novelty” based on free-energy principle and its application for “aesthetic liking” for industrial products},
  author={Hiromasa Sasaki and Takeo Kato and Hideyoshi Yanagisawa},
  year={2023},
  url={https://www.semanticscholar.org/paper/017503359d8501389232c85436ecf00d4c3358bb},
  doi={10.1007/s00163-023-00422-6},
  journal={Research in Engineering Design}
}

@article{miyagi2023fetal,
  title={Fetal brain activity and the free energy principle},
  author={Yasunari Miyagi and T. Hata and T. Miyake},
  year={2023},
  url={https://www.semanticscholar.org/paper/ad4c8aad105b685734abb75e4782b82b12edbdd3},
  abstract={Abstract Objectives To study whether the free energy principle can explain fetal brain activity and the existence of fetal consciousness via a chaotic dimension derived using artificial intelligence. Methods In this observational study, we used a four-dimensional ultrasound technique obtained to collect images of fetal faces from pregnancies at 27–37 weeks of gestation, between February and December 2021. We developed an artificial intelligence classifier that recognizes fetal facial expressions, which are thought to relate to fetal brain activity. We then applied the classifier to video files of facial images to generate each expression category’s probabilities. We calculated the chaotic dimensions from the probability lists, and we created and investigated the free energy principle’s mathematical model that was assumed to be linked to the chaotic dimension. We used a Mann–Whitney test, linear regression test, and one-way analysis of variance for statistical analysis. Results The chaotic dimension revealed that the fetus had dense and sparse states of brain activity, which fluctuated at a statistically significant level. The chaotic dimension and free energy were larger in the sparse state than in the dense state. Conclusions The fluctuating free energy suggests consciousness seemed to exist in the fetus after 27 weeks.},
  doi={10.1515/jpm-2023-0092},
  journal={Journal of Perinatal Medicine}
}

@article{piekarski2023incorporating,
  title={Incorporating (variational) free energy models into mechanisms: the case of predictive processing under the free energy principle},
  author={M. Piekarski},
  year={2023},
  url={https://www.semanticscholar.org/paper/fb55dc1ff5762919195aa4ea2360a0f1c79a0087},
  abstract={The issue of the relationship between predictive processing (PP) and the free energy principle (FEP) remains a subject of debate and controversy within the research community. Many researchers have expressed doubts regarding the actual integration of PP with the FEP, questioning whether the FEP can truly contribute significantly to the mechanistic understanding of PP or even undermine such integration altogether. In this paper, I present an alternative perspective. I argue that, from the viewpoint of the constraint-based mechanisms approach, the FEP imposes an important constraint, namely variational free energy, on the mechanistic architecture proposed by PP. According to the constraint-based mechanisms approach, high-level cognitive mechanisms are integral parts of extensive heterarchical networks that govern the physiology and behavior of agents. Consequently, mechanistic explanations of cognitive phenomena should incorporate constraints and flows of free energy as relevant components, given that the implemented constraints operate as long as free energy is available. Within this framework, I contend that the FEP provides a relevant constraint for explaining at least some biological cognitive mechanisms described in terms of Bayesian generative models that minimize prediction errors.},
  doi={10.1007/s11229-023-04292-2},
  journal={Synthese}
}

@article{mazzaglia2022free,
  title={The Free Energy Principle for Perception and Action: A Deep Learning Perspective},
  author={Pietro Mazzaglia and Tim Verbelen and Ozan Çatal and B. Dhoedt},
  year={2022},
  url={https://www.semanticscholar.org/paper/5f4f196fc6277185d85816501bb814dfaeed69e4},
  abstract={The free energy principle, and its corollary active inference, constitute a bio-inspired theory that assumes biological agents act to remain in a restricted set of preferred states of the world, i.e., they minimize their free energy. Under this principle, biological agents learn a generative model of the world and plan actions in the future that will maintain the agent in an homeostatic state that satisfies its preferences. This framework lends itself to being realized in silico, as it comprehends important aspects that make it computationally affordable, such as variational inference and amortized planning. In this work, we investigate the tool of deep learning to design and realize artificial agents based on active inference, presenting a deep-learning oriented presentation of the free energy principle, surveying works that are relevant in both machine learning and active inference areas, and discussing the design choices that are involved in the implementation process. This manuscript probes newer perspectives for the active inference framework, grounding its theoretical aspects into more pragmatic affairs, offering a practical guide to active inference newcomers and a starting point for deep learning practitioners that would like to investigate implementations of the free energy principle.},
  doi={10.3390/e24020301},
  journal={Entropy}
}

@article{andrews2021math,
  title={The math is not the territory: navigating the free energy principle},
  author={Melody Andrews},
  year={2021},
  url={https://www.semanticscholar.org/paper/a8f6638dc7e621de192e62a1cdaa4f7f24055940},
  doi={10.1007/s10539-021-09807-0},
  journal={Biology & Philosophy}
}

@article{gu2015using,
  title={Using Free Energy Principle For Blind Image Quality Assessment},
  author={Ke Gu and Guangtao Zhai and Xiaokang Yang and Wenjun Zhang},
  year={2015},
  url={https://www.semanticscholar.org/paper/c7c27c520cca5d874460d46639f8e8d7cc39ecd5},
  doi={10.1109/TMM.2014.2373812},
  journal={IEEE transactions on multimedia}
}

@article{song2023human,
  title={Human ear inspired solar thermochemical reactor for steam methane reforming with the consideration of minimum Gibbs free energy principle},
  author={Jintao Song and Ziming Cheng and Yaping Fan and Fuqiang Wang and Xuhan Shi and Jie Xu and Hongliang Yi},
  year={2023},
  url={https://www.semanticscholar.org/paper/46f9641c6aef4297ecefe08c734d0f88850ff89b},
  doi={10.1016/j.est.2023.108172},
  journal={Journal of Energy Storage}
}

@article{mcgovern2022learned,
  title={Learned uncertainty: The free energy principle in anxiety},
  author={H. McGovern and A. De Foe and Hannah Biddell and P. Leptourgos and P. Corlett and Kavindu Bandara and B. Hutchinson},
  year={2022},
  url={https://www.semanticscholar.org/paper/58158b5fdd139fc22c80086c38a47368520f01d1},
  abstract={Generalized anxiety disorder is among the world’s most prevalent psychiatric disorders and often manifests as persistent and difficult to control apprehension. Despite its prevalence, there is no integrative, formal model of how anxiety and anxiety disorders arise. Here, we offer a perspective derived from the free energy principle; one that shares similarities with established constructs such as learned helplessness. Our account is simple: anxiety can be formalized as learned uncertainty. A biological system, having had persistent uncertainty in its past, will expect uncertainty in its future, irrespective of whether uncertainty truly persists. Despite our account’s intuitive simplicity—which can be illustrated with the mere flip of a coin—it is grounded within the free energy principle and hence situates the formation of anxiety within a broader explanatory framework of biological self-organization and self-evidencing. We conclude that, through conceptualizing anxiety within a framework of working generative models, our perspective might afford novel approaches in the clinical treatment of anxiety and its key symptoms.},
  doi={10.3389/fpsyg.2022.943785},
  journal={Frontiers in Psychology}
}

@article{kiverstein2022problem,
  title={The Problem of Meaning: The Free Energy Principle and Artificial Agency},
  author={J. Kiverstein and Michael D. Kirchhoff and T. Froese},
  year={2022},
  url={https://www.semanticscholar.org/paper/41595d541175d4c88740bff1b4315079e61a7469},
  abstract={Biological agents can act in ways that express a sensitivity to context-dependent relevance. So far it has proven difficult to engineer this capacity for context-dependent sensitivity to relevance in artificial agents. We give this problem the label the “problem of meaning”. The problem of meaning could be circumvented if artificial intelligence researchers were to design agents based on the assumption of the continuity of life and mind. In this paper, we focus on the proposal made by enactive cognitive scientists to design artificial agents that possess sensorimotor autonomy—stable, self-sustaining patterns of sensorimotor interaction that can ground values, norms and goals necessary for encountering a meaningful environment. More specifically, we consider whether the Free Energy Principle (FEP) can provide formal tools for modeling sensorimotor autonomy. There is currently no consensus on how to understand the relationship between enactive cognitive science and the FEP. However, a number of recent papers have argued that the two frameworks are fundamentally incompatible. Some argue that biological systems exhibit historical path-dependent learning that is absent from systems that minimize free energy. Others have argued that a free energy minimizing system would fail to satisfy a key condition for sensorimotor agency referred to as “interactional asymmetry”. These critics question the claim we defend in this paper that the FEP can be used to formally model autonomy and adaptivity. We will argue it is too soon to conclude that the two frameworks are incompatible. There are undeniable conceptual differences between the two frameworks but in our view each has something important and necessary to offer. The FEP needs enactive cognitive science for the solution it provides to the problem of meaning. Enactive cognitive science needs the FEP to formally model the properties it argues to be constitutive of agency. Our conclusion will be that active inference models based on the FEP provides a way by which scientists can think about how to address the problems of engineering autonomy and adaptivity in artificial agents in formal terms. In the end engaging more closely with this formalism and its further developments will benefit those working within the enactive framework.},
  doi={10.3389/fnbot.2022.844773},
  journal={Frontiers in Neurorobotics}
}

@article{kirchhoff2018markov,
  title={The Markov blankets of life: autonomy, active inference and the free energy principle},
  author={Michael D. Kirchhoff and Thomas Parr and E. Palacios and Karl J. Friston and J. Kiverstein},
  year={2018},
  url={https://www.semanticscholar.org/paper/e1d3f7eb3bf11a0881d9417df8071ca663eefbaf},
  abstract={This work addresses the autonomous organization of biological systems. It does so by considering the boundaries of biological systems, from individual cells to Home sapiens, in terms of the presence of Markov blankets under the active inference scheme—a corollary of the free energy principle. A Markov blanket defines the boundaries of a system in a statistical sense. Here we consider how a collective of Markov blankets can self-assemble into a global system that itself has a Markov blanket; thereby providing an illustration of how autonomous systems can be understood as having layers of nested and self-sustaining boundaries. This allows us to show that: (i) any living system is a Markov blanketed system and (ii) the boundaries of such systems need not be co-extensive with the biophysical boundaries of a living organism. In other words, autonomous systems are hierarchically composed of Markov blankets of Markov blankets—all the way down to individual cells, all the way up to you and me, and all the way out to include elements of the local environment.},
  doi={10.1098/rsif.2017.0792},
  journal={Journal of the Royal Society Interface}
}

@article{fields2022free,
  title={The free energy principle induces neuromorphic development},
  author={C. Fields and K. Friston and J. Glazebrook and Michael Levin and A. Marcianò},
  year={2022},
  url={https://www.semanticscholar.org/paper/3f680ba04037160d746b4bde48218ed640395b55},
  abstract={We show how any finite physical system with morphological, i.e. three-dimensional embedding or shape, degrees of freedom and locally limited free energy will, under the constraints of the free energy principle, evolve over time towards a neuromorphic morphology that supports hierarchical computations in which each ‘level’ of the hierarchy enacts a coarse-graining of its inputs, and dually, a fine-graining of its outputs. Such hierarchies occur throughout biology, from the architectures of intracellular signal transduction pathways to the large-scale organization of perception and action cycles in the mammalian brain. The close formal connections between cone-cocone diagrams (CCCD) as models of quantum reference frames on the one hand, and between CCCDs and topological quantum field theories on the other, allow the representation of such computations in the fully-general quantum-computational framework of topological quantum neural networks.},
  doi={10.1088/2634-4386/aca7de},
  journal={Neuromorph. Comput. Eng.}
}

@article{zhu2022energy,
  title={Energy Management Based on Multi-Agent Deep Reinforcement Learning for A Multi-Energy Industrial Park},
  author={Dafeng Zhu and Bo Yang and Yuxiang Liu and Zhaojian Wang and Kai Ma and Xinping Guan},
  year={2022},
  url={http://arxiv.org/abs/2202.03771v2},
  abstract={Owing to large industrial energy consumption, industrial production has brought a huge burden to the grid in terms of renewable energy access and power supply. Due to the coupling of multiple energy sources and the uncertainty of renewable energy and demand, centralized methods require large calculation and coordination overhead. Thus, this paper proposes a multi-energy management framework achieved by decentralized execution and centralized training for an industrial park. The energy management problem is formulated as a partially-observable Markov decision process, which is intractable by dynamic programming due to the lack of the prior knowledge of the underlying stochastic process. The objective is to minimize long-term energy costs while ensuring the demand of users. To solve this issue and improve the calculation speed, a novel multi-agent deep reinforcement learning algorithm is proposed, which contains the following key points: counterfactual baseline for facilitating contributing agents to learn better policies, soft actor-critic for improving robustness and exploring optimal solutions. A novel reward is designed by Lagrange multiplier method to ensure the capacity constraints of energy storage. In addition, considering that the increase in the number of agents leads to performance degradation due to large observation spaces, an attention mechanism is introduced to enhance the stability of policy and enable agents to focus on important energy-related information, which improves the exploration efficiency of soft actor-critic. Numerical results based on actual data verify the performance of the proposed algorithm with high scalability, indicating that the industrial park can minimize energy costs under different demands.},
  doi={10.1016/j.apenergy.2022.118636},
  journal={arXiv}
}

@article{sahoo2014charged,
  title={Charged Particle and Photon Multiplicity, and Transverse Energy Production in High-Energy Heavy-Ion Collisions},
  author={Raghunath Sahoo and Aditya Nath Mishra and Nirbhay K. Behera and Basanta K. Nandi},
  year={2014},
  url={http://arxiv.org/abs/1408.5773v1},
  abstract={We review the charged particle and photon multiplicity, and transverse energy production in heavy-ion collisions starting from few GeV to TeV energies. The experimental results of pseudorapidity distribution of charged particles and photons at different collision energies and centralities are discussed. We also discuss the hypothesis of limiting fragmentation and expansion dynamics using the Landau hydrodynamics and the underlying physics. Meanwhile, we present the estimation of initial energy density multiplied with formation time as a function of different collision energies and centralities. In the end, the transverse energy per charged particle in connection with the chemical freeze-out criteria is discussed. We invoke various models and phenomenological arguments to interpret and characterize the fireball created in heavy-ion collisions. This review overall provides a scope to understand the heavy-ion collision data and a possible formation of a deconfined phase of partons via the global observables like charged particles, photons and the transverse energy measurement.},
  doi={10.1155/2015/612390},
  journal={arXiv}
}

@article{chen2023extracting,
  title={Extracting Kinetic Freeze-out Properties in High Energy Collisions Using a Multi-source Thermal Model},
  author={Jia-Yu Chen and Mai-Ying Duan and Fu-Hu Liu and Khusniddin K. Olimov},
  year={2023},
  url={http://arxiv.org/abs/2309.05923v2},
  abstract={We study the transverse momentum ($p_T$) spectra of neutral pions and identified charged hadrons produced in proton--proton ($pp$), deuteron--gold ($d$--Au), and gold--gold (Au--Au) collisions at the center of mass energy $\sqrt{s_{NN}}=200$ GeV. The study is made in the framework of a multi-source thermal model used in the partonic level. It is assumed that the contribution to the $p_T$-value of any hadron comes from two or three partons with an isotropic distribution of the azimuthal angle. The contribution of each parton to the $p_T$-value of a given hadron is assumed to obey any one of the standard (Maxwell-Boltzmann, Fermi-Dirac, and Bose-Einstein) distributions with the kinetic freeze-out temperature and average transverse flow velocity. The $p_T$-spectra of the final-state hadrons can be fitted by the superposition of two or three components. The results obtained from our Monte Carlo method are used to fit the experimental results of the PHENIX and STAR Collaborations. The results of present work serve as a suitable reference baseline for other experiments and simulation studies.},
  doi={10.1155/2024/9938669},
  journal={arXiv}
}

@article{champion2024reframing,
  title={Reframing the Expected Free Energy: Four Formulations and a Unification},
  author={Théophile Champion and Howard Bowman and Dimitrije Markovi'c and Marek Grze's},
  year={2024},
  url={https://www.semanticscholar.org/paper/88853bbd0878637c1bf02a9f1e4ce3acc151bed1},
  abstract={Active inference is a leading theory of perception, learning and decision making, which can be applied to neuroscience, robotics, psychology, and machine learning. Active inference is based on the expected free energy, which is mostly justified by the intuitive plausibility of its formulations, e.g., the risk plus ambiguity and information gain / pragmatic value formulations. This paper seek to formalize the problem of deriving these formulations from a single root expected free energy definition, i.e., the unification problem. Then, we study two settings, each one having its own root expected free energy definition. In the first setting, no justification for the expected free energy has been proposed to date, but all the formulations can be recovered from it. However, in this setting, the agent cannot have arbitrary prior preferences over observations. Indeed, only a limited class of prior preferences over observations is compatible with the likelihood mapping of the generative model. In the second setting, a justification of the root expected free energy definition is known, but this setting only accounts for two formulations, i.e., the risk over states plus ambiguity and entropy plus expected energy formulations.},
  doi={10.48550/arXiv.2402.14460},
  journal={arXiv.org}
}

@article{kouw2023informationseeking,
  title={Information-Seeking Polynomial NARX Model-Predictive Control Through Expected Free Energy Minimization},
  author={Wouter M. Kouw},
  year={2023},
  url={https://www.semanticscholar.org/paper/464b6f650b718fc20b100696b21e45b94eebdc70},
  abstract={We propose an adaptive model-predictive controller that balances driving the system to a goal state and seeking system observations that are informative with respect to the parameters of a nonlinear autoregressive exogenous model. The controller’s objective function is derived from an expected free energy functional and contains information-theoretic terms expressing uncertainty over model parameters and output predictions. Experiments illustrate how parameter uncertainty affects the control objective and evaluate the proposed controller for a pendulum swing-up task.},
  doi={10.1109/LCSYS.2023.3347190},
  journal={IEEE Control Systems Letters}
}

@article{vries2025expected,
  title={Expected Free Energy-based Planning as Variational Inference},
  author={Bert de Vries and Wouter W. L. Nuijten and T. V. D. Laar and Wouter M. Kouw and Sepideh Adamiat and T. Nisslbeck and Mykola Lukashchuk and Hoang M. H. Nguyen and Marco Hidalgo Araya and Raphael Tresor and Thijs Jenneskens and Ivana Nikoloska and Raaja Subramanian and Bart van Erp and Dmitry V. Bagaev and Albert Podusenko},
  year={2025},
  url={https://www.semanticscholar.org/paper/b4f8a1ae399fb801a251ca4f588b8dff259d0314},
  abstract={We address the problem of planning under uncertainty, where an agent must choose actions that not only achieve desired outcomes but also reduce uncertainty. Traditional methods often treat exploration and exploitation as separate objectives, lacking a unified inferential foundation. Active inference, grounded in the Free Energy Principle, provides such a foundation by minimizing Expected Free Energy (EFE), a cost function that combines utility with epistemic drives, such as ambiguity resolution and novelty seeking. However, the computational burden of EFE minimization had remained a significant obstacle to its scalability. In this paper, we show that EFE-based planning arises naturally from minimizing a variational free energy functional on a generative model augmented with preference and epistemic priors. This result reinforces theoretical consistency with the Free Energy Principle by casting planning under uncertainty itself as a form of variational inference. Our formulation yields policies that jointly support goal achievement and information gain, while incorporating a complexity term that accounts for bounded computational resources. This unifying framework connects and extends existing methods, enabling scalable, resource-aware implementations of active inference agents.},
  doi={10.48550/arXiv.2504.14898},
  journal={arXiv.org}
}

@article{nuijten2025message,
  title={A Message Passing Realization of Expected Free Energy Minimization},
  author={Wouter W. L. Nuijten and Mykola Lukashchuk and T. V. D. Laar and Bert de Vries},
  year={2025},
  url={https://www.semanticscholar.org/paper/8dd97f5dbe690988b7ebb8ed31e8aa36ae8a8910},
  abstract={We present a message passing approach to Expected Free Energy (EFE) minimization on factor graphs, based on the theory introduced in arXiv:2504.14898. By reformulating EFE minimization as Variational Free Energy minimization with epistemic priors, we transform a combinatorial search problem into a tractable inference problem solvable through standard variational techniques. Applying our message passing method to factorized state-space models enables efficient policy inference. We evaluate our method on environments with epistemic uncertainty: a stochastic gridworld and a partially observable Minigrid task. Agents using our approach consistently outperform conventional KL-control agents on these tasks, showing more robust planning and efficient exploration under uncertainty. In the stochastic gridworld environment, EFE-minimizing agents avoid risky paths, while in the partially observable minigrid setting, they conduct more systematic information-seeking. This approach bridges active inference theory with practical implementations, providing empirical evidence for the efficiency of epistemic priors in artificial agents.},
  doi={10.48550/arXiv.2508.02197},
  journal={arXiv.org}
}

@article{millidge2020whence,
  title={Whence the Expected Free Energy?},
  author={Beren Millidge and Alexander Tschantz and C. Buckley},
  year={2020},
  url={https://www.semanticscholar.org/paper/25ffa86f4dd81b3795d39f1a0caa957c39bc40b3},
  abstract={The expected free energy (EFE) is a central quantity in the theory of active inference. It is the quantity that all active inference agents are mandated to minimize through action, and its decomposition into extrinsic and intrinsic value terms is key to the balance of exploration and exploitation that active inference agents evince. Despite its importance, the mathematical origins of this quantity and its relation to the variational free energy (VFE) remain unclear. In this letter, we investigate the origins of the EFE in detail and show that it is not simply ”the free energy in the future.” We present a functional that we argue is the natural extension of the VFE but actively discourages exploratory behavior, thus demonstrating that exploration does not directly follow from free energy minimization into the future. We then develop a novel objective, the free energy of the expected future (FEEF), which possesses both the epistemic component of the EFE and an intuitive mathematical grounding as the divergence between predicted and desired futures.},
  doi={10.1162/neco_a_01354},
  journal={Neural Computation}
}

@article{koudahl2021epistemics,
  title={On Epistemics in Expected Free Energy for Linear Gaussian State Space Models},
  author={Magnus T. Koudahl and Wouter M. Kouw and B. Vries},
  year={2021},
  url={https://www.semanticscholar.org/paper/47fbc3ba2eeed3b5f02587b90708f912235067d3},
  abstract={Active Inference (AIF) is a framework that can be used both to describe information processing in naturally intelligent systems, such as the human brain, and to design synthetic intelligent systems (agents). In this paper we show that Expected Free Energy (EFE) minimisation, a core feature of the framework, does not lead to purposeful explorative behaviour in linear Gaussian dynamical systems. We provide a simple proof that, due to the specific construction used for the EFE, the terms responsible for the exploratory (epistemic) drive become constant in the case of linear Gaussian systems. This renders AIF equivalent to KL control. From a theoretical point of view this is an interesting result since it is generally assumed that EFE minimisation will always introduce an exploratory drive in AIF agents. While the full EFE objective does not lead to exploration in linear Gaussian dynamical systems, the principles of its construction can still be used to design objectives that include an epistemic drive. We provide an in-depth analysis of the mechanics behind the epistemic drive of AIF agents and show how to design objectives for linear Gaussian dynamical systems that do include an epistemic drive. Concretely, we show that focusing solely on epistemics and dispensing with goal-directed terms leads to a form of maximum entropy exploration that is heavily dependent on the type of control signals driving the system. Additive controls do not permit such exploration. From a practical point of view this is an important result since linear Gaussian dynamical systems with additive controls are an extensively used model class, encompassing for instance Linear Quadratic Gaussian controllers. On the other hand, linear Gaussian dynamical systems driven by multiplicative controls such as switching transition matrices do permit an exploratory drive.},
  doi={10.3390/e23121565},
  journal={Entropy}
}

@article{tschantz2020derivation,
  title={Derivation of expected free energy.},
  author={Alexander Tschantz and A. Seth and C. Buckley},
  year={2020},
  url={https://www.semanticscholar.org/paper/867c4724861eb09e267970d10bacd7034999193f},
  abstract={In this appendix, we formally describe the relationship between free energy and expected free energy. (PDF)},
  doi={10.1371/journal.pcbi.1007805.s002}
}

@article{connolly2018expected,
  title={Expected Free Energy Formalizes Conflict Underlying Defense in Freudian Psychoanalysis},
  author={P. Connolly},
  year={2018},
  url={https://www.semanticscholar.org/paper/0905d6d8b3713e5c9b9630f42d7af41daf29203e},
  abstract={Freud's core interest in the psyche was the dynamic unconscious: that part of the psyche which is unconscious due to conflict (Freud, 1923/1961). Over the course of his career, Freud variously described conflict as an opposition to the discharge of activation (Freud, 1950), opposition to psychic activity due to the release of unpleasure (Freud, 1990/1991), opposition between the primary principle and the reality principle (Freud, 1911/1963), structural conflict between id, ego, and superego (Freud, 1923/1961), and ambivalence (Freud, 1912/1963). Besides this difficulty of the shifting description of conflict, an underlying question remained the specific shared terrain in which emotions, thoughts, intentions or wishes could come into conflict with one another (the neuronal homolog of conflict), and most especially how they may exist as quantities in opposition within that terrain. Friston's free-energy principle (FEP henceforth) connected to the work of Friston (Friston et al., 2006; Friston, 2010) has provided the potential for a powerful unifying theory in psychology, neuroscience, and related fields that has been shown to have tremendous consilience with psychoanalytic concepts (Hopkins, 2012). Hopkins (2016), drawing on a formulation by Hobson et al. (2014), suggests that conflict may be potentially quantifiable as free energy from a FEP perspective. More recently, work by Friston et al. (2017a) has framed the selection of action as a gradient descent of expected free energy under different policies of action. From this perspective, the article describes how conflict could potentially be formalized as a situation where opposing action policies have similar expected free energy, for example between actions driven by competing basic prototype emotion systems as described by Panksepp (1998). This conflict state may be avoided in the future through updating the relative precision of a particular set of prior beliefs about outcomes: this has the result of tending to favor one of the policies of action over others in future instances, a situation analogous to defense. Through acting as a constraint on the further development of the person, the defensive operation can become entrenched, and resistant to alteration. The implications that this formalization has for psychoanalysis is explored.},
  doi={10.3389/fpsyg.2018.01264},
  journal={Frontiers in Psychology}
}

@article{lin2024regulating,
  title={Regulating the Gibbs Free Energy to Design Aqueous Battery‐Compatible Robust Host},
  author={Jing Lin and Yanyi Wang and Minfeng Chen and Jinlin Lu and Hongwei Mi and Jizhang Chen and Chuanxin He and Dingtao Ma and Peixin Zhang},
  year={2024},
  url={https://www.semanticscholar.org/paper/4fd7dfc58fe455abc9213440f7f1fc8007dbeb8b},
  abstract={Low‐cost, high‐voltage‐platform, and high‐capacity MnO2 is the most promising cathode candidate for developing high‐energy‐density aqueous zinc‐ion batteries. However, the Buckets effect of runaway phase transition and irreversible dissolution restricts the electrochemical performance of MnO2. To address this issue, this report presents a bottom‐up targeted assembly concept driven by Gibbs free energy for the design of a robust Ni‐MnO2‐xFx host via Ni2+ pre‐intercalation coupled with fluorine doping. The Gibbs free energy of the host is regulated by the coordination of interlayer reinforcement and interfacial defect repair, which prevents the “layer‐to‐spinel” transition and inhibits dissolution during long‐term cycling. As expected, this cathode provides superior H+/Zn2+ storage performance across a wide temperature range. A capacity of 180.4 mAh g−1 is retained after 1000 cycles at 2 A g−1, a high specific capacity of 293.9 mAh g−1 is retained after 250 cycles at 50 °C and 2 A g−1, and a capacity of 144.5 mAh g−1 is retained after 3000 cycles at 0 °C and 0.5 A g−1. This work provides new insights into the design of stable aqueous battery‐compatible hosts for aqueous zinc‐ion batteries as well as other battery chemistries.},
  doi={10.1002/aenm.202401275},
  journal={Advanced Energy Materials}
}

@article{pattisapu2024free,
  title={Free Energy in a Circumplex Model of Emotion},
  author={Candice Pattisapu and Tim Verbelen and R. J. Pitliya and Alex B. Kiefer and Mahault Albarracin},
  year={2024},
  url={https://www.semanticscholar.org/paper/e9158e6b6c83a4c01acfeb84b0824cee57dd554d},
  abstract={Previous active inference accounts of emotion translate fluctuations in free energy to a sense of emotion, mainly focusing on valence. However, in affective science, emotions are often represented as multi-dimensional. In this paper, we propose to adopt a Circumplex Model of emotion by mapping emotions into a two-dimensional spectrum of valence and arousal. We show how one can derive a valence and arousal signal from an agent's expected free energy, relating arousal to the entropy of posterior beliefs and valence to utility less expected utility. Under this formulation, we simulate artificial agents engaged in a search task. We show that the manipulation of priors and object presence results in commonsense variability in emotional states.},
  doi={10.48550/arXiv.2407.02474},
  journal={International Workshop on Affective Interactions}
}

@article{gusev2023active,
  title={Active Learning Guided Drug Design Lead Optimization Based on Relative Binding Free Energy Modeling},
  author={Filipp Gusev and Evgeny Gutkin and M. Kurnikova and O. Isayev},
  year={2023},
  url={https://www.semanticscholar.org/paper/e1c54e4b883e5f60ccf4b1993002d4540bf66931},
  abstract={In silico identification of potent protein inhibitors commonly requires prediction of a ligand binding free energy (BFE). Thermodynamics integration (TI) based on molecular dynamics (MD) simulations is a BFE calculation method capable of acquiring accurate BFE, but it is computationally expensive and time-consuming. In this work, we have developed an efficient automated workflow for identifying compounds with the lowest BFE among thousands of congeneric ligands, which requires only hundreds of TI calculations. Automated machine learning (AutoML) orchestrated by active learning (AL) in an AL-AutoML workflow allows unbiased and efficient search for a small set of best-performing molecules. We have applied this workflow to select inhibitors of the SARS-CoV-2 papain-like protease and were able to find 133 compounds with improved binding affinity, including 16 compounds with better than 100-fold binding affinity improvement. We obtained a hit rate that outperforms that expected of traditional expert medicinal chemist-guided campaigns. Thus, we demonstrate that the combination of AL and AutoML with free energy simulations provides at least 20× speedup relative to the naïve brute force approaches.},
  doi={10.1021/acs.jcim.2c01052},
  journal={Journal of Chemical Information and Modeling}
}

@article{scheid2008expected,
  title={On the Expected Free Energy of RNA Molecules},
  author={Anika Scheid and M. Nebel},
  year={2008},
  url={https://www.semanticscholar.org/paper/1a4b884ea0db879afa63973c253ab140444169a9}
}

@article{elfwing2016from,
  title={From free energy to expected energy: Improving energy-based value function approximation in reinforcement learning},
  author={Stefan Elfwing and E. Uchibe and K. Doya},
  year={2016},
  url={https://www.semanticscholar.org/paper/db8ef16d8eff463836787f96ff093cabbb30f17c},
  doi={10.1016/j.neunet.2016.07.013},
  journal={Neural Networks}
}

@article{maele2021active,
  title={Active Vision for Robot Manipulators Using the Free Energy Principle},
  author={Toon Van de Maele and Tim Verbelen and Ozan Çatal and C. D. Boom and B. Dhoedt},
  year={2021},
  url={https://www.semanticscholar.org/paper/907c709344583b9db16c20875dc5dd30ab2b2a38},
  abstract={Occlusions, restricted field of view and limited resolution all constrain a robot's ability to sense its environment from a single observation. In these cases, the robot first needs to actively query multiple observations and accumulate information before it can complete a task. In this paper, we cast this problem of active vision as active inference, which states that an intelligent agent maintains a generative model of its environment and acts in order to minimize its surprise, or expected free energy according to this model. We apply this to an object-reaching task for a 7-DOF robotic manipulator with an in-hand camera to scan the workspace. A novel generative model using deep neural networks is proposed that is able to fuse multiple views into an abstract representation and is trained from data by minimizing variational free energy. We validate our approach experimentally for a reaching task in simulation in which a robotic agent starts without any knowledge about its workspace. Each step, the next view pose is chosen by evaluating the expected free energy. We find that by minimizing the expected free energy, exploratory behavior emerges when the target object to reach is not in view, and the end effector is moved to the correct reach position once the target is located. Similar to an owl scavenging for prey, the robot naturally prefers higher ground for exploring, approaching its target once located.},
  doi={10.3389/fnbot.2021.642780},
  journal={Frontiers in Neurorobotics}
}

@article{mourrat2020free,
  title={Free energy upper bound for mean-field vector spin glasses},
  author={J. Mourrat},
  year={2020},
  url={https://www.semanticscholar.org/paper/77d3166d6faddf8741ccb77b665368546b271c44},
  abstract={We consider vector spin glasses whose energy function is a Gaussian random field with covariance given in terms of the matrix of scalar products. For essentially any model in this class, we give an upper bound for the limit free energy, which is expected to be sharp. The bound is expressed in terms of an infinite-dimensional Hamilton-Jacobi equation.},
  doi={10.1214/22-aihp1292},
  journal={Annales De L Institut Henri Poincare-probabilites Et Statistiques}
}

@article{tsai2020validation,
  title={Validation of Free Energy Methods in AMBER},
  author={H. Tsai and Yujun Tao and Tai-Sung Lee and K. Merz and D. York},
  year={2020},
  url={https://www.semanticscholar.org/paper/893b4d820a1ade0ef153f8a77424edcb954b74f7},
  abstract={Herein we provide high precision validation tests of the latest GPU-accelerated free energy code in AMBER. We demonstrate that consistent free energy results are obtained in both the gas phase and in solution. We first show, in the context of thermodynamic integration (TI), that results are invariant with respect to "split" (e.g., stepwise decharge-vdW-recharge) versus "unified" protocols. This brought to light a subtle inconsistency in previous versions of AMBER that was traced to the improper treatment of 1-4 vdW and electrostatic interactions involving atoms across the softcore boundary. We illustrate that, under the assumption that the ensembles produced by different legs of the alchemical transformation between molecules "A" and "B" in the gas phase and aqueous phase are very small, the inconsistency on the relative hydration free energy ΔΔGhydr[A → B] = ΔG(aq)[A → B] - △G(gas)[A → B] is minimal. However, for general cases where the ensembles are shown to be substantially different, as expected in ligand-protein binding applications, these errors can be large. Finally, we demonstrate that results for relative hydration free energy simulations are independent of TI or multistate Bennett's acceptance ratio (MBAR) analysis, invariant to the specific choice of the softcore region, and agree with results derived from absolute hydration free energy values.},
  doi={10.1021/acs.jcim.0c00285},
  journal={Journal of Chemical Information and Modeling}
}

@article{solms2019hard,
  title={The Hard Problem of Consciousness and the Free Energy Principle},
  author={M. Solms},
  year={2019},
  url={https://www.semanticscholar.org/paper/b017d5ba90e05de3fd0567b1c47ff7ec63a5580f},
  abstract={This article applies the free energy principle to the hard problem of consciousness. After clarifying some philosophical issues concerning functionalism, it identifies the elemental form of consciousness as affect and locates its physiological mechanism (an extended form of homeostasis) in the upper brainstem. This mechanism is then formalized in terms of free energy minimization (in unpredicted contexts) where decreases and increases in expected uncertainty are felt as pleasure and unpleasure, respectively. Emphasis is placed on the reasons why such existential imperatives feel like something to and for an organism.},
  doi={10.3389/fpsyg.2018.02714},
  journal={Frontiers in Psychology}
}

@article{parr2018generalised,
  title={Generalised free energy and active inference},
  author={Thomas Parr and Karl J. Friston},
  year={2018},
  url={https://www.semanticscholar.org/paper/e09f6b0ddee0f7cfd1a7e2d56899f2d8d8774e77},
  abstract={Active inference is an approach to understanding behaviour that rests upon the idea that the brain uses an internal generative model to predict incoming sensory data. The fit between this model and data may be improved in two ways. The brain could optimise probabilistic beliefs about the variables in the generative model (i.e. perceptual inference). Alternatively, by acting on the world, it could change the sensory data, such that they are more consistent with the model. This implies a common objective function (variational free energy) for action and perception that scores the fit between an internal model and the world. We compare two free energy functionals for active inference in the framework of Markov decision processes. One of these is a functional of beliefs (i.e. probability distributions) about states and policies, but a function of observations, while the second is a functional of beliefs about all three. In the former (expected free energy), prior beliefs about outcomes are not part of the generative model (because they are absorbed into the prior over policies). Conversely, in the second (generalised free energy), priors over outcomes become an explicit component of the generative model. When using the free energy function, which is blind to future observations, we equip the generative model with a prior over policies that ensure preferred (i.e. priors over) outcomes are realised. In other words, if we expect to encounter a particular kind of outcome, this lends plausibility to those policies for which this outcome is a consequence. In addition, this formulation ensures that selected policies minimise uncertainty about future outcomes by minimising the free energy expected in the future. When using the free energy functional—that effectively treats future observations as hidden states—we show that policies are inferred or selected that realise prior preferences by minimising the free energy of future expectations. Interestingly, the form of posterior beliefs about policies (and associated belief updating) turns out to be identical under both formulations, but the quantities used to compute them are not.},
  doi={10.1007/s00422-019-00805-w},
  journal={Biological cybernetics}
}

@article{karasiev2019status,
  title={Status of free-energy representations for the homogeneous electron gas},
  author={V. Karasiev and S. Trickey and J. Dufty},
  year={2019},
  url={https://www.semanticscholar.org/paper/1995fb57ee7018ee14b4cab7ea160bd0ddcac988},
  abstract={Renewed interest in the homogeneous electron gas (HEG) has been stimulated by recent accurate simulations of it over a wide range of densities and temperatures. Those data, combined with known theoretical limits, have led to analytical representations of the free energy. Such a representation is, at least in principle, the complete HEG equation of state. The initial objective here is to establish that the two best representations [“corrKSDT,” Phys. Rev. Lett. 112, 076403 (2014), Phys. Rev. Lett. 120, 076401 (2018), and “GDB” Phys. Rev. Lett. 119, 135001 (2017)] of the simulation data and constraints are effectively the same in both functional form and accuracy of representation. The second objective is to disclose and delineate a significant difficulty. Despite their expected accuracy for the free energy, the underlying functional form is not adequate for derived thermodynamic properties. As an example, the specific heats obtained from the representations exhibit anomalies suggesting the need first for additional simulation data in critical regimes, then for refined fitting functions. The existing representations are, however, almost certainly adequate for applications based on the free energy alone (e.g., density-functional theory for warm dense matter). The third objective is to show that, despite their inability to provide a complete thermodynamic description of the HEG, the best analytical representations do provide a fully adequate exchange-correlation local density approximation for free-energy density-functional calculations.},
  doi={10.1103/PHYSREVB.99.195134},
  journal={Physical review B}
}

@article{baskin2019ion,
  title={"Ion Solvation Spectra": Free Energy Analysis of Solvation Structures of Multivalent Cations in Aprotic Solvents.},
  author={Artem Baskin and D. Prendergast},
  year={2019},
  url={https://www.semanticscholar.org/paper/3c832bf11d28c8a9e3c5abb5108e896ffabaa345},
  abstract={Using advanced molecular dynamics free energy sampling techniques - both classical and ab initio - we analyze the solvation structures of multivalent cations in aprotic solvents. In contrast to previous studies of mono- and bivalent ions in organic solvents, mainly performed using hybrid cluster-continuum quantum chemistry calculations that rely on the assumption of uniqueness of ion solvation free energies, here we find that monoatomic bivalent cations may have multiple well-defined minima, as previously reported only for water, or plateaus of free energy with respect to the ion-solvent coordination. These observations are generalized in the concept of the ``ion solvation spectrum`` to highlight the rich phenomenology related to ion solvation as opposed to the normally expected free energy profiles with a single coordination minimum. Specifically, we show that a single chemical species may exhibit a multiplicity of distinctly different electrochemical properties. Using one- and two-dimensional projections of the free energy landscape, we analyze the stability of ion solvation structures and reveal minimum free energy pathways for ion (de-)solvation with low-dimensional approximations to associated kinetic barriers. Unexpectedly, we show that in some cases the process of opening the first ion solvation shell, by removing a solvent molecule, may actually drive the ion into a free-energy basin with a higher coordination number. Our study highlights some deficiencies of conventional methodologies for studying ion solvation as a path to determine redox potentials and provides experimentally testable predictions.},
  doi={10.1021/acs.jpclett.9b01569},
  journal={Journal of Physical Chemistry Letters}
}

@article{guo2023design,
  title={Design strategies of high-performance lead-free electroceramics for energy storage applications},
  author={Biao Guo and Fei Jin and Li Li and Zizhao Pan and Xin-Wei Xu and Hong Wang},
  year={2023},
  url={https://www.semanticscholar.org/paper/dd32c908d5cb7a01c5f32c279713b04d2f52d466},
  doi={10.1007/s12598-023-02452-4},
  journal={Rare Metals}
}

@article{fan2018tap,
  title={TAP free energy, spin glasses and variational inference},
  author={Z. Fan and Song Mei and A. Montanari},
  year={2018},
  url={https://www.semanticscholar.org/paper/3815209a771d1c2f9dc42624cc6d4fd7ecaed1f0},
  abstract={We consider the Sherrington-Kirkpatrick model of spin glasses with ferromagnetically biased couplings. For a specific choice of the couplings mean, the resulting Gibbs measure is equivalent to the Bayesian posterior for a high-dimensional estimation problem known as `$Z_2$ synchronization'. Statistical physics suggests to compute the expectation with respect to this Gibbs measure (the posterior mean in the synchronization problem), by minimizing the so-called Thouless-Anderson-Palmer (TAP) free energy, instead of the mean field (MF) free energy. We prove that this identification is correct, provided the ferromagnetic bias is larger than a constant (i.e. the noise level is small enough in synchronization). Namely, we prove that the scaled $\ell_2$ distance between any low energy local minimizers of the TAP free energy and the mean of the Gibbs measure vanishes in the large size limit. Our proof technique is based on upper bounding the expected number of critical points of the TAP free energy using the Kac-Rice formula.},
  doi={10.1214/20-AOP1443},
  journal={Annals of Probability}
}

@article{abel2017critical,
  title={A Critical Review of Validation, Blind Testing, and Real- World Use of Alchemical Protein-Ligand Binding Free Energy Calculations.},
  author={Robert Abel and Lingle Wang and D. Mobley and R. Friesner},
  year={2017},
  url={https://www.semanticscholar.org/paper/c60e97986c0e78a970ea2ff63ebd9f5cbacb0fdc},
  abstract={Protein-ligand binding is among the most fundamental phenomena underlying all molecular biology, and a greater ability to more accurately and robustly predict the binding free energy of a small molecule ligand for its cognate protein is expected to have vast consequences for improving the efficiency of pharmaceutical drug discovery. We briefly reviewed a number of scientific and technical advances that have enabled alchemical free energy calculations to recently emerge as a preferred approach, and critically considered proper validation and effective use of these techniques. In particular, we characterized a selection bias effect which may be important in prospective free energy calculations, and introduced a strategy to improve the accuracy of the free energy predictions.},
  doi={10.2174/1568026617666170414142131},
  journal={Current Topics in Medicinal Chemistry}
}

@article{shi2022wireless,
  title={Wireless Energy Transfer in RIS-Aided Cell-Free Massive MIMO Systems: Opportunities and Challenges},
  author={En-dong Shi and Jiayi Zhang and Shuaifei Chen and Jiakang Zheng and Yan Zhang and Derrick Wing Kwan Ng and Bo Ai},
  year={2022},
  url={https://www.semanticscholar.org/paper/59f4fc56b2d45318eab2feb13628bbcb64bfe5b9},
  abstract={In future 6G mobile networks, the Internet-of-Everything (IoE) is expected to provide extremely massive connectivity for small battery-powered devices. Indeed, massive devices with limited energy storage capacity impose persistent energy demand hindering the lifetime of communication networks. As a remedy, wireless energy transfer (WET) is a key technology to address these critical energy supply issues. On the other hand, cell-free (CF) massive multiple-input multiple-output (MIMO) systems offer an efficient network architecture to realize the rollout of IoE. In this article, we first propose the paradigm of reconfigurable intelligent surface (RIS)-aided CF massive MIMO systems for WET, including its potential application scenarios and system architecture. The four-stage transmission procedure is discussed and analyzed to illustrate the practicality of the architecture. Then we put forward and analyze the hardware design of RIS. In particular, we discuss the three corresponding operating modes and the amalgamation of WET technology and RIS-aided CF massive MIMO. Representative simulation results are given to confirm the superior performance achieved by our proposed schemes. Also, we investigate the optimal location of deploying multiple RISs to achieve the best system performance. Finally, several important research directions of RIS-aided CF massive MIMO systems with WET are presented to inspire further potential investigation.},
  doi={10.1109/MCOM.001.2100671},
  journal={IEEE Communications Magazine}
}

@article{boom2023changing,
  title={Changing Data Sources in the Age of Machine Learning for Official Statistics},
  author={Cedric De Boom and Michael Reusens},
  year={2023},
  url={http://arxiv.org/abs/2306.04338v1},
  abstract={Data science has become increasingly essential for the production of official statistics, as it enables the automated collection, processing, and analysis of large amounts of data. With such data science practices in place, it enables more timely, more insightful and more flexible reporting. However, the quality and integrity of data-science-driven statistics rely on the accuracy and reliability of the data sources and the machine learning techniques that support them. In particular, changes in data sources are inevitable to occur and pose significant risks that are crucial to address in the context of machine learning for official statistics.   This paper gives an overview of the main risks, liabilities, and uncertainties associated with changing data sources in the context of machine learning for official statistics. We provide a checklist of the most prevalent origins and causes of changing data sources; not only on a technical level but also regarding ownership, ethics, regulation, and public perception. Next, we highlight the repercussions of changing data sources on statistical reporting. These include technical effects such as concept drift, bias, availability, validity, accuracy and completeness, but also the neutrality and potential discontinuation of the statistical offering. We offer a few important precautionary measures, such as enhancing robustness in both data sourcing and statistical techniques, and thorough monitoring. In doing so, machine learning-based official statistics can maintain integrity, reliability, consistency, and relevance in policy-making, decision-making, and public discourse.},
  journal={arXiv}
}

@article{walsh2020dome,
  title={DOME: Recommendations for supervised machine learning validation in biology},
  author={Ian Walsh and Dmytro Fishman and Dario Garcia-Gasulla and Tiina Titma and Gianluca Pollastri and The ELIXIR Machine Learning focus group and Jen Harrow and Fotis E. Psomopoulos and Silvio C. E. Tosatto},
  year={2020},
  url={http://arxiv.org/abs/2006.16189v4},
  abstract={Modern biology frequently relies on machine learning to provide predictions and improve decision processes. There have been recent calls for more scrutiny on machine learning performance and possible limitations. Here we present a set of community-wide recommendations aiming to help establish standards of supervised machine learning validation in biology. Adopting a structured methods description for machine learning based on data, optimization, model, evaluation (DOME) will aim to help both reviewers and readers to better understand and assess the performance and limitations of a method or outcome. The recommendations are formulated as questions to anyone wishing to pursue implementation of a machine learning algorithm. Answers to these questions can be easily included in the supplementary material of published papers.},
  journal={arXiv}
}

@article{mohr2022learning,
  title={Learning Curves for Decision Making in Supervised Machine Learning: A Survey},
  author={Felix Mohr and Jan N. van Rijn},
  year={2022},
  url={http://arxiv.org/abs/2201.12150v2},
  abstract={Learning curves are a concept from social sciences that has been adopted in the context of machine learning to assess the performance of a learning algorithm with respect to a certain resource, e.g., the number of training examples or the number of training iterations. Learning curves have important applications in several machine learning contexts, most notably in data acquisition, early stopping of model training, and model selection. For instance, learning curves can be used to model the performance of the combination of an algorithm and its hyperparameter configuration, providing insights into their potential suitability at an early stage and often expediting the algorithm selection process. Various learning curve models have been proposed to use learning curves for decision making. Some of these models answer the binary decision question of whether a given algorithm at a certain budget will outperform a certain reference performance, whereas more complex models predict the entire learning curve of an algorithm. We contribute a framework that categorises learning curve approaches using three criteria: the decision-making situation they address, the intrinsic learning curve question they answer and the type of resources they use. We survey papers from the literature and classify them into this framework.},
  doi={10.1007/s10994-024-06619-7},
  journal={arXiv}
}

@article{cacciarelli2023active,
  title={Active learning for data streams: a survey},
  author={Davide Cacciarelli and Murat Kulahci},
  year={2023},
  url={http://arxiv.org/abs/2302.08893v4},
  abstract={Online active learning is a paradigm in machine learning that aims to select the most informative data points to label from a data stream. The problem of minimizing the cost associated with collecting labeled observations has gained a lot of attention in recent years, particularly in real-world applications where data is only available in an unlabeled form. Annotating each observation can be time-consuming and costly, making it difficult to obtain large amounts of labeled data. To overcome this issue, many active learning strategies have been proposed in the last decades, aiming to select the most informative observations for labeling in order to improve the performance of machine learning models. These approaches can be broadly divided into two categories: static pool-based and stream-based active learning. Pool-based active learning involves selecting a subset of observations from a closed pool of unlabeled data, and it has been the focus of many surveys and literature reviews. However, the growing availability of data streams has led to an increase in the number of approaches that focus on online active learning, which involves continuously selecting and labeling observations as they arrive in a stream. This work aims to provide an overview of the most recently proposed approaches for selecting the most informative observations from data streams in real time. We review the various techniques that have been proposed and discuss their strengths and limitations, as well as the challenges and opportunities that exist in this area of research.},
  doi={10.1007/s10994-023-06454-2},
  journal={arXiv}
}

@article{niroomand2023physicsinspired,
  title={Physics-Inspired Interpretability Of Machine Learning Models},
  author={Maximilian P Niroomand and David J Wales},
  year={2023},
  url={http://arxiv.org/abs/2304.02381v2},
  abstract={The ability to explain decisions made by machine learning models remains one of the most significant hurdles towards widespread adoption of AI in highly sensitive areas such as medicine, cybersecurity or autonomous driving. Great interest exists in understanding which features of the input data prompt model decision making. In this contribution, we propose a novel approach to identify relevant features of the input data, inspired by methods from the energy landscapes field, developed in the physical sciences. By identifying conserved weights within groups of minima of the loss landscapes, we can identify the drivers of model decision making. Analogues to this idea exist in the molecular sciences, where coordinate invariants or order parameters are employed to identify critical features of a molecule. However, no such approach exists for machine learning loss landscapes. We will demonstrate the applicability of energy landscape methods to machine learning models and give examples, both synthetic and from the real world, for how these methods can help to make models more interpretable.},
  journal={arXiv}
}

@article{guerramanzanares2023privacypreserving,
  title={Privacy-preserving machine learning for healthcare: open challenges and future perspectives},
  author={Alejandro Guerra-Manzanares and L. Julian Lechuga Lopez and Michail Maniatakos and Farah E. Shamout},
  year={2023},
  url={http://arxiv.org/abs/2303.15563v1},
  abstract={Machine Learning (ML) has recently shown tremendous success in modeling various healthcare prediction tasks, ranging from disease diagnosis and prognosis to patient treatment. Due to the sensitive nature of medical data, privacy must be considered along the entire ML pipeline, from model training to inference. In this paper, we conduct a review of recent literature concerning Privacy-Preserving Machine Learning (PPML) for healthcare. We primarily focus on privacy-preserving training and inference-as-a-service, and perform a comprehensive review of existing trends, identify challenges, and discuss opportunities for future research directions. The aim of this review is to guide the development of private and efficient ML models in healthcare, with the prospects of translating research efforts into real-world settings.},
  doi={10.1007/978-3-031-39539-0_3},
  journal={arXiv}
}

@article{khan2019benchmark,
  title={A Benchmark Study of Machine Learning Models for Online Fake News Detection},
  author={Junaed Younus Khan and Md. Tawkat Islam Khondaker and Sadia Afroz and Gias Uddin and Anindya Iqbal},
  year={2019},
  url={http://arxiv.org/abs/1905.04749v2},
  abstract={The proliferation of fake news and its propagation on social media has become a major concern due to its ability to create devastating impacts. Different machine learning approaches have been suggested to detect fake news. However, most of those focused on a specific type of news (such as political) which leads us to the question of dataset-bias of the models used. In this research, we conducted a benchmark study to assess the performance of different applicable machine learning approaches on three different datasets where we accumulated the largest and most diversified one. We explored a number of advanced pre-trained language models for fake news detection along with the traditional and deep learning ones and compared their performances from different aspects for the first time to the best of our knowledge. We find that BERT and similar pre-trained models perform the best for fake news detection, especially with very small dataset. Hence, these models are significantly better option for languages with limited electronic contents, i.e., training data. We also carried out several analysis based on the models' performance, article's topic, article's length, and discussed different lessons learned from them. We believe that this benchmark study will help the research community to explore further and news sites/blogs to select the most appropriate fake news detection method.},
  doi={10.1016/j.mlwa.2021.100032},
  journal={arXiv}
}

@article{moerland2017emotion,
  title={Emotion in Reinforcement Learning Agents and Robots: A Survey},
  author={Thomas M. Moerland and Joost Broekens and Catholijn M. Jonker},
  year={2017},
  url={http://arxiv.org/abs/1705.05172v1},
  abstract={This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on agent/robot emotions, and mostly ignores human user emotions. Emotions are recognized as functional in decision-making by influencing motivation and action selection. Therefore, computational emotion models are usually grounded in the agent's decision making architecture, of which RL is an important subclass. Studying emotions in RL-based agents is useful for three research fields. For machine learning (ML) researchers, emotion models may improve learning efficiency. For the interactive ML and human-robot interaction (HRI) community, emotions can communicate state and enhance user investment. Lastly, it allows affective modelling (AM) researchers to investigate their emotion theories in a successful AI agent class. This survey provides background on emotion theory and RL. It systematically addresses 1) from what underlying dimensions (e.g., homeostasis, appraisal) emotions can be derived and how these can be modelled in RL-agents, 2) what types of emotions have been derived from these dimensions, and 3) how these emotions may either influence the learning efficiency of the agent or be useful as social signals. We also systematically compare evaluation criteria, and draw connections to important RL sub-domains like (intrinsic) motivation and model-based RL. In short, this survey provides both a practical overview for engineers wanting to implement emotions in their RL agents, and identifies challenges and directions for future emotion-RL research.},
  doi={10.1007/s10994-017-5666-0},
  journal={arXiv}
}

@article{granziol2019meme,
  title={MEMe: An Accurate Maximum Entropy Method for Efficient Approximations in Large-Scale Machine Learning},
  author={Diego Granziol and Binxin Ru and Stefan Zohren and Xiaowen Doing and Michael Osborne and Stephen Roberts},
  year={2019},
  url={http://arxiv.org/abs/1906.01101v1},
  abstract={Efficient approximation lies at the heart of large-scale machine learning problems. In this paper, we propose a novel, robust maximum entropy algorithm, which is capable of dealing with hundreds of moments and allows for computationally efficient approximations. We showcase the usefulness of the proposed method, its equivalence to constrained Bayesian variational inference and demonstrate its superiority over existing approaches in two applications, namely, fast log determinant estimation and information-theoretic Bayesian optimisation.},
  doi={10.3390/e21060551},
  journal={arXiv}
}

@article{cherednichenko2024generalizing,
  title={Generalizing Machine Learning Evaluation through the Integration of Shannon Entropy and Rough Set Theory},
  author={Olga Cherednichenko and Dmytro Chernyshov and Dmytro Sytnikov and Polina Sytnikova},
  year={2024},
  url={http://arxiv.org/abs/2404.12511v1},
  abstract={This research paper delves into the innovative integration of Shannon entropy and rough set theory, presenting a novel approach to generalize the evaluation approach in machine learning. The conventional application of entropy, primarily focused on information uncertainty, is extended through its combination with rough set theory to offer a deeper insight into data's intrinsic structure and the interpretability of machine learning models. We introduce a comprehensive framework that synergizes the granularity of rough set theory with the uncertainty quantification of Shannon entropy, applied across a spectrum of machine learning algorithms. Our methodology is rigorously tested on various datasets, showcasing its capability to not only assess predictive performance but also to illuminate the underlying data complexity and model robustness. The results underscore the utility of this integrated approach in enhancing the evaluation landscape of machine learning, offering a multi-faceted perspective that balances accuracy with a profound understanding of data attributes and model dynamics. This paper contributes a groundbreaking perspective to machine learning evaluation, proposing a method that encapsulates a holistic view of model performance, thereby facilitating more informed decision-making in model selection and application.},
  journal={arXiv}
}

@article{martinturrero2024alerttransformer,
  title={ALERT-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data},
  author={Carmen Martin-Turrero and Maxence Bouvier and Manuel Breitenstein and Pietro Zanuttigh and Vincent Parret},
  year={2024},
  url={http://arxiv.org/abs/2402.01393v3},
  abstract={We seek to enable classic processing of continuous ultra-sparse spatiotemporal data generated by event-based sensors with dense machine learning models. We propose a novel hybrid pipeline composed of asynchronous sensing and synchronous processing that combines several ideas: (1) an embedding based on PointNet models -- the ALERT module -- that can continuously integrate new and dismiss old events thanks to a leakage mechanism, (2) a flexible readout of the embedded data that allows to feed any downstream model with always up-to-date features at any sampling rate, (3) exploiting the input sparsity in a patch-based approach inspired by Vision Transformer to optimize the efficiency of the method. These embeddings are then processed by a transformer model trained for object and gesture recognition. Using this approach, we achieve performances at the state-of-the-art with a lower latency than competitors. We also demonstrate that our asynchronous model can operate at any desired sampling rate.},
  journal={arXiv}
}

@article{chehreghani2018learning,
  title={Learning Representations from Dendrograms},
  author={Morteza Haghir Chehreghani and Mostafa Haghir Chehreghani},
  year={2018},
  url={http://arxiv.org/abs/1812.09225v4},
  abstract={We propose unsupervised representation learning and feature extraction from dendrograms. The commonly used Minimax distance measures correspond to building a dendrogram with single linkage criterion, with defining specific forms of a level function and a distance function over that. Therefore, we extend this method to arbitrary dendrograms. We develop a generalized framework wherein different distance measures and representations can be inferred from different types of dendrograms, level functions and distance functions. Via an appropriate embedding, we compute a vector-based representation of the inferred distances, in order to enable many numerical machine learning algorithms to employ such distances. Then, to address the model selection problem, we study the aggregation of different dendrogram-based distances respectively in solution space and in representation space in the spirit of deep representations. In the first approach, for example for the clustering problem, we build a graph with positive and negative edge weights according to the consistency of the clustering labels of different objects among different solutions, in the context of ensemble methods. Then, we use an efficient variant of correlation clustering to produce the final clusters. In the second approach, we investigate the combination of different distances and features sequentially in the spirit of multi-layered architectures to obtain the final features. Finally, we demonstrate the effectiveness of our approach via several numerical studies.},
  doi={10.1007/s10994-020-05895-3},
  journal={arXiv}
}

@article{batarseh2021public,
  title={Public Policymaking for International Agricultural Trade using Association Rules and Ensemble Machine Learning},
  author={Feras A. Batarseh and Munisamy Gopinath and Anderson Monken and Zhengrong Gu},
  year={2021},
  url={http://arxiv.org/abs/2111.07508v1},
  abstract={International economics has a long history of improving our understanding of factors causing trade, and the consequences of free flow of goods and services across countries. The recent shocks to the free trade regime, especially trade disputes among major economies, as well as black swan events, such as trade wars and pandemics, raise the need for improved predictions to inform policy decisions. AI methods are allowing economists to solve such prediction problems in new ways. In this manuscript, we present novel methods that predict and associate food and agricultural commodities traded internationally. Association Rules (AR) analysis has been deployed successfully for economic scenarios at the consumer or store level, such as for market basket analysis. In our work however, we present analysis of imports and exports associations and their effects on commodity trade flows. Moreover, Ensemble Machine Learning methods are developed to provide improved agricultural trade predictions, outlier events' implications, and quantitative pointers to policy makers.},
  doi={10.1016/j.mlwa.2021.100046},
  journal={arXiv}
}

@article{chehreghani2019unsupervised,
  title={Unsupervised Representation Learning with Minimax Distance Measures},
  author={Morteza Haghir Chehreghani},
  year={2019},
  url={http://arxiv.org/abs/1904.13223v3},
  abstract={We investigate the use of Minimax distances to extract in a nonparametric way the features that capture the unknown underlying patterns and structures in the data. We develop a general-purpose and computationally efficient framework to employ Minimax distances with many machine learning methods that perform on numerical data. We study both computing the pairwise Minimax distances for all pairs of objects and as well as computing the Minimax distances of all the objects to/from a fixed (test) object. We first efficiently compute the pairwise Minimax distances between the objects, using the equivalence of Minimax distances over a graph and over a minimum spanning tree constructed on that. Then, we perform an embedding of the pairwise Minimax distances into a new vector space, such that their squared Euclidean distances in the new space equal to the pairwise Minimax distances in the original space. We also study the case of having multiple pairwise Minimax matrices, instead of a single one. Thereby, we propose an embedding via first summing up the centered matrices and then performing an eigenvalue decomposition to obtain the relevant features. In the following, we study computing Minimax distances from a fixed (test) object which can be used for instance in K-nearest neighbor search. Similar to the case of all-pair pairwise Minimax distances, we develop an efficient and general-purpose algorithm that is applicable with any arbitrary base distance measure. Moreover, we investigate in detail the edges selected by the Minimax distances and thereby explore the ability of Minimax distances in detecting outlier objects. Finally, for each setting, we perform several experiments to demonstrate the effectiveness of our framework.},
  doi={10.1007/s10994-020-05886-4},
  journal={arXiv}
}

@article{drori2019automatic,
  title={Automatic Machine Learning by Pipeline Synthesis using Model-Based Reinforcement Learning and a Grammar},
  author={Iddo Drori and Yamuna Krishnamurthy and Raoni Lourenco and Remi Rampin and Kyunghyun Cho and Claudio Silva and Juliana Freire},
  year={2019},
  url={http://arxiv.org/abs/1905.10345v1},
  abstract={Automatic machine learning is an important problem in the forefront of machine learning. The strongest AutoML systems are based on neural networks, evolutionary algorithms, and Bayesian optimization. Recently AlphaD3M reached state-of-the-art results with an order of magnitude speedup using reinforcement learning with self-play. In this work we extend AlphaD3M by using a pipeline grammar and a pre-trained model which generalizes from many different datasets and similar tasks. Our results demonstrate improved performance compared with our earlier work and existing methods on AutoML benchmark datasets for classification and regression tasks. In the spirit of reproducible research we make our data, models, and code publicly available.},
  journal={arXiv}
}

@article{feldman2017beyond,
  title={Beyond Volume: The Impact of Complex Healthcare Data on the Machine Learning Pipeline},
  author={Keith Feldman and Louis Faust and Xian Wu and Chao Huang and Nitesh V. Chawla},
  year={2017},
  url={http://arxiv.org/abs/1706.01513v2},
  abstract={From medical charts to national census, healthcare has traditionally operated under a paper-based paradigm. However, the past decade has marked a long and arduous transformation bringing healthcare into the digital age. Ranging from electronic health records, to digitized imaging and laboratory reports, to public health datasets, today, healthcare now generates an incredible amount of digital information. Such a wealth of data presents an exciting opportunity for integrated machine learning solutions to address problems across multiple facets of healthcare practice and administration. Unfortunately, the ability to derive accurate and informative insights requires more than the ability to execute machine learning models. Rather, a deeper understanding of the data on which the models are run is imperative for their success. While a significant effort has been undertaken to develop models able to process the volume of data obtained during the analysis of millions of digitalized patient records, it is important to remember that volume represents only one aspect of the data. In fact, drawing on data from an increasingly diverse set of sources, healthcare data presents an incredibly complex set of attributes that must be accounted for throughout the machine learning pipeline. This chapter focuses on highlighting such challenges, and is broken down into three distinct components, each representing a phase of the pipeline. We begin with attributes of the data accounted for during preprocessing, then move to considerations during model building, and end with challenges to the interpretation of model output. For each component, we present a discussion around data as it relates to the healthcare domain and offer insight into the challenges each may impose on the efficiency of machine learning techniques.},
  doi={10.1007/978-3-319-69775-8_9},
  journal={arXiv}
}

@article{ai2022explanatory,
  title={Explanatory machine learning for sequential human teaching},
  author={Lun Ai and Johannes Langer and Stephen H. Muggleton and Ute Schmid},
  year={2022},
  url={http://arxiv.org/abs/2205.10250v2},
  abstract={The topic of comprehensibility of machine-learned theories has recently drawn increasing attention. Inductive Logic Programming (ILP) uses logic programming to derive logic theories from small data based on abduction and induction techniques. Learned theories are represented in the form of rules as declarative descriptions of obtained knowledge. In earlier work, the authors provided the first evidence of a measurable increase in human comprehension based on machine-learned logic rules for simple classification tasks. In a later study, it was found that the presentation of machine-learned explanations to humans can produce both beneficial and harmful effects in the context of game learning. We continue our investigation of comprehensibility by examining the effects of the ordering of concept presentations on human comprehension. In this work, we examine the explanatory effects of curriculum order and the presence of machine-learned explanations for sequential problem-solving. We show that 1) there exist tasks A and B such that learning A before B has a better human comprehension with respect to learning B before A and 2) there exist tasks A and B such that the presence of explanations when learning A contributes to improved human comprehension when subsequently learning B. We propose a framework for the effects of sequential teaching on comprehension based on an existing definition of comprehensibility and provide evidence for support from data collected in human trials. Empirical results show that sequential teaching of concepts with increasing complexity a) has a beneficial effect on human comprehension and b) leads to human re-discovery of divide-and-conquer problem-solving strategies, and c) studying machine-learned explanations allows adaptations of human problem-solving strategy with better performance.},
  doi={10.1007/s10994-023-06351-8},
  journal={arXiv}
}

@article{publio2018mlschema,
  title={ML-Schema: Exposing the Semantics of Machine Learning with Schemas and Ontologies},
  author={Gustavo Correa Publio and Diego Esteves and Agnieszka Ławrynowicz and Panče Panov and Larisa Soldatova and Tommaso Soru and Joaquin Vanschoren and Hamid Zafar},
  year={2018},
  url={http://arxiv.org/abs/1807.05351v1},
  abstract={The ML-Schema, proposed by the W3C Machine Learning Schema Community Group, is a top-level ontology that provides a set of classes, properties, and restrictions for representing and interchanging information on machine learning algorithms, datasets, and experiments. It can be easily extended and specialized and it is also mapped to other more domain-specific ontologies developed in the area of machine learning and data mining. In this paper we overview existing state-of-the-art machine learning interchange formats and present the first release of ML-Schema, a canonical format resulted of more than seven years of experience among different research institutions. We argue that exposing semantics of machine learning algorithms, models, and experiments through a canonical format may pave the way to better interpretability and to realistically achieve the full interoperability of experiments regardless of platform or adopted workflow solution.},
  journal={arXiv}
}

@article{mcdermott2019reproducibility,
  title={Reproducibility in Machine Learning for Health},
  author={Matthew B. A. McDermott and Shirly Wang and Nikki Marinsek and Rajesh Ranganath and Marzyeh Ghassemi and Luca Foschini},
  year={2019},
  url={http://arxiv.org/abs/1907.01463v1},
  abstract={Machine learning algorithms designed to characterize, monitor, and intervene on human health (ML4H) are expected to perform safely and reliably when operating at scale, potentially outside strict human supervision. This requirement warrants a stricter attention to issues of reproducibility than other fields of machine learning.   In this work, we conduct a systematic evaluation of over 100 recently published ML4H research papers along several dimensions related to reproducibility. We find that the field of ML4H compares poorly to more established machine learning fields, particularly concerning data and code accessibility. Finally, drawing from success in other fields of science, we propose recommendations to data providers, academic publishers, and the ML4H research community in order to promote reproducible research moving forward.},
  journal={arXiv}
}

@article{dubourgfelonneau2018framework,
  title={A Framework for Implementing Machine Learning on Omics Data},
  author={Geoffroy Dubourg-Felonneau and Timothy Cannings and Fergal Cotter and Hannah Thompson and Nirmesh Patel and John W Cassidy and Harry W Clifford},
  year={2018},
  url={http://arxiv.org/abs/1811.10455v1},
  abstract={The potential benefits of applying machine learning methods to -omics data are becoming increasingly apparent, especially in clinical settings. However, the unique characteristics of these data are not always well suited to machine learning techniques. These data are often generated across different technologies in different labs, and frequently with high dimensionality. In this paper we present a framework for combining -omics data sets, and for handling high dimensional data, making -omics research more accessible to machine learning applications. We demonstrate the success of this framework through integration and analysis of multi-analyte data for a set of 3,533 breast cancers. We then use this data-set to predict breast cancer patient survival for individuals at risk of an impending event, with higher accuracy and lower variance than methods trained on individual data-sets. We hope that our pipelines for data-set generation and transformation will open up -omics data to machine learning researchers. We have made these freely available for noncommercial use at www.ccg.ai.},
  journal={arXiv}
}

@article{rudin2018stop,
  title={Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead},
  author={Cynthia Rudin},
  year={2018},
  url={http://arxiv.org/abs/1811.10154v3},
  abstract={Black box machine learning models are currently being used for high stakes decision-making throughout society, causing problems throughout healthcare, criminal justice, and in other domains. People have hoped that creating methods for explaining these black box models will alleviate some of these problems, but trying to \textit{explain} black box models, rather than creating models that are \textit{interpretable} in the first place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society. There is a way forward -- it is to design models that are inherently interpretable. This manuscript clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare, and computer vision.},
  journal={arXiv}
}

@article{valdenegrotoro2021teaching,
  title={Teaching Uncertainty Quantification in Machine Learning through Use Cases},
  author={Matias Valdenegro-Toro},
  year={2021},
  url={http://arxiv.org/abs/2108.08712v1},
  abstract={Uncertainty in machine learning is not generally taught as general knowledge in Machine Learning course curricula. In this paper we propose a short curriculum for a course about uncertainty in machine learning, and complement the course with a selection of use cases, aimed to trigger discussion and let students play with the concepts of uncertainty in a programming setting. Our use cases cover the concept of output uncertainty, Bayesian neural networks and weight distributions, sources of uncertainty, and out of distribution detection. We expect that this curriculum and set of use cases motivates the community to adopt these important concepts into courses for safety in AI.},
  journal={arXiv}
}

@article{forde2019scientific,
  title={The Scientific Method in the Science of Machine Learning},
  author={Jessica Zosa Forde and Michela Paganini},
  year={2019},
  url={http://arxiv.org/abs/1904.10922v1},
  abstract={In the quest to align deep learning with the sciences to address calls for rigor, safety, and interpretability in machine learning systems, this contribution identifies key missing pieces: the stages of hypothesis formulation and testing, as well as statistical and systematic uncertainty estimation -- core tenets of the scientific method. This position paper discusses the ways in which contemporary science is conducted in other domains and identifies potentially useful practices. We present a case study from physics and describe how this field has promoted rigor through specific methodological practices, and provide recommendations on how machine learning researchers can adopt these practices into the research ecosystem. We argue that both domain-driven experiments and application-agnostic questions of the inner workings of fundamental building blocks of machine learning models ought to be examined with the tools of the scientific method, to ensure we not only understand effect, but also begin to understand cause, which is the raison d'être of science.},
  journal={arXiv}
}

@article{yoon2019tapnet,
  title={TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning},
  author={Sung Whan Yoon and Jun Seo and Jaekyun Moon},
  year={2019},
  url={http://arxiv.org/abs/1905.06549v2},
  abstract={Handling previously unseen tasks after given only a few training examples continues to be a tough challenge in machine learning. We propose TapNets, neural networks augmented with task-adaptive projection for improved few-shot learning. Here, employing a meta-learning strategy with episode-based training, a network and a set of per-class reference vectors are learned across widely varying tasks. At the same time, for every episode, features in the embedding space are linearly projected into a new space as a form of quick task-specific conditioning. The training loss is obtained based on a distance metric between the query and the reference vectors in the projection space. Excellent generalization results in this way. When tested on the Omniglot, miniImageNet and tieredImageNet datasets, we obtain state of the art classification accuracies under various few-shot scenarios.},
  journal={arXiv}
}

@article{xu2018multimodal,
  title={Multimodal Machine Learning for Automated ICD Coding},
  author={Keyang Xu and Mike Lam and Jingzhi Pang and Xin Gao and Charlotte Band and Piyush Mathur and Frank Papay and Ashish K. Khanna and Jacek B. Cywinski and Kamal Maheshwari and Pengtao Xie and Eric Xing},
  year={2018},
  url={http://arxiv.org/abs/1810.13348v4},
  abstract={This study presents a multimodal machine learning model to predict ICD-10 diagnostic codes. We developed separate machine learning models that can handle data from different modalities, including unstructured text, semi-structured text and structured tabular data. We further employed an ensemble method to integrate all modality-specific models to generate ICD-10 codes. Key evidence was also extracted to make our prediction more convincing and explainable. We used the Medical Information Mart for Intensive Care III (MIMIC -III) dataset to validate our approach. For ICD code prediction, our best-performing model (micro-F1 = 0.7633, micro-AUC = 0.9541) significantly outperforms other baseline models including TF-IDF (micro-F1 = 0.6721, micro-AUC = 0.7879) and Text-CNN model (micro-F1 = 0.6569, micro-AUC = 0.9235). For interpretability, our approach achieves a Jaccard Similarity Coefficient (JSC) of 0.1806 on text data and 0.3105 on tabular data, where well-trained physicians achieve 0.2780 and 0.5002 respectively.},
  journal={arXiv}
}

@article{sivarajah2022tierkreis,
  title={Tierkreis: A Dataflow Framework for Hybrid Quantum-Classical Computing},
  author={Seyon Sivarajah and Lukas Heidemann and Alan Lawrence and Ross Duncan},
  year={2022},
  url={http://arxiv.org/abs/2211.02350v1},
  abstract={We present Tierkreis, a higher-order dataflow graph program representation and runtime designed for compositional, quantum-classical hybrid algorithms. The design of the system is motivated by the remote nature of quantum computers, the need for hybrid algorithms to involve cloud and distributed computing, and the long-running nature of these algorithms. The graph-based representation reflects how designers reason about and visualise algorithms, and allows automatic parallelism and asynchronicity. A strong, static type system and higher-order semantics allow for high expressivity and compositionality in the program. The flexible runtime protocol enables third-party developers to add functionality using any language or environment. With Tierkreis, quantum software developers can easily build, visualise, verify, test, and debug complex hybrid workflows, and immediately deploy them to the cloud or a custom distributed environment.},
  doi={10.1109/QCS56647.2022.00007},
  journal={arXiv}
}

@article{gill2024quantum,
  title={Quantum Computing: Vision and Challenges},
  author={Sukhpal Singh Gill and Oktay Cetinkaya and Stefano Marrone and Daniel Claudino and David Haunschild and Leon Schlote and Huaming Wu and Carlo Ottaviani and Xiaoyuan Liu and Sree Pragna Machupalli and Kamalpreet Kaur and Priyansh Arora and Ji Liu and Ahmed Farouk and Houbing Herbert Song and Steve Uhlig and Kotagiri Ramamohanarao},
  year={2024},
  url={http://arxiv.org/abs/2403.02240v5},
  abstract={The recent development of quantum computing, which uses entanglement, superposition, and other quantum fundamental concepts, can provide substantial processing advantages over traditional computing. These quantum features help solve many complex problems that cannot be solved otherwise with conventional computing methods. These problems include modeling quantum mechanics, logistics, chemical-based advances, drug design, statistical science, sustainable energy, banking, reliable communication, and quantum chemical engineering. The last few years have witnessed remarkable progress in quantum software and algorithm creation and quantum hardware research, which has significantly advanced the prospect of realizing quantum computers. It would be helpful to have comprehensive literature research on this area to grasp the current status and find outstanding problems that require considerable attention from the research community working in the quantum computing industry. To better understand quantum computing, this paper examines the foundations and vision based on current research in this area. We discuss cutting-edge developments in quantum computer hardware advancement and subsequent advances in quantum cryptography, quantum software, and high-scalability quantum computers. Many potential challenges and exciting new trends for quantum technology research and development are highlighted in this paper for a broader debate.},
  doi={10.1016/B978-0-443-29096-1.00008-8},
  journal={arXiv}
}

@article{violaris2025entangling,
  title={Entangling Disciplines: Causality, Entropy and Time-Travel Paradoxes on a Quantum Computer},
  author={Maria Violaris},
  year={2025},
  url={http://arxiv.org/abs/2506.15909v1},
  abstract={Merging disciplines has led to incredible learnings and breakthroughs throughout history, including the discovery of quantum computing: a cross between computation and quantum physics. In this paper, I will discuss how we can cross quantum computing with topics in fundamental physics. This leads to fruitful, interactive learning opportunities that fuse deep open physics problems with key insights about quantum information science. By outlining quantum circuit experiments that can be run on current and near-term quantum computers, I demonstrate how to help learners engage with principles in special relativity, general relativity and thermodynamics. In turn, these connections can advance their understanding of quantum computing. Learners can further explore the quantum computing activities in this paper via the Quantum Paradoxes content series of videos, blogs and code tutorials that I created with IBM Quantum.},
  doi={10.1109/QCE60285.2024.20461},
  journal={arXiv}
}

@article{vallury2023arbitrary,
  title={Arbitrary Ground State Observables from Quantum Computed Moments},
  author={Harish J. Vallury and Lloyd C. L. Hollenberg},
  year={2023},
  url={http://arxiv.org/abs/2312.06975v1},
  abstract={The determination of ground state properties of quantum systems is a fundamental problem in physics and chemistry, and is considered a key application of quantum computers. A common approach is to prepare a trial ground state on the quantum computer and measure observables such as energy, but this is often limited by hardware constraints that prevent an accurate description of the target ground state. The quantum computed moments (QCM) method has proven to be remarkably useful in estimating the ground state energy of a system by computing Hamiltonian moments with respect to a suboptimal or noisy trial state. In this paper, we extend the QCM method to estimate arbitrary ground state observables of quantum systems. We present preliminary results of using QCM to determine the ground state magnetisation and spin-spin correlations of the Heisenberg model in its various forms. Our findings validate the well-established advantage of QCM over existing methods in handling suboptimal trial states and noise, extend its applicability to the estimation of more general ground state properties, and demonstrate its practical potential for solving a wide range of problems on near-term quantum hardware.},
  doi={10.1109/QCE57702.2023.00040},
  journal={arXiv}
}

@article{maldonadoromo2023quantum,
  title={Quantum computing online workshops and hackathon for Spanish speakers: A case study},
  author={Alberto Maldonado-Romo and Lia Yeh},
  year={2023},
  url={http://arxiv.org/abs/2302.12119v1},
  abstract={We discuss the challenges and findings of organizing an online event in Spanish, consisting of a series of introductory workshops leading up to a quantum hackathon for Latin America. 220 Spanish speakers were registered, 66% of whom self-identified as being at an introductory level of quantum computing. We gain a better picture of the impact of quantum computing in Latin America, and the importance of generating educational resources in Spanish about quantum computing. Additionally, we report results on surveying the participants by country; educational status; self-reported levels of quantum computing, linear algebra, and Python competency; and their areas of interest within quantum.   This event was organized by Quantum Universal Education with the Centro de Investigación en Computación del Instituto Politécnico Nacional (CIC-IPN) as the host institution, in collaboration with a number of organizations and companies: IBM Quantum, Xanadu, Multiverse Computing, Quantum Universal Education, Quantum Hispano, QMexico, Haq.ai, Dive in Learning. This was part of a larger event, the Qiskit Fall Fest 2021, as one of several hackathons organized around the world in a similar span of time. In each Qiskit Fall Fest hackathon, participants were challenged to form teams of up to 5, to develop in 5 days a project using the IBM Qiskit framework.},
  doi={10.1109/QCE53715.2022.00096},
  journal={arXiv}
}

@article{bennett1997strengths,
  title={Strengths and Weaknesses of Quantum Computing},
  author={Charles H. Bennett and Ethan Bernstein and Gilles Brassard and Umesh Vazirani},
  year={1997},
  url={http://arxiv.org/abs/quant-ph/9701001v1},
  abstract={Recently a great deal of attention has focused on quantum computation following a sequence of results suggesting that quantum computers are more powerful than classical probabilistic computers. Following Shor's result that factoring and the extraction of discrete logarithms are both solvable in quantum polynomial time, it is natural to ask whether all of NP can be efficiently solved in quantum polynomial time. In this paper, we address this question by proving that relative to an oracle chosen uniformly at random, with probability 1, the class NP cannot be solved on a quantum Turing machine in time $o(2^{n/2})$. We also show that relative to a permutation oracle chosen uniformly at random, with probability 1, the class $NP \cap coNP$ cannot be solved on a quantum Turing machine in time $o(2^{n/3})$. The former bound is tight since recent work of Grover shows how to accept the class NP relative to any oracle on a quantum computer in time $O(2^{n/2})$.},
  doi={10.1137/S0097539796300933},
  journal={arXiv}
}

@article{preskill2018quantum,
  title={Quantum Computing in the NISQ era and beyond},
  author={John Preskill},
  year={2018},
  url={http://arxiv.org/abs/1801.00862v3},
  abstract={Noisy Intermediate-Scale Quantum (NISQ) technology will be available in the near future. Quantum computers with 50-100 qubits may be able to perform tasks which surpass the capabilities of today's classical digital computers, but noise in quantum gates will limit the size of quantum circuits that can be executed reliably. NISQ devices will be useful tools for exploring many-body quantum physics, and may have other useful applications, but the 100-qubit quantum computer will not change the world right away --- we should regard it as a significant step toward the more powerful quantum technologies of the future. Quantum technologists should continue to strive for more accurate quantum gates and, eventually, fully fault-tolerant quantum computing.},
  doi={10.22331/q-2018-08-06-79},
  journal={arXiv}
}

@article{benenti2004quantum,
  title={Quantum computing and information extraction for a dynamical quantum system},
  author={Giuliano Benenti and Giulio Casati and Simone Montangero},
  year={2004},
  url={http://arxiv.org/abs/quant-ph/0402010v1},
  abstract={We discuss the simulation of a complex dynamical system, the so-called quantum sawtooth map model, on a quantum computer. We show that a quantum computer can be used to efficiently extract relevant physical information for this model. It is possible to simulate the dynamical localization of classical chaos and extract the localization length of the system with quadratic speed up with respect to any known classical computation. We can also compute with algebraic speed up the diffusion coefficient and the diffusion exponent both in the regimes of Brownian and anomalous diffusion. Finally, we show that it is possible to extract the fidelity of the quantum motion, which measures the stability of the system under perturbations, with exponential speed up.},
  doi={10.1007/s11128-004-0415-2},
  journal={arXiv}
}

@article{fujii2005cavity,
  title={Cavity QED and Quantum Computation in the Weak Coupling Regime II : Complete Construction of the Controlled-Controlled NOT Gate},
  author={Kazuyuki Fujii and Kyoko Higashida and Ryosuke Kato and Yukako Wada},
  year={2005},
  url={http://arxiv.org/abs/quant-ph/0501046v1},
  abstract={In this paper we treat a cavity QED quantum computation. Namely, we consider a model of quantum computation based on n atoms of laser-cooled and trapped linearly in a cavity and realize it as the n atoms Tavis-Cummings Hamiltonian interacting with n external (laser) fields.   We solve the Schr{\" o}dinger equation of the model in the weak coupling regime to construct the controlled NOT gate in the case of n=2, and to construct the controlled-controlled NOT gate in the case of n=3 by making use of several resonance conditions and rotating wave approximation associated to them. We also present an idea to construct general quantum circuits.   The approach is more sophisticated than that of the paper [K. Fujii, Higashida, Kato and Wada, Cavity QED and Quantum Computation in the Weak Coupling Regime, J. Opt. B : Quantum Semiclass. Opt. {\bf 6} (2004), 502].   Our method is not heuristic but completely mathematical, and the significant feature is based on a consistent use of Rabi oscillations.},
  journal={arXiv}
}

@article{j2018quantum,
  title={Quantum Algorithm Implementations for Beginners},
  author={Abhijith J. and Adetokunbo Adedoyin and John Ambrosiano and Petr Anisimov and William Casper and Gopinath Chennupati and Carleton Coffrin and Hristo Djidjev and David Gunter and Satish Karra and Nathan Lemons and Shizeng Lin and Alexander Malyzhenkov and David Mascarenas and Susan Mniszewski and Balu Nadiga and Daniel O'Malley and Diane Oyen and Scott Pakin and Lakshman Prasad and Randy Roberts and Phillip Romero and Nandakishore Santhi and Nikolai Sinitsyn and Pieter J. Swart and James G. Wendelberger and Boram Yoon and Richard Zamora and Wei Zhu and Stephan Eidenbenz and Andreas Bärtschi and Patrick J. Coles and Marc Vuffray and Andrey Y. Lokhov},
  year={2018},
  url={http://arxiv.org/abs/1804.03719v3},
  abstract={As quantum computers become available to the general public, the need has arisen to train a cohort of quantum programmers, many of whom have been developing classical computer programs for most of their careers. While currently available quantum computers have less than 100 qubits, quantum computing hardware is widely expected to grow in terms of qubit count, quality, and connectivity. This review aims to explain the principles of quantum programming, which are quite different from classical programming, with straightforward algebra that makes understanding of the underlying fascinating quantum mechanical principles optional. We give an introduction to quantum computing algorithms and their implementation on real quantum hardware. We survey 20 different quantum algorithms, attempting to describe each in a succinct and self-contained fashion. We show how these algorithms can be implemented on IBM's quantum computer, and in each case, we discuss the results of the implementation with respect to differences between the simulator and the actual hardware runs. This article introduces computer scientists, physicists, and engineers to quantum algorithms and provides a blueprint for their implementations.},
  doi={10.1145/3517340},
  journal={arXiv}
}

@article{volpe2024predictive,
  title={A Predictive Approach for Selecting the Best Quantum Solver for an Optimization Problem},
  author={Deborah Volpe and Nils Quetschlich and Mariagrazia Graziano and Giovanna Turvani and Robert Wille},
  year={2024},
  url={http://arxiv.org/abs/2408.03613v1},
  abstract={Leveraging quantum computers for optimization problems holds promise across various application domains. Nevertheless, utilizing respective quantum computing solvers requires describing the optimization problem according to the Quadratic Unconstrained Binary Optimization (QUBO) formalism and selecting a proper solver for the application of interest with a reasonable setting. Both demand significant proficiency in quantum computing, QUBO formulation, and quantum solvers, a background that usually cannot be assumed by end users who are domain experts rather than quantum computing specialists. While tools aid in QUBO formulations, support for selecting the best-solving approach remains absent. This becomes even more challenging because selecting the best solver for a problem heavily depends on the problem itself. In this work, we are accepting this challenge and propose a predictive selection approach, which aids end users in this task. To this end, the solver selection task is first formulated as a classification task that is suitable to be solved by supervised machine learning. Based on that, we then propose strategies for adjusting solver parameters based on problem size and characteristics. Experimental evaluations, considering more than 500 different QUBO problems, confirm the benefits of the proposed solution. In fact, we show that in more than 70% of the cases, the best solver is selected, and in about 90% of the problems, a solver in the top two, i.e., the best or its closest suboptimum, is selected. This exploration proves the potential of machine learning in quantum solver selection and lays the foundations for its automation, broadening access to quantum optimization for a wider range of users.},
  doi={10.1109/QCE60285.2024.00121},
  journal={arXiv}
}

@article{bera2021quantum,
  title={Quantum and Randomised Algorithms for Non-linearity Estimation},
  author={Debajyoti Bera and Tharrmashastha Sapv},
  year={2021},
  url={http://arxiv.org/abs/2103.07934v2},
  abstract={Non-linearity of a Boolean function indicates how far it is from any linear function. Despite there being several strong results about identifying a linear function and distinguishing one from a sufficiently non-linear function, we found a surprising lack of work on computing the non-linearity of a function. The non-linearity is related to the Walsh coefficient with the largest absolute value; however, the naive attempt of picking the maximum after constructing a Walsh spectrum requires $Θ(2^n)$ queries to an $n$-bit function. We improve the scenario by designing highly efficient quantum and randomised algorithms to approximate the non-linearity allowing additive error, denoted $λ$, with query complexities that depend polynomially on $λ$. We prove lower bounds to show that these are not very far from the optimal ones. The number of queries made by our randomised algorithm is linear in $n$, already an exponential improvement, and the number of queries made by our quantum algorithm is surprisingly independent of $n$. Our randomised algorithm uses a Goldreich-Levin style of navigating all Walsh coefficients and our quantum algorithm uses a clever combination of Deutsch-Jozsa, amplitude amplification and amplitude estimation to improve upon the existing quantum versions of the Goldreich-Levin technique.},
  doi={10.1145/3456509},
  journal={arXiv}
}

@article{morgado2020quantum,
  title={Quantum simulation and computing with Rydberg-interacting qubits},
  author={M. Morgado and S. Whitlock},
  year={2020},
  url={http://arxiv.org/abs/2011.03031v2},
  abstract={Arrays of optically trapped atoms excited to Rydberg states have recently emerged as a competitive physical platform for quantum simulation and computing, where high-fidelity state preparation and readout, quantum logic gates and controlled quantum dynamics of more than 100 qubits have all been demonstrated. These systems are now approaching the point where reliable quantum computations with hundreds of qubits and realistically thousands of multiqubit gates with low error rates should be within reach for the first time. In this article we give an overview of the Rydberg quantum toolbox, emphasizing the high degree of flexibility for encoding qubits, performing quantum operations and engineering quantum many-body Hamiltonians. We then review the state-of-the-art concerning high-fidelity quantum operations and logic gates as well as quantum simulations in many-body regimes. Finally, we discuss computing schemes that are particularly suited to the Rydberg platform and some of the remaining challenges on the road to general purpose quantum simulators and quantum computers.},
  doi={10.1116/5.0036562},
  journal={arXiv}
}

@article{sannia2022dissipation,
  title={Dissipation as a resource for Quantum Reservoir Computing},
  author={Antonio Sannia and Rodrigo Martínez-Peña and Miguel C. Soriano and Gian Luca Giorgi and Roberta Zambrini},
  year={2022},
  url={http://arxiv.org/abs/2212.12078v2},
  abstract={Dissipation induced by interactions with an external environment typically hinders the performance of quantum computation, but in some cases can be turned out as a useful resource. We show the potential enhancement induced by dissipation in the field of quantum reservoir computing introducing tunable local losses in spin network models. Our approach based on continuous dissipation is able not only to reproduce the dynamics of previous proposals of quantum reservoir computing, based on discontinuous erasing maps but also to enhance their performance. Control of the damping rates is shown to boost popular machine learning temporal tasks as the capability to linearly and non-linearly process the input history and to forecast chaotic series. Finally, we formally prove that, under non-restrictive conditions, our dissipative models form a universal class for reservoir computing. It means that considering our approach, it is possible to approximate any fading memory map with arbitrary precision.},
  doi={10.22331/q-2024-03-20-1291},
  journal={arXiv}
}

@article{deutsch1995universality,
  title={Universality in Quantum Computation},
  author={D. Deutsch and A. Barenco and A. Ekert},
  year={1995},
  url={http://arxiv.org/abs/quant-ph/9505018v1},
  abstract={We show that in quantum computation almost every gate that operates on two or more bits is a universal gate. We discuss various physical considerations bearing on the proper definition of universality for computational components such as logic gates.},
  doi={10.1098/rspa.1995.0065},
  journal={arXiv}
}

@article{sørensen2015exploring,
  title={Exploring the Quantum Speed Limit with Computer Games},
  author={Jens Jakob W. H. Sørensen and Mads Kock Pedersen and Michael Munch and Pinja Haikka and Jesper Halkjær Jensen and Tilo Planke and Morten Ginnerup Andreasen and Miroslav Gajdacz and Klaus Mølmer and Andreas Lieberoth and Jacob F. Sherson and Quantum Moves players},
  year={2015},
  url={http://arxiv.org/abs/1506.09091v3},
  abstract={Humans routinely solve problems of immense computational complexity by intuitively forming simple, low-dimensional heuristic strategies. Citizen science exploits this ability by presenting scientific research problems to non-experts. Gamification is an effective tool for attracting citizen scientists to provide solutions to research problems. While citizen science games Foldit, EteRNA and EyeWire have been used successfully to study protein and RNA folding and neuron mapping, so far gamification has not been applied to problems in quantum physics. Does the fact that everyday experiences are based on classical physics hinder the use of non-expert citizen scientists in the realm of quantum mechanics? Here we report on Quantum Moves, an online platform gamifying optimization problems in quantum physics. We show that human players are able to find solutions to difficult problems associated with the task of quantum computing. Players succeed where purely numerical optimization fails, and analyses of their solutions provide insights into the problem of optimization of a more profound and general nature. Based on player strategies, we have thus developed a new, few-parameter heuristic optimization method which efficiently outperforms the most prominent established numerical methods. The numerical complexity associated with time-optimal solutions increases for shorter process durations. To better understand this, we have made a low-dimensional rendering of the optimization landscape. These studies show why traditional optimization methods fail near the quantum speed limit, and they bring promise that combined analyses of optimization landscapes and heuristic solution strategies may benefit wider classes of optimization problems in quantum physics and beyond.},
  doi={10.1038/nature17620},
  journal={arXiv}
}

@article{kolarovszki2024piquasso,
  title={Piquasso: A Photonic Quantum Computer Simulation Software Platform},
  author={Zoltán Kolarovszki and Tomasz Rybotycki and Péter Rakyta and Ágoston Kaposi and Boldizsár Poór and Szabolcs Jóczik and Dániel T. R. Nagy and Henrik Varga and Kareem H. El-Safty and Gregory Morse and Michał Oszmaniec and Tamás Kozsik and Zoltán Zimborás},
  year={2024},
  url={http://arxiv.org/abs/2403.04006v3},
  abstract={We introduce the Piquasso quantum programming framework, a full-stack open-source software platform for the simulation and programming of photonic quantum computers. Piquasso can be programmed via a high-level Python programming interface enabling users to perform efficient quantum computing with discrete and continuous variables. Via optional high-performance C++ backends, Piquasso provides state-of-the-art performance in the simulation of photonic quantum computers. The Piquasso framework is supported by an intuitive web-based graphical user interface where the users can design quantum circuits, run computations, and visualize the results.},
  doi={10.22331/q-2025-04-15-1708},
  journal={arXiv}
}

@article{barenco1995universal,
  title={A Universal Two--Bit Gate for Quantum Computation},
  author={A. Barenco},
  year={1995},
  url={http://arxiv.org/abs/quant-ph/9505016v1},
  abstract={We prove the existence of a class of two--input, two--output gates any one of which is universal for quantum computation. This is done by explicitly constructing the three--bit gate introduced by Deutsch [Proc.~R.~Soc.~London.~A {\bf 425}, 73 (1989)] as a network consisting of replicas of a single two--bit gate.},
  doi={10.1098/rspa.1995.0066},
  journal={arXiv}
}

@article{datta2011quantum,
  title={Quantum Discord and Quantum Computing - An Appraisal},
  author={Animesh Datta and Anil Shaji},
  year={2011},
  url={http://arxiv.org/abs/1109.5549v1},
  abstract={We discuss models of computing that are beyond classical. The primary motivation is to unearth the cause of nonclassical advantages in computation. Completeness results from computational complexity theory lead to the identification of very disparate problems, and offer a kaleidoscopic view into the realm of quantum enhancements in computation. Emphasis is placed on the `power of one qubit' model, and the boundary between quantum and classical correlations as delineated by quantum discord. A recent result by Eastin on the role of this boundary in the efficient classical simulation of quantum computation is discussed. Perceived drawbacks in the interpretation of quantum discord as a relevant certificate of quantum enhancements are addressed.},
  doi={10.1142/S0219749911008416},
  journal={arXiv}
}

@article{mukherjee2018interaction,
  title={Interaction of light and semiconductor can generate quantum states required for solid state quantum computing: Entangled, steered and other nonclassical states},
  author={Arjun Mukherjee and Biswajit Sen and Kishore Thapliyal and Swapan Mandal and Anirban Pathak},
  year={2018},
  url={http://arxiv.org/abs/1811.09849v1},
  abstract={Proposals for solid state quantum computing are extremely promising as they can be used to built room temperature quantum computers. If such a quantum computer is ever built it would require in-built sources of nonclassical states required for various quantum information processing tasks. Possibilities of generation of such nonclassical states are investigated here for a physical system composed of a monochromatic light coupled to a two-band semiconductor with direct band gap. The model Hamiltonian includes both photon-exciton and exciton-exciton interactions. Time evolution of the relevant bosonic operators are obtained analytically by using a perturbative technique that provides operator solution for the coupled Heisenberg's equations of motion corresponding to the system Hamiltonian. The bosonic operators are subsequently used to study the possibilities of observing single and two mode squeezing and antibunching after interaction in the relevant modes of light and semiconductor. Further, entanglement between the exciton and photon modes is reported. Finally, the nonclassical effects have been studied numerically for the open quantum system scenario. In this situation, the nonlocal correlations between two modes are shown to violate EPR steering inequality. The observed nonclassical features, induced due to exciton-exciton pair interaction, can be controlled by the phase of input field and the correlations between two modes are shown to enhance due to nonclassicality in the input field.},
  doi={10.1007/s11128-019-2344-0},
  journal={arXiv}
}

@article{steiger2016projectq,
  title={ProjectQ: An Open Source Software Framework for Quantum Computing},
  author={Damian S. Steiger and Thomas Häner and Matthias Troyer},
  year={2016},
  url={http://arxiv.org/abs/1612.08091v2},
  abstract={We introduce ProjectQ, an open source software effort for quantum computing. The first release features a compiler framework capable of targeting various types of hardware, a high-performance simulator with emulation capabilities, and compiler plug-ins for circuit drawing and resource estimation. We introduce our Python-embedded domain-specific language, present the features, and provide example implementations for quantum algorithms. The framework allows testing of quantum algorithms through simulation and enables running them on actual quantum hardware using a back-end connecting to the IBM Quantum Experience cloud service. Through extension mechanisms, users can provide back-ends to further quantum hardware, and scientists working on quantum compilation can provide plug-ins for additional compilation, optimization, gate synthesis, and layout strategies.},
  doi={10.22331/q-2018-01-31-49},
  journal={arXiv}
}

@article{freedman2021symmetry,
  title={Symmetry Protected Quantum Computation},
  author={Michael H. Freedman and Matthew B. Hastings and Modjtaba Shokrian Zini},
  year={2021},
  url={http://arxiv.org/abs/2105.04649v3},
  abstract={We consider a model of quantum computation using qubits where it is possible to measure whether a given pair are in a singlet (total spin $0$) or triplet (total spin $1$) state. The physical motivation is that we can do these measurements in a way that is protected against revealing other information so long as all terms in the Hamiltonian are $SU(2)$-invariant. We conjecture that this model is equivalent to BQP. Towards this goal, we show: (1) this model is capable of universal quantum computation with polylogarithmic overhead if it is supplemented by single qubit $X$ and $Z$ gates. (2) Without any additional gates, it is at least as powerful as the weak model of "permutational quantum computation" of Jordan [14, 18]. (3) With postselection, the model is equivalent to PostBQP.},
  doi={10.22331/q-2021-09-28-554},
  journal={arXiv}
}

@article{chabaud2021holomorphic,
  title={Holomorphic representation of quantum computations},
  author={Ulysse Chabaud and Saeed Mehraban},
  year={2021},
  url={http://arxiv.org/abs/2111.00117v3},
  abstract={We study bosonic quantum computations using the Segal-Bargmann representation of quantum states. We argue that this holomorphic representation is a natural one which not only gives a canonical description of bosonic quantum computing using basic elements of complex analysis but also provides a unifying picture which delineates the boundary between discrete- and continuous-variable quantum information theory. Using this representation, we show that the evolution of a single bosonic mode under a Gaussian Hamiltonian can be described as an integrable dynamical system of classical Calogero-Moser particles corresponding to the zeros of the holomorphic function, together with a conformal evolution of Gaussian parameters. We explain that the Calogero-Moser dynamics is due to unique features of bosonic Hilbert spaces such as squeezing. We then generalize the properties of this holomorphic representation to the multimode case, deriving a non-Gaussian hierarchy of quantum states and relating entanglement to factorization properties of holomorphic functions. Finally, we apply this formalism to discrete- and continuous- variable quantum measurements and obtain a classification of subuniversal models that are generalizations of Boson Sampling and Gaussian quantum computing.},
  doi={10.22331/q-2022-10-06-831},
  journal={arXiv}
}

@article{sinayskiy2014efficiency,
  title={Efficiency of open quantum walk implementation of dissipative quantum computing algorithms},
  author={I. Sinayskiy and F. Petruccione},
  year={2014},
  url={http://arxiv.org/abs/1401.6658v1},
  abstract={An open quantum walk formalism for dissipative quantum computing is presented. The approach is illustrated with the examples of the Toffoli gate and the Quantum Fourier Transform for 3 and 4 qubits. It is shown that the algorithms based on the open quantum walk formalism are more efficient than the canonical dissipative quantum computing approach. In particular, the open quantum walks can be designed to converge faster to the desired steady state and to increase the probability of detection of the outcome of the computation.},
  doi={10.1007/s11128-012-0426-3},
  journal={arXiv}
}

@article{daley2011quantum,
  title={Quantum Computing and Quantum Simulation with Group-II Atoms},
  author={Andrew J. Daley},
  year={2011},
  url={http://arxiv.org/abs/1106.5712v1},
  abstract={Recent experimental progress in controlling neutral group-II atoms for optical clocks, and in the production of degenerate gases with group-II atoms has given rise to novel opportunities to address challenges in quantum computing and quantum simulation. In these systems, it is possible to encode qubits in nuclear spin states, which are decoupled from the electronic state in the $^1$S$_0$ ground state and the long-lived $^3$P$_0$ metastable state on the clock transition. This leads to quantum computing scenarios where qubits are stored in long lived nuclear spin states, while electronic states can be accessed independently, for cooling of the atoms, as well as manipulation and readout of the qubits. The high nuclear spin in some fermionic isotopes also offers opportunities for the encoding of multiple qubits on a single atom, as well as providing an opportunity for studying many-body physics in systems with a high spin symmetry. Here we review recent experimental and theoretical progress in these areas, and summarise the advantages and challenges for quantum computing and quantum simulation with group-II atoms.},
  doi={10.1007/s11128-011-0293-3},
  journal={arXiv}
}

@article{javadiabhari2024quantum,
  title={Quantum computing with Qiskit},
  author={Ali Javadi-Abhari and Matthew Treinish and Kevin Krsulich and Christopher J. Wood and Jake Lishman and Julien Gacon and S. Martiel and P. Nation and Lev S. Bishop and Andrew W. Cross and Blake R. Johnson and J. Gambetta},
  year={2024},
  url={https://www.semanticscholar.org/paper/ed1c8676a7c13421afa315af9702fad182ee2347},
  abstract={We describe Qiskit, a software development kit for quantum information science. We discuss the key design decisions that have shaped its development, and examine the software architecture and its core components. We demonstrate an end-to-end workflow for solving a problem in condensed matter physics on a quantum computer that serves to highlight some of Qiskit's capabilities, for example the representation and optimization of circuits at various abstraction levels, its scalability and retargetability to new gates, and the use of quantum-classical computations via dynamic circuits. Lastly, we discuss some of the ecosystem of tools and plugins that extend Qiskit for various tasks, and the future ahead.},
  doi={10.48550/arXiv.2405.08810},
  journal={arXiv.org}
}

@article{kim2023evidence,
  title={Evidence for the utility of quantum computing before fault tolerance},
  author={Youngseok Kim and A. Eddins and Sajant Anand and K. X. Wei and Ewout van den Berg and S. Rosenblatt and Hasan Nayfeh and Yantao Wu and M. Zaletel and K. Temme and A. Kandala},
  year={2023},
  url={https://www.semanticscholar.org/paper/f9253a3e2627f1c2a0a7e2cea320a4ec4e4d2ff9},
  abstract={Quantum computing promises to offer substantial speed-ups over its classical counterpart for certain problems. However, the greatest impediment to realizing its full potential is noise that is inherent to these systems. The widely accepted solution to this challenge is the implementation of fault-tolerant quantum circuits, which is out of reach for current processors. Here we report experiments on a noisy 127-qubit processor and demonstrate the measurement of accurate expectation values for circuit volumes at a scale beyond brute-force classical computation. We argue that this represents evidence for the utility of quantum computing in a pre-fault-tolerant era. These experimental results are enabled by advances in the coherence and calibration of a superconducting processor at this scale and the ability to characterize^ 1 and controllably manipulate noise across such a large device. We establish the accuracy of the measured expectation values by comparing them with the output of exactly verifiable circuits. In the regime of strong entanglement, the quantum computer provides correct results for which leading classical approximations such as pure-state-based 1D (matrix product states, MPS) and 2D (isometric tensor network states, isoTNS) tensor network methods^ 2 , 3 break down. These experiments demonstrate a foundational tool for the realization of near-term quantum applications^ 4 , 5 . Experiments on a noisy 127-qubit superconducting quantum processor report the accurate measurement of expectation values beyond the reach of current brute-force classical computation, demonstrating evidence for the utility of quantum computing before fault tolerance.},
  doi={10.1038/s41586-023-06096-3},
  journal={Nature}
}

@article{larocca2024barren,
  title={Barren plateaus in variational quantum computing},
  author={Martín Larocca and Supanut Thanasilp and Samson Wang and Kunal Sharma and Jacob Biamonte and Patrick J. Coles and L. Cincio and J. McClean and Zoe Holmes and M. Cerezo},
  year={2024},
  url={https://www.semanticscholar.org/paper/204008df9e9d4e6499f48add49291c12f3aa1ffc},
  abstract={Variational quantum computing offers a flexible computational approach with a broad range of applications. However, a key obstacle to realizing their potential is the barren plateau (BP) phenomenon. When a model exhibits a BP, its parameter optimization landscape becomes exponentially flat and featureless as the problem size increases. Importantly, all the moving pieces of an algorithm — choices of ansatz, initial state, observable, loss function and hardware noise — can lead to BPs if they are ill-suited. As BPs strongly impact on trainability, researchers have dedicated considerable effort to develop theoretical and heuristic methods to understand and mitigate their effects. As a result, the study of BPs has become a thriving area of research, influencing and exchanging ideas with other fields such as quantum optimal control, tensor networks and learning theory. This article provides a review of the current understanding of the BP phenomenon. Barren plateaus are widely considered as one of the main limitations for variational quantum algorithms. This Review summarizes the latest understandings of barren plateaus, indicating its causes, architecture that will suffer from this phenomenon, and discusses strategies that can — and cannot — avoid it. Variational quantum algorithms (VQAs) — this hybrid computational approach aims at training a quantum learning model (usually a parametrized quantum circuit) to solve a given task. The parameters in the model are trained by minimizing a loss function that encodes the degree to which the problem has been solved. Barren plateaus — a phenomenon in which the gradients of the loss landscape of VQAs get exponentially suppressed. Currently, this issue is understood as a form of curse of dimensionality arising from operating in an unstructured manner in an exponentially large Hilbert space. Trainability — in the context of VQAs, trainability refers to the ability to optimize parameters of a model and minimize the loss function. Barren plateaus are one of the main barriers to the trainability of VQAs. Variational quantum algorithms (VQAs) — this hybrid computational approach aims at training a quantum learning model (usually a parametrized quantum circuit) to solve a given task. The parameters in the model are trained by minimizing a loss function that encodes the degree to which the problem has been solved. Barren plateaus — a phenomenon in which the gradients of the loss landscape of VQAs get exponentially suppressed. Currently, this issue is understood as a form of curse of dimensionality arising from operating in an unstructured manner in an exponentially large Hilbert space. Trainability — in the context of VQAs, trainability refers to the ability to optimize parameters of a model and minimize the loss function. Barren plateaus are one of the main barriers to the trainability of VQAs.},
  doi={10.1038/s42254-025-00813-9},
  journal={Nature Reviews Physics}
}

@article{maring2024versatile,
  title={A versatile single-photon-based quantum computing platform},
  author={N. Maring and A. Fyrillas and M. Pont and Edouard Ivanov and Petr Stepanov and N. Margaria and W. Hease and A. Pishchagin and Aristide Lemaître and Isabelle Sagnes and Thi Huong Au and S. Boissier and Eric Bertasi and Aur'elien Baert and Mario Valdivia and Marie Billard and Ozan Acar and A. Brieussel and R. Mezher and S. Wein and A. Salavrakos and Patrick Sinnott and D. Fioretto and P. Emeriau and N. Belabas and S. Mansfield and P. Senellart and J. Senellart and N. Somaschi},
  year={2024},
  url={https://www.semanticscholar.org/paper/3519dc42599631579823d3d3746fe1ae2a02ab61},
  abstract={Quantum computing aims at exploiting quantum phenomena to efficiently perform computations that are unfeasible even for the most powerful classical supercomputers. Among the promising technological approaches, photonic quantum computing offers the advantages of low decoherence, information processing with modest cryogenic requirements, and native integration with classical and quantum networks. So far, quantum computing demonstrations with light have implemented specific tasks with specialized hardware, notably Gaussian boson sampling, which permits the quantum computational advantage to be realized. Here we report a cloud-accessible versatile quantum computing prototype based on single photons. The device comprises a high-efficiency quantum-dot single-photon source feeding a universal linear optical network on a reconfigurable chip for which hardware errors are compensated by a machine-learned transpilation process. Our full software stack allows remote control of the device to perform computations via logic gates or direct photonic operations. For gate-based computation, we benchmark one-, two- and three-qubit gates with state-of-the art fidelities of 99.6 ± 0.1%, 93.8 ± 0.6% and 86 ± 1.2%, respectively. We also implement a variational quantum eigensolver, which we use to calculate the energy levels of the hydrogen molecule with chemical accuracy. For photon native computation, we implement a classifier algorithm using a three-photon-based quantum neural network and report a six-photon boson sampling demonstration on a universal reconfigurable integrated circuit. Finally, we report on a heralded three-photon entanglement generation, a key milestone toward measurement-based quantum computing. A versatile cloud-accessible single-photon-based quantum computing machine is developed, which shows a six-photon sampling rate of 4 Hz over weeks. Heralded generation of a three-photon Greenberger–Horne–Zeilinger state—a key milestone toward measurement-based quantum computing—is implemented.},
  doi={10.1038/s41566-024-01403-4},
  journal={Nature Photonics}
}

@article{main2024distributed,
  title={Distributed quantum computing across an optical network link},
  author={D. Main and P. Drmota and D. P. Nadlinger and E. Ainley and A. Agrawal and B. C. Nichol and R. Srinivas and G. Araneda and D. M. Lucas},
  year={2024},
  url={https://www.semanticscholar.org/paper/0ad5c8e1fe12db2495da136183930fa7c3c8f4f4},
  abstract={Distributed quantum computing (DQC) combines the computing power of multiple networked quantum processing modules, ideally enabling the execution of large quantum circuits without compromising performance or qubit connectivity1,2. Photonic networks are well suited as a versatile and reconfigurable interconnect layer for DQC; remote entanglement shared between matter qubits across the network enables all-to-all logical connectivity through quantum gate teleportation (QGT)3,4. For a scalable DQC architecture, the QGT implementation must be deterministic and repeatable; until now, no demonstration has satisfied these requirements. Here we experimentally demonstrate the distribution of quantum computations between two photonically interconnected trapped-ion modules. The modules, separated by about two metres, each contain dedicated network and circuit qubits. By using heralded remote entanglement between the network qubits, we deterministically teleport a controlled-Z (CZ) gate between two circuit qubits in separate modules, achieving 86% fidelity. We then execute Grover’s search algorithm5—to our knowledge, the first implementation of a distributed quantum algorithm comprising several non-local two-qubit gates—and measure a 71% success rate. Furthermore, we implement distributed iSWAP and SWAP circuits, compiled with two and three instances of QGT, respectively, demonstrating the ability to distribute arbitrary two-qubit operations6. As photons can be interfaced with a variety of systems, the versatile DQC architecture demonstrated here provides a viable pathway towards large-scale quantum computing for a range of physical platforms. The distribution of quantum computations is demonstrated between two photonically interconnected trapped-ion modules, using repeatable, deterministic teleported controlled-Z gates to perform Grover’s search algorithm.},
  doi={10.1038/s41586-024-08404-x},
  journal={Nature}
}

@article{burridge2024manufacturable,
  title={A manufacturable platform for photonic quantum computing},
  author={Koen Avishai Dylan Damien Stanley Ben Hugo Geoff Gabrie Alexander Benyamini Black Bonneau Burgos Burridge  and Koen Alexander and A. Benyamini and Dylan Black and D. Bonneau and S. Burgos and Ben M. Burridge and Hugo Cable and Geoff Campbell and Gabriel Catalano and Alejandro Ceballos and Chia-Ming Chang and Sourav Sen Choudhury and C. J. Chung and Fariba Danesh and Tom Dauer and Michael Davis and Eric Dudley and Er-Xuan Ping and Josep Fargas and A. Farsi and Colleen Fenrich and Jonathan Frazer and Masaya Fukami and Y. Ganesan and Gary Gibson and Mercedes Gimeno-Segovia and Sebastian Goeldi and Patrick S. Goley and Ryan Haislmaier and Sami Halimi and Paul Hansen and Sam Hardy and Jason Horng and Matthew House and Hong Hu and M. Jadidi and Vijay Jain and Henrik Johansson and Thomas Jones and V. Kamineni and N. Kelez and Ravi Koustuban and G. Kovall and P. Krogen and Nikhil Kumar and Yong Liang and N. Licausi and D. Llewellyn and K. Lokovic and Michael Lovelady and V. Manfrinato and A. Melnichuk and G. Mendoza and Brad Moores and Shaunak Mukherjee and J. Munns and François-Xavier Musalem and F. Najafi and Jeremy L. O'Brien and J. Ortmann and Sunil Pai and Bryan Park and Hsuan-Tung Peng and N. Penthorn and Brennan Peterson and Gabriel Peterson and Matt Poush and G. J. Pryde and Tarun Ramprasad and Gareth Ray and A. Rodriguez and B. Roxworthy and T. Rudolph and D. J. Saunders and P. Shadbolt and Deesha Shah and Andrea Bahgat Shehata and Hyungki Shin and Jeffrey Sinsky and Jake Smith and Ben Sohn and Young-Ik Sohn and Gyeongho Son and Mario Souza and Chris Sparrow and M. Staffaroni and C. Stavrakas and Vijay Sukumaran and D. Tamborini and Mark G. Thompson and Khanh Tran and Mark Triplett and Maryann Tung and A. Veitia and Alexey Vert and M. Vidrighin and I. Vorobeichik and Peter Weigel and Matthew Wingert and Jamie P. Wooding and Xinran Zhou},
  year={2024},
  url={https://www.semanticscholar.org/paper/46062a1225c3f9f178530020cdc35051e5682037},
  abstract={Although holding great promise for low noise, ease of operation and networking1, useful photonic quantum computing has been precluded by the need for beyond-state-of-the-art components, manufactured by the millions2, 3, 4, 5–6. Here we introduce a manufacturable platform7 for quantum computing with photons. We benchmark a set of monolithically integrated silicon-photonics-based modules to generate, manipulate, network and detect heralded photonic qubits, demonstrating dual-rail photonic qubits with 99.98% ± 0.01% state preparation and measurement fidelity, Hong–Ou–Mandel (HOM) quantum interference between independent photon sources with 99.50% ± 0.25% visibility, two-qubit fusion with 99.22% ± 0.12% fidelity and a chip-to-chip qubit interconnect with 99.72% ± 0.04% fidelity, conditional on photon detection and not accounting for loss. We preview a selection of next-generation technologies: low-loss silicon nitride (SiN) waveguides and components to address loss, as well as fabrication-tolerant photon sources, high-efficiency photon-number-resolving detectors (PNRDs), low-loss chip-to-fibre coupling and barium titanate (BTO) electro-optic phase shifters for high-performance fast switching. A manufacturable platform for quantum computing with photons is introduced and a set of monolithically integrated silicon-photonics-based modules is benchmarked, demonstrating dual-rail photonic qubits with performance close to thresholds required for operation.},
  doi={10.1038/s41586-025-08820-7},
  journal={Nature}
}

@article{coccia2024evolution,
  title={Evolution of Quantum Computing: Theoretical and Innovation Management Implications for Emerging Quantum Industry},
  author={M. Coccia and S. Roshani and M. Mosleh},
  year={2024},
  url={https://www.semanticscholar.org/paper/867170876dff8379701023591883ad9609653210},
  abstract={Quantum computing is a vital research field in science and technology. One of the fundamental questions hardly known is how quantum computing research is developing to support scientific advances and the evolution of path-breaking technologies for economic, industrial, and social change. This study confronts the question here by applying methods of computational scientometrics for publication analyses to explain the structure and evolution of quantum computing research and technologies over a 30-year period. Results reveal that the evolution of quantum computing from 1990 to 2020 has a considerable average increase of connectivity in the network (growth of degree centrality measure), a moderate increase of the average influence of nodes on the flow between nodes (little growth of betweenness centrality measure), and a little reduction of the easiest access of each node to all other nodes (closeness centrality measure). This evolutionary dynamics is due to the increase in size and complexity of the network in quantum computing research over time. This study also suggests that the network of quantum computing has a transition from hardware to software research that supports accelerated evolution of technological pathways in quantum image processing, quantum machine learning, and quantum sensors. Theoretical implications of this study show the morphological evolution of the network in quantum computing from a symmetric to an asymmetric shape driven by new inter-related research fields and emerging technological trajectories. Findings here suggest best practices of innovation management based on R&D investments in new technological directions of quantum computing having a high potential for growth and impact in science and markets.},
  doi={10.1109/TEM.2022.3175633},
  journal={IEEE transactions on engineering management}
}

@article{rouze2024efficient,
  title={Efficient Thermalization and Universal Quantum Computing with Quantum Gibbs Samplers},
  author={Cambyse Rouz'e and Daniel Stilck França and Álvaro M. Alhambra},
  year={2024},
  url={https://www.semanticscholar.org/paper/ab38d797e2bb769ade768b67d143996535072bd5},
  abstract={The preparation of quantum Gibbs states is a crucial task in quantum computing. In this work, we prove that a recently introduced, efficiently implementable dissipative evolution thermalizes to the Gibbs state in time scaling polynomially or even logarithmically with system size at high enough temperatures for any Hamiltonian that satisfies a Lieb-Robinson bound, such as local Hamiltonians on a lattice. Furthermore, we show the efficient adiabatic preparation of the associated purifications or "thermofield double" states. To the best of our knowledge, these are the first results rigorously establishing the efficient preparation of high-temperature Gibbs states and their purifications. In the low-temperature regime, we show that implementing this family of dissipative evolutions for inverse temperatures polynomial in the system's size is computationally equivalent to standard quantum computations. On a technical level, for high temperatures, our proof makes use of the mapping of the generator of the evolution into a Hamiltonian, and then connecting its convergence to that of the infinite temperature limit. We further present an alternative proof that is based on showing the exponential decay of the so-called oscillator norm, yielding convergence in logarithmic times. For low temperature, we instead perform a perturbation at zero temperature and resort to circuit-to-Hamiltonian mappings akin to the proof of universality of quantum adiabatic computing. Taken together, our results show that a family of quasi-local dissipative evolutions efficiently prepares a large class of quantum many-body states of interest, and has the potential to mirror the success of classical Monte Carlo methods for quantum many-body systems.},
  doi={10.1145/3717823.3718268},
  journal={Symposium on the Theory of Computing}
}

@article{wille2024mqt,
  title={The MQT Handbook : A Summary of Design Automation Tools and Software for Quantum Computing},
  author={Robert Wille and Lucas Berent and Tobias Forster and Jagatheesan Kunasaikaran and Kevin Mato and Tom Peham and Nils Quetschlich and Damian Rovara and Aaron Sander and Ludwig Schmid and Daniel Schönberger and Yannick Stade and Lukas Burgholzer},
  year={2024},
  url={https://www.semanticscholar.org/paper/3bd031ad93f5c1d013170a51050d6657f24fbb81},
  abstract={Quantum computers are becoming a reality and numerous quantum computing applications with a near-term perspective (e.g., for finance, chemistry, machine learning, and optimization) and with a long-term perspective (e.g., for cryptography or unstructured search) are currently being investigated. However, designing and realizing potential applications for these devices in a scalable fashion requires automated, efficient, and user-friendly software tools that cater to the needs of end users, engineers, and physicists at every level of the entire quantum software stack. Many of the problems to be tackled in that regard are similar to design problems from the classical realm for which sophisticated design automation tools have been developed in the previous decades.The Munich Quantum Toolkit (MQT) is a collection of software tools for quantum computing developed by the Chair for Design Automation at the Technical University of Munich which explicitly utilizes this design automation expertise. Our overarching objective is to provide solutions for design tasks across the entire quantum software stack. This entails high-level support for end users in realizing their applications, efficient methods for the classical simulation, compilation, and verification of quantum circuits, tools for quantum error correction, support for physical design, and more. These methods are supported by corresponding data structures (such as decision diagrams or the ZX-calculus) and core methods (such as SAT encodings/solvers). All of the developed tools are available as open-source implementations and are hosted on github.com/cda-tum.Note: A live version of this document is available at mqt.readthedocs.io.},
  doi={10.1109/QSW62656.2024.00013},
  journal={2024 IEEE International Conference on Quantum Software (QSW)}
}

@article{herman2023quantum,
  title={Quantum computing for finance},
  author={Dylan Herman and Cody Googin and Xiaoyuan Liu and Yue Sun and A. Galda and Ilya Safro and Marco Pistoia and Y. Alexeev},
  year={2023},
  url={https://www.semanticscholar.org/paper/ea160adc0d78e54669281b8b145bcd832e648fee},
  abstract={Quantum computers are expected to surpass classical computers and transform industries. This Review focuses on quantum computing for financial applications and provides a summary for physicists on potential advantages and limitations of quantum techniques, as well as challenges that physicists could help tackle. Quantum algorithms for stochastic modelling, optimization and machine learning are applicable to various financial problems. Quantum Monte Carlo integration and gradient estimation can provide quadratic speedup over classical methods, but more work is required to reduce the amount of quantum resources for early fault-tolerant feasibility and achieving an actual speedup. Financial optimization problems can be continuous (convex or non-convex), discrete or mixed, and thus quantum algorithms for these problems can be applied. The advantages and challenges of quantum machine learning for classical problems are also apparent in finance. Quantum computers are expected to surpass the computational capabilities of classical computers and have a transformative impact on numerous industry sectors. We present a comprehensive summary of the state of the art of quantum computing for financial applications, with particular emphasis on stochastic modelling, optimization and machine learning. This Review is aimed at physicists, so it outlines the classical techniques used by the financial industry and discusses the potential advantages and limitations of quantum techniques. Finally, we look at the challenges that physicists could help tackle.},
  doi={10.1038/s42254-023-00603-1},
  journal={Nature Reviews Physics}
}

@article{meglio2023quantum,
  title={Quantum Computing for High-Energy Physics: State of the Art and Challenges},
  author={A. D. Meglio and K. Jansen and I. Tavernelli and C. Alexandrou and Srinivasan Arunachalam and C. Bauer and K. Borras and S. Carrazza and Arianna Crippa and V. Croft and R. D. Putter and Andrea Delgado and V. Dunjko and D. Egger and E. Fernández-Combarro and Elina Fuchs and L. Funcke and D. González-Cuadra and M. Grossi and Jad C. Halimeh and Zoe Holmes and S. Kuhn and D. Lacroix and R. Lewis and D. Lucchesi and Miriam Lucio Martínez and F. Meloni and Antonio Mezzacapo and S. Montangero and Lento Nagano and V. Radescu and Enrique Rico Ortega and A. Roggero and Julian Schuhmacher and J. Seixas and P. Silvi and P. Spentzouris and F. Tacchino and K. Temme and K. Terashi and Jordi Tura i Brugués and Cenk Tüysüz and S. Vallecorsa and U. Wiese and Shinjae Yoo and Jinglei Zhang},
  year={2023},
  url={https://www.semanticscholar.org/paper/194073c405e9c362c955e9ac31979ddbc037ff8d},
  abstract={Quantum computers offer an intriguing path for a paradigmatic change of computing in the natural sciences and beyond, with the potential for achieving a so-called quantum advantage—namely, a significant (in some cases exponential) speedup of numerical simulations. The rapid development of hardware devices with various realizations of qubits enables the execution of small-scale but representative applications on quantum computers. In particular, the high-energy physics community plays a pivotal role in accessing the power of quantum computing, since the field is a driving source for challenging computational problems. This concerns, on the theoretical side, the exploration of models that are very hard or even impossible to address with classical techniques and, on the experimental side, the enormous data challenge of newly emerging experiments, such as the upgrade of the Large Hadron Collider. In this Roadmap paper, led by CERN, DESY, and IBM, we provide the status of high-energy physics quantum computations and give examples of theoretical and experimental target benchmark applications, which can be addressed in the near future. Having in mind hardware with about 100 qubits capable of executing several thousand two-qubit gates, where possible, we also provide resource estimates for the examples given using error-mitigated quantum computing. The ultimate declared goal of this task force is therefore to trigger further research in the high-energy physics community to develop interesting use cases for demonstrations on near-term quantum computers.
 
 
 
 
 Published by the American Physical Society
 2024
 
 
},
  doi={10.1103/PRXQuantum.5.037001},
  journal={PRX Quantum}
}

@article{yang2023survey,
  title={A Survey of Important Issues in Quantum Computing and Communications},
  author={Zebo Yang and Maede Zolanvari and R. Jain},
  year={2023},
  url={https://www.semanticscholar.org/paper/d90efed28eb3670c45adf91a1b8c1cb7e1eb340d},
  abstract={Driven by the rapid progress in quantum hardware, recent years have witnessed a furious race for quantum technologies in both academia and industry. Universal quantum computers have supported up to hundreds of qubits, while the scale of quantum annealers has reached three orders of magnitude (i.e., thousands of qubits). Quantum computing power keeps climbing. Race has consequently generated an overwhelming number of research papers and documents. This article provides an entry point for interested readers to learn the key aspects of quantum computing and communications from a computer science perspective. It begins with a pedagogical introduction and then reviews the key milestones and recent advances in quantum computing. In this article, the key elements of a quantum Internet are categorized into four important issues, which are investigated in detail: a) quantum computers, b) quantum networks, c) quantum cryptography, and d) quantum machine learning. Finally, the article identifies and discusses the main barriers, the major research directions, and trends.},
  doi={10.1109/COMST.2023.3254481},
  journal={IEEE Communications Surveys and Tutorials}
}

@article{wintersperger2023neutral,
  title={Neutral atom quantum computing hardware: performance and end-user perspective},
  author={Karen Wintersperger and F. Dommert and Thomas Ehmer and Andrey Hoursanov and Johannes Klepsch and Wolfgang Mauerer and G. Reuber and T. Strohm and Ming-Yu Yin and S. Luber},
  year={2023},
  url={https://www.semanticscholar.org/paper/c45fa92e955b8e94cb6fd9a35ae13927c835d5ed},
  abstract={We present an industrial end-user perspective on the current state of quantum computing hardware for one specific technological approach, the neutral atom platform. Our aim is to assist developers in understanding the impact of the specific properties of these devices on the effectiveness of algorithm execution. Based on discussions with different vendors and recent literature, we discuss the performance data of the neutral atom platform. Specifically, we focus on the physical qubit architecture, which affects state preparation, qubit-to-qubit connectivity, gate fidelities, native gate instruction set, and individual qubit stability. These factors determine both the quantum-part execution time and the end-to-end wall clock time relevant for end-users, but also the ability to perform fault-tolerant quantum computation in the future. We end with an overview of which applications have been shown to be well suited for the peculiar properties of neutral atom-based quantum computers.},
  doi={10.1140/epjqt/s40507-023-00190-1},
  journal={EPJ Quantum Technology}
}

@article{qiao2023splitting,
  title={Splitting phonons: Building a platform for linear mechanical quantum computing},
  author={Hong Qiao and É. Dumur and Gustav Andersson and Haoxiong Yan and M. Chou and J. Grebel and C. Conner and Yash J. Joshi and Jacob M. Miller and R. Povey and Xuntao Wu and Andrew N. Cleland},
  year={2023},
  url={https://www.semanticscholar.org/paper/53103ae318a19569ac82cee5062de2cf73bf386c},
  abstract={Linear optical quantum computing provides a desirable approach to quantum computing, with only a short list of required computational elements. The similarity between photons and phonons points to the interesting potential for linear mechanical quantum computing using phonons in place of photons. Although single-phonon sources and detectors have been demonstrated, a phononic beam splitter element remains an outstanding requirement. Here we demonstrate such an element, using two superconducting qubits to fully characterize a beam splitter with single phonons. We further use the beam splitter to demonstrate two-phonon interference, a requirement for two-qubit gates in linear computing. This advances a new solid-state system for implementing linear quantum computing, further providing straightforward conversion between itinerant phonons and superconducting qubits. Description Editor’s summary Phonons are the fundamental quantum vibrations within materials, with individual phonons representing the collective motion of many trillions of atoms. Efforts are underway to determine whether these mechanical vibrations can be developed into a quantum-computing architecture just like their optical cousin, photons. Qiao et al. demonstrate a beam splitter for single phonons and controlled two-phonon interference. Adding to the ability to launch and detect single phonons, a beam splitter now provides the final piece in the toolbox to develop a mechanically based platform for quantum computing. —Ian S. Osborne A beam splitter for phonons completes the toolbox required to develop a mechanically based quantum computing system.},
  doi={10.1126/science.adg8715},
  journal={Science}
}

@article{flöther2023state,
  title={The state of quantum computing applications in health and medicine},
  author={Frederik F. Flöther},
  year={2023},
  url={https://www.semanticscholar.org/paper/6e74403ab75d0080c056fd66702ab1f54f04d9b1},
  abstract={
 Quantum computing hardware and software have made enormous strides over the last years1. Questions around quantum computing’s impact on research and society have changed from “if” to “when/how”. The 2020s have been described as the “quantum decade”, and the first production solutions that drive scientific and business value are expected to become available over the next years. Medicine, including fields in healthcare and life sciences, has seen a flurry of quantum-related activities and experiments in the last few years (although medicine and quantum theory have arguably been entangled ever since Schrödinger’s cat2). The initial focus was on biochemical and computational biology problems3,4,5,6,7,8; recently, however, clinical and medical quantum solutions have drawn increasing interest. The rapid emergence of quantum computing in health and medicine necessitates a mapping of the landscape.
 In this review, clinical and medical proof-of-concept quantum computing applications are outlined and put into perspective. These consist of over 40 experimental and theoretical studies from the last few years. The use case areas span genomics, clinical research and discovery, diagnostics, and treatments and interventions. Quantum machine learning (QML) in particular has rapidly evolved and shown to be competitive with classical benchmarks in recent medical research. Near-term QML algorithms, for instance, quantum support vector classifiers and quantum neural networks, have been trained with diverse clinical and real-world data sets. This includes studies in generating new molecular entities as drug candidates, diagnosing based on medical image classification, predicting patient persistence, forecasting treatment effectiveness, and tailoring radiotherapy. The use cases and the applied algorithms are summarized.
 In addition, this review provides an outlook on medicine in the quantum era. There has been much discussion about healthcare’s journey towards precision medicine and the quadruple aim (better health, lower costs, enhanced patient experiences, and improved healthcare practitioner work lives)9. While a range of technical and ethical challenges remain, quantum computing is poised to become a key enabler for advancing towards the holy grail: keeping people healthy through proactive medical care and guidance at the level of an individual.},
  doi={10.1017/qut.2023.4},
  journal={Research Directions: Quantum Technologies}
}

@article{gutperle2017entanglement,
  title={Entanglement entropy vs. free energy in IIB supergravity duals for 5d SCFTs},
  author={M. Gutperle and Chrysostomos Marasinou and A. Trivella and C. Uhlemann},
  year={2017},
  url={https://www.semanticscholar.org/paper/8e45b2d11c230d21dfdf01df7001514b3b95554e},
  abstract={A bstractWe study entanglement entropy and the free energy in recently constructed holographic duals for 5d SCFTs in type IIB supergravity. The solutions exhibit mild singularities, which could potentially complicate holographic applications. We use the relation of the entanglement entropy for a spherical entangling surface to the free energy of the field theory on the five sphere as a well-motivated benchmark to assess how problematic the singularities are. The holographic supergravity computations give well-defined results for both quantities and they satisfy the expected relations. This supports the interpretation of the solutions as holographic duals for 5d SCFTs and gives first quantitative indications for the nature of the dual SCFTs.},
  doi={10.1007/JHEP09(2017)125}
}

@article{svozil2002dangerous,
  title={The dangerous misconceptions of Sir Karl Raimund Popper},
  author={Karl Svozil},
  year={2002},
  url={http://arxiv.org/abs/physics/0207115v3},
  abstract={Insofar as Sir Karl Raimund Popper's writings deal with political statements, they are evident; yet insofar as they deal with scientific issues, they are misleading. If applied to the concrete implementation of science, such as distribution of research funds and (peer) review, they would seriously impede progress.},
  journal={arXiv}
}

@article{cooray2017bayesian,
  title={Bayesian Belief Updating of Spatiotemporal Seizure Dynamics},
  author={Gerald K Cooray and Richard Rosch and Torsten Baldeweg and Louis Lemieux and Karl Friston and Biswa Sengupta},
  year={2017},
  url={http://arxiv.org/abs/1705.07278v2},
  abstract={Epileptic seizure activity shows complicated dynamics in both space and time. To understand the evolution and propagation of seizures spatially extended sets of data need to be analysed. We have previously described an efficient filtering scheme using variational Laplace that can be used in the Dynamic Causal Modelling (DCM) framework [Friston, 2003] to estimate the temporal dynamics of seizures recorded using either invasive or non-invasive electrical recordings (EEG/ECoG). Spatiotemporal dynamics are modelled using a partial differential equation -- in contrast to the ordinary differential equation used in our previous work on temporal estimation of seizure dynamics [Cooray, 2016]. We provide the requisite theoretical background for the method and test the ensuing scheme on simulated seizure activity data and empirical invasive ECoG data. The method provides a framework to assimilate the spatial and temporal dynamics of seizure activity, an aspect of great physiological and clinical importance.},
  journal={arXiv}
}

@article{jafarian2019structure,
  title={Structure Learning in Coupled Dynamical Systems and Dynamic Causal Modelling},
  author={Amirhossein Jafarian and Peter Zeidman and Vladimir Litvak and Karl Friston},
  year={2019},
  url={http://arxiv.org/abs/1904.03093v2},
  abstract={Identifying a coupled dynamical system out of many plausible candidates, each of which could serve as the underlying generator of some observed measurements, is a profoundly ill posed problem that commonly arises when modelling real world phenomena. In this review, we detail a set of statistical procedures for inferring the structure of nonlinear coupled dynamical systems (structure learning), which has proved useful in neuroscience research. A key focus here is the comparison of competing models of (ie, hypotheses about) network architectures and implicit coupling functions in terms of their Bayesian model evidence. These methods are collectively referred to as dynamical casual modelling (DCM). We focus on a relatively new approach that is proving remarkably useful; namely, Bayesian model reduction (BMR), which enables rapid evaluation and comparison of models that differ in their network architecture. We illustrate the usefulness of these techniques through modelling neurovascular coupling (cellular pathways linking neuronal and vascular systems), whose function is an active focus of research in neurobiology and the imaging of coupled neuronal systems.},
  journal={arXiv}
}

@article{friston2020sophisticated,
  title={Sophisticated Inference},
  author={Karl Friston and Lancelot Da Costa and Danijar Hafner and Casper Hesp and Thomas Parr},
  year={2020},
  url={http://arxiv.org/abs/2006.04120v1},
  abstract={Active inference offers a first principle account of sentient behaviour, from which special and important cases can be derived, e.g., reinforcement learning, active learning, Bayes optimal inference, Bayes optimal design, etc. Active inference resolves the exploitation-exploration dilemma in relation to prior preferences, by placing information gain on the same footing as reward or value. In brief, active inference replaces value functions with functionals of (Bayesian) beliefs, in the form of an expected (variational) free energy. In this paper, we consider a sophisticated kind of active inference, using a recursive form of expected free energy. Sophistication describes the degree to which an agent has beliefs about beliefs. We consider agents with beliefs about the counterfactual consequences of action for states of affairs and beliefs about those latent states. In other words, we move from simply considering beliefs about 'what would happen if I did that' to 'what would I believe about what would happen if I did that'. The recursive form of the free energy functional effectively implements a deep tree search over actions and outcomes in the future. Crucially, this search is over sequences of belief states, as opposed to states per se. We illustrate the competence of this scheme, using numerical simulations of deep decision problems.},
  journal={arXiv}
}

@article{fagerholm2020principle,
  title={The principle of stationary action in neural systems},
  author={Erik D. Fagerholm and Karl J. Friston and Rosalyn J. Moran and Robert Leech},
  year={2020},
  url={http://arxiv.org/abs/2010.02993v1},
  abstract={The principle of stationary action is a cornerstone of modern physics, providing a powerful framework for investigating dynamical systems found in classical mechanics through to quantum field theory. However, computational neuroscience, despite its heavy reliance on concepts in physics, is anomalous in this regard as its main equations of motion are not compatible with a Lagrangian formulation and hence with the principle of stationary action. Taking the Dynamic Causal Modelling neuronal state equation, Hodgkin-Huxley model, and the Leaky Integrate-and-Fire model as examples, we show that it is possible to write complex oscillatory forms of these equations in terms of a single Lagrangian. We therefore bring mathematical descriptions in computational neuroscience under the remit of the principle of stationary action and use this reformulation to express symmetries and associated conservation laws arising in neural systems.},
  journal={arXiv}
}

@article{fagerholm2018breaking,
  title={Breaking the bonds of weak coupling: the dynamic causal modelling of oscillator amplitudes},
  author={Erik D. Fagerholm and Rosalyn J. Moran and Inês R. Violante and Robert Leech and Karl J. Friston},
  year={2018},
  url={http://arxiv.org/abs/1812.06315v1},
  abstract={Models of coupled oscillators are useful in describing a wide variety of phenomena in physics, biology and economics. These models typically rest on the premise that the oscillators are weakly coupled, meaning that amplitudes can be assumed to be constant and dynamics can therefore be described purely in terms of phase differences. Whilst mathematically convenient, the restrictive nature of the weak coupling assumption can limit the explanatory power of these phase-coupled oscillator models. We therefore propose an extension to the weakly-coupled oscillator model that incorporates both amplitude and phase as dependent variables. We use the bilinear neuronal state equations of dynamic causal modelling as a foundation in deriving coupled differential equations that describe the activity of both weakly and strongly coupled oscillators. We show that weakly-coupled oscillator models are inadequate in describing the processes underlying the temporally variable signals observed in a variety of systems. We demonstrate that phase-coupled models perform well on simulations of weakly coupled systems but fail when connectivity is no longer weak. On the other hand, using Bayesian model selection, we show that our phase-amplitude coupling model can describe non-weakly coupled systems more effectively despite the added complexity associated with using amplitude as an extra dependent variable. We demonstrate the advantage of our phase-amplitude model in the context of model-generated data, as well as of a simulation of inter-connected pendula, neural local field potential recordings in rodents under anaesthesia and international economic gross domestic product data.},
  journal={arXiv}
}

@article{jafarian2020parametric,
  title={Parametric dynamic causal modelling},
  author={Amirhossein Jafarian and Peter Zeidman and Rob. C Wykes and Matthew Walker and Karl J. Friston},
  year={2020},
  url={http://arxiv.org/abs/2008.11650v1},
  abstract={This technical note introduces parametric dynamic causal modelling, a method for inferring slow changes in biophysical parameters that control fluctuations of fast neuronal states. The application domain we have in mind is inferring slow changes in variables (e.g., extracellular ion concentrations or synaptic efficacy) that underlie phase transitions in brain activity (e.g., paroxysmal seizure activity). The scheme is efficient and yet retains a biophysical interpretation, in virtue of being based on established neural mass models that are equipped with a slow dynamic on the parameters (such as synaptic rate constants or effective connectivity). In brief, we use an adiabatic approximation to summarise fast fluctuations in hidden neuronal states (and their expression in sensors) in terms of their second order statistics; namely, their complex cross spectra. This allows one to specify and compare models of slowly changing parameters (using Bayesian model reduction) that generate a sequence of empirical cross spectra of electrophysiological recordings. Crucially, we use the slow fluctuations in the spectral power of neuronal activity as empirical priors on changes in synaptic parameters. This introduces a circular causality, in which synaptic parameters underwrite fast neuronal activity that, in turn, induces activity-dependent plasticity in synaptic parameters. In this foundational paper, we describe the underlying model, establish its face validity using simulations and provide an illustrative application to a chemoconvulsant animal model of seizure activity.},
  journal={arXiv}
}

@article{yang2020bayesian,
  title={Bayesian data assimilation for estimating epidemic evolution: a COVID-19 study},
  author={Xian Yang and Shuo Wang and Yuting Xing and Ling Li and Richard Yi Da Xu and Karl J. Friston and Yike Guo},
  year={2020},
  url={http://arxiv.org/abs/2101.01532v2},
  abstract={The evolution of epidemiological parameters, such as instantaneous reproduction number Rt, is important for understanding the transmission dynamics of infectious diseases. Current estimates of time-varying epidemiological parameters often face problems such as lagging observations, averaging inference, and improper quantification of uncertainties. To address these problems, we propose a Bayesian data assimilation framework for time-varying parameter estimation. Specifically, this framework is applied to Rt estimation, resulting in the state-of-the-art DARt system. With DARt, time misalignment caused by lagging observations is tackled by incorporating observation delays into the joint inference of infections and Rt; the drawback of averaging is overcome by instantaneously updating upon new observations and developing a model selection mechanism that captures abrupt changes; the uncertainty is quantified and reduced by employing Bayesian smoothing. We validate the performance of DARt and demonstrate its power in revealing the transmission dynamics of COVID-19. The proposed approach provides a promising solution for accurate and timely estimating transmission dynamics from reported data.},
  journal={arXiv}
}

@article{slifer2013novel,
  title={Novel Physics With Tensor Polarized Targets},
  author={Karl Slifer and Elena Long},
  year={2013},
  url={http://arxiv.org/abs/1311.4835v3},
  abstract={The Jefferson Lab PAC recently approved an experiment which will use an enhanced tensor po- larized solid target. This exciting development holds the potential of initiating a new field of tensor spin physics at JLab. Experiments which utilize tensor polarized targets can help clarify how nuclear properties arise from partonic degrees of freedom, provide unique insight into short range correlations and quark angular momentum, and help pin down the polarization of the quark sea.},
  journal={arXiv}
}

@article{friston2020second,
  title={Second waves, social distancing, and the spread of COVID-19 across America},
  author={Karl J. Friston and Thomas Parr and Peter Zeidman and Adeel Razi and Guillaume Flandin and Jean Daunizeau and Oliver J. Hulme and Alexander J. Billig and Vladimir Litvak and Cathy J. Price and Rosalyn J. Moran and Christian Lambert},
  year={2020},
  url={http://arxiv.org/abs/2004.13017v1},
  abstract={We recently described a dynamic causal model of a COVID-19 outbreak within a single region. Here, we combine several of these (epidemic) models to create a (pandemic) model of viral spread among regions. Our focus is on a second wave of new cases that may result from loss of immunity--and the exchange of people between regions--and how mortality rates can be ameliorated under different strategic responses. In particular, we consider hard or soft social distancing strategies predicated on national (Federal) or regional (State) estimates of the prevalence of infection in the population. The modelling is demonstrated using timeseries of new cases and deaths from the United States to estimate the parameters of a factorial (compartmental) epidemiological model of each State and, crucially, coupling between States. Using Bayesian model reduction, we identify the effective connectivity between States that best explains the initial phases of the outbreak in the United States. Using the ensuing posterior parameter estimates, we then evaluate the likely outcomes of different policies in terms of mortality, working days lost due to lockdown and demands upon critical care. The provisional results of this modelling suggest that social distancing and loss of immunity are the two key factors that underwrite a return to endemic equilibrium.},
  journal={arXiv}
}

@article{wegner2022frontal,
  title={Frontal effective connectivity increases with task demands and time on task: a Dynamic Causal Model of electrocorticogram in macaque monkeys},
  author={Katharina Wegner and Charles R. E. Wilson and Emmanuel Procyk and Karl J. Friston and Frederik Van de Steen and Dimitris A. Pinotsis and Daniele Marinazzo},
  year={2022},
  url={http://arxiv.org/abs/2202.10021v3},
  abstract={We apply Dynamic Causal Models to electrocorticogram recordings from two macaque monkeys performing a problem-solving task that engages working memory, and induces time-on-task effects. We thus provide a computational account of changes in effective connectivity within two regions of the fronto-parietal network, the dorsolateral prefrontal cortex and the pre-supplementary motor area. We find that forward connections between the two regions increased in strength when task demands increased, and as the experimental session progressed. Similarities in the effects of task demands and time on task allow us to interpret changes in frontal connectivity in terms of increased attentional effort allocation that compensates cognitive fatigue.},
  doi={10.51628/001c.68433},
  journal={arXiv}
}

@article{fagerholm2019dynamic,
  title={Dynamic causal modelling of phase-amplitude interactions},
  author={Erik D. Fagerholm and Rosalyn J. Moran and Ines R. Violante and Robert Leech and Karl J. Friston},
  year={2019},
  url={http://arxiv.org/abs/1909.08509v1},
  abstract={Models of coupled oscillators are used to describe a wide variety of phenomena in neuroimaging. These models typically rest on the premise that oscillator dynamics do not evolve beyond their respective limit cycles, and hence that interactions can be described purely in terms of phase differences. Whilst mathematically convenient, the restrictive nature of phase-only models can limit their explanatory power. We therefore propose a generalisation of dynamic causal modelling that incorporates both phase and amplitude. This allows for the separate quantifications of phase and amplitude contributions to the connectivity between neural regions. We establish, using model-generated data and simulations of coupled pendula, that phase-only models perform well only under weak coupling conditions. We also show that, despite their higher complexity, phase-amplitude models can describe strongly coupled systems more effectively than their phase-only counterparts. We relate our findings to four metrics commonly used in neuroimaging: the Kuramoto order parameter, cross-correlation, phase-lag index, and spectral entropy. We find that, with the exception of spectral entropy, the phase-amplitude model is able to capture all metrics more effectively than the phase-only model. We then demonstrate, using local field potential recordings in rodents and functional magnetic resonance imaging in macaque monkeys, that amplitudes in oscillator models play an important role in describing neural dynamics in anaesthetised brain states.},
  journal={arXiv}
}

@article{friston2020dynamic,
  title={Dynamic causal modelling of COVID-19},
  author={Karl J. Friston and Thomas Parr and Peter Zeidman and Adeel Razi and Guillaume Flandin and Jean Daunizeau and Oliver J. Hulme and Alexander J. Billig and Vladimir Litvak and Rosalyn J. Moran and Cathy J. Price and Christian Lambert},
  year={2020},
  url={http://arxiv.org/abs/2004.04463v1},
  abstract={This technical report describes a dynamic causal model of the spread of coronavirus through a population. The model is based upon ensemble or population dynamics that generate outcomes, like new cases and deaths over time. The purpose of this model is to quantify the uncertainty that attends predictions of relevant outcomes. By assuming suitable conditional dependencies, one can model the effects of interventions (e.g., social distancing) and differences among populations (e.g., herd immunity) to predict what might happen in different circumstances. Technically, this model leverages state-of-the-art variational (Bayesian) model inversion and comparison procedures, originally developed to characterise the responses of neuronal ensembles to perturbations. Here, this modelling is applied to epidemiological populations to illustrate the kind of inferences that are supported and how the model per se can be optimised given timeseries data. Although the purpose of this paper is to describe a modelling protocol, the results illustrate some interesting perspectives on the current pandemic; for example, the nonlinear effects of herd immunity that speak to a self-organised mitigation process.},
  journal={arXiv}
}

@article{friston2020tracking,
  title={Tracking and tracing in the UK: a dynamic causal modelling study},
  author={Karl J. Friston and Thomas Parr and Peter Zeidman and Adeel Razi and Guillaume Flandin and Jean Daunizeau and Oliver J. Hulme and Alexander J. Billig and Vladimir Litvak and Cathy J. Price and Rosalyn J. Moran and Christian Lambert},
  year={2020},
  url={http://arxiv.org/abs/2005.07994v1},
  abstract={By equipping a previously reported dynamic causal model of COVID-19 with an isolation state, we modelled the effects of self-isolation consequent on tracking and tracing. Specifically, we included a quarantine or isolation state occupied by people who believe they might be infected but are asymptomatic, and only leave if they test negative. We recovered maximum posteriori estimates of the model parameters using time series of new cases, daily deaths, and tests for the UK. These parameters were used to simulate the trajectory of the outbreak in the UK over an 18-month period. Several clear-cut conclusions emerged from these simulations. For example, under plausible (graded) relaxations of social distancing, a rebound of infections within weeks is unlikely. The emergence of a later second wave depends almost exclusively on the rate at which we lose immunity, inherited from the first wave. There exists no testing strategy that can attenuate mortality rates, other than by deferring or delaying a second wave. A sufficiently powerful tracking and tracing policy--implemented at the time of writing (10th May 2020)--will defer any second wave beyond a time horizon of 18 months. Crucially, this deferment is within current testing capabilities (requiring an efficacy of tracing and tracking of about 20% of asymptomatic infected cases, with less than 50,000 tests per day). These conclusions are based upon a dynamic causal model for which we provide some construct and face validation, using a comparative analysis of the United Kingdom and Germany, supplemented with recent serological studies.},
  journal={arXiv}
}

@article{friston2020effective,
  title={Effective immunity and second waves: a dynamic causal modelling study},
  author={Karl J. Friston and Thomas Parr and Peter Zeidman and Adeel Razi and Guillaume Flandin and Jean Daunizeau and Oliver J. Hulme and Alexander J. Billig and Vladimir Litvak and Cathy J. Price and Rosalyn J. Moran and Anthony Costello and Deenan Pillay and Christian Lambert},
  year={2020},
  url={http://arxiv.org/abs/2006.09429v1},
  abstract={This technical report addresses a pressing issue in the trajectory of the coronavirus outbreak; namely, the rate at which effective immunity is lost following the first wave of the pandemic. This is a crucial epidemiological parameter that speaks to both the consequences of relaxing lockdown and the propensity for a second wave of infections. Using a dynamic causal model of reported cases and deaths from multiple countries, we evaluated the evidence models of progressively longer periods of immunity. The results speak to an effective population immunity of about three months that, under the model, defers any second wave for approximately six months in most countries. This may have implications for the window of opportunity for tracking and tracing, as well as for developing vaccination programmes, and other therapeutic interventions.},
  journal={arXiv}
}

@article{parr2020dynamic,
  title={Dynamic causal modelling of immune heterogeneity},
  author={Thomas Parr and Anjali Bhat and Peter Zeidman and Aimee Goel and Alexander J. Billig and Rosalyn Moran and Karl J. Friston},
  year={2020},
  url={http://arxiv.org/abs/2009.08411v1},
  abstract={An interesting inference drawn by some Covid-19 epidemiological models is that there exists a proportion of the population who are not susceptible to infection -- even at the start of the current pandemic. This paper introduces a model of the immune response to a virus. This is based upon the same sort of mean-field dynamics as used in epidemiology. However, in place of the location, clinical status, and other attributes of people in an epidemiological model, we consider the state of a virus, B and T-lymphocytes, and the antibodies they generate. Our aim is to formalise some key hypotheses as to the mechanism of resistance. We present a series of simple simulations illustrating changes to the dynamics of the immune response under these hypotheses. These include attenuated viral cell entry, pre-existing cross-reactive humoral (antibody-mediated) immunity, and enhanced T-cell dependent immunity. Finally, we illustrate the potential application of this sort of model by illustrating variational inversion (using simulated data) of this model to illustrate its use in testing hypotheses. In principle, this furnishes a fast and efficient immunological assay--based on sequential serology--that provides a (i) quantitative measure of latent immunological responses and (ii) a Bayes optimal classification of the different kinds of immunological response (c.f., glucose tolerance tests used to test for insulin resistance). This may be especially useful in assessing SARS-CoV-2 vaccines.},
  journal={arXiv}
}

@article{schilling2022predictive,
  title={Predictive coding and stochastic resonance as fundamental principles of auditory perception},
  author={Achim Schilling and William Sedley and Richard Gerum and Claus Metzner and Konstantin Tziridis and Andreas Maier and Holger Schulze and Fan-Gang Zeng and Karl J. Friston and Patrick Krauss},
  year={2022},
  url={http://arxiv.org/abs/2204.03354v2},
  abstract={How is information processed in the brain during perception? Mechanistic insight is achieved only when experiments are employed to test formal or computational models. In analogy to lesion studies, phantom perception may serve as a vehicle to understand the fundamental processing principles underlying auditory perception. With a special focus on tinnitus -- as the prime example of auditory phantom perception -- we review recent work at the intersection of artificial intelligence, psychology, and neuroscience. In particular, we discuss why everyone with tinnitus suffers from hearing loss, but not everyone with hearing loss suffers from tinnitus. We argue that the increase of sensory precision due to Bayesian inference could be caused by intrinsic neural noise and lead to a prediction error in the cerebral cortex. Hence, two fundamental processing principles - being ubiquitous in the brain - provide the most explanatory power for the emergence of tinnitus: predictive coding as a top-down, and stochastic resonance as a complementary bottom-up mechanism. We conclude that both principles play a crucial role in healthy auditory perception.},
  journal={arXiv}
}

@article{fagerholm2019estimating,
  title={Estimating quantities conserved by virtue of scale invariance in timeseries},
  author={Erik D. Fagerholm and W. M. C. Foulkes and Yasir Gallero-Salas and Fritjof Helmchen and Karl J. Friston and Rosalyn J. Moran and Robert Leech},
  year={2019},
  url={http://arxiv.org/abs/1911.00775v1},
  abstract={In contrast to the symmetries of translation in space, rotation in space, and translation in time, the known laws of physics are not universally invariant under transformation of scale. However, the action can be invariant under change of scale in the special case of a scale free dynamical system that can be described in terms of a Lagrangian, that itself scales inversely with time. Crucially, this means symmetries under change of scale can exist in dynamical systems under certain constraints. Our contribution lies in the derivation of a generalised scale invariant Lagrangian - in the form of a power series expansion - that satisfies these constraints. This generalised Lagrangian furnishes a normal form for dynamic causal models (i.e., state space models based upon differential equations) that can be used to distinguish scale invariance (scale symmetry) from scale freeness in empirical data. We establish face validity with an analysis of simulated data and then show how scale invariance can be identified - and how the associated conserved quantities can be estimated - in neuronal timeseries.},
  journal={arXiv}
}

@article{fagerholm2020fighting,
  title={Fighting seizures with seizures: diffusion and stability in neural systems},
  author={Erik D. Fagerholm and Chayanin Tangwiriyasakul and Karl J. Friston and Inês R. Violante and Steven Williams and David W. Carmichael and Suejen Perani and Federico E. Turkheimer and Rosalyn J. Moran and Robert Leech and Mark P. Richardson},
  year={2020},
  url={http://arxiv.org/abs/2005.00805v1},
  abstract={Seizure activity is a ubiquitous and pernicious pathophysiology that, in principle, should yield to mathematical treatments of (neuronal) ensemble dynamics - and therefore interventions on stochastic chaos. A seizure can be characterised as a deviation of neural activity from a stable dynamical regime, i.e. one in which signals fluctuate only within a limited range. In silico treatments of neural activity are an important tool for understanding how the brain can achieve stability, as well as how pathology can lead to seizures and potential strategies for mitigating instabilities, e.g. via external stimulation. Here, we demonstrate that the (neuronal) state equation used in Dynamic Causal Modelling generalises to a Fokker-Planck formalism when propagation of neuronal activity along structural connections is considered. Using the Jacobian of this generalised state equation, we show that an initially unstable system can be rendered stable via a reduction in diffusivity (i.e., connectivity that disperses neuronal fluctuations). We show, for neural systems prone to epileptic seizures, that such a reduction can be achieved via external stimulation. Specifically, we show that this stimulation should be applied in such a way as to temporarily mirror epileptic activity in the areas adjoining an affected brain region - thus 'fighting seizures with seizures'. We offer proof of principle using simulations based on functional neuroimaging data collected from patients with idiopathic generalised epilepsy, in which we successfully suppress pathological activity in a distinct sub-network. Our hope is that this technique can form the basis for real-time monitoring and intervention devices that are capable of suppressing or even preventing seizures in a non-invasive manner.},
  journal={arXiv}
}

@article{fagerholm2019network,
  title={Network constraints in scale free dynamical systems},
  author={Erik D. Fagerholm and W. M. C. Foulkes and Yasir Gallero-Salas and Fritjof Helmchen and Karl J. Friston and Robert Leech and Rosalyn J. Moran},
  year={2019},
  url={http://arxiv.org/abs/1908.06678v1},
  abstract={Scale free dynamics are observed in a variety of physical and biological systems. These include neural activity in which evidence for scale freeness has been reported using a range of imaging modalities. Here, we derive the ways in which connections within a network must transform - relative to system size - in order to maintain scale freeness and test these theoretical transformations via simulations. First, we explore the known invariance of planetary motion for orbits varying in size. Using parametric empirical Bayesian modelling and a generic dynamical systems model, we show that we recover Kepler's third law from orbital timeseries, using our proposed transformations; thereby providing construct validation. We then demonstrate that the dynamical critical exponent is inversely proportional to the time rescaling exponent, in the context of coarse graining operations. Using murine calcium imaging data, we then show that the dynamical critical exponent can be estimated in an empirical biological setting. Specifically, we compare dynamical critical exponents - associated with spontaneous and task states in two regions of imaged cortex - that are classified as task-relevant and task-irrelevant. We find, consistently across animals, that the task-irrelevant region exhibits higher dynamical critical exponents during spontaneous activity than during task performance. Conversely, the task-relevant region is associated with higher dynamical critical exponents in task vs. spontaneous states. These data support the idea that higher dynamical critical exponents, within relevant cortical structures, underwrite neuronal processing due to the implicit increase in cross-scale information transmission.},
  journal={arXiv}
}

@article{maluf2018variations,
  title={Variations of the Energy of Free Particles in the pp-Wave Spacetimes},
  author={J. W. Maluf and J. F. da Rocha-Neto and S. C. Ulhoa and F. L. Carneiro},
  year={2018},
  url={http://arxiv.org/abs/1805.05513v2},
  abstract={We consider the action of exact plane gravitational waves, or pp-waves, on free particles. The analysis is carried out by investigating the variations of the geodesic trajectories of the particles, before and after the passage of the wave. The initial velocities of the particles are non-vanishing. We evaluate numerically the Kinetic energy per unit mass of the free particles, and obtain interesting, quasi-periodic behaviour of the variations of the Kinetic energy with respect to the width $λ$ of the gaussian that represents the wave. The variation of the energy of the free particle is expected to be exactly minus the variation of the energy of the gravitational field, and therefore provides an estimation of the local variation of the gravitational energy. The investigation is carried out in the context of short bursts of gravitational waves, and of waves described by normalised gaussians, that yield impulsive waves in a certain limit.},
  doi={10.3390/universe4070074},
  journal={arXiv}
}

@article{guerra2025multigrid,
  title={Multigrid methods for total variation},
  author={Felipe Guerra and Tuomo Valkonen},
  year={2025},
  url={http://arxiv.org/abs/2502.18659v1},
  abstract={Based on a nonsmooth coherence condition, we construct and prove the convergence of a forward-backward splitting method that alternates between steps on a fine and a coarse grid. Our focus is a total variation regularised inverse imaging problems, specifically, their dual problems, for which we develop in detail the relevant coarse-grid problems. We demonstrate the performance of our method on total variation denoising and magnetic resonance imaging.},
  doi={10.1007/978-3-031-92369-2_1},
  journal={arXiv}
}

@article{safdari2015shape,
  title={On the shape of the free boundary of variational inequalities with gradient constraints},
  author={Mohammad Safdari},
  year={2015},
  url={http://arxiv.org/abs/1508.02026v1},
  abstract={In this paper we derive an estimate on the number of local maxima of the free boundary of some variational inequalities with pointwise gradient constraints. This also gives an estimate on the number of connected components of the free boundary.},
  journal={arXiv}
}

@article{lobzaev2024protein,
  title={Protein engineering using variational free energy approximation},
  author={E. Lobzaev and Michael A. Herrera and Martyna Kasprzyk and G. Stracquadanio},
  year={2024},
  url={https://www.semanticscholar.org/paper/4eab7d751c1112eb2dce7f626c09db280b0a140f},
  abstract={Engineering proteins is a challenging task requiring the exploration of a vast design space. Traditionally, this is achieved using Directed Evolution (DE), which is a laborious process. Generative deep learning, instead, can learn biological features of functional proteins from sequence and structural datasets and return novel variants. However, most models do not generate thermodynamically stable proteins, thus leading to many non-functional variants. Here we propose a model called PRotein Engineering by Variational frEe eNergy approximaTion (PREVENT), which generates stable and functional variants by learning the sequence and thermodynamic landscape of a protein. We evaluate PREVENT by designing 40 variants of the conditionally essential E. coli phosphotransferase N-acetyl-L-glutamate kinase (EcNAGK). We find 85% of the variants to be functional, with 55% of them showing similar growth rate compared to the wildtype enzyme, despite harbouring up to 9 mutations. Our results support a new approach that can significantly accelerate protein engineering. Generative deep learning models can generate novel proteins, but these are often not functional due to thermodynamic instability. Here, authors present a method to learn both the sequence and thermodynamic landscape of a protein and generate new functional variants.},
  doi={10.1038/s41467-024-54814-w},
  journal={Nature Communications}
}

@article{sutter2023variational,
  title={Variational free energy based macroscopical modeling of ferroelectroelasticity},
  author={F. Sutter and M. Kamlah},
  year={2023},
  url={https://www.semanticscholar.org/paper/33060bb74166497b39e041fc5997c3a0d4dae640},
  doi={10.1016/j.jmps.2023.105341},
  journal={Journal of the mechanics and physics of solids}
}

@article{li2025deep,
  title={Deep Variational Free Energy Calculation of Hydrogen Hugoniot},
  author={Zihang Li and Hao Xie and Xi-Shang Dong and Lei Wang},
  year={2025},
  url={https://www.semanticscholar.org/paper/2b6af51a937df3579d3ab9d81bef8fdca43a14f4},
  abstract={We develop a deep variational free energy framework to compute the equation of state of hydrogen in the warm dense matter region. This method parameterizes the variational density matrix of hydrogen nuclei and electrons at finite temperature using three deep generative models: a normalizing flow model that represents the Boltzmann distribution of the classical nuclei, an autoregressive transformer that models the distribution of electrons in excited states, and a permutational equivariant flow model that constructs backflow coordinates for electrons in Hartree-Fock orbitals. By jointly optimizing the three neural networks to minimize the variational free energy, we obtain the equation of state and related thermodynamic properties of dense hydrogen. We compare our results with other theoretical and experimental results on the deuterium Hugoniot curve, aiming to resolve existing discrepancies. The calculated results provide a valuable benchmark for deuterium in the warm dense matter region.},
  doi={10.48550/arXiv.2507.18540},
  journal={arXiv.org}
}

@article{xie2022deep,
  title={Deep Variational Free Energy Approach to Dense Hydrogen.},
  author={H.-j. Xie and Ziqun Li and Han Wang and Linfeng Zhang and Lei Wang},
  year={2022},
  url={https://www.semanticscholar.org/paper/7ae5080c0945d722ee31068bea317af151e73cfe},
  abstract={We developed a deep generative model-based variational free energy approach to the equations of state of dense hydrogen. We employ a normalizing flow network to model the proton Boltzmann distribution and a fermionic neural network to model the electron wave function at given proton positions. By jointly optimizing the two neural networks we reached a comparable variational free energy to the previous coupled electron-ion Monte Carlo calculation. The predicted equation of state of dense hydrogen under planetary conditions is denser than the findings of ab initio molecular dynamics calculation and empirical chemical model. Moreover, direct access to the entropy and free energy of dense hydrogen opens new opportunities in planetary modeling and high-pressure physics research.},
  doi={10.1103/PhysRevLett.131.126501},
  journal={Physical Review Letters}
}

@article{beckers2022principled,
  title={Principled Pruning of Bayesian Neural Networks Through Variational Free Energy Minimization},
  author={Jim Beckers and Bart Van Erp and Ziyue Zhao and K. Kondrashov and Bert de Vries},
  year={2022},
  url={https://www.semanticscholar.org/paper/90229121782f3ebfae75645a5c97cc9a03cb5051},
  abstract={Bayesian model reduction provides an efficient approach for comparing the performance of all nested sub-models of a model, without re-evaluating any of these sub-models. Until now, Bayesian model reduction has been applied mainly in the computational neuroscience community on simple models. In this paper, we formulate and apply Bayesian model reduction to perform principled pruning of Bayesian neural networks, based on variational free energy minimization. Direct application of Bayesian model reduction, however, gives rise to approximation errors. Therefore, a novel iterative pruning algorithm is presented to alleviate the problems arising with naive Bayesian model reduction, as supported experimentally on the publicly available UCI datasets for different inference algorithms. This novel parameter pruning scheme solves the shortcomings of current state-of-the-art pruning methods that are used by the signal processing community. The proposed approach has a clear stopping criterion and minimizes the same objective that is used during training. Next to these benefits, our experiments indicate better model performance in comparison to state-of-the-art pruning schemes.},
  doi={10.1109/OJSP.2023.3337718},
  journal={IEEE Open Journal of Signal Processing}
}

@article{giese2021extension,
  title={Extension of the Variational Free Energy Profile and Multistate Bennett Acceptance Ratio Methods for High-Dimensional Potential of Mean Force Profile Analysis.},
  author={Timothy J. Giese and S. Ekesan and D. York},
  year={2021},
  url={https://www.semanticscholar.org/paper/1735030e1206de9f2f2e9db8b7c85453305a7b39},
  abstract={We redevelop the variational free energy profile (vFEP) method using a cardinal B-spline basis to extend the method for analyzing free energy surfaces (FESs) involving three or more reaction coordinates. We also implemented software for evaluating high-dimensional profiles based on the multistate Bennett acceptance ratio (MBAR) method which constructs an unbiased probability density from global reweighting of the observed samples. The MBAR method takes advantage of a fast algorithm for solving the unbinned weighted histogram (UWHAM)/MBAR equations which replaces the solution of simultaneous equations with a nonlinear optimization of a convex function. We make use of cardinal B-splines and multiquadric radial basis functions to obtain smooth, differentiable MBAR profiles in arbitrary high dimensions. The cardinal B-spline vFEP and MBAR methods are compared using three example systems that examine 1D, 2D, and 3D profiles. Both methods are found to be useful and produce nearly indistinguishable results. The vFEP method is found to be 150 times faster than MBAR when applied to periodic 2D profiles, but the MBAR method is 4.5 times faster than vFEP when evaluating unbounded 3D profiles. In agreement with previous comparisons, we find the vFEP method produces superior FESs when the overlap between umbrella window simulations decreases. Finally, the associative reaction mechanism of hammerhead ribozyme is characterized using 3D, 4D, and 6D profiles, and the higher-dimensional profiles are found to have smaller reaction barriers by as much as 1.5 kcal/mol. The methods presented here have been implemented into the FE-ToolKit software package along with new methods for network-wide free energy analysis in drug discovery.},
  doi={10.1021/acs.jpca.1c00736},
  journal={Journal of Physical Chemistry A}
}

@article{baltieri2021kalman,
  title={Kalman filters as the steady-state solution of gradient descent on variational free energy},
  author={M. Baltieri and Takuya Isomura},
  year={2021},
  url={https://www.semanticscholar.org/paper/e8b97e604cbc2a9430fcb017133491d3d4d2d50c},
  abstract={The Kalman filter is an algorithm for the estimation of hidden variables in dynamical systems under linear Gauss-Markov assumptions with widespread applications across different fields. Recently, its Bayesian interpretation has received a growing amount of attention especially in neuroscience, robotics and machine learning. In neuroscience, in particular, models of perception and control under the banners of predictive coding, optimal feedback control, active inference and more generally the so-called Bayesian brain hypothesis, have all heavily relied on ideas behind the Kalman filter. Active inference, an algorithmic theory based on the free energy principle, specifically builds on approximate Bayesian inference methods proposing a variational account of neural computation and behaviour in terms of gradients of variational free energy. Using this ambitious framework, several works have discussed different possible relations between free energy minimisation and standard Kalman filters. With a few exceptions, however, such relations point at a mere qualitative resemblance or are built on a set of very diverse comparisons based on purported differences between free energy minimisation and Kalman filtering. In this work, we present a straightforward derivation of Kalman filters consistent with active inference via a variational treatment of free energy minimisation in terms of gradient descent. The approach considered here offers a more direct link between models of neural dynamics as gradient descent and standard accounts of perception and decision making based on probabilistic inference, further bridging the gap between hypotheses about neural implementation and computational principles in brain and behavioural sciences.},
  journal={arXiv.org}
}

@article{xie2022deep2,
  title={A deep variational free energy approach to dense hydrogen},
  author={Hao Xie and Zi-Hang Li and Han Wang and Linfeng Zhang and Lei Wang},
  year={2022},
  url={https://www.semanticscholar.org/paper/a1205a1b4b19e489f9696ca15c75ff62502a473d},
  doi={10.48550/arXiv.2209.06095},
  journal={arXiv.org}
}

@article{henriksen2020variational,
  title={Variational Free Energy and Economics Optimizing With Biases and Bounded Rationality},
  author={M. Henriksen},
  year={2020},
  url={https://www.semanticscholar.org/paper/7db285472b4c974058229640990fe43b432865aa},
  abstract={The purpose of this paper is to offer a new framework for understanding action, optimization, and choice when applied to economic theory more generally. By drawing upon the concept known as the variational free energy principle, the paper will explore how this principle can be used to temper rational choice theory by re-formulating how agents optimize. The approach will result in agent behavior that encompasses a wide range of so-called cognitive biases, as seen in the scientific literature of behavioral economics, but instead of using these biases as further indications of market inefficiencies or market failures, the paper will likewise attempt to show the limits to which these biases can inform or critique standard economic theory. The paper therefore offers up a “middle of the road” approach, in which the neoclassical agent is not quite as “rational” as rational choice theory assumes, but at the same time, not quite as irrational as behavioral economics would often have us believe.},
  doi={10.3389/fpsyg.2020.549187},
  journal={Frontiers in Psychology}
}

@article{isomura2018vitro,
  title={In vitro neural networks minimise variational free energy},
  author={Takuya Isomura and Karl J. Friston},
  year={2018},
  url={https://www.semanticscholar.org/paper/5037b0342ba925b418068e69f1b734685ac6dc0d},
  abstract={In this work, we address the neuronal encoding problem from a Bayesian perspective. Specifically, we ask whether neuronal responses in an in vitro neuronal network are consistent with ideal Bayesian observer responses under the free energy principle. In brief, we stimulated an in vitro cortical cell culture with stimulus trains that had a known statistical structure. We then asked whether recorded neuronal responses were consistent with variational message passing based upon free energy minimisation (i.e., evidence maximisation). Effectively, this required us to solve two problems: first, we had to formulate the Bayes-optimal encoding of the causes or sources of sensory stimulation, and then show that these idealised responses could account for observed electrophysiological responses. We describe a simulation of an optimal neural network (i.e., the ideal Bayesian neural code) and then consider the mapping from idealised in silico responses to recorded in vitro responses. Our objective was to find evidence for functional specialisation and segregation in the in vitro neural network that reproduced in silico learning via free energy minimisation. Finally, we combined the in vitro and in silico results to characterise learning in terms of trajectories in a variational information plane of accuracy and complexity.},
  doi={10.1038/s41598-018-35221-w},
  journal={Scientific Reports}
}

@article{ramstead2020is,
  title={Is the Free-Energy Principle a Formal Theory of Semantics? From Variational Density Dynamics to Neural and Phenotypic Representations},
  author={M. Ramstead and Karl J. Friston and Inês Hipólito},
  year={2020},
  url={https://www.semanticscholar.org/paper/8493a53d586e4f345358c13ec81ba7c413a7f646},
  abstract={The aim of this paper is twofold: (1) to assess whether the construct of neural representations plays an explanatory role under the variational free-energy principle and its corollary process theory, active inference; and (2) if so, to assess which philosophical stance—in relation to the ontological and epistemological status of representations—is most appropriate. We focus on non-realist (deflationary and fictionalist-instrumentalist) approaches. We consider a deflationary account of mental representation, according to which the explanatorily relevant contents of neural representations are mathematical, rather than cognitive, and a fictionalist or instrumentalist account, according to which representations are scientifically useful fictions that serve explanatory (and other) aims. After reviewing the free-energy principle and active inference, we argue that the model of adaptive phenotypes under the free-energy principle can be used to furnish a formal semantics, enabling us to assign semantic content to specific phenotypic states (the internal states of a Markovian system that exists far from equilibrium). We propose a modified fictionalist account—an organism-centered fictionalism or instrumentalism. We argue that, under the free-energy principle, pursuing even a deflationary account of the content of neural representations licenses the appeal to the kind of semantic content involved in the ‘aboutness’ or intentionality of cognitive systems; our position is thus coherent with, but rests on distinct assumptions from, the realist position. We argue that the free-energy principle thereby explains the aboutness or intentionality in living systems and hence their capacity to parse their sensory stream using an ontology or set of semantic factors.},
  doi={10.3390/e22080889},
  journal={Entropy}
}

@article{friston2007variational,
  title={Variational free energy and the Laplace approximation},
  author={Karl J. Friston and J. Mattout and N. Trujillo-Barreto and J. Ashburner and W. Penny},
  year={2007},
  url={https://www.semanticscholar.org/paper/329705a255360c8f86a10d909a92794ed8a0857a},
  doi={10.1016/j.neuroimage.2006.08.035},
  journal={NeuroImage}
}

@article{yang2018refining,
  title={Refining Collective Coordinates and Improving Free Energy Representation in Variational Enhanced Sampling.},
  author={Y. Yang and M. Parrinello},
  year={2018},
  url={https://www.semanticscholar.org/paper/17fe6d3c7c4e133d112ba48fdc8a3a69288f79b6},
  abstract={Collective variables are used often in many enhanced sampling methods, and their choice is a crucial factor in determining sampling efficiency. However, at times, searching for good collective variables can be challenging. In a recent paper, we combined time-lagged independent component analysis with well-tempered metadynamics in order to obtain improved collective variables from metadynamics runs that use lower quality collective variables [ McCarty, J.; Parrinello, M. J. Chem. Phys. 2017 , 147 , 204109 ]. In this work, we extend these ideas to variationally enhanced sampling. This leads to an efficient scheme that is able to make use of the many advantages of the variational scheme. We apply the method to alanine-3 in water. From an alanine-3 variationally enhanced sampling trajectory in which all the six dihedral angles are biased, we extract much better collective variables able to describe in exquisite detail the protein complex free energy surface in a low dimensional representation. The success of this investigation is helped by a more accurate way of calculating the correlation functions needed in the time-lagged independent component analysis and from the introduction of a new basis set to describe the dihedral angles arrangement.},
  doi={10.1021/acs.jctc.8b00231},
  journal={Journal of Chemical Theory and Computation}
}

@article{chen2023free,
  title={On the free energy of vector spin glasses with nonconvex interactions},
  author={Hong-Bin Chen and J. Mourrat},
  year={2023},
  url={https://www.semanticscholar.org/paper/1ae8d8e4f21f092fd4624387e1c1a35187f9d4e5},
  abstract={The limit free energy of spin-glass models with convex interactions can be represented as a variational problem involving an explicit functional. Models with non-convex interactions are much less well-understood, and simple variational formulas involving the same functional are known to be invalid in general. We show here that a slightly weaker property of the limit free energy does extend to non-convex models. Indeed, under the assumption that the limit free energy exists, we show that this limit can always be represented as a critical value of the said functional. Up to a small perturbation of the parameters defining the model, we also show that any subsequential limit of the law of the overlap matrix is a critical point of this functional. We believe that these results capture the fundamental conclusions of the non-rigorous replica method.},
  doi={10.2140/pmp.2025.6.1},
  journal={Probability and Mathematical Physics}
}

@article{hartmann2017variational,
  title={Variational Characterization of Free Energy: Theory and Algorithms},
  author={C. Hartmann and Lorenz Richter and C. Schütte and Wei Zhang},
  year={2017},
  url={https://www.semanticscholar.org/paper/7c3dfeefc47c334e61b98a6d87dcf2a7ff547521},
  abstract={The article surveys and extends variational formulations of the thermodynamic free energy and discusses their information-theoretic content from the perspective of mathematical statistics. We revisit the well-known Jarzynski equality for nonequilibrium free energy sampling within the framework of importance sampling and Girsanov change-of-measure transformations. The implications of the different variational formulations for designing efficient stochastic optimization and nonequilibrium simulation algorithms for computing free energies are discussed and illustrated.},
  doi={10.3390/e19110626},
  journal={Entropy}
}

@article{cyron2017mechanobiological,
  title={Mechanobiological free energy: a variational approach to tensional homeostasis in tissue equivalents},
  author={C. Cyron and R. Aydin},
  year={2017},
  url={https://www.semanticscholar.org/paper/3901e7e3e6597893e8eef61d031b15c7a3bb4842},
  doi={10.1002/zamm.201600126}
}

@article{gaybalmaz2017free,
  title={A free energy Lagrangian variational formulation of the Navier–Stokes–Fourier system},
  author={F. Gay-Balmaz and Hiroaki Yoshimura},
  year={2017},
  url={https://www.semanticscholar.org/paper/88aadc9281b66479ebde738158f2209ae0a814e0},
  abstract={We present a variational formulation for the Navier–Stokes–Fourier system based on a free energy Lagrangian. This formulation is a systematic infinite-dimensional extension of the variational approach to the thermodynamics of discrete systems using the free energy, which complements the Lagrangian variational formulation using the internal energy developed in [F. Gay-Balmaz and H. Yoshimura, A Lagrangian variational formulation for nonequilibrium thermodynamics, Part II: Continuum systems, J. Geom. Phys. 111 (2017) 194–212] as one employs temperature, rather than entropy, as an independent variable. The variational derivation is first expressed in the material (or Lagrangian) representation, from which the spatial (or Eulerian) representation is deduced. The variational framework is intrinsically written in a differential-geometric form that allows the treatment of the Navier–Stokes–Fourier system on Riemannian manifolds.},
  doi={10.1142/S0219887819400061},
  journal={International Journal of Geometric Methods in Modern Physics (IJGMMP)}
}

@article{valsson2014variational,
  title={Variational approach to enhanced sampling and free energy calculations.},
  author={O. Valsson and M. Parrinello},
  year={2014},
  url={https://www.semanticscholar.org/paper/4708b42a7ed23633e083c549e5fa7d5ca6866702},
  abstract={The ability of widely used sampling methods, such as molecular dynamics or Monte Carlo simulations, to explore complex free energy landscapes is severely hampered by the presence of kinetic bottlenecks. A large number of solutions have been proposed to alleviate this problem. Many are based on the introduction of a bias potential which is a function of a small number of collective variables. However constructing such a bias is not simple. Here we introduce a functional of the bias potential and an associated variational principle. The bias that minimizes the functional relates in a simple way to the free energy surface. This variational principle can be turned into a practical, efficient, and flexible sampling method. A number of numerical examples are presented which include the determination of a three-dimensional free energy surface. We argue that, beside being numerically advantageous, our variational approach provides a convenient and novel standpoint for looking at the sampling problem.},
  doi={10.1103/PhysRevLett.113.090601},
  journal={Physical Review Letters}
}

@article{watanabe2009upper,
  title={Upper bound for variational free energy of Bayesian networks},
  author={Kazuho Watanabe and Motoki Shiga and Sumio Watanabe},
  year={2009},
  url={https://www.semanticscholar.org/paper/97fc3fec51e89bf7be8a58c53271bedc791e8edd},
  doi={10.1007/s10994-008-5099-x},
  journal={Machine-mediated learning}
}

@article{mackay2001local,
  title={Local Minima, Symmetry-breaking, and Model Pruning in Variational Free Energy Minimization},
  author={D. Mackay},
  year={2001},
  url={https://www.semanticscholar.org/paper/f009659777096291db6db7508a9d47f8795a285b}
}

@article{lin2005variational,
  title={A variational free energy minimization interpretation of multiuser detection in CDMA},
  author={D. Lin and Teng Joon Lim},
  year={2005},
  url={https://www.semanticscholar.org/paper/b32c2b2a92b57332246ea63eab55ece5e3453bf2},
  doi={10.1109/GLOCOM.2005.1577915},
  journal={GLOBECOM '05. IEEE Global Telecommunications Conference, 2005.}
}

@article{silva2022solving,
  title={Solving the Job Shop Scheduling Problem with Ant Colony Optimization},
  author={Alysson Ribeiro da Silva},
  year={2022},
  url={http://arxiv.org/abs/2209.05284v1},
  abstract={The Job Shop Schedule Problem (JSSP) refers to the ability of an agent to allocate tasks that should be executed in a specified time in a machine from a cluster. The task allocation can be achieved from several methods, however, this report it is explored the ability of the Ant Colony Optimization to generate feasible solutions for several JSSP instances. This proposal models the JSSP as a complete graph since disjunct models can prevent the ACO from exploring all the search space. Several instances of the JSSP were used to evaluate the proposal. Results suggest that the algorithm can reach optimum solutions for easy and harder instances with a selection of parameters.},
  journal={arXiv}
}

@article{philippe2022first,
  title={First Competitive Ant Colony Scheme for the CARP},
  author={Lacomme Philippe and Prins Christian and Tanguy Alain},
  year={2022},
  url={http://arxiv.org/abs/2212.02228v1},
  abstract={This paper addresses the Capacitated Arc Routing Problem (CARP) using an Ant Colony Optimization scheme. Ant Colony schemes can compute solutions for medium scale instances of VRP. The proposed Ant Colony is dedicated to large-scale instances of CARP with more than 140 nodes and 190 arcs to service. The Ant Colony scheme is coupled with a local search procedure and provides high quality solutions. The benchmarks we carried out prove possible to obtain solutions as profitable as CARPET ones can be obtained using such scheme when a sufficient number of iterations is devoted to the ants. It competes with the Genetic Algorithm of Lacomme et al. regarding solution quality but it is more time consuming on large scale instances. The method has been intensively benchmarked on the well-known instances of Eglese, DeArmon and the last ones of Belenguer and Benavent. This research report is a step forward CARP resolution by Ant Colony proving ant schemes can compete with Taboo search methods and Genetic Algorithms},
  journal={arXiv}
}

@article{mane2022overview,
  title={Overview and Applications of GPGPU Based Parallel Ant Colony Optimization},
  author={Sandeep U Mane and Pooja S. Lokare and Harsha R. Gaikwad},
  year={2022},
  url={http://arxiv.org/abs/2203.11487v1},
  abstract={Ant Colony Optimization algorithm is a magnificent heuristics technique based on the behavior of ants. Parallel computing is a means to achieve the desired results in commensurable execution time. Parallelization of Ant Colony Optimization is utilized to solve large and complex problems. This paper discusses a review of different parallelization approaches for Ant Colony Optimization and its various applications. Parallel Ant Colony Optimization has proved to be a successful approach for highly constrained problems such as routing, scheduling, timetabling, etc. Parallelization of Ant Colony Optimization reduces the execution time, increases the size of the problem, etc.},
  journal={arXiv}
}

@article{ghaffari2015distributed,
  title={Distributed House-Hunting in Ant Colonies},
  author={Mohsen Ghaffari and Cameron Musco and Tsvetomira Radeva and Nancy Lynch},
  year={2015},
  url={http://arxiv.org/abs/1505.03799v1},
  abstract={We introduce the study of the ant colony house-hunting problem from a distributed computing perspective. When an ant colony's nest becomes unsuitable due to size constraints or damage, the colony must relocate to a new nest. The task of identifying and evaluating the quality of potential new nests is distributed among all ants. The ants must additionally reach consensus on a final nest choice and the full colony must be transported to this single new nest. Our goal is to use tools and techniques from distributed computing theory in order to gain insight into the house-hunting process.   We develop a formal model for the house-hunting problem inspired by the behavior of the Temnothorax genus of ants. We then show a Ω(log n) lower bound on the time for all n ants to agree on one of k candidate nests. We also present two algorithms that solve the house-hunting problem in our model. The first algorithm solves the problem in optimal O(log n) time but exhibits some features not characteristic of natural ant behavior. The second algorithm runs in O(k log n) time and uses an extremely simple and natural rule for each ant to decide on the new nest.},
  journal={arXiv}
}

@article{abdelmoaty2024comparative,
  title={Comparative Analysis of Four Prominent Ant Colony Optimization Variants: Ant System, Rank-Based Ant System, Max-Min Ant System, and Ant Colony System},
  author={Ahmed Mohamed Abdelmoaty and Ibrahim Ihab Ibrahim},
  year={2024},
  url={http://arxiv.org/abs/2405.15397v1},
  abstract={This research conducts a comparative analysis of four Ant Colony Optimization (ACO) variants -- Ant System (AS), Rank-Based Ant System (ASRank), Max-Min Ant System (MMAS), and Ant Colony System (ACS) -- for solving the Traveling Salesman Problem (TSP). Our findings demonstrate that algorithm performance is significantly influenced by problem scale and instance type. ACS excels in smaller TSP instances due to its rapid convergence, while PACS proves more adaptable for medium-sized problems. MMAS consistently achieves competitive results across all scales, particularly for larger instances, due to its ability to avoid local optima. ASRank, however, struggles to match the performance of the other algorithms. This research provides insights into the strengths and weaknesses of these ACO variants, guiding the selection of the most suitable algorithm for specific TSP applications.},
  journal={arXiv}
}

@article{ramos2004artificial,
  title={Artificial Ant Colonies in Digital Image Habitats - A Mass Behaviour Effect Study on Pattern Recognition},
  author={Vitorino Ramos and Filipe Almeida},
  year={2004},
  url={http://arxiv.org/abs/cs/0412086v1},
  abstract={Some recent studies have pointed that, the self-organization of neurons into brain-like structures, and the self-organization of ants into a swarm are similar in many respects. If possible to implement, these features could lead to important developments in pattern recognition systems, where perceptive capabilities can emerge and evolve from the interaction of many simple local rules. The principle of the method is inspired by the work of Chialvo and Millonas who developed the first numerical simulation in which swarm cognitive map formation could be explained. From this point, an extended model is presented in order to deal with digital image habitats, in which artificial ants could be able to react to the environment and perceive it. Evolution of pheromone fields point that artificial ant colonies could react and adapt appropriately to any type of digital habitat. KEYWORDS: Swarm Intelligence, Self-Organization, Stigmergy, Artificial Ant Systems, Pattern Recognition and Perception, Image Segmentation, Gestalt Perception Theory, Distributed Computation.},
  journal={arXiv}
}

@article{macktoobian2022selforganizing,
  title={Self-organizing nest migration dynamics synthesis for ant colony systems},
  author={Matin Macktoobian},
  year={2022},
  url={http://arxiv.org/abs/2210.03975v1},
  abstract={In this study, we synthesize a novel dynamical approach for ant colonies enabling them to migrate to new nest sites in a self-organizing fashion. In other words, we realize ant colony migration as a self-organizing phenotype-level collective behavior. For this purpose, we first segment the edges of the graph of ants' pathways. Then, each segment, attributed to its own pheromone profile, may host an ant. So, multiple ants may occupy an edge at the same time. Thanks to this segment-wise edge formulation, ants have more selection options in the course of their pathway determination, thereby increasing the diversity of their colony's emergent behaviors. In light of the continuous pheromone dynamics of segments, each edge owns a spatio-temporal piece-wise continuous pheromone profile in which both deposit and evaporation processes are unified. The passive dynamics of the proposed migration mechanism is sufficiently rich so that an ant colony can migrate to the vicinity of a new nest site in a self-organizing manner without any external supervision. In particular, we perform extensive simulations to test our migration dynamics applied to a colony including 500 ants traversing a pathway graph comprising 200 nodes and 4000 edges which are segmented based on various resolutions. The obtained results exhibit the effectiveness of our strategy.},
  doi={10.1007/s11047-022-09923-0},
  journal={arXiv}
}

@article{pang2009experiment,
  title={Experiment Study of Entropy Convergence of Ant Colony Optimization},
  author={Chao-Yang Pang and Chong-Bao Wang and Ben-Qiong Hu},
  year={2009},
  url={http://arxiv.org/abs/0905.1751v4},
  abstract={Ant colony optimization (ACO) has been applied to the field of combinatorial optimization widely. But the study of convergence theory of ACO is rare under general condition. In this paper, the authors try to find the evidence to prove that entropy is related to the convergence of ACO, especially to the estimation of the minimum iteration number of convergence. Entropy is a new view point possibly to studying the ACO convergence under general condition. Key Words: Ant Colony Optimization, Convergence of ACO, Entropy},
  journal={arXiv}
}

@article{yang2024tensorized,
  title={Tensorized Ant Colony Optimization for GPU Acceleration},
  author={Luming Yang and Tao Jiang and Ran Cheng},
  year={2024},
  url={http://arxiv.org/abs/2404.04895v2},
  abstract={Ant Colony Optimization (ACO) is renowned for its effectiveness in solving Traveling Salesman Problems, yet it faces computational challenges in CPU-based environments, particularly with large-scale instances. In response, we introduce a Tensorized Ant Colony Optimization (TensorACO) to utilize the advancements of GPU acceleration. As the core, TensorACO fully transforms ant system and ant path into tensor forms, a process we refer to as tensorization. For the tensorization of ant system, we propose a preprocessing method to reduce the computational overhead by calculating the probability transition matrix. In the tensorization of ant path, we propose an index mapping method to accelerate the update of pheromone matrix by replacing the mechanism of sequential path update with parallel matrix operations. Additionally, we introduce an Adaptive Independent Roulette (AdaIR) method to overcome the challenges of parallelizing ACO's selection mechanism on GPUs. Comprehensive experiments demonstrate the superior performance of TensorACO achieving up to 1921$\times$ speedup over standard ACO. Moreover, the AdaIR method further improves TensorACO's convergence speed by 80% and solution quality by 2%. Source codes are available at https://github.com/EMI-Group/tensoraco.},
  journal={arXiv}
}

@article{lin2024carbon,
  title={A Carbon Aware Ant Colony System (CAACS)},
  author={Marina Lin and Laura P. Schaposnik},
  year={2024},
  url={http://arxiv.org/abs/2407.09404v2},
  abstract={In an era where sustainability is becoming increasingly crucial, we introduce a new Carbon-Aware Ant Colony System (CAACS) Algorithm that addresses the Generalized Traveling Salesman Problem (GTSP) while minimizing carbon emissions. This novel approach leverages the natural efficiency of ant colony pheromone trails to find optimal routes, balancing both environmental and economic objectives. By integrating sustainability into transportation models, CAACS provides a powerful tool for real-world applications, including network design, delivery route planning, and commercial aircraft logistics. Our algorithm's unique bi-objective optimization advances the study of sustainable transportation solutions.},
  journal={arXiv}
}

@article{lloyd2018solving,
  title={Solving Sudoku with Ant Colony Optimisation},
  author={Huw Lloyd and Martyn Amos},
  year={2018},
  url={http://arxiv.org/abs/1805.03545v1},
  abstract={In this paper we present a new Ant Colony Optimisation-based algorithm for Sudoku, which out-performs existing methods on large instances. Our method includes a novel anti-stagnation operator, which we call Best Value Evaporation.},
  journal={arXiv}
}

@article{kim2024ant,
  title={Ant Colony Sampling with GFlowNets for Combinatorial Optimization},
  author={Minsu Kim and Sanghyeok Choi and Hyeonah Kim and Jiwoo Son and Jinkyoo Park and Yoshua Bengio},
  year={2024},
  url={http://arxiv.org/abs/2403.07041v4},
  abstract={We present the Generative Flow Ant Colony Sampler (GFACS), a novel meta-heuristic method that hierarchically combines amortized inference and parallel stochastic search. Our method first leverages Generative Flow Networks (GFlowNets) to amortize a \emph{multi-modal} prior distribution over combinatorial solution space that encompasses both high-reward and diversified solutions. This prior is iteratively updated via parallel stochastic search in the spirit of Ant Colony Optimization (ACO), leading to the posterior distribution that generates near-optimal solutions. Extensive experiments across seven combinatorial optimization problems demonstrate GFACS's promising performances.},
  journal={arXiv}
}

@article{pang2009apply,
  title={Apply Ant Colony Algorithm to Search All Extreme Points of Function},
  author={Chao-Yang Pang and Hui Liu and Xia Li and Yun-Fei Wang and Ben-Qiong Hu},
  year={2009},
  url={http://arxiv.org/abs/0911.3209v1},
  abstract={To find all extreme points of multimodal functions is called extremum problem, which is a well known difficult issue in optimization fields. Applying ant colony optimization (ACO) to solve this problem is rarely reported. The method of applying ACO to solve extremum problem is explored in this paper. Experiment shows that the solution error of the method presented in this paper is less than 10^-8. keywords: Extremum Problem; Ant Colony Optimization (ACO)},
  journal={arXiv}
}

@article{raza2014ant,
  title={Ant Colony Optimization for Inferring Key Gene Interactions},
  author={Khalid Raza and Mahish Kohli},
  year={2014},
  url={http://arxiv.org/abs/1406.1626v1},
  abstract={Inferring gene interaction network from gene expression data is an important task in systems biology research. The gene interaction network, especially key interactions, plays an important role in identifying biomarkers for disease that further helps in drug design. Ant colony optimization is an optimization algorithm based on natural evolution and has been used in many optimization problems. In this paper, we applied ant colony optimization algorithm for inferring the key gene interactions from gene expression data. The algorithm has been tested on two different kinds of benchmark datasets and observed that it successfully identify some key gene interactions.},
  journal={arXiv}
}

@article{rukundo2021advances,
  title={Advances on image interpolation based on ant colony algorithm},
  author={Olivier Rukundo and Hanqiang Cao},
  year={2021},
  url={http://arxiv.org/abs/2104.12863v1},
  abstract={This paper presents an advance on image interpolation based on ant colony algorithm (AACA) for high-resolution image scaling. The difference between the proposed algorithm and the previously proposed optimization of bilinear interpolation based on ant colony algorithm (OBACA) is that AACA uses global weighting, whereas OBACA uses a local weighting scheme. The strength of the proposed global weighting of the AACA algorithm depends on employing solely the pheromone matrix information present on any group of four adjacent pixels to decide which case deserves a maximum global weight value or not. Experimental results are further provided to show the higher performance of the proposed AACA algorithm with reference to the algorithms mentioned in this paper.},
  doi={10.1186/s40064-016-2040-9},
  journal={arXiv}
}

@article{skinderowicz2016gpubased,
  title={The GPU-based Parallel Ant Colony System},
  author={Rafał Skinderowicz},
  year={2016},
  url={http://arxiv.org/abs/1605.02669v2},
  abstract={The Ant Colony System (ACS) is, next to Ant Colony Optimization (ACO) and the MAX-MIN Ant System (MMAS), one of the most efficient metaheuristic algorithms inspired by the behavior of ants. In this article we present three novel parallel versions of the ACS for the graphics processing units (GPUs). To the best of our knowledge, this is the first such work on the ACS which shares many key elements of the ACO and the MMAS, but differences in the process of building solutions and updating the pheromone trails make obtaining an efficient parallel version for the GPUs a difficult task. The proposed parallel versions of the ACS differ mainly in their implementations of the pheromone memory. The first two use the standard pheromone matrix, and the third uses a novel selective pheromone memory. Computational experiments conducted on several Travelling Salesman Problem (TSP) instances of sizes ranging from 198 to 2392 cities showed that the parallel ACS on Nvidia Kepler GK104 GPU (1536 CUDA cores) is able to obtain a speedup up to 24.29x vs the sequential ACS running on a single core of Intel Xeon E5-2670 CPU. The parallel ACS with the selective pheromone memory achieved speedups up to 16.85x, but in most cases the obtained solutions were of significantly better quality than for the sequential ACS.},
  doi={10.1016/j.jpdc.2016.04.014},
  journal={arXiv}
}

@article{chaudhuri2013dynamic,
  title={A Dynamic Algorithm for the Longest Common Subsequence Problem using Ant Colony Optimization Technique},
  author={Arindam Chaudhuri},
  year={2013},
  url={http://arxiv.org/abs/1307.1905v1},
  abstract={We present a dynamic algorithm for solving the Longest Common Subsequence Problem using Ant Colony Optimization Technique. The Ant Colony Optimization Technique has been applied to solve many problems in Optimization Theory, Machine Learning and Telecommunication Networks etc. In particular, application of this theory in NP-Hard Problems has a remarkable significance. Given two strings, the traditional technique for finding Longest Common Subsequence is based on Dynamic Programming which consists of creating a recurrence relation and filling a table of size . The proposed algorithm draws analogy with behavior of ant colonies function and this new computational paradigm is known as Ant System. It is a viable new approach to Stochastic Combinatorial Optimization. The main characteristics of this model are positive feedback, distributed computation, and the use of constructive greedy heuristic. Positive feedback accounts for rapid discovery of good solutions, distributed computation avoids premature convergence and greedy heuristic helps find acceptable solutions in minimum number of stages. We apply the proposed methodology to Longest Common Subsequence Problem and give the simulation results. The effectiveness of this approach is demonstrated by efficient Computational Complexity. To the best of our knowledge, this is the first Ant Colony Optimization Algorithm for Longest Common Subsequence Problem.},
  journal={arXiv}
}

@article{ismkhan2014accelerating,
  title={Accelerating the ANT Colony Optimization By Smart ANTs, Using Genetic Operator},
  author={Hassan Ismkhan},
  year={2014},
  url={http://arxiv.org/abs/1411.2897v1},
  abstract={This paper research review Ant colony optimization (ACO) and Genetic Algorithm (GA), both are two powerful meta-heuristics. This paper explains some major defects of these two algorithm at first then proposes a new model for ACO in which, artificial ants use a quick genetic operator and accelerate their actions in selecting next state. Experimental results show that proposed hybrid algorithm is effective and its performance including speed and accuracy beats other version.},
  journal={arXiv}
}

@article{lin2014hybrid,
  title={Hybrid Ant Colony Algorithm Clonal Selection in the Application of the Cloud's Resource Scheduling},
  author={Jianbiao Lin and Yukun Zhong and Xiaowei Lin and Hui Lin and Qiang Zeng},
  year={2014},
  url={http://arxiv.org/abs/1411.2528v1},
  abstract={In this paper, thinking over characteristics of ant colony optimization Algorithm, taking into account the characteristics of cloud computing, combined with clonal selection algorithm (CSA) global optimum advantage of the convergence of the clonal selection algorithm (CSA) into every ACO iteration, speeding up the convergence rate, and the introduction of reverse mutation strategy, ant colony optimization algorithm avoids local optimum. Depth study of the cloud environment ant colony clonal selection algorithm resource scheduling policy, clonal selection algorithm converges to solve optimization problems when sufficient condition for global optimal solution based on clonal selection algorithm for various applications such as BCA and CLONALG algorithm, using these sufficient condition to meet and simulation platform CloudSim achieve a simulation by extending the cloud. Experimental results show that this task can be shortened fusion algorithm running time cloud environment, improve resource utilization. Demonstrate the effectiveness of the method.},
  journal={arXiv}
}

@article{kumar2013load,
  title={Load Balancing using Ant Colony in Cloud Computing},
  author={Ranjan Kumar and G. Sahoo},
  year={2013},
  url={http://arxiv.org/abs/1312.2074v1},
  abstract={Ants are very small insects.They are capable to find food even they are complete blind. The ants lives in their nest and their job is to search food while they get hungry. We are not interested in their living style, such as how they live, how they sleep. But we are interested in how they search for food, and how they find the shortest path. The technique for finding the shortest path are now applying in cloud computing. The Ant Colony approach towards Cloud Computing gives better performance.},
  doi={10.2013/VOL3/NO.5},
  journal={arXiv}
}

@article{tran2025neufaco,
  title={NeuFACO: Neural Focused Ant Colony Optimization for Traveling Salesman Problem},
  author={Dat Thanh Tran and Khai Quang Tran and Khoi Anh Pham and Van Khu Vu and Dong Duc Do},
  year={2025},
  url={http://arxiv.org/abs/2509.16938v2},
  abstract={This study presents Neural Focused Ant Colony Optimization (NeuFACO), a non-autoregressive framework for the Traveling Salesman Problem (TSP) that combines advanced reinforcement learning with enhanced Ant Colony Optimization (ACO). NeuFACO employs Proximal Policy Optimization (PPO) with entropy regularization to train a graph neural network for instance-specific heuristic guidance, which is integrated into an optimized ACO framework featuring candidate lists, restricted tour refinement, and scalable local search. By leveraging amortized inference alongside ACO stochastic exploration, NeuFACO efficiently produces high-quality solutions across diverse TSP instances.},
  journal={arXiv}
}

@article{chavarriamolina2019clustering,
  title={Clustering via Ant Colonies: Parameter Analysis and Improvement of the Algorithm},
  author={Jeffry Chavarria-Molina and Juan Jose Fallas-Monge and Javier Trejos-Zelaya},
  year={2019},
  url={http://arxiv.org/abs/1912.01105v1},
  abstract={An ant colony optimization approach for partitioning a set of objects is proposed. In order to minimize the intra-variance, or within sum-of-squares, of the partitioned classes, we construct ant-like solutions by a constructive approach that selects objects to be put in a class with a probability that depends on the distance between the object and the centroid of the class (visibility) and the pheromone trail; the latter depends on the class memberships that have been defined along the iterations. The procedure is improved with the application of K-means algorithm in some iterations of the ant colony method. We performed a simulation study in order to evaluate the method with a Monte Carlo experiment that controls some sensitive parameters of the clustering problem. After some tuning of the parameters, the method has also been applied to some benchmark real-data sets. Encouraging results were obtained in nearly all cases.},
  journal={arXiv}
}

@article{haryanto2015warehouse,
  title={Warehouse Layout Method Based on Ant Colony and Backtracking Algorithm},
  author={Ardy Wibowo Haryanto and Adhi Kusnadi and Yustinus Eko Soelistio},
  year={2015},
  url={http://arxiv.org/abs/1508.04872v1},
  abstract={Warehouse is one of the important aspects of a company. Therefore, it is necessary to improve Warehouse Management System (WMS) to have a simple function that can determine the layout of the storage goods. In this paper we propose an improved warehouse layout method based on ant colony algorithm and backtracking algorithm. The method works on two steps. First, it generates a solutions parameter tree from backtracking algorithm. Then second, it deducts the solutions parameter by using a combination of ant colony algorithm and backtracking algorithm. This method was tested by measuring the time needed to build the tree and to fill up the space using two scenarios. The method needs 0.294 to 33.15 seconds to construct the tree and 3.23 seconds (best case) to 61.41 minutes (worst case) to fill up the warehouse. This method is proved to be an attractive alternative solution for warehouse layout system.},
  journal={arXiv}
}

@article{skackauskas2023herder,
  title={Herder Ants: Ant Colony Optimization with Aphids for Discrete Event-Triggered Dynamic Optimization Problems},
  author={Jonas Skackauskas and Tatiana Kalganova},
  year={2023},
  url={http://arxiv.org/abs/2304.07646v1},
  abstract={Currently available dynamic optimization strategies for Ant Colony Optimization (ACO) algorithm offer a trade-off of slower algorithm convergence or significant penalty to solution quality after each dynamic change occurs. This paper proposes a discrete dynamic optimization strategy called Ant Colony Optimization (ACO) with Aphids, modelled after a real-world symbiotic relationship between ants and aphids. ACO with Aphids strategy is designed to improve solution quality of discrete domain Dynamic Optimization Problems (DOPs) with event-triggered discrete dynamism. The proposed strategy aims to improve the inter-state convergence rate throughout the entire dynamic optimization. It does so by minimizing the fitness penalty and maximizing the convergence speed that occurs after the dynamic change. This strategy is tested against Full-Restart and Pheromone-Sharing strategies implemented on the same ACO core algorithm solving Dynamic Multidimensional Knapsack Problem (DMKP) benchmarks. ACO with Aphids has demonstrated superior performance over the Pheromone-Sharing strategy in every test on average gap reduced by 29.2%. Also, ACO with Aphids has outperformed the Full-Restart strategy for large datasets groups, and the overall average gap is reduced by 52.5%.},
  journal={arXiv}
}

@article{qiu2024novel,
  title={A Novel Quantum Algorithm for Ant Colony Optimization},
  author={Qian Qiu and Mohan Wu and Qichun Sun and Xiaogang Li and Hua Xu},
  year={2024},
  url={http://arxiv.org/abs/2403.00367v1},
  abstract={Quantum ant colony optimization (QACO) has drew much attention since it combines the advantages of quantum computing and ant colony optimization (ACO) algorithms and overcomes some limitations of the traditional ACO algorithm. However, due to the hardware resource limitations of currently available quantum computers, such as the limited number of qubits, lack of high-fidelity gating operation, and low noisy tolerance, the practical application of the QACO is quite challenging. In this paper, we introduce a hybrid quantum-classical algorithm by combining the clustering algorithm with QACO algorithm, so that this extended QACO can handle large-scale optimization problems, which makes the practical application of QACO based on available quantum computation resource possible. To verify the effectiveness and performance of the algorithm, we tested the developed QACO algorithm with the Travelling Salesman Problem (TSP) as benchmarks. The developed QACO algorithm shows better performance under multiple data set. In addition, the developed QACO algorithm also manifests the robustness to noise of calculation process, which is typically a major barrier for practical application of quantum computers. Our work shows that the combination of the clustering algorithm with QACO has effectively extended the application scenario of QACO in current NISQ era of quantum computing.},
  journal={arXiv}
}

@article{liu2021multisource,
  title={Multi-Source Thermal Model Describing Transverse Momentum Spectra of Final-State Particles in High Energy Collisions},
  author={Fu-Hu Liu and Jia-Yu Chen and Qiang Zhang},
  year={2021},
  url={http://arxiv.org/abs/2111.13433v2},
  abstract={In this mini review article, the transverse momentum spectra of final-state particles produced in high energy hadron-hadron, hadron-nucleus, and nucleus-nucleus collisions described by the multi-source thermal model at the quark or parton level is summarized. In the model, the participant or contributor quarks or partons are considered to contribute together to the transverse momentum distribution of final-state particles with different modes of contributions. The concrete mode of contribution is generally determined by the difference of azimuthal angles of contributor partons in their emissions.},
  doi={10.1155/2022/7274958},
  journal={arXiv}
}

@article{menafernández2024dark,
  title={Dark Energy Survey: 2.1% measurement of the Baryon Acoustic Oscillation scale from the final dataset},
  author={Juan Mena-Fernández and Dark Energy Survey Collaboration},
  year={2024},
  url={http://arxiv.org/abs/2409.08759v1},
  abstract={Here, we present the angular diameter distance measurement obtained from the measurement of the Baryonic Acoustic Oscillation (BAO) feature using the completed Dark Energy Survey (DES) data, summarizing the main results of [Phys. Rev. D 110, 063514] and [Phys. Rev. D 110, 063515]. We use a galaxy sample optimized for BAO science in the redshift range 0.6 < z < 1.2, with an effective redshift of $z_{\rm eff}$ = 0.85. Our consensus measurement constrains the ratio of the angular distance to the sound horizon scale to $D_M(z_{\rm eff})/r_d$ = 19.51 $\pm$ 0.41. This measurement is found to be 2.13$σ$ below the angular BAO scale predicted by Planck. To date, it represents the most precise measurement from purely photometric data, and the most precise from any Stage-III experiment at such high redshift. The analysis was performed blinded to the BAO position and is shown to be robust against analysis choices, data removal, redshift calibrations and observational systematics.},
  journal={arXiv}
}

@article{wang2020excitation,
  title={Excitation function of initial temperature of heavy flavor quarkonium emission source in high energy collisions},
  author={Qi Wang and Fu-Hu Liu},
  year={2020},
  url={http://arxiv.org/abs/2005.04940v3},
  abstract={The transverse momentum spectra of $J/ψ$, $ψ(2S)$, and $Υ(nS, n=1,2,3)$ produced in proton-proton ($p$+$p$), proton-antiproton ($p$+$\bar{p}$), proton-lead ($p$+Pb), gold-gold (Au+Au), and lead-lead (Pb+Pb) collisions over a wide energy range are analyzed by the (two-component) Erlang distribution, the Hagedorn function (the inverse power-law), and the Tsallis-Levy function. The initial temperature is obtained from the color string percolation model due to the fit by the (two-component) Erlang distribution in the framework of multisource thermal model. The excitation functions of some parameters such as the mean transverse momentum and initial temperature increase from dozens of GeV to above 10 TeV. The mean transverse momentum and initial temperature decrease (increase slightly or do not change obviously) with the increase of rapidity (centrality). Meanwhile, the mean transverse momentum of $Υ(nS, n=1,2,3)$ is larger than that of $J/ψ$ and $ψ(2S)$, and the initial temperature for $Υ(nS, n=1,2,3)$ emission is higher than that for $J/ψ$ and $ψ(2S)$ emission, which shows a mass-dependent behavior.},
  doi={10.1155/2020/5031494},
  journal={arXiv}
}

@article{waqas2020dependence,
  title={Dependence of temperatures and kinetic freeze-out volume on centrality in Au-Au and Pb-Pb collisions at high energy},
  author={Muhammad Waqas and Fu-Hu Liu and Zafar Wazir},
  year={2020},
  url={http://arxiv.org/abs/2004.03773v2},
  abstract={Centrality-dependent double-differential transverse momentum spectra of negatively charged particles ($π^-$, $K^-$ and $\bar p$) at mid-(pseudo)rapidity interval in nuclear collisions are analyzed by the standard distribution in terms of multi-component. The experimental data measured in gold-gold (Au-Au) collisions by the PHENIX Collaboration at the Relativistic Heavy Ion Collider (RHIC) and in lead-lead (Pb-Pb) collisions by the ALICE Collaboration at the Large Hadron Collider (LHC) are studied. The effective temperature, initial temperature, kinetic freeze-out temperature, transverse flow velocity and kinetic freeze-out volume are extracted from the fitting to transverse momentum spectra. We observed, that the mentioned five quantities increase with the increase of event centrality due to the fact that the average transverse momentum increases with the increase of event centrality. This renders that larger momentum (energy) transfer and further multiple-scattering had happened in central centrality.},
  doi={10.1155/2020/8198126},
  journal={arXiv}
}

@article{zhang2020statistical2,
  title={Statistical Behavior of Lepton Pair Spectrum in Drell-Yan Process and Signal from Quark-Gluon Plasma in High Energy Collisions},
  author={Xu-Hong Zhang and Fu-Hu Liu},
  year={2020},
  url={http://arxiv.org/abs/2005.08554v3},
  abstract={We analyze the transverse momentum ($p_{T}$) spectra of lepton pairs ($\ell\bar \ell$) generated in the Drell-Yan process, as detected in proton-nucleus (pion-nucleus) and proton-(anti)proton collisions by ten collaborations over a center-of-mass energy ($\sqrt{s_{NN}}$ or $\sqrt{s}$ if in a simplified form) range from $\sim20$ GeV to above 10 TeV. Three types of probability density functions (the convolution of two Lévy-Tsallis functions, the two-component Erlang distribution, and the convolution of two Hagedorn functions) are utilized to fit and analyze the $p_{T}$ spectra. The fit results are approximately in agreement with the collected experimental data. Consecutively, we obtained the variation law of related parameters as a function of $\sqrt{s}$ and invariant mass ($Q$). In the fit procedure, a given Lévy-Tsallis (or Hagedorn) function can be regarded as the probability density function of transverse momenta contributed by a single quark ($q$) or anti-quark ($\bar q$). The Drell-Yan process is then described by the statistical method.},
  doi={10.1155/2021/9548737},
  journal={arXiv}
}

@article{dowker2017renyi,
  title={Renyi entropies and C_T for higher derivative free scalars and spinors on even spheres},
  author={J. S. Dowker},
  year={2017},
  url={http://arxiv.org/abs/1706.01369v4},
  abstract={General expressions for the Rényi entropies and central charges for higher derivative free spinors and scalars on even spheres are obtained using a direct spectral method on a compact lune division of the sphere. Formulae and numbers are rapidly obtained for any dimension and order of derivative.   The relation between the conformal anomaly and the hyperbolic free energy is briefly explored using standard expansions.   A field theoretic derivation of the central charge formula for higher derivative scalars in any (even) dimension, given by Osborn and Stergiou and by Gliozzi {\it et al}, is thereby provided. The corresponding extension to spinors is made.   Generalised Bernoulli polynomials play an important technical role.},
  journal={arXiv}
}

@article{li2022joint,
  title={Joint Planning of Distributed Generations and Energy Storage in Active Distribution Networks: A Bi-Level Programming Approach},
  author={Yang Li and Bo Feng and Bin Wang and Shuchao Sun},
  year={2022},
  url={http://arxiv.org/abs/2201.05932v1},
  abstract={In order to improve the penetration of renewable energy resources for distribution networks, a joint planning model of distributed generations (DGs) and energy storage is proposed for an active distribution network by using a bi-level programming approach in this paper. In this model, the upper-level aims to seek the optimal location and capacity of DGs and energy storage, while the lower-level optimizes the operation of energy storage devices. To solve this model, an improved binary particle swarm optimization (IBPSO) algorithm based on chaos optimization is developed, and the optimal joint planning is achieved through alternating iterations between the two levels. The simulation results on the PG & E 69-bus distribution system demonstrate that the presented approach manages to reduce the planning deviation caused by the uncertainties of DG outputs and remarkably improve the voltage profile and operational economy of distribution systems.},
  doi={10.1016/j.energy.2022.123226},
  journal={arXiv}
}

@article{pan2018free,
  title={Free energy of bipartite Sherrington-Kirkpatrick model},
  author={Liming Pan and Simone Franchini},
  year={2018},
  url={http://arxiv.org/abs/1808.02542v5},
  abstract={In this paper we study the bipartite version of Sherrington-Kirkpatrick model. We prove that the free energy density is given by an analogue of the Parisi formula, that contains both the usual overlap and an additional new type of overlap. Following Panchenko, we prove the upper bound of the formula by Guerra's replica symmetry breaking interpolation, then the matching lower bound by Ghirlanda-Guerra identities and the Aizenman-Sims-Starr scheme. Based on this result we study the stability of the replica symmetric solution. A new phase exhibiting partial replica symmetry breaking is observed, where the broken phase is realized in the larger group only.},
  journal={arXiv}
}

@article{attia2013hausdorff,
  title={Hausdorff and packing spectra, large deviations, and free energy for branching random walks in $\R^d$},
  author={Najmeddine Attia and Julien Barral},
  year={2013},
  url={http://arxiv.org/abs/1305.2034v2},
  abstract={Consider an $\R^d$-valued branching random walk (BRW) on a supercritical Galton Watson tree. Without any assumption on the distribution of this BRW we compute, almost surely and simultaneously, the Hausdorff and packing dimensions of the level sets $E(K)$ of infinite branches in the boundary of the tree (endowed with its standard metric) along which the averages of the BRW have a given closed connected set of limit points $K$. This goes beyond multifractal analysis, which only considers those level sets when $K$ ranges in the set of singletons $\{α\}$, $α\in\R^d$. We also give a $0$-$\infty$ law for the Hausdorff and packing measures of the level sets $E(\{α\})$, and compute the free energy of the associated logarithmically correlated random energy model in full generality. Moreover, our results complete the previous works on multifractal analysis by including the levels $α$ which do not belong to the range of the gradient of the free energy. This covers in particular a situation until now badly understood, namely the case where a first order phase transition occurs. As a consequence of our study, we can also describe the whole singularity spectrum of Mandelbrot measures, as well as the associated free energy function (or $L^q$-spectrum), when a first order phase transition occurs.},
  doi={10.1007/s00220-014-2087-9},
  journal={arXiv}
}

@article{brown2018synergies,
  title={Synergies of sector coupling and transmission reinforcement in a cost-optimised, highly renewable European energy system},
  author={T. Brown and D. Schlachtberger and A. Kies and S. Schramm and M. Greiner},
  year={2018},
  url={http://arxiv.org/abs/1801.05290v2},
  abstract={There are two competing concepts in the literature for the integration of high shares of renewable energy: the coupling of electricity to other energy sectors, such as transport and heating, and the reinforcement of continent-wide transmission networks. In this paper both cross-sector and cross-border integration are considered in the model PyPSA-Eur-Sec-30, the first open, spatially-resolved, temporally-resolved and sector-coupled energy model of Europe. Using a simplified network with one node per country, the cost-optimal system is calculated for a 95% reduction in carbon dioxide emissions compared to 1990, incorporating electricity, transport and heat demand. Flexibility from battery electric vehicles (BEV), power-to-gas units (P2G) and long-term thermal energy storage (LTES) make a significant contribution to the smoothing of variability from wind and solar and to the reduction of total system costs. The cost-minimising integration of BEV pairs well with the daily variations of solar power, while P2G and LTES balance the synoptic and seasonal variations of demand and renewables. In all scenarios, an expansion of cross-border transmission reduces system costs, but the more tightly the energy sectors are coupled, the weaker the benefit of transmission reinforcement becomes.},
  doi={10.1016/j.energy.2018.06.222},
  journal={arXiv}
}

@article{cremers2022efficient,
  title={Efficient Methods for Approximating the Shapley Value for Asset Sharing in Energy Communities},
  author={Sho Cremers and Valentin Robu and Peter Zhang and Merlinda Andoni and Sonam Norbu and David Flynn},
  year={2022},
  url={http://arxiv.org/abs/2301.00174v1},
  abstract={With the emergence of energy communities, where a number of prosumers invest in shared generation and storage, the issue of fair allocation of benefits is increasingly important. The Shapley value has attracted increasing interest for redistribution in energy settings - however, computing it exactly is intractable beyond a few dozen prosumers. In this paper, we first conduct a systematic review of the literature on the use of Shapley value in energy-related applications, as well as efforts to compute or approximate it. Next, we formalise the main methods for approximating the Shapley value in community energy settings, and propose a new one, which we call the stratified expected value approximation. To compare the performance of these methods, we design a novel method for exact Shapley value computation, which can be applied to communities of up to several hundred agents by clustering the prosumers into a smaller number of demand profiles. We perform a large-scale experimental comparison of the proposed methods, for communities of up to 200 prosumers, using large-scale, publicly available data from two large-scale energy trials in the UK (UKERC Energy Data Centre, 2017, UK Power Networks Innovation, 2021). Our analysis shows that, as the number of agents in the community increases, the relative difference to the exact Shapley value converges to under 1% for all the approximation methods considered. In particular, for most experimental scenarios, we show that there is no statistical difference between the newly proposed stratified expected value method and the existing state-of-the-art method that uses adaptive sampling (O'Brien et al., 2015), although the cost of computation for large communities is an order of magnitude lower.},
  doi={10.1016/j.apenergy.2022.120328},
  journal={arXiv}
}

@article{mao2020planning,
  title={Planning low-carbon distributed power systems: Evaluating the role of energy storage},
  author={Jiachen Mao and Mehdi Jafari and Audun Botterud},
  year={2020},
  url={http://arxiv.org/abs/2009.09325v2},
  abstract={This paper introduces a mathematical formulation of energy storage systems into a generation capacity expansion framework to evaluate the role of energy storage in the decarbonization of distributed power systems. The modeling framework accounts for dynamic charging/discharging efficiencies and maximum cycling powers as well as cycle and calendar degradation of a Li-ion battery system. Results from a small-scale distributed power system indicate that incorporating the dynamic efficiencies and cycling powers of batteries in the generation planning problem does not significantly change the optimal generation portfolio, while adding substantial computational burden. In contrast, accounting for battery degradation leads to substantially different generation expansion outcomes, especially in deep decarbonization scenarios with larger energy storage capacities. Under the assumptions used in this study, it is found that battery energy storage is economically viable for 2020 only under strict carbon emission constraints. In contrast, given the projected technology advances and corresponding cost reductions, battery energy storage exhibits an attractive option to enable deep decarbonization in 2050.},
  doi={10.1016/j.energy.2021.121668},
  journal={arXiv}
}

@article{kharlampovich2016what,
  title={What does a group algebra of a free group know about the group?},
  author={O. Kharlampovich and A. Miasnikov},
  year={2016},
  url={http://arxiv.org/abs/1607.03138v3},
  abstract={We describe solutions to the problem of elementary classification in the class of group algebras of free groups. We will show that unlike free groups, two group algebras of free groups over infinite fields are elementarily equivalent if and only if the groups are isomorphic and the fields are equivalent in the weak second order logic. We will show that the set of all free bases of a free group $F$ is 0-definable in the group algebra $K(F)$ when $K$ is an infinite field, the set of geodesics is definable, and many geometric properties of $F$ are definable in $K(F)$. Therefore $K(F)$ knows some very important information about $F$. We will show that similar results hold for group algebras of limit groups.},
  journal={arXiv}
}

@article{wang2023collaborative,
  title={Collaborative Optimization of Multi-microgrids System with Shared Energy Storage Based on Multi-agent Stochastic Game and Reinforcement Learning},
  author={Yijian Wang and Yang Cui and Yang Li and Yang Xu},
  year={2023},
  url={http://arxiv.org/abs/2306.10754v1},
  abstract={Achieving the economical and stable operation of Multi-microgrids (MMG) systems is vital. However, there are still some challenging problems to be solved. Firstly, from the perspective of stable operation, it is necessary to minimize the energy fluctuation of the main grid. Secondly, the characteristics of energy conversion equipment need to be considered. Finally, privacy protection while reducing the operating cost of an MMG system is crucial. To address these challenges, a Data-driven strategy for MMG systems with Shared Energy Storage (SES) is proposed. The Mixed-Attention is applied to fit the conditions of the equipment, additionally, Multi-Agent Soft Actor-Critic(MA-SAC) and (Multi-Agent Win or Learn Fast Policy Hill-Climbing)MA-WoLF-PHC are proposed to solve the partially observable dynamic stochastic game problem. By testing the operation data of the MMG system in Northwest China, following conclusions are drawn: the R-Square (R2) values of results reach 0.999, indicating the neural network effectively models the nonlinear conditions. The proposed MMG system framework can reduce energy fluctuations in the main grid by 1746.5kW in 24 hours and achieve a cost reduction of 16.21% in the test. Finally, the superiority of the proposed algorithms is verified through their fast convergence speed and excellent optimization performance.},
  doi={10.1016/j.energy.2023.128182},
  journal={arXiv}
}

@article{li2021hierarchical,
  title={Hierarchical Stochastic Scheduling of Multi-Community Integrated Energy Systems in Uncertain Environments via Stackelberg Game},
  author={Yang Li and Bin Wang and Zhen Yang and Jiazheng Li and Chen Chen},
  year={2021},
  url={http://arxiv.org/abs/2112.07103v1},
  abstract={An operating entity utilizing community-integrated energy systems with a large number of small-scale distributed energy sources can easily trade with existing distribution markets. To solve the energy management and pricing problem of multi-community integrated energy systems (MCIESs) with multi-energy interaction, this study investigated a hierarchical stochastic optimal scheduling method for uncertain environments. To handle multiple uncertainties, a Wasserstein generative adversarial network with a gradient penalty was used to generate renewable scenarios, and the Kmeans++ clustering algorithm was employed to generate typical scenarios. A Stackelberg-based hierarchical stochastic schedule with an integrated demand response was constructed, where the MCIES operator acted as the leader pursuing the maximum net profit by setting energy prices, while the building users were followers who adjusted their energy consumption plans to minimize their total costs. Finally, a distributed iterative solution method based on a metaheuristic was designed. The effectiveness of the proposed method was verified using practical examples.},
  doi={10.1016/j.apenergy.2021.118392},
  journal={arXiv}
}

@article{chen2023development,
  title={Development and Evaluation of an Online Home Energy Management Strategy for Load Coordination in Smart Homes with Renewable Energy Sources},
  author={Xiaoling Chen and Cory Miller and Mithun Goutham and Prasad Dev Hanumalagutti and Rachel Blaser and Stephanie Stockar},
  year={2023},
  url={http://arxiv.org/abs/2304.11770v1},
  abstract={In this paper, a real time implementable load coordination strategy is developed for the optimization of electric demands in a smart home. The strategy minimizes the electricity cost to the home owner, while limiting the disruptions associated with the deferring of flexible power loads. A multi-objective nonlinear mixed integer programming is formulated as a sequential model predictive control, which is then solved using genetic algorithm. The load shifting benefits obtained by deploying an advanced coordination strategy are compared against a baseline controller for various home characteristics, such as location, size and equipment. The simulation study shows that the deployment of the smart home energy management strategy achieves approximately 5% reduction in grid cost compared to a baseline strategy. This is achieved by deferring approximately 50\% of the flexible loads, which is possible due to the use of the stationary energy storage.},
  doi={10.1016/j.energy.2023.130134},
  journal={arXiv}
}

@article{han2022research,
  title={Research on Flexibility Margin of Electric-Hydrogen Coupling Energy Block Based on Model Predictive Control},
  author={Zijiao Han and Shun Yuan and Yannan Dong and Shaohua Ma and Yudong Bian and Xinyu Mao},
  year={2022},
  url={http://arxiv.org/abs/2203.13951v1},
  abstract={Hydrogen energy plays an important role in the transformation of low-carbon energy, and electric hydrogen coupling will become a typical energy scenario. Aiming at the operation flexibility of low-carbon electricity hydrogen coupling system with high proportion of wind power and photovoltaic, this paper studies the flexibility margin of electricity hydrogen coupling energy block based on model predictive control (MPC). By analyzing the power exchange characteristics of heterogeneous energy, the homogenization models of various heterogeneous energy sources are established. According to the analysis of power system flexibility margin, three dimensions of flexibility margin evaluation indexes are defined from the dimension of system operation, and an electricity hydrogen coupling energy block scheduling model is established. The model predictive control algorithm is used to optimize the power balance operation of the electro hydrogen coupling energy block, and the flexibility margin of the energy block is quantitatively analyzed and calculated. Through the example analysis, it is verified that the calculation method proposed in this paper can not only realize the on-line power balance optimization of electric hydrogen coupling energy block, but also effectively quantify the operation flexibility margin of electric hydrogen coupling energy block.},
  doi={10.3389/fenrg.2022.879244},
  journal={arXiv}
}

@article{charbonnier2022scalable,
  title={Scalable multi-agent reinforcement learning for distributed control of residential energy flexibility},
  author={Flora Charbonnier and Thomas Morstyn and Malcolm D. McCulloch},
  year={2022},
  url={http://arxiv.org/abs/2203.03417v2},
  abstract={This paper proposes a novel scalable type of multi-agent reinforcement learning-based coordination for distributed residential energy. Cooperating agents learn to control the flexibility offered by electric vehicles, space heating and flexible loads in a partially observable stochastic environment. In the standard independent Q-learning approach, the coordination performance of agents under partial observability drops at scale in stochastic environments. Here, the novel combination of learning from off-line convex optimisations on historical data and isolating marginal contributions to total rewards in reward signals increases stability and performance at scale. Using fixed-size Q-tables, prosumers are able to assess their marginal impact on total system objectives without sharing personal data either with each other or with a central coordinator. Case studies are used to assess the fitness of different combinations of exploration sources, reward definitions, and multi-agent learning frameworks. It is demonstrated that the proposed strategies create value at individual and system levels thanks to reductions in the costs of energy imports, losses, distribution network congestion, battery depreciation and greenhouse gas emissions.},
  doi={10.1016/j.apenergy.2022.118825},
  journal={arXiv}
}

@article{li2023datadriven,
  title={Data-Driven Distributionally Robust Scheduling of Community Integrated Energy Systems with Uncertain Renewable Generations Considering Integrated Demand Response},
  author={Yang Li and Meng Han and Mohammad Shahidehpour and Jiazheng Li and Chao Long},
  year={2023},
  url={http://arxiv.org/abs/2301.08861v2},
  abstract={A community integrated energy system (CIES) is an important carrier of the energy internet and smart city in geographical and functional terms. Its emergence provides a new solution to the problems of energy utilization and environmental pollution. To coordinate the integrated demand response and uncertainty of renewable energy generation (RGs), a data-driven two-stage distributionally robust optimization (DRO) model is constructed. A comprehensive norm consisting of the 1-norm and infinity-norm is used as the uncertainty probability distribution information set, thereby avoiding complex probability density information. To address multiple uncertainties of RGs, a generative adversarial network based on the Wasserstein distance with gradient penalty is proposed to generate RG scenarios, which has wide applicability. To further tap the potential of the demand response, we take into account the ambiguity of human thermal comfort and the thermal inertia of buildings. Thus, an integrated demand response mechanism is developed that effectively promotes the consumption of renewable energy. The proposed method is simulated in an actual CIES in North China. In comparison with traditional stochastic programming and robust optimization, it is verified that the proposed DRO model properly balances the relationship between economical operation and robustness while exhibiting stronger adaptability. Furthermore, our approach outperforms other commonly used DRO methods with better operational economy, lower renewable power curtailment rate, and higher computational efficiency.},
  doi={10.1016/j.apenergy.2023.120749},
  journal={arXiv}
}

@article{ororbia2023neuromimetic,
  title={A Neuro-mimetic Realization of the Common Model of Cognition via Hebbian Learning and Free Energy Minimization},
  author={Alexander Ororbia and Mary Alexandria Kelly},
  year={2023},
  url={http://arxiv.org/abs/2310.15177v2},
  abstract={Over the last few years, large neural generative models, capable of synthesizing semantically rich passages of text or producing complex images, have recently emerged as a popular representation of what has come to be known as ``generative artificial intelligence'' (generative AI). Beyond opening the door to new opportunities as well as challenges for the domain of statistical machine learning, the rising popularity of generative AI brings with it interesting questions for Cognitive Science, which seeks to discover the nature of the processes that underpin minds and brains as well as to understand how such functionality might be acquired and instantianted in biological (or artificial) substrate. With this goal in mind, we argue that a promising research program lies in the crafting of cognitive architectures, a long-standing tradition of the field, cast fundamentally in terms of neuro-mimetic generative building blocks. Concretely, we discuss the COGnitive Neural GENerative system, such an architecture that casts the Common Model of Cognition in terms of Hebbian adaptation operating in service of optimizing a variational free energy functional.},
  journal={arXiv}
}

@article{singha2016first,
  title={The first moment of azimuthal anisotropy in nuclear collisions from AGS to LHC energies},
  author={Subhash Singha and Prashanth Shanmuganathan and Declan Keane},
  year={2016},
  url={http://arxiv.org/abs/1610.00646v1},
  abstract={We review topics related to the first moment of azimuthal anisotropy ($v_1$), commonly known as directed flow, focusing on both charged particles and identified particles from heavy-ion collisions. Beam energies from the highest available, at the CERN LHC, down to projectile kinetic energies per nucleon of a few GeV per nucleon, as studied in experiments at the Brookhaven AGS, fall within our scope. We focus on experimental measurements and on theoretical work where direct comparisons with experiment have been emphasized. The physics addressed or potentially addressed by this review topic includes the study of Quark Gluon Plasma, and more generally, investigation of the Quantum Chromodynamics phase diagram and the equation of state describing the accessible phases.},
  doi={10.1155/2016/2836989},
  journal={arXiv}
}

@article{jentschura2012from,
  title={From Generalized Dirac Equations to a Candidate for Dark Energy},
  author={U. D. Jentschura and B. J. Wundt},
  year={2012},
  url={http://arxiv.org/abs/1205.0521v6},
  abstract={We consider extensions of the Dirac equation with mass terms m1+i*gamma5*m2 and i*m_1+gamma*m2. The corresponding Hamiltonians are Hermitian and pseudo-Hermitian ("gamma5 Hermitian"), respectively. The fundamental spinor solutions for all generalized Dirac equations are found in the helicity basis and brought into concise analytic form. We postulate that the time-ordered product of field operators should yield the Feynman propagator (i*epsilon prescription), and we also postulate that the tardyonic as well as tachyonic Dirac equations should have a smooth massless limit. These postulates lead to sum rules that connect the form of the fundamental field anticommutators with the tensor sums of the fundamental plane-wave eigenspinors and the projectors over positive-energy and negative-energy states. In the massless case, the sum rules are fulfilled by two egregiously simple, distinguished functional forms. The first sum rule remains valid in the case of a tardyonic theory and leads to the canonical massive Dirac field. The second sum rule is valid for a tachyonic mass term and leads to a natural suppression of the right-handed helicity states for tachyonic particles, and left-handed helicity states for tachyonic spin-1/2 antiparticles. When applied to neutrinos, the theory contains a free tachyonic mass parameter. Tachyons are known to be repulsed by gravity. We discuss a possible role of a tachyonic neutrino as a contribution to the accelerated expansion of the Universe ("dark energy").},
  doi={10.1155/2013/374612},
  journal={arXiv}
}

@article{li2018optimal,
  title={Optimal distributed generation planning in active distribution networks considering integration of energy storage},
  author={Yang Li and Bo Feng and Guoqing Li and Junjian Qi and Dongbo Zhao and Yunfei Mu},
  year={2018},
  url={http://arxiv.org/abs/1808.05712v1},
  abstract={A two-stage optimization method is proposed for optimal distributed generation (DG) planning considering the integration of energy storage in this paper. The first stage determines the installation locations and the initial capacity of DGs using the well-known loss sensitivity factor (LSF) approach, and the second stage identifies the optimal installation capacities of DGs to maximize the investment benefits and system voltage stability and to minimize line losses. In the second stage, the multi-objective ant lion optimizer (MOALO) is first applied to obtain the Pareto-optimal solutions, and then the 'best' compromise solution is identified by calculating the priority memberships of each solution via grey relation projection (GRP) method, while finally, in order to address the uncertain outputs of DGs, energy storage devices are installed whose maximum outputs are determined with the use of chance-constrained programming. The test results on the PG&E 69-bus distribution system demonstrate that the proposed method is superior to other current state-of-the-art approaches, and that the integration of energy storage makes the DGs operate at their pre-designed rated capacities with the probability of at least 60% which is novel.},
  doi={10.1016/j.apenergy.2017.08.008},
  journal={arXiv}
}

@article{babinec2023technoeconomic,
  title={Techno-economic analysis of renewable energy generation at the South Pole},
  author={Susan Babinec and Ian Baring-Gould and Amy N. Bender and Nate Blair and Xiangkun Li and Ralph T. Muehleisen and Dan Olis and Silvana Ovaitt},
  year={2023},
  url={http://arxiv.org/abs/2306.13552v2},
  abstract={Transitioning from fossil-fuel power generation to renewable energy generation and energy storage in remote locations has the potential to reduce both carbon emissions and cost. This study presents a techno-economic analysis for implementation of a hybrid renewable energy system at the South Pole in Antarctica, which currently hosts several high-energy physics experiments with nontrivial power needs. A tailored model of resource availability and economics for solar photovoltaics, wind turbine generators, lithium-ion energy storage, and long-duration energy storage at this site is explored in different combinations with and without existing diesel energy generation. The Renewable Energy Integration and Optimization (REopt) platform is used to determine the optimal system component sizing and the associated system economics and environmental benefit. We find that the least-cost system includes all three energy generation sources and lithium-ion energy storage. For an example steady-state load of 170 kW, this hybrid system includes 180 kW-DC of photovoltaic panels, 570 kW of wind turbines, and a 3.4 MWh lithium-ion battery energy storage system. This system reduces diesel consumption by 95% compared to an all-diesel configuration, resulting in approximately 1200 metric tons of carbon footprint avoided annually. Over the course of a 15-year analysis period the reduced diesel usage leads to a net savings of 57 million United States dollars, with a time to payback of approximately two years. All the scenarios modeled show that the transition to renewables is highly cost effective under the unique economics and constraints of this extremely remote site.},
  doi={10.1016/j.rser.2023.114274},
  journal={arXiv}
}

@article{fu2024creating,
  title={Creating synthetic energy meter data using conditional diffusion and building metadata},
  author={Chun Fu and Hussain Kazmi and Matias Quintana and Clayton Miller},
  year={2024},
  url={http://arxiv.org/abs/2404.00525v1},
  abstract={Advances in machine learning and increased computational power have driven progress in energy-related research. However, limited access to private energy data from buildings hinders traditional regression models relying on historical data. While generative models offer a solution, previous studies have primarily focused on short-term generation periods (e.g., daily profiles) and a limited number of meters. Thus, the study proposes a conditional diffusion model for generating high-quality synthetic energy data using relevant metadata. Using a dataset comprising 1,828 power meters from various buildings and countries, this model is compared with traditional methods like Conditional Generative Adversarial Networks (CGAN) and Conditional Variational Auto-Encoders (CVAE). It explicitly handles long-term annual consumption profiles, harnessing metadata such as location, weather, building, and meter type to produce coherent synthetic data that closely resembles real-world energy consumption patterns. The results demonstrate the proposed diffusion model's superior performance, with a 36% reduction in Frechet Inception Distance (FID) score and a 13% decrease in Kullback-Leibler divergence (KL divergence) compared to the following best method. The proposed method successfully generates high-quality energy data through metadata, and its code will be open-sourced, establishing a foundation for a broader array of energy data generation models in the future.},
  doi={10.1016/j.enbuild.2024.114216},
  journal={arXiv}
}

@article{li2021optimal,
  title={Optimal Scheduling of Integrated Demand Response-Enabled Integrated Energy Systems with Uncertain Renewable Generations: A Stackelberg Game Approach},
  author={Yang Li and Chunling Wang and Guoqing Li and Chen Chen},
  year={2021},
  url={http://arxiv.org/abs/2103.04723v1},
  abstract={In order to balance the interests of integrated energy operator (IEO) and users, a novel Stackelberg game-based optimization framework is proposed for the optimal scheduling of integrated demand response (IDR)-enabled integrated energy systems with uncertain renewable generations, where the IEO acts as the leader who pursues the maximization of his profits by setting energy prices, while the users are the follower who adjusts energy consumption plans to minimize their energy costs. Taking into account the inherent uncertainty of renewable generations, the probabilistic spinning reserve is written in the form of a chance constraint; in addition, a district heating network model is built considering the characteristics of time delay and thermal attenuation by fully exploiting its potential, and the flexible thermal comfort requirements of users in IDR are considered by introducing a predicted mean vote (PMV) index. To solve the raised model, sequence operation theory is introduced to convert the chance constraint into its deterministic equivalent form, and thereby, the leader-follower Stackelberg game is tackled into a mixed-integer quadratic programming formulation through Karush-Kuhn-Tucker optimality conditions and is finally solved by the CPLEX optimizer. The results of two case studies demonstrate that the proposed Stackelberg game-based approach manages to achieve the Stackelberg equilibrium between IEO and users by the coordination of renewable generations and IDR. Furthermore, the study on a real integrated energy system in China verifies the applicability of the proposed approach for real-world applications.},
  doi={10.1016/j.enconman.2021.113996},
  journal={arXiv}
}

@article{demni2025finite,
  title={Finite free probability and $S$ transforms of Jacobi processes},
  author={Nizar Demni and Nicolas Gilliers and Tarek Hamdi},
  year={2025},
  url={http://arxiv.org/abs/2511.02758v1},
  abstract={In this paper, we study the $S$ transforms of Jacobi processes in the frameworks of free and finite free probability theories. We begin by deriving a partial differential equation satisfied by the free $S$ transform of the free Jacobi process, and we provide a detailed analysis of its characteristic curves. We turn next our attention to the averaged characteristic polynomial of the Hermitian Jacobi process and to the dynamic of its roots, referred to as the frozen Jacobi process. In particular, we prove, for a specific set of parameters, that the former aligns up to a Szegö variable transformation with the Hermite unitary polynomial. We also provide an expansion of the averaged characteristic polynomial of the Hermitian process in the basis of Jacobi polynomials. Finally, we establish the convergence of the frozen Jacobi process to the free Jacobi process in high dimensions by using the finite free S transform. In doing so, we prove a general result, interesting in its own, on the convergence of the finite differences of the finite free $S$ transform.},
  journal={arXiv}
}

@article{orndorf2020transition,
  title={Transition in the Acid-Base Component of Surface Free Energy of Ice upon the Premelting of its Second Molecular Bilayer},
  author={Nathaniel Orndorf and Saranshu Singla and Ali Dhinojwala},
  year={2020},
  url={http://arxiv.org/abs/2005.04475v2},
  abstract={Molecular disordering of the ice surface occurs below the bulk melting temperature of 273 K, termed surface premelting. The top-most molecular layer begins gradually premelting at 200 K, and has been linked to its low coefficient of friction through an increase in molecular mobility. The second molecular bilayer premelts around 257 K, but no study has linked this transition to a change in any macroscopic phenomena. Here, we show that the thermodynamic work of adhesion between polydimethylsiloxane (PDMS) and ice changes abruptly at 257.0 $\pm$ 0.1 K. Surface-sensitive sum frequency generation spectroscopy shows that there are no molecular level changes at the PDMS surface or the ice-PDMS interface near the transition in adhesion, indicating that the transition arises from changes of the ice surface. Using existing contact angle data in the literature, we show that this transition is due to a decrease in the acid-base component of the surface free energy of ice by 17 $\pm$ 2 mJ/m$^2$ at 257.0 $\pm$ 0.1 K. The change in surface energy provides a possible explanation for a variety of unexplained phenomena seen across the literature including ice adhesion, friction, and the morphology of snowflakes.},
  doi={10.1021/acs.jpcc.0c04610},
  journal={arXiv}
}

@article{kaczmarek2005static,
  title={Static quark anti-quark free and internal energy in 2-flavor QCD},
  author={Olaf Kaczmarek and Felix Zantow},
  year={2005},
  url={http://arxiv.org/abs/hep-lat/0502011v3},
  abstract={We study the change in free and internal energy due to the presence of a heavy quark anti-quark pair in a thermal heat bath in QCD with 2-flavors of staggered quarks at finite temperature. We discuss string breaking below as well as screening above the transition. Similarities and differences to the quenched case are discussed.},
  doi={10.1140/epjc/s2005-02189-9},
  journal={arXiv}
}

@article{you2021digital,
  title={Digital Twins based Day-ahead Integrated Energy System Scheduling under Load and Renewable Energy Uncertainties},
  author={Minglei You and Qian Wang and Hongjian Sun and Ivan Castro and Jing Jiang},
  year={2021},
  url={http://arxiv.org/abs/2109.14423v1},
  abstract={By constructing digital twins (DT) of an integrated energy system (IES), one can benefit from DT's predictive capabilities to improve coordinations among various energy converters, hence enhancing energy efficiency, cost savings and carbon emission reduction. This paper is motivated by the fact that practical IESs suffer from multiple uncertainty sources, and complicated surrounding environment. To address this problem, a novel DT-based day-ahead scheduling method is proposed. The physical IES is modelled as a multi-vector energy system in its virtual space that interacts with the physical IES to manipulate its operations. A deep neural network is trained to make statistical cost-saving scheduling by learning from both historical forecasting errors and day-ahead forecasts. Case studies of IESs show that the proposed DT-based method is able to reduce the operating cost of IES by 63.5%, comparing to the existing forecast-based scheduling methods. It is also found that both electric vehicles and thermal energy storages play proactive roles in the proposed method, highlighting their importance in future energy system integration and decarbonisation.},
  doi={10.1016/j.apenergy.2021.117899},
  journal={arXiv}
}

@article{saleev2007charmonium,
  title={Charmonium Polarization in High Energy Collisions},
  author={V. A. Saleev and D. V. Vasin},
  year={2007},
  url={http://arxiv.org/abs/0709.2259v1},
  abstract={We consider charmonium polarization at high-energy hadron collider Tevatron in the framework of the nonrelativistic QCD (NRQCD) and the k_T-factorization approach. The polarization effects are studied for the direct and the prompt production channels. The obtained predictions can be used to test the Regge limit of QCD and the NRQCD formalism.},
  journal={arXiv}
}

@article{ivashkevich2001kroneckers,
  title={Kronecker's Double Series and Exact Asymptotic Expansion for Free Models of Statistical Mechanics on Torus},
  author={E. V. Ivashkevich and N. Sh. Izmailian and Chin-Kun Hu},
  year={2001},
  url={http://arxiv.org/abs/cond-mat/0102470v3},
  abstract={For the free models of statistical mechanics on torus, exact asymptotic expansions of the free energy, the internal energy and the specific heat in the vicinity of the critical point are found. It is shown that there is direct relation between the terms of the expansion and the Kronecker's double series. The latter can be expressed in terms of the elliptic theta-functions in all orders of the asymptotic expansion.},
  doi={10.1088/0305-4470/35/27/302},
  journal={arXiv}
}

@article{li2020improving,
  title={Improving operational flexibility of integrated energy system with uncertain renewable generations considering thermal inertia of buildings},
  author={Yang Li and Chunling Wang and Guoqing Li and Jinlong Wang and Dongbo Zhao and Chen Chen},
  year={2020},
  url={http://arxiv.org/abs/2001.10371v1},
  abstract={Insufficient flexibility in system operation caused by traditional "heat-set" operating modes of combined heat and power (CHP) units in winter heating periods is a key issue that limits renewable energy consumption. In order to reduce the curtailment of renewable energy resources through improving the operational flexibility, a novel optimal scheduling model based on chance-constrained programming (CCP), aiming at minimizing the lowest generation cost, is proposed for a small-scale integrated energy system (IES) with CHP units, thermal power units, renewable generations and representative auxiliary equipments. In this model, due to the uncertainties of renewable generations including wind turbines and photovoltaic units, the probabilistic spinning reserves are supplied in the form of chance-constrained; from the perspective of user experience, a heating load model is built with consideration of heat comfort and inertia in buildings. To solve the model, a solution approach based on sequence operation theory (SOT) is developed, where the original CCP-based scheduling model is tackled into a solvable mixed-integer linear programming (MILP) formulation by converting a chance constraint into its deterministic equivalence class, and thereby is solved via the CPLEX solver. The simulation results on the modified IEEE 30-bus system demonstrate that the presented method manages to improve operational flexibility of the IES with uncertain renewable generations by comprehensively leveraging thermal inertia of buildings and different kinds of auxiliary equipments, which provides a fundamental way for promoting renewable energy consumption.},
  doi={10.1016/j.enconman.2020.112526},
  journal={arXiv}
}

@article{zhang2017flexible,
  title={Flexible transparent high-voltage diodes for energy management in wearable electronics},
  author={Yonghui Zhang and Zengxia Mei and Tao Wang and Wenxing Huo and Shujuan Cui and Huili Liang and Xiaolong Du},
  year={2017},
  url={http://arxiv.org/abs/1709.06804v1},
  abstract={This work reports flexible fully transparent high-voltage diodes that feature high rectification ratio (Rr 10 8) and high breakdown voltage (Vb 150 V) simultaneously, combined with their applications as building blocks of energy management systems in wearable electronics where triboelectric nanogenerators (TENGs) are used as power source. Both experimental results and technology computer aided design (TCAD) simulations suggest that Rr and Vb can be modulated by the offset length in an opposite tendency. The low reverse leakage current (fA/MICRON) guarantees an ultra-low power consumption in standby mode, which is a core issue in wearable device applications. Besides the unprecedented electrical performance, the diodes exhibit good mechanical robustness with minimal degradation throughout the strain and fatigue tests. By incorporating these high-voltage diodes into half-wave and full-wave rectifier circuits, the high alternating current (AC) output voltage of TENGs is successfully rectified into direct current (DC) voltage and charged into supercapacitors (SCs), indicating their high integration and compatibility with TENGs, and thus their promising applications in various wearable electronic systems.},
  doi={10.1016/j.nanoen.2017.08.025},
  journal={arXiv}
}

@article{li2022optimal,
  title={Optimal scheduling of island integrated energy systems considering multi-uncertainties and hydrothermal simultaneous transmission: A deep reinforcement learning approach},
  author={Yang Li and Fanjin Bu and Yuanzheng Li and Chao Long},
  year={2022},
  url={http://arxiv.org/abs/2212.13472v1},
  abstract={Multi-uncertainties from power sources and loads have brought significant challenges to the stable demand supply of various resources at islands. To address these challenges, a comprehensive scheduling framework is proposed by introducing a model-free deep reinforcement learning (DRL) approach based on modeling an island integrated energy system (IES). In response to the shortage of freshwater on islands, in addition to the introduction of seawater desalination systems, a transmission structure of "hydrothermal simultaneous transmission" (HST) is proposed. The essence of the IES scheduling problem is the optimal combination of each unit's output, which is a typical timing control problem and conforms to the Markov decision-making solution framework of deep reinforcement learning. Deep reinforcement learning adapts to various changes and timely adjusts strategies through the interaction of agents and the environment, avoiding complicated modeling and prediction of multi-uncertainties. The simulation results show that the proposed scheduling framework properly handles multi-uncertainties from power sources and loads, achieves a stable demand supply for various resources, and has better performance than other real-time scheduling methods, especially in terms of computational efficiency. In addition, the HST model constitutes an active exploration to improve the utilization efficiency of island freshwater.},
  doi={10.1016/j.apenergy.2022.120540},
  journal={arXiv}
}

@article{zhao2009quantum,
  title={Quantum Yang-Mills Condensate Dark Energy Models},
  author={W. Zhao and Y. Zhang and M. L. Tong},
  year={2009},
  url={http://arxiv.org/abs/0909.3874v2},
  abstract={We review the quantum Yang-Mills condensate (YMC) dark energy models. As the effective Yang-Mills Lagrangian is completely determined by the quantum field theory, there is no adjustable parameter in the model except the energy scale. In this model, the equation-of-state (EOS) of the YMC dark energy, $w_y > -1$ and $w_y < -1$, can both be naturally realized. By studying the evolution of various components in the model, we find that, in the early stage of the universe, dark energy tracked the evolution of the radiation, i.e. $w_y \to 1/3$. However, in the late stage, $w_y$ naturally runs to the critical state with $w_y = -1$, and the universe transits from matter-dominated into dark energy dominated stage only at recently $z \sim 0.3$. These characters are independent of the choice of the initial condition, and the cosmic coincidence problem is avoided in the models. We also find that, if the possible interaction between YMC and dust matter is considered, the late time attractor solution may exist. In this case, the EOS of YMC must evolve from $w_y>0$ into $w_y < -1$, which is slightly suggested by the observations. At the same time, the total EOS in the attractor solution is $w_{tot} = -1$, the universe being the de Sitter expansion in the late stage, and the cosmic big rip is naturally avoided. These features are all independent of the interacting forms.},
  journal={arXiv}
}

@article{si2017comparing,
  title={Comparing standard distribution and its Tsallis form of transverse momenta in high energy collisions},
  author={Rui-Fang Si and Hui-Ling Li and Fu-Hu Liu},
  year={2017},
  url={http://arxiv.org/abs/1710.09645v3},
  abstract={In this paper, the experimental (simulated) transverse momentum spectra of negatively charged pions produced at mid-rapidity in central nucleus-nucleus collisions at the Heavy Ion Synchrotron (SIS), Relativistic Heavy Ion Collider (RHIC), and Large Hadron Collider (LHC) energies obtained by different collaborations are selected by us to investigate, where a few simulated data are taken from the results of FOPI Collaboration who uses the IQMD transport code based on Quantum Molecular Dynamics. A two-component standard distribution and the Tsallis form of standard distribution are used to fit these data in the framework of a multisource thermal model. The excitation functions of main parameters in the two distributions are analyzed. In particular, the effective temperatures extracted from the two-component standard distribution and the Tsallis form of standard distribution are obtained, and the relation between the two types of effective temperatures is studied.},
  doi={10.1155/2018/7895967},
  journal={arXiv}
}

@article{kotzur2020bottomup,
  title={Bottom-up energy supply optimization of a national building stock},
  author={Leander Kotzur and Peter Markewitz and Martin Robinius and Gonçalo Cardoso and Peter Stenzel and Miguel Heleno and Detlef Stolten},
  year={2020},
  url={http://arxiv.org/abs/2001.01554v1},
  abstract={The installation and operation distributed energy resources (DER) and the electrification of the heat supply significantly changes the interaction of the residential building stock with the grid infrastructure. Evaluating the mass deployment of DER at the national level would require analyzing millions of individual buildings, entailing significant computational burden. To overcome this, this work proposes a novel bottom-up model that consists of an aggregation algorithm to create a spatially distributed set of typical residential buildings from census data. Each typical building is then optimized with a Mixed-Integer Linear Program to derive its cost optimal technology adoption and operation, determining its changing grid load in future scenarios. The model is validated for Germany, with 200 typical buildings considered to sufficiently represent the diversity of the residential building stock. In a future scenario for 2050, photovoltaic and heat pumps are predicted to be the most economically and ecologically robust supply solutions for the different building types. Nevertheless, their electricity generation and demand temporally do not match, resulting in a doubling of the peak electricity grid load in the rural areas during the winter. The urban areas can compensate this with efficient co-generation units, which are not cost-efficient in the rural areas.},
  doi={10.1016/j.enbuild.2019.109667},
  journal={arXiv}
}

@article{nicholas2021reexamining,
  title={Re-examining the Role of Nuclear Fusion in a Renewables-Based Energy Mix},
  author={T. E. G. Nicholas and T. P. Davis and F. Federici and J. E. Leland and B. S. Patel and C. Vincent and S. H. Ward},
  year={2021},
  url={http://arxiv.org/abs/2101.05727v1},
  abstract={Fusion energy is often regarded as a long-term solution to the world's energy needs. However, even after solving the critical research challenges, engineering and materials science will still impose significant constraints on the characteristics of a fusion power plant. Meanwhile, the global energy grid must transition to low-carbon sources by 2050 to prevent the worst effects of climate change. We review three factors affecting fusion's future trajectory: (1) the significant drop in the price of renewable energy, (2) the intermittency of renewable sources and implications for future energy grids, and (3) the recent proposition of intermediate-level nuclear waste as a product of fusion. Within the scenario assumed by our premises, we find that while there remains a clear motivation to develop fusion power plants, this motivation is likely weakened by the time they become available. We also conclude that most current fusion reactor designs do not take these factors into account and, to increase market penetration, fusion research should consider relaxed nuclear waste design criteria, raw material availability constraints and load-following designs with pulsed operation.},
  doi={10.1016/j.enpol.2020.112043},
  journal={arXiv}
}

@article{chandra2019centrality,
  title={Centrality Dependence of Multiplicity Fluctuations in Ion-Ion Collisions from the Beam Energy Scan at FAIR},
  author={Anuj Chandra and Bushra Ali and Shakeel Ahmad},
  year={2019},
  url={http://arxiv.org/abs/1908.00233v1},
  abstract={Multiplicity distributions and event-by-event multiplicity fluctuations in AuAu collisions at energies in future heavy-ion experiment at the Facility for Anti-proton and Ion Research (FAIR) are investigated. Events corresponding to FAIR energies are simulated in the frame work of Ultra Relativistic Quantum Molecular Dynamics (URQMD) model. It is observed that the mean and the width of multiplicity distributions monotonically increase with beam energy. The trend of variations of dispersion with mean number of participating nucleons for the centrality-bin width of 5\% are in accord with the Central Limit Theorem. The multiplicity distributions in various centrality bins as well as for full event samples are observed to obey Koba, Nielsen and Olesen (KNO) scaling. The trends of variations of scaled variance with beam energy are also found to support the KNO scaling predictions for larger collision centrality. The findings also reveal that the statistical fluctuations in 5\% centrality-bin width appear to be under control.},
  doi={10.1155/2019/3905376},
  journal={arXiv}
}

@article{li2023enhancing,
  title={Enhancing Cyber-Resilience in Integrated Energy System Scheduling with Demand Response Using Deep Reinforcement Learning},
  author={Yang Li and Wenjie Ma and Yuanzheng Li and Sen Li and Zhe Chen and Mohammad Shahidehpor},
  year={2023},
  url={http://arxiv.org/abs/2311.17941v2},
  abstract={Optimally scheduling multi-energy flow is an effective method to utilize renewable energy sources (RES) and improve the stability and economy of integrated energy systems (IES). However, the stable demand-supply of IES faces challenges from uncertainties that arise from RES and loads, as well as the increasing impact of cyber-attacks with advanced information and communication technologies adoption. To address these challenges, this paper proposes an innovative model-free resilience scheduling method based on state-adversarial deep reinforcement learning (DRL) for integrated demand response (IDR)-enabled IES. The proposed method designs an IDR program to explore the interaction ability of electricity-gas-heat flexible loads. Additionally, the state-adversarial Markov decision process (SA-MDP) model characterizes the energy scheduling problem of IES under cyber-attack, incorporating cyber-attacks as adversaries directly into the scheduling process. The state-adversarial soft actor-critic (SA-SAC) algorithm is proposed to mitigate the impact of cyber-attacks on the scheduling strategy, integrating adversarial training into the learning process to against cyber-attacks. Simulation results demonstrate that our method is capable of adequately addressing the uncertainties resulting from RES and loads, mitigating the impact of cyber-attacks on the scheduling strategy, and ensuring a stable demand supply for various energy sources. Moreover, the proposed method demonstrates resilience against cyber-attacks. Compared to the original soft actor-critic (SAC) algorithm, it achieves a 10% improvement in economic performance under cyber-attack scenarios.},
  doi={10.1016/j.apenergy.2024.124831},
  journal={arXiv}
}

@article{nardo2025performance,
  title={Performance and applications of optical pin beams in turbulent long-range free space optical communications},
  author={Francesco Nardo and Jan Tepper and Ricardo Barrios and Jonas Krimmer and Sebastian Randel},
  year={2025},
  url={http://arxiv.org/abs/2504.01704v1},
  abstract={Optical pin beams (OPBs) are a promising candidate for realizing turbulence-resilient long-distance free-space optical communication links spanning hundreds of kilometers. In this work, we introduce a unified theoretical model to describe the propagation of OPBs and present comprehensive simulation results based on many realizations and link-budget analyses for constant turbulence strengths. For reference, we compare the performance of the OPBs to weakly diverging and focusing Gaussian beams. For a 100km long air-to-air link, 10km above sea level, our simulation results show that OPBs offer an improved link budget of up to 8.6dB and enhanced beam wander statistics of up to 3dB compared to the considered Gaussian beams. Additionally, we identified a quadratic relationship between the transmitter aperture diameter and the maximum achievable distances, which is crucial in deciding the suitability of OPBs for a given application scenario.},
  doi={10.1117/12.3040720},
  journal={arXiv}
}

@article{hughes2016why,
  title={Why RLC realizations of certain impedances need many more energy storage elements than expected},
  author={Timothy H. Hughes},
  year={2016},
  url={http://arxiv.org/abs/1611.06258v2},
  abstract={It is a significant and longstanding puzzle that the resistor, inductor, capacitor (RLC) networks obtained by the established RLC realization procedures appear highly non-minimal from the perspective of linear systems theory. Specifically, each of these networks contains significantly more energy storage elements than the McMillan degree of its impedance, and possesses a non-minimal state-space representation whose states correspond to the inductor currents and capacitor voltages. Despite this apparent non-minimality, there have been no improved algorithms since the 1950s, with the concurrent discovery by Reza, Pantell, Fialkow and Gerst of a class of networks (the RPFG networks), which are a slight simplification of the Bott-Duffin networks. Each RPFG network contains more than twice as many energy storage elements as the McMillan degree of its impedance, yet it has never been established if all of these energy storage elements are necessary. In this paper, we present some newly discovered alternatives to the RPFG networks. We then prove that the RPFG networks, and these newly discovered networks, contain the least possible number of energy storage elements for realizing certain positive-real functions. In other words, all RLC networks which realize certain impedances contain more than twice the expected number (McMillan degree) of energy storage elements.},
  doi={10.1109/TAC.2017.2667585},
  journal={arXiv}
}

@article{dominković2021reviewing,
  title={Reviewing two decades of energy system analysis with bibliometrics},
  author={Dominik Franjo Dominković and Jann Michael Weinand and Fabian Scheller and Matteo D'Andrea and Russell McKenna},
  year={2021},
  url={http://arxiv.org/abs/2103.09917v1},
  abstract={The field of Energy System Analysis (ESA) has experienced exponential growth in the number of publications since at least the year 2000. This paper presents a comprehensive bibliometric analysis on ESA by employing different algorithms in Matlab and R. The focus of results is on quantitative indicators relating to number and type of publication outputs, collaboration links between institutions, authors and countries, and dynamic trends within the field. The five and twelve most productive countries have 50% and 80% of ESA publications respectively. The dominant institutions are even more concentrated within a small number of countries. A significant concentration of published papers within countries and institutions was also confirmed by analysing collaboration networks. These show dominant collaboration within the same university or at least the same country. There is also is a strong link among the most successful journals, authors and institutions. The Energy journal has had the most publications in the field, and its editor-in-chief Lund H is the author with most of the publications in the field, as well as the author with most of the highly cited publications in the field. In terms of the dynamics within the field in the past decade, recent years have seen a higher impact of topics related to flexibility and hybrid/integrated energy systems alongside a decline in individual technologies. This paper provides a holistic overview of two decades' research output and enables interested readers to obtain a comprehensive overview of the key trends in this active field.},
  doi={10.1016/j.rser.2021.111749},
  journal={arXiv}
}

@article{shah2025peertopeer,
  title={Peer-to-Peer Energy Trading in Dairy Farms using Multi-Agent Reinforcement Learning},
  author={Mian Ibad Ali Shah and Marcos Eduardo Cruz Victorio and Maeve Duffy and Enda Barrett and Karl Mason},
  year={2025},
  url={http://arxiv.org/abs/2511.23148v1},
  abstract={The integration of renewable energy resources in rural areas, such as dairy farming communities, enables decentralized energy management through Peer-to-Peer (P2P) energy trading. This research highlights the role of P2P trading in efficient energy distribution and its synergy with advanced optimization techniques. While traditional rule-based methods perform well under stable conditions, they struggle in dynamic environments. To address this, Multi-Agent Reinforcement Learning (MARL), specifically Proximal Policy Optimization (PPO) and Deep Q-Networks (DQN), is combined with community/distributed P2P trading mechanisms. By incorporating auction-based market clearing, a price advisor agent, and load and battery management, the approach achieves significant improvements. Results show that, compared to baseline models, DQN reduces electricity costs by 14.2% in Ireland and 5.16% in Finland, while increasing electricity revenue by 7.24% and 12.73%, respectively. PPO achieves the lowest peak hour demand, reducing it by 55.5% in Ireland, while DQN reduces peak hour demand by 50.0% in Ireland and 27.02% in Finland. These improvements are attributed to both MARL algorithms and P2P energy trading, which together results in electricity cost and peak hour demand reduction, and increase electricity selling revenue. This study highlights the complementary strengths of DQN, PPO, and P2P trading in achieving efficient, adaptable, and sustainable energy management in rural communities.},
  doi={10.1016/j.apenergy.2025.127041},
  journal={arXiv}
}

@article{liguori2023opening,
  title={Opening the Black Box: Towards inherently interpretable energy data imputation models using building physics insight},
  author={Antonio Liguori and Matias Quintana and Chun Fu and Clayton Miller and Jérôme Frisch and Christoph van Treeck},
  year={2023},
  url={http://arxiv.org/abs/2311.16632v2},
  abstract={Missing data are frequently observed by practitioners and researchers in the building energy modeling community. In this regard, advanced data-driven solutions, such as Deep Learning methods, are typically required to reflect the non-linear behavior of these anomalies. As an ongoing research question related to Deep Learning, a model's applicability to limited data settings can be explored by introducing prior knowledge in the network. This same strategy can also lead to more interpretable predictions, hence facilitating the field application of the approach. For that purpose, the aim of this paper is to propose the use of Physics-informed Denoising Autoencoders (PI-DAE) for missing data imputation in commercial buildings. In particular, the presented method enforces physics-inspired soft constraints to the loss function of a Denoising Autoencoder (DAE). In order to quantify the benefits of the physical component, an ablation study between different DAE configurations is conducted. First, three univariate DAEs are optimized separately on indoor air temperature, heating, and cooling data. Then, two multivariate DAEs are derived from the previous configurations. Eventually, a building thermal balance equation is coupled to the last multivariate configuration to obtain PI-DAE. Additionally, two commonly used benchmarks are employed to support the findings. It is shown how introducing physical knowledge in a multivariate Denoising Autoencoder can enhance the inherent model interpretability through the optimized physics-based coefficients. While no significant improvement is observed in terms of reconstruction error with the proposed PI-DAE, its enhanced robustness to varying rates of missing data and the valuable insights derived from the physics-based coefficients create opportunities for wider applications within building systems and the built environment.},
  doi={10.1016/j.enbuild.2024.114071},
  journal={arXiv}
}

@article{baima2024public,
  title={Public Sector Sustainable Energy Scheduler -- A Blockchain and IoT Integrated System},
  author={Renan Lima Baima and Iván Abellán Álvarez and Ivan Pavić and Emanuela Podda},
  year={2024},
  url={http://arxiv.org/abs/2403.07895v1},
  abstract={In response to the European Commission's aim of cutting carbon emissions by 2050, there is a growing need for cutting-edge solutions to promote low-carbon energy consumption in public infrastructures. This paper introduces a Proof of Concept (PoC) that integrates the transparency and immutability of blockchain and the Internet of Things (IoT) to enhance energy efficiency in tangible government-held public assets, focusing on curbing carbon emissions. Our system design utilizes a forecasting and optimization framework, inscribing the scheduled operations of heat pumps on a public sector blockchain. Registering usage metrics on the blockchain facilitates the verification of energy conservation, allows transparency in public energy consumption, and augments public awareness of energy usage patterns. The system fine-tunes the operations of electric heat pumps, prioritizing their use during low-carbon emission periods in power systems occurring during high renewable energy generations. Adaptive temperature configuration and schedules enable energy management in public venues, but blockchains' processing power and latency may represent bottlenecks setting scalability limits. However, the proof-of-concept weakness and other barriers are surpassed by the public sector blockchain advantages, leading to future research and tech innovations to fully exploit the synergies of blockchain and IoT in harnessing sustainable, low-carbon energy in the public domain.},
  doi={10.46855/energy-proceedings-10922},
  journal={arXiv}
}

@article{errando2009discovery,
  title={Discovery of very high energy gamma-rays from the flat spectrum radio quasar 3C 279 with the MAGIC telescope},
  author={M. Errando and R. Bock and D. Kranich and E. Lorenz and P. Majumdar and M. Mariotti and D. Mazin and E. Prandini and F. Tavecchio and M. Teshima and R. Wagner},
  year={2009},
  url={http://arxiv.org/abs/0901.3275v1},
  abstract={3C 279 is one of the best studied flat spectrum radio quasars located at a comparatively large redshift of z = 0.536. Observations in the very high energy band of such distant sources were impossible until recently due to the expected steep energy spectrum and the strong gamma-ray attenuation by the extragalactic background light photon field, which conspire to make the source visible only with a low energy threshold. Here the detection of a significant gamma-ray signal from 3C 279 at very high energies (E > 75 GeV) during a flare in early 2006 is reported. Implications of its energy spectrum on the current understanding of the extragalactic background light and very high energy gamma-ray emission mechanism models are discussed.},
  doi={10.1063/1.3076698},
  journal={arXiv}
}

@article{wei2016impact,
  title={Impact parameter dependence of pion ratio in probing the nuclear symmetry energy using heavy-ion collisions},
  author={Gao-Feng Wei and Guo-Qiang He and Xin-Wei Cao and Yi-Xin Lu},
  year={2016},
  url={http://arxiv.org/abs/1601.04246v1},
  abstract={The impact parameter dependence of \rpi ratio is examined in heavy-ion collisions at 400MeV/nucleon within a transport model. It is shown that the sensitivity of \rpi ratio on symmetry energy shows a transition from central to peripheral collisions, i.e., the stiffer symmetry energy leads to a larger \rpi ratio in peripheral collisions while the softer symmetry energy always leads this ratio to be larger in central collisions. After checking the kinematic energy distribution of \rpi ratio, we found this transition of sensitivity of \rpi ratio to symmetry energy is mainly from less energetic pions, i.e., the softer symmetry energy gets the less energetic pions to form a smaller \rpi ratio in peripheral collisions while these pions generate a larger \rpi ratio in central collisions. Undoubtedly, the softer symmetry energy can also lead more energetic pions to form a larger \rpi ratio in peripheral collisions. Nevertheless, considering that most of pions are insufficient energetic at this beam energy, we therefore suggest the \rpi ratio as a probe of the high-density symmetry energy effective only in central at most to midcentral collisions, thereby avoiding the possible information of low-density symmetry energy carried in \rpi ratio from peripheral collisions.},
  journal={arXiv}
}

@article{ali2019contributions,
  title={Contributions of Jets in Net Charge Fluctuations from the Beam Energy Scan at RHIC and LHC},
  author={Bushra Ali and Shaista Khan and Shakeel Ahmad},
  year={2019},
  url={http://arxiv.org/abs/1906.06482v1},
  abstract={Dynamical net charge fluctuations have been studied in ultra-relativistic heavy-ion collisions from the beam energy scan at RHIC and LHC energies by carrying out the hadronic model simulation. Monte Carlo model, HIJING is used to generate events in two different modes, HIJING-default with jet quenching switched off and jet/minijet production switched off. A popular variable, $ν_{[+-,dyn]}$ is used to study the net charge fluctuations in different centrality bins and the findings are compared with the available experimental values reported earlier. Although the broad features of net charge fluctuations are reproduced by the HIJING, yet the model predicts the larger magnitude of fluctuations as compared to the one observed in experiments. The role of jets/minijets production in reducing the net charge fluctuations is, however distinctly visible from the analysis of the two types of HIJING events. Furthermore, $dN_{ch}/dη$ and $1/N$ scaling is partially exhibited which is due to the fact that in HIJING, nucleus-nucleus collisions are treated as multiple independent nucleon-nucleon collisions.},
  doi={10.1155/2019/6034981},
  journal={arXiv}
}

@article{yessenov2021spacetime,
  title={Space-time wave packets localized in all dimensions},
  author={Murat Yessenov and Justin Free and Zhaozhong Chen and Eric G. Johnson and Martin P. J. Lavery and Miguel A. Alonso and Ayman F. Abouraddy},
  year={2021},
  url={http://arxiv.org/abs/2111.03095v2},
  abstract={Optical wave packets that are localized in space and time, but nevertheless overcome diffraction and travel rigidly in free space, are a long sought-after field structure with applications ranging from microscopy and remote sensing, to nonlinear and quantum optics. However, synthesizing such wave packets requires introducing non-differentiable angular dispersion with high spectral precision in two transverse dimensions, a capability that has eluded optics to date. Here, we describe an experimental strategy capable of sculpting the spatio-temporal spectrum of a generic pulsed beam by introducing arbitrary radial chirp via two-dimensional conformal coordinate transformations of the spectrally resolved field. This procedure yields propagation-invariant `space-time' wave packets localized in all dimensions, with tunable group velocity in the range from $0.7c$ to $1.8c$ in free space, and endowed with prescribed orbital angular momentum. By providing unprecedented flexibility in sculpting the three-dimensional structure of pulsed optical fields, our experimental strategy promises to be a versatile platform for the emerging enterprise of space-time optics.},
  doi={10.1038/s41467-022-32240-0},
  journal={arXiv}
}

@article{illingworth2023structure,
  title={The structure and density of $k$-product-free sets in the free semigroup},
  author={Freddie Illingworth and Lukas Michel and Alex Scott},
  year={2023},
  url={http://arxiv.org/abs/2305.05304v2},
  abstract={The free semigroup $\mathcal{F}$ over a finite alphabet $\mathcal{A}$ is the set of all finite words with letters from $\mathcal{A}$ equipped with the operation of concatenation. A subset $S$ of $\mathcal{F}$ is $k$-product-free if no element of $S$ can be obtained by concatenating $k$ words from $S$, and strongly $k$-product-free if no element of $S$ is a (non-trivial) concatenation of at most $k$ words from $S$.   We prove that a $k$-product-free subset of $\mathcal{F}$ has upper Banach density at most $1/ρ(k)$, where $ρ(k) = \min\{\ell \colon \ell \nmid k - 1\}$. We also determine the structure of the extremal $k$-product-free subsets for all $k \notin \{3, 5, 7, 13\}$; a special case of this proves a conjecture of Leader, Letzter, Narayanan, and Walters. We further determine the structure of all strongly $k$-product-free sets with maximum density. Finally, we prove that $k$-product-free subsets of the free group have upper Banach density at most $1/ρ(k)$, which confirms a conjecture of Ortega, Rué, and Serra.},
  journal={arXiv}
}

@article{bondarev1997some,
  title={Some Methods of Minimization of Calculations in High Energy Physics},
  author={Alexander L. Bondarev},
  year={1997},
  url={http://arxiv.org/abs/hep-ph/9701332v1},
  abstract={Two approaches to calculations' minimization in High Energy Physics are considered. The first one is the method of covariant calculations for the amplitudes of processes with polarized Dirac particles. The second one connects with the possibility to reduce the expressions for the traces of products of ten and more Dirac gamma-matrices.},
  journal={arXiv}
}

@article{wang2021privacypreserving,
  title={Privacy-Preserving Energy Storage Sharing with Blockchain and Secure Multi-Party Computation},
  author={Nan Wang and Sid Chi-Kin Chau and Yue Zhou},
  year={2021},
  url={http://arxiv.org/abs/2111.02005v1},
  abstract={Energy storage provides an effective way of shifting temporal energy demands and supplies, which enables significant cost reduction under time-of-use energy pricing plans. Despite its promising benefits, the cost of present energy storage remains expensive, presenting a major obstacle to practical deployment. A more viable solution to improve the cost-effectiveness is by sharing energy storage, such as community sharing, cloud energy storage and peer-to-peer sharing. However, revealing private energy demand data to an external energy storage operator may compromise user privacy, and is susceptible to data misuses and breaches. In this paper, we explore a novel approach to support energy storage sharing with privacy protection, based on privacy-preserving blockchain and secure multi-party computation. We present an integrated solution to enable privacy-preserving energy storage sharing, such that energy storage service scheduling and cost-sharing can be attained without the knowledge of individual users' demands. It also supports auditing and verification by the grid operator via blockchain. Furthermore, our privacy-preserving solution can safeguard against a dishonest majority of users, who may collude in cheating, without requiring a trusted third-party. We implemented our solution as a smart contract on real-world Ethereum blockchain platform, and provide empirical evaluation in this paper.},
  doi={10.1145/3508467.3508471},
  journal={arXiv}
}

@article{nieto1994theoretical,
  title={Theoretical Motivation for Gravitation Experiments on Ultra-Low Energy Antiprotons and Antihydrogen},
  author={Michael Martin Nieto and T. Goldman and John D. Anderson and Eunice L. Lau and J. Pérez-Mercader},
  year={1994},
  url={http://arxiv.org/abs/hep-ph/9412234v1},
  abstract={We know that the generally accepted theories of gravity and quantum mechanics are fundamentally incompatible. Thus, when we try to combine these theories, we must beware of physical pitfalls. Modern theories of quantum gravity are trying to overcome these problems. Any ideas must confront the present agreement with general relativity, but yet be free to wonder about not understood phenomena, such as the dark matter problem and the anomalous spacecraft data which we announce here. This all has led some ``intrepid" theorists to consider a new gravitational regime, that of antimatter. Even more ``daring" experimentalists are attempting, or considering attempting, the measurement of the gravitational force on antimatter, including low-energy antiprotons and, perhaps most enticing, antihydrogen.},
  journal={arXiv}
}

@article{boisseau2012new,
  title={New DRIE-Patterned Electrets for Vibration Energy Harvesting},
  author={S. Boisseau and A. -B. Duret and J. -J. Chaillout and G. Despesse},
  year={2012},
  url={http://arxiv.org/abs/1205.2383v1},
  abstract={This paper is about a new manufacturing process aimed at developing stable SiO2/Si3N4 patterned electrets using a Deep Reactive Ion Etching (DRIE) step for an application in electret-based Vibration Energy Harvesters (e-VEH). This process consists in forming continuous layers of SiO2/Si3N4 electrets in order to limit surface conduction phenomena and is a new way to see the problem of electret patterning. Experimental results prove that patterned electrets charged by a positive corona discharge show excellent stability with high surface charge densities that may reach 5mC/m^2 on 1.1μm-thick layers, even with fine patterning and harsh temperature conditions (up to 250°C). This paves the way to new e-VEH designs and manufacturing processes.},
  doi={10.1051/epjconf/20123302010},
  journal={arXiv}
}

@article{ito2023note,
  title={A note on free divergence-free vector fields},
  author={Hyuga Ito and Akihiro Miyagawa},
  year={2023},
  url={http://arxiv.org/abs/2311.15550v2},
  abstract={We exhibit an orthonormal basis of cyclic gradients and a (non-orthogonal) basis of the homogeneous free divergence-free vector field on the full Fock space and determine the dimension of Voiculescu's free divergence-free vector field of degree k or less. Moreover, we also give a concrete formula for the orthogonal projection onto the space of cyclic gradients as well as the free Leray projection.},
  journal={arXiv}
}

@article{bajnok2024wienerhopf,
  title={Wiener-Hopf solution of the free energy TBA problem and instanton sectors in the O(3) sigma model},
  author={Zoltán Bajnok and János Balog and István Vona},
  year={2024},
  url={http://arxiv.org/abs/2404.07621v2},
  abstract={Perturbation theory in asymptotically free quantum field theories is asymptotic. The factorially growing perturbative coefficients carry information about non-perturbative corrections, which can be related to renormalons and instantons. Using the Wiener-Hopf technique we determine the full analytic solution for the free energy density in the two dimensional $O(N)$ sigma models. For $N>3$ there are no instantons, and we found that the perturbative series carries all the information about the non-perturbative corrections. However, in the $O(3)$ case, we identify several non-perturbative sectors that are not related to the asymptotics of the perturbative series. The number of sectors depends on the observables: for the ground-state energy density we identify three sectors, which we attribute to instantons. For the free energy density in the running perturbative coupling we found infinitely many sectors.},
  journal={arXiv}
}

@article{pal2019inclusion,
  title={Inclusion of Enclosed Hydration Effects in the Binding Free Energy Estimation of Dopamine D3 Receptor Complexes},
  author={Rajat Kumar Pal and Steve Ramsey and Satishkumar Gadhiya and Pierpaolo Cordone and Lauren Wickstrom and Wayne W. Harding and Tom Kurtzman and Emilio Gallicchio},
  year={2019},
  url={http://arxiv.org/abs/1904.11058v1},
  abstract={Confined hydration and conformational flexibility are some of the challenges encountered for the rational design of selective antagonists of G-protein coupled receptors. We present a set of C3-substituted (-)-stepholidine derivatives as potent binders of the dopamine D3 receptor. The compounds are characterized biochemically, as well as by computer modeling using a novel molecular dynamics-based alchemical binding free energy approach which incorporates the effect of the displacement of enclosed water molecules from the binding site. The free energy of displacement of specific hydration sites is obtained using the Hydration Site Analysis method with explicit solvation. This work underscores the critical role of confined hydration and conformational reorganization in the molecular recognition mechanism of dopamine receptors and illustrates the potential of binding free energy models to represent these key phenomena.},
  doi={10.1371/journal.pone.0222902},
  journal={arXiv}
}

@article{bashir2023jointly,
  title={Jointly Managing Electrical and Thermal Energy in Solar- and Battery-powered Computer Systems},
  author={Noman Bashir and Yasra Chandio and David Irwin and Fatima M. Anwar and Jeremy Gummeson and Prashant Shenoy},
  year={2023},
  url={http://arxiv.org/abs/2305.00855v1},
  abstract={Environmentally-powered computer systems operate on renewable energy harvested from their environment, such as solar or wind, and stored in batteries. While harvesting environmental energy has long been necessary for small-scale embedded systems without access to external power sources, it is also increasingly important in designing sustainable larger-scale systems for edge applications. For sustained operations, such systems must consider not only the electrical energy but also the thermal energy available in the environment in their design and operation. Unfortunately, prior work generally ignores the impact of thermal effects, and instead implicitly assumes ideal temperatures. To address the problem, we develop a thermodynamic model that captures the interplay of electrical and thermal energy in environmentally-powered computer systems. The model captures the effect of environmental conditions, the system's physical properties, and workload scheduling on performance. In evaluating our model, we distill the thermal effects that impact these systems using a small-scale prototype and a programmable incubator. We then leverage our model to show how considering these thermal effects in designing and operating environmentally-powered computer systems of varying scales can improve their energy-efficiency, performance, and availability.},
  doi={10.1145/3575813.3595191},
  journal={arXiv}
}

@article{li2021coordinating,
  title={Coordinating Flexible Demand Response and Renewable Uncertainties for Scheduling of Community Integrated Energy Systems with an Electric Vehicle Charging Station: A Bi-level Approach},
  author={Yang Li and Meng Han and Zhen Yang and Guoqing Li},
  year={2021},
  url={http://arxiv.org/abs/2107.07772v1},
  abstract={A community integrated energy system (CIES) with an electric vehicle charging station (EVCS) provides a new way for tackling growing concerns of energy efficiency and environmental pollution, it is a critical task to coordinate flexible demand response and multiple renewable uncertainties. To this end, a novel bi-level optimal dispatching model for the CIES with an EVCS in multi-stakeholder scenarios is established in this paper. In this model, an integrated demand response program is designed to promote a balance between energy supply and demand while maintaining a user comprehensive satisfaction within an acceptable range. To further tap the potential of demand response through flexibly guiding users' energy consumption and electric vehicles' behaviors (charging, discharging and providing spinning reserves), a dynamic pricing mechanism combining time-of-use and real-time pricing is put forward. In the solution phase, by using sequence operation theory (SOT), the original chance-constrained programming (CCP) model is converted into a readily solvable mixed-integer linear programming (MILP) formulation and finally solved by CPLEX solver. The simulation results on a practical CIES located in North China demonstrate that the presented method manages to balance the interests between CIES and EVCS via the coordination of flexible demand response and uncertain renewables.},
  doi={10.1109/TSTE.2021.3090463},
  journal={arXiv}
}

@article{dorame2013invisible,
  title={Invisible decays of ultra-high energy neutrinos},
  author={L. Dorame and O. G. Miranda and J. W. F. Valle},
  year={2013},
  url={http://arxiv.org/abs/1303.4891v2},
  abstract={Gamma-ray bursts (GRBs) are expected to provide a source of ultra high energy cosmic rays, accompanied with potentially detectable neutrinos at neutrino telescopes. Recently, IceCube has set an upper bound on this neutrino flux well below theoretical expectation. We investigate whether this mismatch between expectation and observation can be due to neutrino decay. We demosntrate the phenomenological consistency and theoretical plausibility of the neutrino decay hypothesis. A potential implication is the observability of majoron-emitting neutrinoless double beta decay.},
  journal={arXiv}
}

@article{marković2020voltage,
  title={Voltage Estimation in Low-Voltage Distribution Grids with Distributed Energy Resources},
  author={Marija Marković and Amirhossein Sajadi and Anthony Florita and Robert Cruickshank and Bri-Mathias Hodge},
  year={2020},
  url={http://arxiv.org/abs/2011.05598v1},
  abstract={The present distribution grids generally have limited sensing capabilities and are therefore characterized by low observability. Improved observability is a prerequisite for increasing the hosting capacity of distributed energy resources such as solar photovoltaics (PV) in distribution grids. In this context, this paper presents learning-aided low-voltage estimation using untapped but readily available and widely distributed sensors from cable television (CATV) networks. The CATV sensors offer timely local voltage magnitude sensing with 5-minute resolution and can provide an order of magnitude more data on the state of a distribution system than currently deployed utility sensors. The proposed solution incorporates voltage readings from neighboring CATV sensors, taking into account spatio-temporal aspects of the observations, and estimates single-phase voltage magnitudes at all non-monitored buses using random forest. The effectiveness of the proposed approach was demonstrated using a 1572-bus feeder from the SMART-DS data set for two case studies - passive distribution feeder (without PV) and active distribution feeder (with PV). The analysis was conducted on simulated data, and the results show voltage estimates with a high degree of accuracy, even at extremely low percentages of observable nodes.},
  doi={10.1109/TSTE.2021.3060546},
  journal={arXiv}
}

@article{dimca2015exponents,
  title={On the exponents of free and nearly free projective plane curves},
  author={Alexandru Dimca and Gabriel Sticlaru},
  year={2015},
  url={http://arxiv.org/abs/1511.08938v2},
  abstract={We show that all the possible pairs of integers occur as exponents for free or nearly free irreducible plane curves and line arrangements, by producing only two types of simple families of examples. The topology of the complements of these curves and line arrangements is also discussed, and many of them are shown not to be $K(π,1)$ spaces.},
  journal={arXiv}
}

@article{varga2016analytic,
  title={Analytic approximation of energy resolution in cascaded gaseous detectors},
  author={Dezső Varga},
  year={2016},
  url={http://arxiv.org/abs/1602.01316v1},
  abstract={An approximate formula has been derived for gain fluctuations in cascaded gaseous detectors such as GEM-s, based on the assumption that the charge collection, avalanche formation and extraction steps are independent cascaded processes. In order to test the approximation experimentally, a setup involving a standard GEM layer has been constructed to measure the energy resolution for 5.9 keV gamma particles. The formula reasonably traces both the charge collection as well as the extraction process dependence of the energy resolution. Such analytic approximation for gain fluctuations can be applied to multi-GEM detectors where it aids the interpretation of measurements as well as simulations.},
  doi={10.1155/2016/8561743},
  journal={arXiv}
}

@article{wietzke2024occupancy,
  title={Occupancy Prediction for Building Energy Systems with Latent Force Models},
  author={Thore Wietzke and Jan Gall and Knut Graichen},
  year={2024},
  url={http://arxiv.org/abs/2401.05074v2},
  abstract={This paper presents a new approach to predict the occupancy for building energy systems (BES). A Gaussian Process (GP) is used to model the occupancy and is represented as a state space model that is equivalent to the full GP if Kalman filtering and smoothing is used. The combination of GPs and mechanistic models is called Latent Force Model (LFM). An LFM-based model predictive control (MPC) concept for BES is presented that benefits from the extrapolation capability of mechanistic models and the learning ability of GPs to predict the occupancy within the building. Simulations with EnergyPlus and a comparison with real-world data from the Bosch Research Campus in Renningen show that a reduced energy demand and thermal discomfort can be obtained with the LFM-based MPC scheme by accounting for the predicted stochastic occupancy.},
  doi={10.1016/j.enbuild.2024.113968},
  journal={arXiv}
}

@article{kang2025novel,
  title={A novel approach of day-ahead cooling load prediction and optimal control for ice-based thermal energy storage (TES) system in commercial buildings},
  author={Xuyuan Kang and Xiao Wang and Jingjing An and Da Yan},
  year={2025},
  url={http://arxiv.org/abs/2509.13371v1},
  abstract={Thermal energy storage (TES) is an effective method for load shifting and demand response in buildings. Optimal TES control and management are essential to improve the performance of the cooling system. Most existing TES systems operate on a fixed schedule, which cannot take full advantage of its load shifting capability, and requires extensive investigation and optimization. This study proposed a novel integrated load prediction and optimized control approach for ice-based TES in commercial buildings. A cooling load prediction model was developed and a mid-day modification mechanism was introduced into the prediction model to improve the accuracy. Based on the predictions, a rule-based control strategy was proposed according to the time-of-use tariff; the mid-day control adjustment mechanism was introduced in accordance with the mid-day prediction modifications. The proposed approach was applied in the ice-based TES system of a commercial complex in Beijing, and achieved a mean absolute error (MAE) of 389 kW and coefficient of variance of MAE of 12.5%. The integrated prediction-based control strategy achieved an energy cost saving rate of 9.9%. The proposed model was deployed in the realistic building automation system of the case building and significantly improved the efficiency and automation of the cooling system.},
  doi={10.1016/j.enbuild.2022.112478},
  journal={arXiv}
}

@article{handel2011free,
  title={The free splitting complex of a free group I: Hyperbolicity},
  author={Michael Handel and Lee Mosher},
  year={2011},
  url={http://arxiv.org/abs/1111.1994v2},
  abstract={We prove that the free splitting complex of a finite rank free group, also known as Hatcher's sphere complex, is hyperbolic.},
  doi={10.2140/gt.2013.17.1581},
  journal={arXiv}
}

@article{teichmann2024towards,
  title={Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow},
  author={Marvin Tom Teichmann and Manasi Datar and Lisa Kratzke and Fernando Vega and Florin C. Ghesu},
  year={2024},
  url={http://arxiv.org/abs/2409.18628v1},
  abstract={The precision of contouring target structures and organs-at-risk (OAR) in radiotherapy planning is crucial for ensuring treatment efficacy and patient safety. Recent advancements in deep learning (DL) have significantly improved OAR contouring performance, yet the reliability of these models, especially in the presence of out-of-distribution (OOD) scenarios, remains a concern in clinical settings. This application study explores the integration of epistemic uncertainty estimation within the OAR contouring workflow to enable OOD detection in clinically relevant scenarios, using specifically compiled data. Furthermore, we introduce an advanced statistical method for OOD detection to enhance the methodological framework of uncertainty estimation. Our empirical evaluation demonstrates that epistemic uncertainty estimation is effective in identifying instances where model predictions are unreliable and may require an expert review. Notably, our approach achieves an AUC-ROC of 0.95 for OOD detection, with a specificity of 0.95 and a sensitivity of 0.92 for implant cases, underscoring its efficacy. This study addresses significant gaps in the current research landscape, such as the lack of ground truth for uncertainty estimation and limited empirical evaluations. Additionally, it provides a clinically relevant application of epistemic uncertainty estimation in an FDA-approved and widely used clinical solution for OAR segmentation from Varian, a Siemens Healthineers company, highlighting its practical benefits.},
  journal={arXiv}
}

@article{machon2023influence,
  title={The Influence of Epistemic Communities on International Political Negotiations about the Space Debris Problem},
  author={Miloslav Machon},
  year={2023},
  url={http://arxiv.org/abs/2312.00612v2},
  abstract={Since the 1970's the debate about the rising importance of transnational relations has existed in international relations. Apart from states, related research also focuses on other actors, including epistemic communities. The article uses the concept of epistemic communities and finds whether the activity of epistemic communities determines the process of the international management of outer space in the case of the political negotiations relating to space debris in UNCOPUOS and UNOOSA. The activity of epistemic communities exists in the political negotiations relating to space debris in UNCOPUOS and UNOOSA, but it has not been reflected in the related scholarly literature. Epistemic communities from the non-governmental organizations IAF, COSPAR and IISL contributed to setting the space debris problem on the agenda of UNCOPUOS. Also, under the influence of epistemic communities from the governmental organization IADC, UNCOPUOS adopted guidelines preventing the creation of further amounts of space debris.},
  doi={10.32422/cjir.245},
  journal={arXiv}
}

@article{dongen2020epistemic,
  title={The Epistemic Virtues of the Virtuous Theorist: On Albert Einstein and His Autobiography},
  author={Jeroen van Dongen},
  year={2020},
  url={http://arxiv.org/abs/2002.01301v1},
  abstract={Albert Einstein's practice in physics and his philosophical positions gradually reoriented themselves from more empiricist towards rationalist viewpoints. This change accompanied his turn towards unified field theory and different presentations of himself, eventually leading to his highly programmatic Autobiographical Notes in 1949. Einstein enlisted his own history and professional stature to mold an ideal of a theoretical physicist who represented particular epistemic virtues and moral qualities. These in turn reflected the theoretical ideas of his strongly mathematical unification program and professed Spinozist beliefs.},
  doi={10.1007/978-3-319-48893-6_5},
  journal={arXiv}
}

@article{moyse2025social,
  title={Social hierarchy shapes foraging decisions},
  author={Lisa Blum Moyse and Ahmed El Hady},
  year={2025},
  url={http://arxiv.org/abs/2503.02794v1},
  abstract={Social foraging is a widespread form of animal foraging in which groups of individuals coordinate their decisions to exploit resources in the environment. Animals show a variety of social structures from egalitarian to hierarchical. In this study, we examine how different forms of social hierarchy shape foraging decisions. We developed a mechanistic analytically tractable model to study the underlying processes of social foraging, tying the microscopic individual to the macroscopic group levels. Based on a stochastic evidence accumulation framework, we developed a model of patch-leaving decisions in a large hierarchical group with leading and following individuals. Across a variety of information sharing mechanisms, we were able to analytically quantify emergent collective dynamics. We found that follower-leader dynamics through observations of leader movements or through counting the number of individuals in a patch confers, for most conditions, a benefit for the following individuals by increasing their accuracy in inferring patch richness. On the other hand, misinformation, through the communication of false beliefs about food rewards or patch quality, shows to be detrimental to following individuals, but paradoxically may lead to increased group cohesion. In an era where there is a huge amount of animal foraging data collected, our model provides a systematic way to conceptualize and understand those data by uncovering hidden mechanisms underlying social foraging decisions.},
  journal={arXiv}
}

@article{kilpatrick2020normative,
  title={Normative theory of patch foraging decisions},
  author={Zachary P Kilpatrick and Jacob D Davidson and Ahmed El Hady},
  year={2020},
  url={http://arxiv.org/abs/2004.10671v1},
  abstract={Foraging is a fundamental behavior as animals' search for food is crucial for their survival. Patch leaving is a canonical foraging behavior, but classic theoretical conceptions of patch leaving decisions lack some key naturalistic details. Optimal foraging theory provides general rules for when an animal should leave a patch, but does not provide mechanistic insights about how those rules change with the structure of the environment. Such a mechanistic framework would aid in designing quantitative experiments to unravel behavioral and neural underpinnings of foraging. To address these shortcomings, we develop a normative theory of patch foraging decisions. Using a Bayesian approach, we treat patch leaving behavior as a statistical inference problem. We derive the animals' optimal decision strategies in both non-depleting and depleting environments. A majority of these cases can be analyzed explicitly using methods from stochastic processes. Our behavioral predictions are expressed in terms of the optimal patch residence time and the decision rule by which an animal departs a patch. We also extend our theory to a hierarchical model in which the forager learns the environmental food resource distribution. The quantitative framework we develop will therefore help experimenters move from analyzing trial based behavior to continuous behavior without the loss of quantitative rigor. Our theoretical framework both extends optimal foraging theory and motivates a variety of behavioral and neuroscientific experiments investigating patch foraging behavior.},
  journal={arXiv}
}

@article{bhattacharya2013collective,
  title={Collective foraging in heterogeneous landscapes},
  author={Kunal Bhattacharya and Tamás Vicsek},
  year={2013},
  url={http://arxiv.org/abs/1311.2169v1},
  abstract={Animals foraging alone are hypothesized to optimize the encounter rates with resources through Lévy walks. However, the issue of how the interactions between multiple foragers influence their search efficiency is still not completely understood. To address this, we consider a model to study the optimal strategy for a group of foragers searching for targets distributed heterogeneously. In our model foragers move on a square lattice containing immobile but regenerative targets. At any instant a forager is able to detect only those targets that happen to be in the same site. However, we allow the foragers to have information about the state of other foragers. A forager who has not detected any target walks towards the nearest location, where another forager has detected a target, with probability $\exp{\left(-αd\right)}$, where $d$ is the distance and $α$ is a parameter. The model reveals that neither overcrowding ($α\to 0$) nor independent searching ($α\to\infty$) is beneficial for the group. For patchy distribution of targets the efficiency is maximum for intermediate values of $α$. Also, in the limit $α\to 0$, the length of the walks can become scale-free.},
  journal={arXiv}
}

@article{zhao2014optimal,
  title={Optimal Lévy-flight foraging in a finite landscape},
  author={Kun Zhao and Raja Jurdak and Jiajun Liu and David Westcott and Branislav Kusy and Hazel Parry and Philipp Sommer and Adam McKeown},
  year={2014},
  url={http://arxiv.org/abs/1406.1649v2},
  abstract={We present a simple model to study Lévy-flight foraging in a finite landscape with countable targets. In our approach, foraging is a step-based exploratory random search process with a power-law step-size distribution $P(l) \propto l^{-μ}$. We find that, when the termination is regulated by a finite number of steps $N$, the optimum value of $μ$ that maximises the foraging efficiency can vary substantially in the interval $μ\in (1,3)$, depending on the landscape features (landscape size and number of targets). We further demonstrate that subjective returning can be another significant factor that affects the foraging efficiency in such context. Our results suggest that Lévy-flight foraging may arise through an interaction between the environmental context and the termination of exploitation, and particularly that the number of steps can play an important role in this scenario which is overlooked by most previous work. Our study not only provides a new perspective on Lévy-flight foraging, but also opens new avenues for investigating the interaction between foraging dynamics and environment as well as offers a realistic framework for analysing animal movement patterns from empirical data.},
  doi={10.1098/rsif.2014.1158},
  journal={arXiv}
}

@article{dipierro2022efficiency,
  title={Efficiency functionals for the Lévy flight foraging hypothesis},
  author={Serena Dipierro and Giovanni Giacomin and Enrico Valdinoci},
  year={2022},
  url={http://arxiv.org/abs/2207.09873v1},
  abstract={We consider a forager diffusing via a fractional heat equation and we introduce several efficiency functionals whose optimality is discussed in relation to the Lévy exponent of the evolution equation.   Several biological scenarios, such as a target close to the forager, a sparse environment, a target located away from the forager and two targets are specifically taken into account.   The optimal strategies of each of these configurations are here analyzed explicitly also with the aid of some special functions of classical flavor and the results are confronted with the existing paradigms of the Lévy foraging hypothesis.   Interestingly, one discovers bifurcation phenomena in which a sudden switch occurs between an optimal (but somehow unreliable) Lévy foraging pattern of inverse square law type and a less ideal (but somehow more secure) classical Brownian motion strategy.   Additionally, optimal foraging strategies can be detected in the vicinity of the Brownian one even in cases in which the Brownian one is pessimizing an efficiency functional.},
  journal={arXiv}
}

@article{muñozgil2023optimal,
  title={Optimal foraging strategies can be learned},
  author={Gorka Muñoz-Gil and Andrea López-Incera and Lukas J. Fiderer and Hans J. Briegel},
  year={2023},
  url={http://arxiv.org/abs/2303.06050v3},
  abstract={The foraging behavior of animals is a paradigm of target search in nature. Understanding which foraging strategies are optimal and how animals learn them are central challenges in modeling animal foraging. While the question of optimality has wide-ranging implications across fields such as economy, physics, and ecology, the question of learnability is a topic of ongoing debate in evolutionary biology. Recognizing the interconnected nature of these challenges, this work addresses them simultaneously by exploring optimal foraging strategies through a reinforcement learning framework. To this end, we model foragers as learning agents. We first prove theoretically that maximizing rewards in our reinforcement learning model is equivalent to optimizing foraging efficiency. We then show with numerical experiments that, in the paradigmatic model of non-destructive search, our agents learn foraging strategies which outperform the efficiency of some of the best known strategies such as Lévy walks. These findings highlight the potential of reinforcement learning as a versatile framework not only for optimizing search strategies but also to model the learning process, thus shedding light on the role of learning in natural optimization processes.},
  doi={10.1088/1367-2630/ad19a8},
  journal={arXiv}
}

@article{macqueen2025importance,
  title={The importance of exploration: Modelling site-constant foraging},
  author={Sarah A. MacQueen and Clara F. Hardy and W. John Braun and Rebecca C. Tyson},
  year={2025},
  url={http://arxiv.org/abs/2503.20086v1},
  abstract={Foraging site constancy, or repeated return to the same foraging location, is a foraging strategy used by many species to decrease uncertainty, but it is often unclear exactly how the foraging site is identified. Here we focus on the context where food harvesting is first preceded by a separate exploration period. Foraging then consists of three distinct steps: (1) exploration of the landscape (site-generation), (2) selection of a foraging site (site-selection), and (3) exploitation (harvesting) through repeated trips between the foraging site and "home base". This type of foraging has received scant attention by modellers, leading to two main knowledge gaps. First, little is known about how organisms implement steps (1) and (2). Second, it is not known how the choice of implementation method affects the outcomes of step (3). We investigate these two gaps using an agent-based model, with bumble bees as our model organism, foraging in a patchy resource landscape of crop, wildflower, and empty cells. We tested two different site-generation methods (random and circular foray exploration behaviour) and four different site-selection methods (random and optimizing based on distance from the nest, local wildflower density, or net rate of energy return) on a variety of outcomes from the site-constant harvesting step. We find that site-selection method has a high impact on crop pollination services as well as the percent of crop resources collected, while site-generation method has a high impact on the percent of time spent harvesting and the total trip time. We also find that some of the patterns we identify can be used to infer how a given real organism is identifying a foraging site. Our results underscore the importance of explicitly considering exploratory behaviour to better understand the ecological consequences of foraging dynamics.},
  journal={arXiv}
}

@article{simonelli2024human,
  title={Human foraging strategies flexibly adapt to resource distribution and time constraints},
  author={Valeria Simonelli and Davide Nuzzi and Gian Luca Lancia and Giovanni Pezzulo},
  year={2024},
  url={http://arxiv.org/abs/2408.01350v4},
  abstract={Foraging is a crucial activity, yet the extent to which humans employ flexible versus rigid strategies remains unclear. This study investigates how individuals adapt their foraging strategies in response to resource distribution and foraging time constraints. For this, we designed a video-game-like foraging task that requires participants to navigate a four-areas environment to collect coins from treasure boxes within a limited time. This task engages multiple cognitive abilities, such as navigation, learning, and memorization of treasure box locations. Findings indicate that participants adjust their foraging strategies -- encompassing both stay-or-leave decisions, such as the number of boxes opened in initial areas and behavioral aspects, such as the time to navigate from box to box -- depending on both resource distribution and foraging time. Additionally, they improved their performance over time as an effect of both enhanced navigation skills and adaptation of foraging strategies. Finally, participants' performance was initially distant from the reward-maximizing performance of optimal agents due to the learning process humans undergo; however, it approximated the optimal agent's performance towards the end of the task, without fully reaching it. These results highlight the flexibility of human foraging behavior and underscore the importance of employing optimality models and ecologically rich scenarios to study foraging.},
  journal={arXiv}
}

@article{wispinski2022adaptive,
  title={Adaptive patch foraging in deep reinforcement learning agents},
  author={Nathan J. Wispinski and Andrew Butcher and Kory W. Mathewson and Craig S. Chapman and Matthew M. Botvinick and Patrick M. Pilarski},
  year={2022},
  url={http://arxiv.org/abs/2210.08085v2},
  abstract={Patch foraging is one of the most heavily studied behavioral optimization challenges in biology. However, despite its importance to biological intelligence, this behavioral optimization problem is understudied in artificial intelligence research. Patch foraging is especially amenable to study given that it has a known optimal solution, which may be difficult to discover given current techniques in deep reinforcement learning. Here, we investigate deep reinforcement learning agents in an ecological patch foraging task. For the first time, we show that machine learning agents can learn to patch forage adaptively in patterns similar to biological foragers, and approach optimal patch foraging behavior when accounting for temporal discounting. Finally, we show emergent internal dynamics in these agents that resemble single-cell recordings from foraging non-human primates, which complements experimental and theoretical work on the neural mechanisms of biological foraging. This work suggests that agents interacting in complex environments with ecologically valid pressures arrive at common solutions, suggesting the emergence of foundational computations behind adaptive, intelligent behavior in both biological and artificial agents.},
  journal={arXiv}
}

@article{amorim2014continuous,
  title={A continuous model of ant foraging with pheromones and trail formation},
  author={Paulo Amorim},
  year={2014},
  url={http://arxiv.org/abs/1402.5611v1},
  abstract={We propose and numerically analyze a PDE model of ant foraging behavior. Ant foraging is a prime example of individuals following simple behavioral rules based on local information producing complex, organized and ``intelligent'' strategies at the population level. One of its main aspects is the widespread use of pheromones, which are chemical compounds laid by the ants used to attract other ants to a food source. In this work, we consider a continuous description of a population of ants and simulate numerically the foraging behavior using a system of PDEs of chemotaxis type. We show that, numerically, this system accurately reproduces observed foraging behavior, such as trail formation and efficient removal of food sources.},
  journal={arXiv}
}

@article{penney2017toward,
  title={Toward Foraging for Understanding of StarCraft Agents: An Empirical Study},
  author={Sean Penney and Jonathan Dodge and Claudia Hilderbrand and Andrew Anderson and Logan Simpson and Margaret Burnett},
  year={2017},
  url={http://arxiv.org/abs/1711.08019v3},
  abstract={Assessing and understanding intelligent agents is a difficult task for users that lack an AI background. A relatively new area, called "Explainable AI," is emerging to help address this problem, but little is known about how users would forage through information an explanation system might offer. To inform the development of Explainable AI systems, we conducted a formative study, using the lens of Information Foraging Theory, into how experienced users foraged in the domain of StarCraft to assess an agent. Our results showed that participants faced difficult foraging problems. These foraging problems caused participants to entirely miss events that were important to them, reluctantly choose to ignore actions they did not want to ignore, and bear high cognitive, navigation, and information costs to access the information they needed.},
  journal={arXiv}
}

@article{benichou2017optimally,
  title={Optimally Frugal Foraging},
  author={O. Benichou and U. Bhat and P. L. Krapivsky and S. Redner},
  year={2017},
  url={http://arxiv.org/abs/1711.03610v1},
  abstract={We introduce the \emph{frugal foraging} model in which a forager performs a discrete-time random walk on a lattice, where each site initially contains $\mathcal{S}$ food units. The forager metabolizes one unit of food at each step and starves to death when it last ate $\mathcal{S}$ steps in the past. Whenever the forager decides to eat, it consumes all food at its current site and this site remains empty (no food replenishment). The crucial property of the forager is that it is \emph{frugal} and eats only when encountering food within at most $k$ steps of starvation. We compute the average lifetime analytically as a function of frugality threshold and show that there exists an optimal strategy, namely, a frugality threshold $k^*$ that maximizes the forager lifetime.},
  doi={10.1103/PhysRevE.97.022110},
  journal={arXiv}
}

@article{kim2023finite,
  title={Finite population effects on optimal communication for social foragers},
  author={Hyunjoong Kim and Yoichiro Mori and Joshua B Plotkin},
  year={2023},
  url={http://arxiv.org/abs/2308.00298v1},
  abstract={Foraging is crucial for animals to survive. Many species forage in groups, as individuals communicate to share information about the location of available resources. For example, eusocial foragers, such as honey bees and many ants, recruit members from their central hive or nest to a known foraging site. However, the optimal level of communication and recruitment depends on the overall group size, the distribution of available resources, and the extent of interference between multiple individuals attempting to forage from a site. In this paper, we develop a discrete-time Markov chain model of eusocial foragers, who communicate information with a certain probability. We compare the stochastic model and its corresponding infinite-population limit. We find that foraging efficiency tapers off when recruitment probability is too high -- a phenomenon that does not occur in the infinite-population model, even though it occurs for any finite population size. The marginal inefficiency at high recruitment probability increases as the population increases, similar to a boundary layer. In particular, we prove there is a significant gap between the foraging efficiency of finite and infinite population models in the extreme case of complete communication. We also analyze this phenomenon by approximating the stationary distribution of foragers over sites in terms of mean escape times from multiple quasi-steady states. We conclude that for any finite group of foragers, an individual who has found a resource should only sometimes recruit others to the same resource. We discuss the relationship between our analysis and multi-agent multi-arm bandit problems.},
  journal={arXiv}
}

@article{roberts2012group,
  title={Group Foraging in Dynamic Environments},
  author={Michael E. Roberts and Sam Cheesman and Patrick McMullen},
  year={2012},
  url={http://arxiv.org/abs/1204.3673v1},
  abstract={Previous human foraging experiments have shown that human groups routinely undermatch environmental resources much like other animal species. In this experiment, we test whether humans also selectively rely on others as information sources when the environmental state is uncertain, and we also test whether overt signals of other foragers' success influences group matching behavior and group adaptation to a changing environment. The results show evidence of reliance on social information in specific conditions, but participants were primarily influenced by their individual assessments of food location rather than the success of other foragers.},
  journal={arXiv}
}

@article{revilla2016pollinator,
  title={Pollinator foraging flexibility and coexistence of competing plants},
  author={Tomás A. Revilla and Vlastimil Křivan},
  year={2016},
  url={http://arxiv.org/abs/1602.02569v3},
  abstract={We use the optimal foraging theory to study coexistence between two plant species and a generalist pollinator. We compare conditions for plant coexistence for non-adaptive vs. adaptive pollinators that adjust their foraging strategy to maximize fitness. When pollinators have fixed preferences, we show that plant coexistence typically requires both weak competition between plants for resources (e.g., space or nutrients) and pollinator preferences that are not too biased in favour of either plant. We also show how plant coexistence is promoted by indirect facilitation via the pollinator. When pollinators are adaptive foragers, pollinator's diet maximizes pollinator's fitness measured as the per capita population growth rate. Simulations show that this has two conflicting consequences for plant coexistence. On the one hand, when competition between pollinators is weak, adaptation favours pollinator specialization on the more profitable plant which increases asymmetries in plant competition and makes their coexistence less likely. On the other hand, when competition between pollinators is strong, adaptation promotes generalism, which facilitates plant coexistence. In addition, adaptive foraging allows pollinators to survive sudden loss of the preferred plant host, thus preventing further collapse of the entire community.   Keywords: mutualism, competition, optimal foraging, evolutionarily stable strategy, coexistence, adaptation rate},
  doi={10.1371/journal.pone.0160076},
  journal={arXiv}
}

@article{narendhar2012hybrid,
  title={A Hybrid Bacterial Foraging Algorithm For Solving Job Shop Scheduling Problems},
  author={S. Narendhar and T. Amudha},
  year={2012},
  url={http://arxiv.org/abs/1211.4971v1},
  abstract={Bio-Inspired computing is the subset of Nature-Inspired computing. Job Shop Scheduling Problem is categorized under popular scheduling problems. In this research work, Bacterial Foraging Optimization was hybridized with Ant Colony Optimization and a new technique Hybrid Bacterial Foraging Optimization for solving Job Shop Scheduling Problem was proposed. The optimal solutions obtained by proposed Hybrid Bacterial Foraging Optimization algorithms are much better when compared with the solutions obtained by Bacterial Foraging Optimization algorithm for well-known test problems of different sizes. From the implementation of this research work, it could be observed that the proposed Hybrid Bacterial Foraging Optimization was effective than Bacterial Foraging Optimization algorithm in solving Job Shop Scheduling Problems. Hybrid Bacterial Foraging Optimization is used to implement real world Job Shop Scheduling Problems.},
  journal={arXiv}
}

@article{davidson2018foraging,
  title={Foraging as an evidence accumulation process},
  author={Jacob D. Davidson and Ahmed El Hady},
  year={2018},
  url={http://arxiv.org/abs/1809.05023v1},
  abstract={A canonical foraging task is the patch-leaving problem, in which a forager must decide to leave a current resource in search for another. Theoretical work has derived optimal strategies for when to leave a patch, and experiments have tested for conditions where animals do or do not follow an optimal strategy. Nevertheless, models of patch-leaving decisions do not consider the imperfect and noisy sampling process through which an animal gathers information, and how this process is constrained by neurobiological mechanisms. In this theoretical study, we formulate an evidence accumulation model of patch-leaving decisions where the animal averages over noisy measurements to estimate the state of the current patch and the overall environment. Evidence accumulation models belong to the class of drift diffusion processes and have been used to model decision making in different contexts. We solve the model for conditions where foraging decisions are optimal and equivalent to the marginal value theorem, and perform simulations to analyze deviations from optimal when these conditions are not met. By adjusting the drift rate and decision threshold, the model can represent different strategies, for example an increment-decrement or counting strategy. These strategies yield identical decisions in the limiting case but differ in how patch residence times adapt when the foraging environment is uncertain. To account for sub-optimal decisions, we introduce an energy-dependent utility function that predicts longer than optimal patch residence times when food is plentiful. Our model provides a quantitative connection between ecological models of foraging behavior and evidence accumulation models of decision making. Moreover, it provides a theoretical framework for potential experiments which seek to identify neural circuits underlying patch leaving decisions.},
  doi={10.1371/journal.pcbi.1007060},
  journal={arXiv}
}

@article{bidari2022stochastic,
  title={Stochastic dynamics of social patch foraging decisions},
  author={Subekshya Bidari and Ahmed El Hady and Jacob Davidson and Zachary P Kilpatrick},
  year={2022},
  url={http://arxiv.org/abs/2202.05761v1},
  abstract={Animals typically forage in groups. Social foraging can help animals avoid predation and decrease their uncertainty about the richness of food resources. Despite this, theoretical mechanistic models of patch foraging have overwhelmingly focused on the behavior of single foragers. In this study, we develop a mechanistic model describing the behavior of individuals foraging together and departing food patches following an evidence accumulation process. Each individual's belief about patch quality is represented by a stochastically accumulating variable coupled to others' belief, representing the transfer of information. We consider a cohesive group, and model information sharing as either intermittent pulsatile coupling (communicate decision to leave) or continuous diffusive coupling (communicate online belief). Foraging efficiency under pulsatile coupling has a stronger dependence on the coupling strength parameter compared to diffusive. Despite employing minimal information transfer, pulsatile coupling can still provide similar or higher foraging efficiency compared to diffusive coupling. Conversely, diffusive coupling is more robust to parameter detuning and performs better when individuals have heterogeneous departure criteria and social information weighting. Efficiency is measured by a reward rate function that balances the amount of energy accumulated against the time spent in a patch, computed by solving an ordered first passage time problem for the patch departures of each individual. Using synthetic data we show that we can distinguish between the two modes of communication and identify the model parameters. Our model establishes a social patch foraging framework to parse and identify deliberative decision strategies, to distinguish different forms of social communication, and to allow model fitting to real world animal behavior data.},
  journal={arXiv}
}

@article{chupeau2015universality,
  title={Universality classes of foraging with resource renewal},
  author={M. Chupeau and O. Bénichou and S. Redner},
  year={2015},
  url={http://arxiv.org/abs/1511.01347v2},
  abstract={We determine the impact of resource renewal on the lifetime of a forager that depletes its environment and starves if it wanders too long without eating. In the framework of the minimal starving random walk model with resource renewal, there are three universal classes of behavior as a function of the renewal time. For sufficiently rapid renewal, foragers are immortal, while foragers have a finite lifetime otherwise. In one dimension, there is a third regime, for sufficiently slow renewal, in which the lifetime of the forager is independent of the renewal time. We outline an enumeration method to determine the mean lifetime of the forager in the mortal regime.},
  doi={10.1103/PhysRevE.93.032403},
  journal={arXiv}
}

@article{boyer2006scalefree,
  title={Scale-free foraging by primates emerges from their interaction with a complex environment},
  author={Denis Boyer and Gabriel Ramos-Fernández and Octavio Miramontes and José L. Mateos and Germinal Cocho and Hernán Larralde and Humberto Ramos and Fernando Rojas},
  year={2006},
  url={http://arxiv.org/abs/q-bio/0601024v2},
  abstract={Scale-free foraging patterns are widespread among animals. These may be the outcome of an optimal searching strategy to find scarce randomly distributed resources, but a less explored alternative is that this behaviour may result from the interaction of foraging animals with a particular distribution of resources. We introduce a simple foraging model where individuals follow mental maps and choose their displacements according to a maximum efficiency criterion, in a spatially disordered environment containing many trees with a heterogeneous size distribution. We show that a particular tree size frequency distribution induces non-Gaussian movement patterns with multiple spatial scales (Lévy walks). These results are consistent with tree size variation and Spider monkey (Ateles geoffroyi) foraging patterns. We discuss the consequences that our results may have for the patterns of seed dispersal by foraging primates.},
  journal={arXiv}
}

@article{rager2018advantage,
  title={The Advantage of Foraging Myopically},
  author={C. L. Rager and U. Bhat and O. Bénichou and S. Redner},
  year={2018},
  url={http://arxiv.org/abs/1804.08045v1},
  abstract={We study the dynamics of a \emph{myopic} forager that randomly wanders on a lattice in which each site contains one unit of food. Upon encountering a food-containing site, the forager eats all the food at this site with probability $p<1$; otherwise, the food is left undisturbed. When the forager eats, it can wander $\mathcal{S}$ additional steps without food before starving to death. When the forager does not eat, either by not detecting food on a full site or by encountering an empty site, the forager goes hungry and comes one time unit closer to starvation. As the forager wanders, a multiply connected spatial region where food has been consumed---a desert---is created. The forager lifetime depends non-monotonically on its degree of myopia $p$, and at the optimal myopia $p=p^*(\mathcal{S})$, the forager lives much longer than a normal forager that always eats when it encounters food. This optimal lifetime grows as $\mathcal{S}^2/\ln\mathcal{S}$ in one dimension and faster than a power law in $\mathcal{S}$ in two and higher dimensions.},
  doi={10.1088/1742-5468/aace2d},
  journal={arXiv}
}

@article{michelot2016estimation,
  title={Estimation and simulation of foraging trips in land-based marine predators},
  author={Théo Michelot and Roland Langrock and Sophie Bestley and Ian D. Jonsen and Theoni Photopoulou and Toby A. Patterson},
  year={2016},
  url={http://arxiv.org/abs/1610.06953v3},
  abstract={The behaviour of colony-based marine predators is the focus of much research globally. Large telemetry and tracking data sets have been collected for this group of animals, and are accompanied by many theoretical studies of optimal foraging strategies. However, relatively few studies have detailed statistical methods for inferring behaviours in central place foraging trips. In this paper we describe an approach based on hidden Markov models, which splits foraging trips into segments labelled as "outbound", "search", "forage", and "inbound". By structuring the hidden Markov model transition matrix appropriately, the model naturally handles the sequence of behaviours within a foraging trip. Additionally, by structuring the model in this way, we are able to develop realistic simulations from the fitted model. We demonstrate our approach on data from southern elephant seals (Mirounga leonina) tagged on Kerguelen Island in the Southern Ocean. We discuss the differences between our 4-state model and the widely used 2-state model, and the advantages and disadvantages of employing a more complex model.},
  journal={arXiv}
}

@article{bidari2019social,
  title={Social inhibition maintains adaptivity and consensus of foraging honeybee swarms in dynamic environments},
  author={Subekshya Bidari and Orit Peleg and Zachary P Kilpatrick},
  year={2019},
  url={http://arxiv.org/abs/1907.03061v1},
  abstract={To effectively forage in natural environments, organisms must adapt to changes in the quality and yield of food sources across multiple timescales. Individuals foraging in groups act based on both their private observations and the opinions of their neighbors. How do these information sources interact in changing environments? We address this problem in the context of honeybee swarms, showing inhibitory social interactions help maintain adaptivity and consensus needed for effective foraging. Individual and social interactions of a mathematical swarm model shape the nutrition yield of a group foraging from feeders with temporally switching food quality. Social interactions improve foraging from a single feeder if temporal switching is fast or feeder quality is low. When the swarm chooses from multiple feeders, the most effective form of social interaction is direct switching, whereby bees flip the opinion of nestmates foraging at lower yielding feeders. Model linearization shows that effective social interactions increase the fraction of the swarm at the correct feeder (consensus) and the rate at which bees reach that feeder (adaptivity). Our mathematical framework allows us to compare a suite of social inhibition mechanisms, suggesting experimental protocols for revealing effective swarm foraging strategies in dynamic environments.},
  journal={arXiv}
}

@article{adams2021selfguided,
  title={A Self-Guided Approach for Navigation in a Minimalistic Foraging Robotic Swarm},
  author={Steven Adams and Daniel Jarne Ornia and Manuel Mazo},
  year={2021},
  url={http://arxiv.org/abs/2105.10331v3},
  abstract={We present a biologically inspired design for swarm foraging based on ant's pheromone deployment, where the swarm is assumed to have very restricted capabilities. The robots do not require global or relative position measurements and the swarm is fully decentralized and needs no infrastructure in place. Additionally, the system only requires one-hop communication over the robot network, we do not make any assumptions about the connectivity of the communication graph and the transmission of information and computation is scalable versus the number of agents. This is done by letting the agents in the swarm act as foragers or as guiding agents (beacons). We present experimental results computed for a swarm of Elisa-3 robots on a simulator, and show how the swarm self-organizes to solve a foraging problem over an unknown environment, converging to trajectories around the shortest path. At last, we discuss the limitations of such a system and propose how the foraging efficiency can be increased.},
  journal={arXiv}
}

@article{saavedra2012foraging,
  title={Foraging under conditions of short-term exploitative competition: The case of stock traders},
  author={Serguei Saavedra and R. Dean Malmgren and Nicholas Switanek and Brian Uzzi},
  year={2012},
  url={http://arxiv.org/abs/1205.3124v2},
  abstract={Theory purports that animal foraging choices evolve to maximize returns, such as net energy intake. Empirical research in both human and nonhuman animals reveals that individuals often attend to the foraging choices of their competitors while making their own foraging choices. Due to the complications of gathering field data or constructing experiments, however, broad facts relating theoretically optimal and empirically realized foraging choices are only now emerging. Here, we analyze foraging choices of a cohort of professional day traders who must choose between trading the same stock multiple times in a row---patch exploitation---or switching to a different stock---patch exploration---with potentially higher returns. We measure the difference between a trader's resource intake and the competitors' expected intake within a short period of time---a difference we call short-term comparative returns. We find that traders' choices can be explained by foraging heuristics that maximize their daily short-term comparative returns. However, we find no one-best relationship between different trading choices and net income intake. This suggests that traders' choices can be short-term win oriented and, paradoxically, maybe maladaptive for absolute market returns.},
  journal={arXiv}
}

@article{tao2004flexible,
  title={Flexible Foraging of Ants under Unsteadily Varying Environment},
  author={Tomomi Tao and Hiroyuki Nakagawa and Masato Yamasaki and Hiraku Nishimori},
  year={2004},
  url={http://arxiv.org/abs/q-bio/0407007v1},
  abstract={Using a simple model for the trail formation of ants, the relation between i)the schedule of feeding which represents the unsteady natural environment, ii)emerging patterns of trails connecting a nest with food resources, and iii)the foraging efficiency is studied. Simulations and a simple analysis show that the emergent trail pattern flexibly varies depending on the feeding schedule by which ants can make an efficient foraging according to the underlying unsteady environment.},
  doi={10.1143/JPSJ.73.2333},
  journal={arXiv}
}

@article{sarkar2022eating,
  title={Eating Smart: Free-ranging dogs follow an optimal foraging strategy while scavenging in groups},
  author={Rohan Sarkar and Sreelekshmi R and Abhijit Nayek and Anirban Bhowmick and Poushali Chakraborty and Rituparna Sonowal and Debsruti Dasgupta and Rounak Banerjee and Aritra Roy and Amartya Baran Mandal and Anindita Bhadra},
  year={2022},
  url={http://arxiv.org/abs/2208.12265v1},
  abstract={Foraging and acquiring of food is a delicate balance between managing the costs, both energy and social, and individual preferences. Previous research on the solitary foraging of free ranging dogs showed that they prioritized the nutritionally highest valued food patch first but do not ignore other less valuable food either, displaying typical scavenger behaviour. The current experiment was carried out on groups of dogs with the same set up to see the change in foraging strategies, if any, under the influence of social cost like intra-group competition. We found multiple differences between the strategies of dogs foraging alone versus in groups with competition playing an implicit role in the decision making of dogs when foraging in groups. Dogs were able to continually assess and evaluate the available resources in a patch and adjust their behaviour accordingly. Foraging in groups also provided benefits of reduced individual vigilance. The various decisions and choices made seemed to have a basis in the optimal foraging theory wherein the dogs harvested the nutritionally richest patch possible with the least risk and cost involved but was willing to compromise if that was not possible. This underscores the cognitive, quick decision-making abilities and adaptable behaviour of these dogs.},
  journal={arXiv}
}

@article{m2024early,
  title={Early Epilepsy Diagnosis using Epistemic Neural Networks with Electric Eel Foraging Optimization and Secure EEG Data Sharing via Blockchain},
  author={M. M and Baba Fakruddin Ali B H and Hariharan R and Sukanya Ledalla and S. Kadam},
  year={2024},
  url={https://www.semanticscholar.org/paper/bdaebad34d875e76047e8afa8ded12cf395cab87},
  abstract={Epilepsy is still quite common, affecting over 50 million individuals worldwide, despite the tremendous advances in contemporary therapy. Early detection and treatment can greatly lower the chance of long-term harm and raise living standards for those with epilepsy. Electroencephalography (EEG), a non-invasive method that tracks electrical activity in the brain, is frequently used to diagnose this neurological disorder. Yet, using EEG data for diagnosis and study raises a number of issues with patient privacy and security protocols for such private digital data. An early epilepsy diagnostic system and a decentralized, secure environment for exchanging EEG data based on a block chain-based system with DL integration are presented in this work. The proposed method makes it possible to maintain patients’ personal data confidentiality and, at the same time, increase the efficiency of early epilepsy diagnosis. The most frequently used preprocessing technique in the strategy is Multiple Discrete Orthonormal S-Transforms (MDOSTs), and for feature extraction, Memory Efficient Vision Transformer-based Feature Extraction is employed. In classification, we use an Epistemic Neural Network (ENN) to achieve high precision and reliable prediction through the Electric Eel Foraging Optimization (EEFO) algorithm. The storage and dissemination of the data are both proactively secured through blockchain; through smart contracts, patients completely govern their data. The analysis of the Temple University Hospital EEG Corpus (TUH EEG) dataset proves that this method is diagnosed more than the traditional one, while the protection level of this data is also high. By achieving above 99% performance on all evaluation measures, such as F1-score, accuracy, recall, specificity, and precision, the suggested method demonstrates its remarkable efficacy in both secure EEG data sharing and early epilepsy detection. The method's higher performance over conventional approaches can be attributed to its strong deep learning models and block chain integration.},
  doi={10.1109/ICACRS62842.2024.10841765},
  journal={2024 3rd International Conference on Automation, Computing and Renewable Systems (ICACRS)}
}

@article{trimble2021epistemic,
  title={Epistemic Foraging and the Creative Process: Crawling Over Creation},
  author={W. Trimble},
  year={2021},
  url={https://www.semanticscholar.org/paper/a7c95af4cf351789da026d44c1240a61f696bb6c},
  doi={10.1007/978-3-030-89708-6_6},
  journal={Technology, Innovation and Creativity in Digital Society}
}

@article{koponen2017modelling,
  title={Modelling conceptual change as foraging for explanations on an epistemic landscape},
  author={I. Koponen and Tommi Kokkonen},
  year={2017},
  url={https://www.semanticscholar.org/paper/3ed4b0581b414920ee4ef179fb57d0bbc3ab5ada},
  journal={Annual Meeting of the Cognitive Science Society}
}

@article{németh2025hippocampus,
  title={The hippocampus as an epistemic forager: When curiosity and reward jointly steer exploration and hippocampal replay},
  author={E. Németh and Augustin Chartouny and Krisztina Jedlovszky and Ismael T. Freire and M. Khamassi},
  year={2025},
  url={https://www.semanticscholar.org/paper/b163f6306d7894ac8cae3c5160dd2040042197b5},
  doi={10.1101/2025.10.31.685837},
  journal={bioRxiv}
}

@article{gerjets2010topical,
  title={Topical Relevance and Information Quality in Cognitive Models of Web Search Behavior: Introducing Epistemic Scent into Information Foraging Theory - eScholarship},
  author={Peter Gerjets and Yvonne Kammerer},
  year={2010},
  url={https://www.semanticscholar.org/paper/e69ced4876ef9bfbcc6b76b3be1f691f725425d0}
}

@article{mirza2016scene,
  title={Scene Construction, Visual Foraging, and Active Inference},
  author={M. Berk Mirza and Rick A Adams and C. Mathys and Karl J. Friston},
  year={2016},
  url={https://www.semanticscholar.org/paper/c6b98b4dbc9f00a55393c76736918d55206f7cd3},
  abstract={This paper describes an active inference scheme for visual searches and the perceptual synthesis entailed by scene construction. Active inference assumes that perception and action minimize variational free energy, where actions are selected to minimize the free energy expected in the future. This assumption generalizes risk-sensitive control and expected utility theory to include epistemic value; namely, the value (or salience) of information inherent in resolving uncertainty about the causes of ambiguous cues or outcomes. Here, we apply active inference to saccadic searches of a visual scene. We consider the (difficult) problem of categorizing a scene, based on the spatial relationship among visual objects where, crucially, visual cues are sampled myopically through a sequence of saccadic eye movements. This means that evidence for competing hypotheses about the scene has to be accumulated sequentially, calling upon both prediction (planning) and postdiction (memory). Our aim is to highlight some simple but fundamental aspects of the requisite functional anatomy; namely, the link between approximate Bayesian inference under mean field assumptions and functional segregation in the visual cortex. This link rests upon the (neurobiologically plausible) process theory that accompanies the normative formulation of active inference for Markov decision processes. In future work, we hope to use this scheme to model empirical saccadic searches and identify the prior beliefs that underwrite intersubject variability in the way people forage for information in visual scenes (e.g., in schizophrenia).},
  doi={10.3389/fncom.2016.00056},
  journal={Frontiers in Computational Neuroscience}
}

@article{schulkin2016foraging,
  title={Foraging for Coherence in Neuroscience: A Pragmatist Orientation},
  author={J. Schulkin},
  year={2016},
  url={https://www.semanticscholar.org/paper/61bf2705ac60e77b345eef456543a244d25cd114},
  doi={10.1163/18758185-01301001}
}

@article{bhakta2018epistemic,
  title={Epistemic guidance of visual attention for robotic agents in dynamic visual scenes},
  author={Arindam Bhakta},
  year={2018},
  url={https://www.semanticscholar.org/paper/40de29a2815ce13c123043915010c59f6ba6b08d},
  abstract={Humans and many animals can selectively sample important parts of their visual surroundings to carry out their daily activities like foraging or finding prey or mates. Selective attention allows them to efficiently use the limited resources of the brain by deploying sensory apparatus to collect data believed to be pertinent to the organism's current task in hand.  Robots or other computational agents operating in dynamic environments are similarly exposed to a wide variety of stimuli, which they must process with limited sensory and computational resources. Developing computational models of visual attention has long been of interest as such models enable artificial systems to select necessary information from complex and cluttered visual environments, hence reducing the data-processing burden.  Biologically inspired computational saliency models have previously been used in selectively sampling a visual scene, but these have limited capacity to deal with dynamic environments and have no capacity to reason about uncertainty when planning their visual scene sampling strategy. These models typically select contrast in colour, shape or orientation as salient and sample locations of a visual scene in descending order of salience. After each observation, the area around the sampled location is blocked using inhibition of return mechanism to keep it from being re-visited.  This thesis generalises the traditional model of saliency by using an adaptive Kalman filter estimator to model an agent's understanding of the world and uses a utility function based approach to describe what the agent cares about in the visual scene. This allows the agents to adopt a richer set of perceptual strategies than is possible with the classical winner-take-all mechanism of the traditional saliency model. In contrast with the traditional approach, inhibition of return is achieved without implementing an extra mechanism on top of the underlying structure.  This thesis demonstrates the use of five utility functions that are used to encapsulate the perceptual state that is valued by the agent. Each utility function thereby produces a distinct perceptual behaviour that is matched to particular scenarios.  The resulting visual attention distribution of the five proposed utility functions is demonstrated on five real-life videos.  In most of the experiments, pixel intensity has been used as the source of the saliency map. As the proposed approach is independent of the saliency map used, it can be used with other existing more complex saliency map building models. Moreover, the underlying structure of the model is sufficiently general and flexible, hence it can be used as the base of a new range of more sophisticated gaze control systems.},
  doi={10.26686/wgtn.17072006.v1}
}

@article{paolo2024active,
  title={Active inference goes to school: the importance of active learning in the age of large language models},
  author={Laura Desirée Di Paolo and Ben White and Avel Guénin-Carlut and Axel Constant and Andy Clark},
  year={2024},
  url={https://www.semanticscholar.org/paper/6487183abf8097a44cca9c7f8af640f8885a737d},
  abstract={Human learning essentially involves embodied interactions with the material world. But our worlds now include increasing numbers of powerful and (apparently) disembodied generative artificial intelligence (AI). In what follows we ask how best to understand these new (somewhat ‘alien’, because of their disembodied nature) resources and how to incorporate them in our educational practices. We focus on methodologies that encourage exploration and embodied interactions with ‘prepared’ material environments, such as the carefully organized settings of Montessori education. Using the active inference framework, we approach our questions by thinking about human learning as epistemic foraging and prediction error minimization. We end by arguing that generative AI should figure naturally as new elements in prepared learning environments by facilitating sequences of precise prediction error enabling trajectories of self-correction. In these ways, we anticipate new synergies between (apparently) disembodied and (essentially) embodied forms of intelligence. This article is part of the theme issue ‘Minds in movement: embodied cognition in the age of artificial intelligence’.},
  doi={10.1098/rstb.2023.0148},
  journal={Philosophical Transactions B}
}

@article{parr2017uncertainty,
  title={Uncertainty, epistemics and active inference},
  author={Thomas Parr and Karl J. Friston},
  year={2017},
  url={https://www.semanticscholar.org/paper/185b7f3c6fe8e647ae9c79fbb463768b64c59a52},
  abstract={Biological systems—like ourselves—are constantly faced with uncertainty. Despite noisy sensory data, and volatile environments, creatures appear to actively maintain their integrity. To account for this remarkable ability to make optimal decisions in the face of a capricious world, we propose a generative model that represents the beliefs an agent might possess about their own uncertainty. By simulating a noisy and volatile environment, we demonstrate how uncertainty influences optimal epistemic (visual) foraging. In our simulations, saccades were deployed less frequently to regions with a lower sensory precision, while a greater volatility led to a shorter inhibition of return. These simulations illustrate a principled explanation for some cardinal aspects of visual foraging—and allow us to propose a correspondence between the representation of uncertainty and ascending neuromodulatory systems, complementing that suggested by Yu & Dayan (Yu & Dayan 2005 Neuron 46, 681–692. (doi:10.1016/j.neuron.2005.04.026)).},
  doi={10.1098/rsif.2017.0376},
  journal={Journal of the Royal Society Interface}
}

@article{clark2018nice,
  title={A nice surprise? Predictive processing and the active pursuit of novelty},
  author={A. Clark},
  year={2018},
  url={https://www.semanticscholar.org/paper/558283649fc657b1a35eeea91e038a0dc6ca74ed},
  abstract={Recent work in cognitive and computational neuroscience depicts human brains as devices that minimize prediction error signals: signals that encode the difference between actual and expected sensory stimulations. This raises a series of puzzles whose common theme concerns a potential misfit between this bedrock informationtheoretic vision and familiar facts about the attractions of the unexpected. We humans often seem to actively seek out surprising events, deliberately harvesting novel and exciting streams of sensory stimulation. Conversely, we often experience some wellexpected sensations as unpleasant and to-be-avoided. In this paper, I explore several core and variant forms of this puzzle, using them to display multiple interacting elements that together deliver a satisfying solution. That solution requires us to go beyond the discussion of simple information-theoretic imperatives (such as 'minimize long-term prediction error') and to recognize the essential role of species-specific prestructuring, epistemic foraging, and cultural practices in shaping the restless, curious, novelty-seeking human mind.},
  doi={10.1007/S11097-017-9525-Z}
}

@article{mirza2018human,
  title={Human visual exploration reduces uncertainty about the sensed world},
  author={M. Berk Mirza and Rick A Adams and C. Mathys and Karl J. Friston},
  year={2018},
  url={https://www.semanticscholar.org/paper/3f86de0e343444288fd4d351585672be4e757349},
  abstract={In previous papers, we introduced a normative scheme for scene construction and epistemic (visual) searches based upon active inference. This scheme provides a principled account of how people decide where to look, when categorising a visual scene based on its contents. In this paper, we use active inference to explain the visual searches of normal human subjects; enabling us to answer some key questions about visual foraging and salience attribution. First, we asked whether there is any evidence for ‘epistemic foraging’; i.e. exploration that resolves uncertainty about a scene. In brief, we used Bayesian model comparison to compare Markov decision process (MDP) models of scan-paths that did–and did not–contain the epistemic, uncertainty-resolving imperatives for action selection. In the course of this model comparison, we discovered that it was necessary to include non-epistemic (heuristic) policies to explain observed behaviour (e.g., a reading-like strategy that involved scanning from left to right). Despite this use of heuristic policies, model comparison showed that there is substantial evidence for epistemic foraging in the visual exploration of even simple scenes. Second, we compared MDP models that did–and did not–allow for changes in prior expectations over successive blocks of the visual search paradigm. We found that implicit prior beliefs about the speed and accuracy of visual searches changed systematically with experience. Finally, we characterised intersubject variability in terms of subject-specific prior beliefs. Specifically, we used canonical correlation analysis to see if there were any mixtures of prior expectations that could predict between-subject differences in performance; thereby establishing a quantitative link between different behavioural phenotypes and Bayesian belief updating. We demonstrated that better scene categorisation performance is consistently associated with lower reliance on heuristics; i.e., a greater use of a generative model of the scene to direct its exploration.},
  doi={10.1371/journal.pone.0190429},
  journal={PLoS ONE}
}

@article{mirza2019introducing,
  title={Introducing a Bayesian model of selective attention based on active inference},
  author={M. Berk Mirza and Rick A Adams and Karl J. Friston and Thomas Parr},
  year={2019},
  url={https://www.semanticscholar.org/paper/f093c343638dc8d81a2349b724e3a045a8744dfc},
  abstract={Information gathering comprises actions whose (sensory) consequences resolve uncertainty (i.e., are salient). In other words, actions that solicit salient information cause the greatest shift in beliefs (i.e., information gain) about the causes of our sensations. However, not all information is relevant to the task at hand: this is especially the case in complex, naturalistic scenes. This paper introduces a formal model of selective attention based on active inference and contextual epistemic foraging. We consider a visual search task with a special emphasis on goal-directed and task-relevant exploration. In this scheme, attention modulates the expected fidelity (precision) of the mapping between observations and hidden states in a state-dependent or context-sensitive manner. This ensures task-irrelevant observations have little expected information gain, and so the agent – driven to reduce expected surprise (i.e., uncertainty) – does not actively seek them out. Instead, it selectively samples task-relevant observations, which inform (task-relevant) hidden states. We further show, through simulations, that the atypical exploratory behaviours in conditions such as autism and anxiety may be due to a failure to appropriately modulate sensory precision in a context-specific way.},
  doi={10.1038/s41598-019-50138-8},
  journal={Scientific Reports}
}

@article{babac2006verification,
  title={Verification of Intelligent Agents with ACTL for Epistemic Reasoning},
  author={Marina Bagić Babac and M. Kunstic},
  year={2006},
  url={https://www.semanticscholar.org/paper/b35f979cfe5c02ec90ed1e283142c0e614743f0c},
  doi={10.1109/CIMCA.2006.229},
  journal={International Conference on Computational Intelligence for Modelling, Control and Automation}
}

@article{friston2022graphical,
  title={The graphical brain and deep inference},
  author={K. Friston},
  year={2022},
  url={https://www.semanticscholar.org/paper/f40bc0fa12ab85f86bc4d69712196e1aae6f3563},
  journal={Conference of the Association for Machine Translation in the Americas}
}

@article{chandrasekharan2004epistemic,
  title={Epistemic Structure : How Agents Change the World for Cognitive Congeniality},
  author={S. Chandrasekharan},
  year={2004},
  url={https://www.semanticscholar.org/paper/510a01f5c9f534f8bc7fc1ac920982f424f8f46d}
}

@article{vijay2021settled,
  title={Settled knowledge practices, truncated imaginations},
  author={Devi Vijay},
  year={2021},
  url={https://www.semanticscholar.org/paper/09387ee344e842de3915502ffd7efbaa1b2cfea2},
  abstract={Martin Parker recently auto-critiqued his book Against Management. Parker reflected on the book’s circulation, responded to some criticisms, and proposed a manifesto for a School of Organizing that must emphasize alternative organizational forms. I highlight the Eurocentric frame that permeates the book and the auto-critique. This Eurocentrism manifests as settled geographies, histories, and epistemic practices. Such knowledge practices truncate the possibilities of radically imagining alternatives to the contemporary crises of capitalism. I borrow Anna Lowenhaupt Tsing’s metaphor of foraging to briefly consider how subterranean struggles and solidaristic transgressions offer possibilities for alternative world-making.},
  doi={10.1177/13505084211057261},
  journal={Organization}
}

@article{smedt2011role,
  title={The role of material culture in human time representation: Calendrical systems as extensions of mental time travel},
  author={J. Smedt and H. Cruz},
  year={2011},
  url={https://www.semanticscholar.org/paper/d21909021290b94f5ff08159b31573ade87c8791},
  doi={10.1177/1059712310396382},
  journal={Adaptive Behavior}
}

@article{doonan2015techniques,
  title={Techniques of Making Public: The Sensorium Through Eating and Walking},
  author={Natalie Doonan},
  year={2015},
  url={https://www.semanticscholar.org/paper/8eb95176c36aa846f45fb2a9340918017dec70cc},
  doi={10.3138/tric.36.1.52}
}

@article{koponen2019agentbasedmodel,
  title={Agent-Based-Model of Students’ Sociocognitive Learning Process in Acquiring Tiered Knowledge},
  author={I. Koponen},
  year={2019},
  url={https://www.semanticscholar.org/paper/70e827a316d8dc899ca371da98a1477eb518dbfa},
  doi={10.1007/978-3-030-29862-3_7},
  journal={Communications in Computer and Information Science}
}

@article{buchel2010connections,
  title={Connections 2010 Abstract},
  author={Olha Buchel},
  year={2010},
  url={https://www.semanticscholar.org/paper/632028b1937d95e88ff231ef5f109c2e51575b4e}
}

@article{broncano2008epistemological,
  title={The epistemological authority of testimony 1},
  author={Fernando Broncano},
  year={2008},
  url={https://www.semanticscholar.org/paper/b1141f8c0f4ca777ee953cdf8afda797a117eae9}
}

@article{shevchenko2024epistemic,
  title={On epistemic dependence},
  author={A. A. Shevchenko},
  year={2024},
  url={https://www.semanticscholar.org/paper/de434b4e21b077d05083cf42763b5a415779c800},
  abstract={The article considers the thesis of epistemic dependence, which problematizes the current ideas about the nature of knowledge, its historical and methodological premises. It shows both undesirable consequences of its uncritical acceptance (such as a possible gap between knowledge and understanding) and the possibility of its interpretation in a more general social context, as a conflict of epistemic interests. It also highlights the need to consider this phenomenon in the analysis of collective knowledge and collective rationality.},
  doi={10.25205/2541-7517-2024-22-1-16-26},
  journal={Siberian Journal of Philosophy}
}

@article{liotti2023unpacking,
  title={Unpacking trust: The Italian validation of the Epistemic Trust, Mistrust, and Credulity Questionnaire (ETMCQ)},
  author={M. Liotti and A. Milesi and G. Spitoni and Annalisa Tanzilli and A. M. Speranza and L. Parolin and C. Campbell and P. Fonagy and V. Lingiardi and G. Giovanardi},
  year={2023},
  url={https://www.semanticscholar.org/paper/6e2e840954bb1885040743b84c3fbea6f73c2412},
  abstract={The construct of epistemic trust has received much consideration in recent psychological literature, even though mainly from a theoretical perspective. The overall aim of this study was to validate the first self-report measure of epistemic trust–the Epistemic Trust, Mistrust, and Credulity Questionnaire (ETMCQ)–in an Italian sample. Our primary goal was to test the factorial validity of the instrument, also exploring the influence of age, gender, and level of education on epistemic trust (Study 1, n = 843). Secondarily, we investigated the associations between epistemic trust, mistrust, credulity, and other aspects of psychological functioning, as well as with the presence of adverse childhood experiences in a smaller number of participants (Study 2, n = 445). Besides the ETMCQ, the survey included an ad hoc questionnaire investigating socio-demographic characteristics and self-report measures of reflective functioning, mentalized affectivity, traumatic experiences, attachment, and psychological symptoms. Statistical analysis showed a three-factor hierarchical structure similar to the model proposed in the original validation, with some differences that suggest an influence of cultural factors in determining individuals’ epistemic stance. Our results corroborate previous theoretical contributions regarding the association between epistemic trust and psychological wellbeing, and between epistemic disruptions and higher levels of psychological suffering. Both Mistrust and Credulity were significantly related to the presence of childhood traumatic experiences, attachment avoidance and anxiety, lower levels of mentalization, lower abilities in emotional regulation, and higher levels of psychopathological symptoms. The ETMCQ represents an easily administered and time-effective tool. Its use could pave the way for interesting clinical and theoretical findings.},
  doi={10.1371/journal.pone.0280328},
  journal={PLoS ONE}
}

@article{alvarado2023ai,
  title={AI as an Epistemic Technology},
  author={Ramón Alvarado},
  year={2023},
  url={https://www.semanticscholar.org/paper/255f17f7a2689612d3839c5f57a35675bafd5ae0},
  doi={10.1007/s11948-023-00451-3},
  journal={Science and Engineering Ethics}
}

@article{pratt2023where,
  title={Where is knowledge from the global South? An account of epistemic justice for a global bioethics},
  author={Bridget Pratt and J. de Vries},
  year={2023},
  url={https://www.semanticscholar.org/paper/e878c284b716b1d490ede63e266a87ccd0dfd6b3},
  abstract={The silencing of the epistemologies, theories, principles, values, concepts and experiences of the global South constitutes a particularly egregious epistemic injustice in bioethics. Our shared responsibility to rectify that injustice should be at the top of the ethics agenda. That it is not, or only is in part, is deeply problematic and endangers the credibility of the entire field. As a first step towards reorienting the field, this paper offers a comprehensive account of epistemic justice for global health ethics. We first introduce several different conceptions of justice and decolonisation in relation to knowledge, purposefully drawing on work emanating from the global South as well as the global North. We then apply those conceptions to the global health ethics context to generate a tripartite account of the layers of epistemic justice in the field: who is producing ethics knowledge; what theories and concepts are being applied to produce ethics knowledge; and whose voices are sought, recorded and used to generate ethics knowledge. These layers reflect that the field spans conceptual and empirical research. We conclude by proposing that, going forward, three avenues are key to achieve greater epistemic justice at each layer and to help decolonise global health ethics: namely, understanding the problem, dialogue and structural change.},
  doi={10.1136/jme-2022-108291},
  journal={Journal of Medical Ethics}
}

