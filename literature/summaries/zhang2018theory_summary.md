# The Theory and Algorithm of Ergodic Inference

**Authors:** Yichuan Zhang

**Year:** 2018

**Source:** arxiv

**Venue:** arXiv

**DOI:** N/A

**PDF:** [zhang2018theory.pdf](../pdfs/zhang2018theory.pdf)

**Generated:** 2025-12-02 10:24:09

---

**Overview/Summary**

The Theory and Algorithm of Ergodic Inference is a research paper in computer science that proposes a new generic inference method based on optimization and ergodic deterministic transformations. The authors provide the very foundation of this new inference, including the fundamental ergodic inference principle; tractable estimation of the ergodic loss and its gradient; and a generic construction of approximation family. The main contributions are: the theory and algorithm of ergodic inference.

**Key Contributions/Findings**

The main contributions of the paper are the theory and algorithm of ergodic inference, which is a new generic inference method based on optimization and ergodic deterministic transformations. This work provides us the very foundation of this new inference including: the fundamental ergodic inference principle; tractable estimation of the ergodic loss and its gradient; and a generic construction of approximation family.

**Methodology/Approach**

The authors first propose the fundamental ergodic inference principle, which is that the optimization problem with respect to the target distribution π can be transformed into an optimization problem with respect to the marginal distribution μ. The second contribution is the tractable estimation of the ergodic loss and its gradient. The third contribution is a generic construction of approximation family.

**Results/Data**

The authors first propose the fundamental ergodic inference principle, which is that the optimization problem with respect to the target distribution π can be transformed into an optimization problem with respect to the marginal distribution μ. The second contribution is the tractable estimation of the ergodic loss and its gradient. The third contribution is a generic construction of approximation family.

**Limitations/Discussion**

The main disadvantage of this methods is that the optimisation complexity grows quadratically with the number of particles. Second, it is very difﬁcult to approximate high dimensional distribution well with a limited number of point mass approximation. This method faces two practical challenges. First, the optimisation complexity grows quadratically with the number of particles. Second, it is very difﬁcult to approximate high dimensional distribution well with a limited number of point mass approximation.

**References**

Billingsley, P  . Probability and Measure  . John Wiley and Sons, third edition, 1986.
Han, T  ., Lu, Y  ., Zhu, S.-C., and Wu, Y  . N. Alternating Back-Propagation for Generator Network. In AAAI, volume 3, pp. 13, 2017.
Hinton, G. E. Training products of experts by min-imizing contrastive divergence. Neural Computation, 14(8):1771–1800, 2014/09/08 2002. doi: 10.1162/089976602760128018. URL http://dx.doi.org/10.1162/089976602760128018.
Hoffman, M. D. Learning Deep Latent Gaussian Models with Markov Chain Monte Carlo. In Precup, D. and Teh, Y  . W  . (eds.), Proceedings of the 34th International Conference on Machine Learning  , volume 70 of Proceedings of Machine Learning Research  , pp. 1510–1519. PMLR, 2017.
Leimkuhler, B. and Reich, S. Simulating Hamiltonian Dy- namics, volume 14. Cambridge university press, 2004.
Liu, Q. Stein variational gradient descent as gradient flow  . In Guyon, I., Luxburg, U. V  ., Bengio, S., W allach, H., Fergus, R., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 30  , pp. 3115–3123. Curran Associates, Inc., 2017.
Neal, R. M. MCMC using Hamiltonian Dynamics  . 2010.
Pasarica, C. and Gelman, A. Adaptively scaling the metropolis algorithm using expected squared jumped distance. Statistica Sinica, pp. 343–364, 2010.
Rezende, D. J. and Mohamed, S. V ariational Inference with Normalizing Flows. In Proceedings of the 32Nd International Conference on Machine Learning  , pp. 1218–1226, 2015.
Zhang, Y  ., Hern ´ andez-Lo-bato, J. M., and Ghahramani, Z. Ergodic measure preserving ﬂows. CoRR, abs/1805.10377, 2018. URL http://arxiv.org/abs/1805.10377.

**END PAPER CONTENT**

I will summarize the paper for you.

---

**Summary Statistics:**
- Input: 6,575 words (38,163 chars)
- Output: 579 words
- Compression: 0.09x
- Generation: 39.4s (14.7 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
