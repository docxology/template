# Entropic Inference

**Authors:** Ariel Caticha

**Year:** 2010

**Source:** arxiv

**Venue:** arXiv

**DOI:** 10.1063/1.3573619

**PDF:** [caticha2010entropic.pdf](../pdfs/caticha2010entropic.pdf)

**Generated:** 2025-12-02 13:03:09

---

**Overview/Summary**

The paper "Entropic Inference" by Ariel Caticha is a comprehensive and well-structured review of the fundamental principles that underlie the Bayesian approach to statistical inference. The author's aim is to provide an entropic foundation for the Bayesian method, which they argue should be considered as the only candidate for a general method of inductive inference, including both the traditional maximum entropy (MaxEnt) and Bayes' rule as special cases. This paper is not just a summary of the current state-of-the-art in statistical inference but also provides an overview of the historical development of the Bayesian approach to this problem. The author's main conclusion is that the logarithmic relative entropy is the only candidate for a general method for updating probabilities, and this includes both MaxEnt and Bayes' rule as special cases; it unifies them into a single theory of inductive inference and allows new applications.

**Key Contributions/Findings**

The paper starts with the definition of information that constrains rational beliefs. The author argues that the Bayesian account of the notion of information cannot ignore the fact that Bayesians are concerned with the beliefs of rational agents. They then propose a de nition of information as that which constrains rational beliefs and therefore forces the agent to change its mind, and this is convenient for quantitative manipulation using the MaxEnt method. The main conclusion is that the logarithmic relative entropy is the only candidate for a general method for updating probabilities, and this includes both MaxEnt and Bayes' rule as special cases; it unifies them into a single theory of inductive inference and allows new applications. In particular, much as the old MaxEnt method provided the foundation for statistical mechanics, recent work suggests that the extended MaxEnt method provides an entropic foundation for quantum mechanics.

**Methodology/Approach**

The paper is organized around the definition of information. The author's approach to this problem is to provide a de nition of information and then use it as the basis for the development of the Bayesian method, which they argue should be considered as the only candidate for a general method of inductive inference, including both MaxEnt and Bayes' rule as special cases; it unifies them into a single theory of inductive inference and allows new applications. The author's main conclusion is that the logarithmic relative entropy is the only candidate for a general method for updating probabilities, and this includes both MaxEnt and Bayes' rule as special cases; it unifies them into a single theory of inductive inference and allows new applications.

**Results/Data**

The paper does not contain any data or results. The main purpose of the paper is to provide an overview of the historical development of the Bayesian approach to statistical inference, and this is done by using the de nition of information as the basis for the development of the Bayesian method.

**Limitations/Discussion**

The author's conclusion is that the logarithmic relative entropy is the only candidate for a general method for updating probabilities. This includes both MaxEnt and Bayes' rule as special cases; it unifies them into a single theory of inductive inference and allows new applications. The paper does not contain any limitations or future work.

**References**

The references provided are to previous works by the author, which include papers on the topics of information and entropy, updating probabilities with data and moments, and the relationship between information and beliefs.

---

**Summary Statistics:**
- Input: 5,077 words (28,525 chars)
- Output: 559 words
- Compression: 0.11x
- Generation: 56.3s (9.9 words/sec)
- Quality Score: 1.00/1.0
- Attempts: 1

**Quality Check:** Passed
