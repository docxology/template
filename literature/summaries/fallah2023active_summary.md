# Active Inference-Based Optimization of Discriminative Neural Network Classifiers

**Authors:** Faezeh Fallah

**Year:** 2023

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [fallah2023active.pdf](../pdfs/fallah2023active.pdf)

**Generated:** 2025-12-05 13:03:25

---

**Overview/Summary**

The paper proposes an active inference-based optimization of a discriminative neural network for 3D volumetric fat-water image segmentation. The proposed method is based on the V-Net architecture and optimizes it using the active inference (AI) framework, which provides a principled way to learn the model parameters by minimizing the expected loss over the data distribution. In this paper, the authors use the V-Net as the base network for 3D volumetric fat-water image segmentation. The V-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors tailor the number and sizes of the feature maps and the kernels of the 3D convolutional/ deconvolutional layers to their volumetric fat- water images. The V-Net is trained by using a mini-batch-based gradient descent optimizer with backpropagation and a sufficiently large input volume to capture as much contextual information as possible. Due to the memory limitations of the used GPU, the authors could only include 2 volumetric fat-water images in each batch. Moreover, each volumetric fat- water image had 2 channels containing its voxelwise fat and water intensities. The V-Net is trained by using a mini-batch-based gradient descent optimizer with backpropagation and a sufficiently large input volume to capture as much contextual information as possible. 

**Key Contributions/Findings**

The authors propose an active inference (AI) based optimization of the discriminative neural network for 3D volumetric fat-water image segmentation. The proposed method is based on the V-Net architecture and optimizes it using the AI framework, which provides a principled way to learn the model parameters by minimizing the expected loss over the data distribution. In this paper, the authors use the V-Net as the base network for 3D volumetric fat-water image segmentation. The V-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors tailor the number and sizes of the feature maps and the kernels of the 3D convolutional/ deconvolutional layers to their volumetric fat- water images. The V-Net is trained by using a mini-batch-based gradient descent optimizer with backpropagation and a sufficiently large input volume to capture as much contextual information as possible. 

**Methodology/Approach**

The authors use the V-Net as the base network for 3D volumetric fat-water image segmentation. The V-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors tailor the number and sizes of the feature maps and the kernels of the 3D convolutional/ deconvolutional layers to their volumetric fat- water images. The V-Net is trained by using a mini-batch-based gradient descent optimizer with backpropagation and a sufficiently large input volume to capture as much contextual information as possible. 

**Results/Data**

The authors train the V-Net on 3D volumetric fat-water image segmentation. In this paper, the authors use the V-Net as the base network for 3D volumetric fat-water image segmentation. The V-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer with backpropagation and a sufficiently large input volume to capture enough contextual information. In this paper, the authors tailor the number and sizes of the feature maps and the kernels of the 3D convolutional/ deconvolutional layers to their volumetric fat- water images. The V-Net is trained by using a mini-batch-based gradient descent optimizer with backpropagation and a sufficiently large input volume to capture as much contextual information as possible. 

**Limitations/Discussion**

The authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional and residual neural network that can be trained end-to-end with a mini-batch-based gradient descent optimizer and a sufficiently large input volume to capture enough contextual information. In this paper, the authors use the 3D U-Net as the base network for 3D volumetric fat-water image segmentation. The 3D U-Net is a fully convolutional

---

**Summary Statistics:**
- Input: 20,472 words (127,251 chars)
- Output: 1,469 words
- Compression: 0.07x
- Generation: 67.9s (21.6 words/sec)
- Quality Score: 0.40/1.0
- Attempts: 1

**Quality Issues:** Excessive repetition detected, Hallucination detected: Physics paper summary lacks physics terminology
