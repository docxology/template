# Teaching Uncertainty Quantification in Machine Learning through Use Cases

**Authors:** Matias Valdenegro-Toro

**Year:** 2021

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [valdenegrotoro2021teaching.pdf](../pdfs/valdenegrotoro2021teaching.pdf)

**Generated:** 2025-12-05 10:28:59

---

**Overview/Summary**

The paper presents a small course curriculum and a selection of use cases to teach students about uncertainty quantification in machine learning models. The authors argue that the importance of teaching uncertainty quantification and BNNs (Bayesian Neural Networks) to students learning about machine learning, and how it relates to the concept of safety in artificial intelligence. 

**Key Contributions/Findings**

The curriculum is centered on specific applications of machine learning and artificial intelligence, such as Computer Vision, Robotics, or Autonomous Systems. The authors hope that this work can motivate the community about the importance of teaching uncertainty quantification and BNNs to students learning about machine learning, and how it relates to the concept of safety in arti- cial intelligence. 

**Methodology/Approach**

The curriculum is centered on specific applications of machine learning and artificial intelligence, such as Computer Vision, Robotics, or Autonomous Systems. The authors hope that this work can motivate the community about the importance of teaching uncertainty quantification and BNNs to students learning about machine learning, and how it relates to the concept of safety in arti- cial intelligence. 

**Results/Data**

The teacher can also show that uncertainty in the OOD set should be proportional to the distance (in input space) from the sample to the edge of the OOD set, and that this proportionality is expected for proper uncertainty quantification. Misconceptions. Students might be confused that some OOD examples have low uncertainty and are easily confused with ID examples. This can be explained with models are not perfect and make mistakes, and this also translates into mistakes in OOD. Another issue is the de- finition of out of distribution data can be very abstract, as it is an open set that corresponds to anything not in the training data distribution. Multiple OOD datasets can be used to show this. 

**Limitations/Discussion**

The authors hope that this work can motivate the community about the importance of teaching uncertainty quantification and BNNs to students learning about machine learning, and how it relates to the concept of safety in arti- cial intelligence. Future course contents and use cases can be centered in specific applications of machine learning and artificial intelligence, such as Computer Vision, Robotics, or Autonomous Systems. There is a good demand to connect theoretical fields (BNNs in particular) into practical applications as a way to lead future research. 

**References**

Betancourt, M. A conceptual introduction to hamiltonian monte carlo. arXiv preprint arXiv:1701.02434, 2017. DeGroot, M. H. and Fienberg, S. E. The comparison and evaluation of forecasters. Journal of the Royal Statistical Society: Series D (The Statistician), 32(1-2):12–22, 1983. Der Kiureghian, A. and Ditlevsen, O. Aleatory or epistemic? Does it matter? Structural safety, 31(2):105–112, 2009. Gal, Y. and Ghahramani, Z. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In international conference on machine learning, pp. 1050–1059. PMLR, 2016. Gawlikowski, J., Tassi, C. R. N., Ali, M., Lee, J., Humt, M., Feng, J., Kruspe, A., Triebel, R., Jung, P., Roscher, R., et al. A survey of uncertainty in deep neural networks. arXiv preprint arXiv:2107.03342, 2021. Guo, C., Pleiss, G., Sun, Y. and Weinberger, K. Q. On calibration of modern neural networks. arXiv preprint arXiv:1706.04599, 2017. Kendall, A. and Gal, Y. What uncertainties do we need in bayesian deep learning for computer vision? arXiv preprint arXiv:1703.04977, 2017. Lakshminarayanan, B., Pritzel, A., and Blundell, C. Simple and scalable predictive uncertainty estimation using deep ensembles. arXiv preprint arXiv:1612.01474, 2016. Lynn Jr, L. E. Teaching and learning with cases: A guide-book. CQ Press, 1999. Mobiny, A., Nguyen, H. V., Moulik, S., Garg, N., Lee, J., Humt, M., Feng, J., Kruspe, A., Triebel, R., Jung, P., Roscher, R., et al. A survey of uncertainty in deep neural networks. arXiv preprint arXiv:1906.04569, 2019. Rasmussen, C. E. and Williams, C. K. Gaussian processes for machine learning (adaptive computation and machine learning), 2005. Valdenegro-Toro, M. I find your lack of uncertainty in computer vision disturbing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 1263–1272, June 2021.

**END OF SUMMARY**

Please let me know if you need any further assistance!

---

**Summary Statistics:**
- Input: 2,937 words (18,572 chars)
- Output: 675 words
- Compression: 0.23x
- Generation: 43.8s (15.4 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
