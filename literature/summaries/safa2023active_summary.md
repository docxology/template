# Active Inference in Hebbian Learning Networks

**Authors:** Ali Safa, Tim Verbelen, Lars Keuninckx, Ilja Ocket, Andr√© Bourdoux, Francky Catthoor, Georges Gielen, Gert Cauwenberghs

**Year:** 2023

**Source:** arxiv

**Venue:** arXiv

**DOI:** N/A

**PDF:** [safa2023active.pdf](../pdfs/safa2023active.pdf)

**Generated:** 2025-12-03 06:14:07

---

**Overview/Summary**

The paper "Active Inference in Hebbian Learning Networks" by [Authors] discusses a novel learning rule for the popular Hebbian network model that is inspired from the active inference framework. The authors propose an active version of the Hebbian learning rule, called Active Hebbian (AH) and show that it can be used to learn generative models of the environment in the context of active inference. They also demonstrate that the AH rule can be used for unsupervised reinforcement learning with sparse rewards. The paper is organized as follows.

**Key Contributions/Findings**

The main contributions of the paper are threefold. First, the authors show that the Hebbian network can be used to learn generative models in the context of active inference. Second, they demonstrate that the AH rule can be used for unsupervised reinforcement learning with sparse rewards. Finally, they compare the AH and the UAC (unfolded) versions of the Hebbian learning rule on a simple control problem.

**Methodology/Approach**

The authors first review the active inference framework and its application to the Hebbian network. Then, they propose an Active Hebbian (AH) version of the Hebbian learning rule that is inspired from the UAC (unfolded) version of the Hebbian learning rule. The AH rule is a novel unsupervised learning rule for the Hebbian network and is different from the UAC rule in its learning mechanism. The authors also compare the AH and the UAC versions of the Hebbian learning rule on a simple control problem.

**Results/Data**

The authors first show that the Hebbian network can be used to learn generative models in the context of active inference. They then demonstrate that the AH rule can be used for unsupervised reinforcement learning with sparse rewards. Finally, they compare the AH and the UAC versions of the Hebbian learning rule on a simple control problem.

**Limitations/Discussion**

The authors discuss the limitations of their work in the last section. The first limitation is that the paper only considers the case where the generative model is a Gaussian mixture model (GMM). They also mention some future research directions, such as how to learn more complex generative models and how to apply the AH rule for other types of learning tasks.

**References**

The authors cite 25 references.

---

**Summary Statistics:**
- Input: 5,066 words (31,793 chars)
- Output: 369 words
- Compression: 0.07x
- Generation: 23.5s (15.7 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
