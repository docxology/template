# Active Bayesian Causal Inference

**Authors:** Christian Toth, Lars Lorch, Christian Knoll, Andreas Krause, Franz Pernkopf, Robert Peharz, Julius von Kügelgen

**Year:** 2022

**Source:** arxiv

**Venue:** arXiv

**DOI:** N/A

**PDF:** [toth2022active.pdf](../pdfs/toth2022active.pdf)

**Generated:** 2025-12-03 04:27:04

---

**Overview/Summary**

The paper "Active Bayesian Causal Inference" by Christian et al. proposes a new approach to causal inference in the presence of unobserved confounders. The authors show that it is possible to learn the causal structure from interventional data, even if some interventions are not perfectly controlled and the targets of the interventions are unknown. They also provide an algorithm for learning the causal structure with the optimal number of experiments.

**Key Contributions/Findings**

The main contributions of this paper are: (1) a new approach to active Bayesian causal inference that is able to learn the causal structure from interventional data, even if some interventions are not perfectly controlled and the targets of the interventions are unknown; (2) an algorithm for learning the causal structure with the optimal number of experiments. The authors show that it is possible to learn the causal structure from interventional data, even if some interventions are not perfectly controlled and the targets of the interventions are unknown. They also provide an algorithm for learning the causal structure with the optimal number of experiments.

**Methodology/Approach**

The approach in this paper is based on a recent development in the field of Bayesian nonparametric statistics. The authors use Stein's method to obtain the upper bound of the expected information gain, and they show that it is possible to learn the causal structure from interventional data, even if some interventions are not perfectly controlled and the targets of the interventions are unknown. They also provide an algorithm for learning the causal structure with the optimal number of experiments.

**Results/Data**

The authors use Stein's method to obtain the upper bound of the expected information gain, and they show that it is possible to learn the causal structure from interventional data, even if some interventions are not perfectly controlled and the targets of the interventions are unknown. They also provide an algorithm for learning the causal structure with the optimal number of experiments.

**Limitations/Discussion**

The authors discuss the limitations of their approach, including: (1) the assumption that the unobserved confounders do not have a direct effect on the observed variables; (2) the identifiability of the causal structure. The authors also provide an algorithm for learning the causal structure with the optimal number of experiments.

**References**

The references in this paper are: [1] Lindley, D. V., Smith, C. A. 1956. On a measure of the information provided by an experiment. The Annals of Mathematical Statistics, 27(4):986–1005; [2] Mockus, J. 1975. On Bayesian methods for seeking the extremum. InOptimization Techniques IFIP Technical Conference, pages 400–404. Springer; [3] Lindley, D. V., Smith, C. A. 1956. On a measure of the information provided by an experiment. The Annals of Mathematical Statistics, 27(4):986–1005; [4] Mockus, J. 2012. Bayesian Approach to Global Optimization: Theory and Applications , volume 37. Springer Sc. The authors also provide references for the Stein's method.

---

**Summary Statistics:**
- Input: 16,553 words (101,959 chars)
- Output: 472 words
- Compression: 0.03x
- Generation: 29.0s (16.3 words/sec)
- Quality Score: 1.00/1.0
- Attempts: 1

**Quality Check:** Passed
