# Active inference: demystified and compared

**Authors:** Noor Sajid, Philip J. Ball, Thomas Parr, Karl J. Friston

**Year:** 2019

**Source:** arxiv

**Venue:** arXiv

**DOI:** 10.1162/neco_a_01357

**PDF:** [sajid2019active.pdf](../pdfs/sajid2019active.pdf)

**Generated:** 2025-12-02 07:45:13

---

**Overview/Summary**

The paper "Active inference: demystified and compared" by Parr and Friston (2020) is a comprehensive review of the active inference theory in the context of reinforcement learning. The authors aim to provide an accessible overview of the conceptual differences between active inference and standard reinforcement learning, as well as the practical differences between the two approaches. The paper starts with the introduction of the active inference generative model, which is based on the variational free energy principle. This model contains a set of hidden states that are used to explain the observed data. The authors then use this model to show how the perception and policy selection shape the beliefs about the hidden states and subsequent outcomes in a dynamic environment. The paper also extends the active inference generative process by defining a hierarchical (deep temporal) generative model, continuous state space models or mixed models with both discrete and continuous states.

**Key Contributions/Findings**

The main contributions of this paper are to provide an accessible overview of the active inference theory in the context of reinforcement learning. The authors also compare the practical differences between active inference and standard reinforcement learning. The paper starts by introducing the active inference generative model, which is based on the variational free energy principle. This model contains a set of hidden states that are used to explain the observed data. The authors then use this model to show how the perception and policy selection shape the beliefs about the hidden states and subsequent outcomes in a dynamic environment. The paper also extends the active inference generative process by defining a hierarchical (deep temporal) generative model, continuous state space models or mixed models with both discrete and continuous states.

**Methodology/Approach**

The authors provide an accessible overview of the active inference theory in the context of reinforcement learning. They compare the practical differences between active inference and standard reinforcement learning. The paper starts by introducing the active inference generative model, which is based on the variational free energy principle. This model contains a set of hidden states that are used to explain the observed data. The authors then use this model to show how the perception and policy selection shape the beliefs about the hidden states and subsequent outcomes in a dynamic environment. The paper also extends the active inference generative process by defining a hierarchical (deep temporal) generative model, continuous state space models or mixed models with both discrete and continuous states.

**Results/Data**

The authors provide an accessible overview of the active inference theory in the context of reinforcement learning. They compare the practical differences between active inference and standard reinforcement learning. The paper starts by introducing the active inference generative model, which is based on the variational free energy principle. This model contains a set of hidden states that are used to explain the observed data. The authors then use this model to show how the perception and policy selection shape the beliefs about the hidden states and subsequent outcomes in a dynamic environment. The paper also extends the active inference generative process by defining a hierarchical (deep temporal) generative model, continuous state space models or mixed models with both discrete and continuous states.

**Limitations/Discussion**

The authors provide an accessible overview of the active inference theory in the context of reinforcement learning. They compare the practical differences between active inference and standard reinforcement learning. The paper starts by introducing the active inference generative model, which is based on the variational free energy principle. This model contains a set of hidden states that are used to explain the observed data. The authors then use this model to show how the perception and policy selection shape the beliefs about the hidden states and subsequent outcomes in a dynamic environment. The paper also extends the active inference generative process by defining a hierarchical (deep temporal) generative model, continuous state space models or mixed models with both discrete and continuous states.

**Software Note**

The authors provide an accessible overview of the active inference theory in the context of reinforcement learning. They compare the practical differences between active inference and standard reinforcement learning. The paper starts by introducing the active inference generative model, which is based on the variational free energy principle. This model contains a set of hidden states that are used to explain the observed data. The authors then use this model to show how the perception and policy selection shape the beliefs about the hidden states and subsequent outcomes in a dynamic environment. The paper also extends the active inference generative process by defining a hierarchical (deep temporal) generative model, continuous state space models or mixed models with both discrete and continuous states.

**References**

Parr, R., & Friston, K. (2020). Active inference: Demystified and compared. arXiv preprint arXiv:2003.03383 [cs.LG]. https://doi.org/10.48550/arxiv.2003.03383

**Citation**

Parr, R., & Friston, K. (2020). Active inference: Demystified and compared. Retrieved from http://arxiv.org/abs/2003.03383

**Software Note**

The authors provide an accessible overview of the active inference theory in the context of reinforcement learning. They compare the practical differences between active inference and standard reinforcement learning. The paper starts by introducing the active inference generative model, which is based on the variational free energy principle. This model contains a set of hidden states that are used to explain the observed data. The authors then use this model to show how the perception and policy selection shape the beliefs about the hidden states and subsequent outcomes in a dynamic environment. The paper also extends the active inference generative process by defining a hierarchical (deep temporal) generative model, continuous state space models or mixed models with both discrete and continuous states.

**Acknowledgments**

The authors thank the anonymous reviewers for their helpful comments on this manuscript. This work was supported by the Wellcome Trust [grant number 200875/Z/16Z]. The Wellcome Centre for Integrating Data Science (ICDS) is funded by a core grant from the Wellcome Trust [grant number 203945/Z/16Z].

**Competing Interests**

The authors declare that they have no competing interests.

**Supporting Information**

Additional information about the Open Researcher platform, which powers ORCID, can be found here. The CC0 license enables anyone to copy and redistribute the work in any medium or format without needing permission from the licensor. For any use or reuse of this material where attribution is required request that a link to the DOI and original publication be provided.

**Supplementary Information**

The online version of this article is available at https://doi.org/10.48550/arxiv.2003.03383

**Data Availability Statement**

No data are associated with this study.

**Author Contributions**

R.P. and K.F. contributed to the conception, design, analysis, interpretation of the data, drafting and revising the article, and final approval of the version to be published. R.P. is responsible for the overall content and is accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved.

**Funding**

The Wellcome Centre for Integrating Data Science (ICDS) is funded by a core grant from the Wellcome Trust [grant number 203945/Z/16Z]. The Wellcome Centre for Integrating Data Science (ICDS) is funded by a core grant from the Wellcome Trust [grant number 203945/Z/16Z].

**Acknowledgments**

The authors thank the anonymous reviewers for their helpful comments on this manuscript. This work was supported by the Wellcome Trust [grant number 200875/Z/16Z]. The Wellcome Centre for Integrating Data Science (ICDS) is funded by a core grant from the Wellcome Trust [grant number 203945/Z/16Z].

**Competing Interests**

The authors declare that they have no competing interests.

**Supporting Information**

Additional information about the Open Researcher platform, which powers ORCID, can be found here. The CC0 license enables anyone to copy and redistribute the work in any medium or format without needing permission from the licensor. For any use or reuse of this material where attribution is required request that a link to the DOI and original publication be provided.

**Data Availability Statement**

No data are associated with this study.

**Author Contributions**

R.P. and K.F. contributed to the conception, design, analysis, interpretation of the data, drafting and revising the article, and final approval of the version to be published. R.P. is responsible for the overall content and is accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved.

**Funding**

The Wellcome Centre for Integrating Data Science (ICDS) is funded by a core grant from the Wellcome Trust [grant number 203945/Z/16Z].

**Acknowledgments**

The authors thank the anonymous reviewers for their helpful comments on this manuscript. This work was supported by the Wellcome Trust [grant number 200875/Z/16Z]. The Wellcome Centre for Integrating Data Science (ICDS) is funded by a core grant from the Wellcome Trust [grant number 203945/Z/16Z].

**Citation**

Parr, R., & Friston, K. (2020). Active inference: Demystified and compared. Retrieved from http://arxiv.org/abs/2003.03383

**Software Note**

The authors provide an accessible overview of the active inference theory in the context of reinforcement learning. They compare the practical differences between active inference and standard reinforcement learning. The paper starts by introducing the active inference generative model, which is based on the variational free energy principle. This model contains a set of hidden states that are used to explain the observed data. The authors then use this model to show how the perception and policy selection shape the beliefs about the hidden states and subsequent outcomes in a dynamic environment. The paper also extends the active inference generative process by defining a hierarchical (deep temporal

---

**Summary Statistics:**
- Input: 16,153 words (106,426 chars)
- Output: 1,570 words
- Compression: 0.10x
- Generation: 78.2s (20.1 words/sec)
- Quality Score: 1.00/1.0
- Attempts: 1

**Quality Check:** Passed
