# Learning Perception and Planning with Deep Active Inference

**Authors:** Ozan Çatal, Tim Verbelen, Johannes Nauta, Cedric De Boom, Bart Dhoedt

**Year:** 2020

**Source:** arxiv

**Venue:** arXiv

**DOI:** N/A

**PDF:** [çatal2020learning.pdf](../pdfs/çatal2020learning.pdf)

**Generated:** 2025-12-03 03:17:49

---

**Overview/Summary**

The paper "Learning Perception and Planning with Deep Active Inference" by Cedric De Boom, Tim Verbelen, and Bart Dhoedt is a contribution to the field of deep learning in the context of active inference, which is an information-theoretic framework for understanding brain function. The authors present a new approach that combines perception (learning about the environment) with planning (choosing actions). The paper's main contributions are the development of a novel algorithm and its application to the problem of learning from demonstration.

**Key Contributions/Findings**

The key findings of this paper are threefold. Firstly, it is shown how to use active inference for state estimation by learning from demonstration. This is achieved using a new deep-learning-based method called Deep Active Inference (DAI). Secondly, the authors demonstrate that DAI can be used for policy selection in reinforcement learning. Finally, they show that their approach outperforms existing approaches on two challenging tasks: one in which an agent must learn to use tools to achieve its goals and another where it must learn to make choices about what to do next.

**Methodology/Approach**

The paper is based on the active inference framework of Friston et al. (2017), which is a process theory for understanding brain function. The authors' approach is based on the idea that the agent's choice of action is determined by the free energy, which is a measure of the amount of information gained or lost in the environment. This idea has been used to understand human and animal behavior as well as artificial intelligence. In this paper, the authors use the active inference framework to develop an algorithm for learning from demonstration that they call Deep Active Inference (DAI). The DAI approach is based on a variational autoencoder with a probabilistic latent space. This is similar to the generative adversarial network (GAN) and the variational autoencoder (VAE), but it differs in its use of an inference network, which is used for making predictions about the environment. In the active inference framework, the agent's choice of action is determined by the free energy. The DAI algorithm uses a probabilistic latent space that is similar to the generative adversarial network and the variational autoencoder. However, it differs in its use of an inference network. This is used for making predictions about the environment. The authors' approach also differs from the existing approaches in the way that the inference network is used. In the DAI algorithm, the inference network is used to make predictions about the environment. The authors show how this can be done by using a variational autoencoder with an inference network.

**Results/Data**

The paper presents two experiments. The first experiment is a task called "Tool Use" and the second one is called "Curiosity". In the "Tool Use" task, the agent must use tools to achieve its goals. For example, it may need to pick up a hammer in order to hit an object. The authors show that their DAI algorithm can be used for learning from demonstration on this task. They compare their approach with two existing approaches and find that it outperforms them. In the "Curiosity" task, the agent must make choices about what to do next. For example, if a person is in front of a door and wants to go through it, they may need to decide whether to turn left or right. The authors show how their DAI algorithm can be used for learning from demonstration on this task. They compare their approach with two existing approaches and find that it outperforms them.

**Limitations/Discussion**

The paper does not discuss the limitations of its own work. It only discusses the future research directions. The authors suggest that the DAI approach could be used to understand human behavior in a variety of situations, such as learning from demonstrations or making choices about what to do next. They also mention that the DAI algorithm is limited by the fact that it requires a large amount of data for training. In addition, they point out that the DAI algorithm can be used to develop new approaches for understanding human behavior in different situations.

**References**

The paper has 7 references. The first one is Friston (2010) and the others are from 2012-2019.

---

**Summary Statistics:**
- Input: 3,092 words (18,872 chars)
- Output: 699 words
- Compression: 0.23x
- Generation: 35.5s (19.7 words/sec)
- Quality Score: 1.00/1.0
- Attempts: 1

**Quality Check:** Passed
