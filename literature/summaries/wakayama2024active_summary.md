# Active Inference in Contextual Multi-Armed Bandits for Autonomous Robotic Exploration

**Authors:** Shohei Wakayama, Alberto Candela, Paul Hayne, Nisar Ahmed

**Year:** 2024

**Source:** arxiv

**Venue:** arXiv

**DOI:** 10.1109/TRO.2025.3577041

**PDF:** [wakayama2024active.pdf](../pdfs/wakayama2024active.pdf)

**Generated:** 2025-12-03 04:04:19

---

**Overview/Summary**

The paper "Active Inference in Contextual Multi-Armed Bandits" by Wakayama et al. (2023) proposes a novel approach to the problem of autonomous decision-making with contextual multi-armed bandits, which is a type of partially observable Markov decision process (POMDP). The authors introduce an active inference algorithm that can be used for robotic search and exploration in environments where the reward function depends on the context. In this paper, the authors first formulate the problem as a POMDP and then propose an active inference algorithm based on the expected free energy (EFE) framework. They also provide two variants of the EFE-based algorithm: one is called observation-augmented contextual multi-armed bandits for robotic search and exploration, and the other is called active inference for autonomous decision-making with contextual multi-armed bandits. The authors apply these algorithms to a real-world problem in which the reward function depends on the context. In this paper, the authors first formulate the problem as a POMDP and then propose an active inference algorithm based on the EFE framework. They also provide two variants of the EFE-based algorithm: one is called observation-augmented contextual multi-armed bandits for robotic search and exploration, and the other is called active inference for autonomous decision-making with contextual multi-armed bandits. The authors apply these algorithms to a real-world problem in which the reward function depends on the context.

**Key Contributions/Findings**

The key contributions of this paper are threefold: First, the authors formulate the problem as a POMDP and then propose an active inference algorithm based on the EFE framework. Second, the authors provide two variants of the EFE-based algorithm: one is called observation-augmented contextual multi-armed bandits for robotic search and exploration, and the other is called active inference for autonomous decision-making with contextual multi-armed bandits. Third, the authors apply these algorithms to a real-world problem in which the reward function depends on the context.

**Methodology/Approach**

The authors first formulate the problem as a POMDP and then propose an active inference algorithm based on the EFE framework. The authors also provide two variants of the EFE-based algorithm: one is called observation-augmented contextual multi-armed bandits for robotic search and exploration, and the other is called active inference for autonomous decision-making with contextual multi-armed bandits. The authors apply these algorithms to a real-world problem in which the reward function depends on the context.

**Results/Data**

The authors provide two variants of the EFE-based algorithm: one is called observation-augmented contextual multi-armed bandits for robotic search and exploration, and the other is called active inference for autonomous decision-making with contextual multi-armed bandits. The authors apply these algorithms to a real-world problem in which the reward function depends on the context.

**Limitations/Discussion**

The enhancement of the proposed method is attributed to the unique characteristics of EFE, which underpin AIF's ability to adapt and optimize exploration-exploitation tradeoffs efficiently in response to changing preferences. The authors also discuss some limitations and future work directions for this research.

**References**

Work supported by the NASA COLDTech Program, grant #80NSSC21K1031. S. Wakayama was also supported by the Masason Foundation. Part of this research was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration 80NM0018D0004.

**Additional References**

[1] J. A. Grant, M. P. Golombek, S. A. Wilson, K. A. Farley, K. H. Williford, and A. Chen, “The science process for selecting the landing site for the 2020 mars rover,” Planetary and Space Science, vol. 164, pp. 106–126, 2018.

[2] J. R. Johnson, “Practicing mars 2020 ops,” 2019, https://www.planetary.org/articles/practicing-mars-2020-ops.

[3] J. Foust, “Europa clipper passes key review,” https://spacenews.com/europa-clipper-passes-key-review/.

[4] NASA, “Nasa’s mars 2020 project,” PDF, 2017, https://oig.nasa.gov/wp-content/uploads/2024/02/IG-17-009.pdf.

[5] B. K. Muirhead, A. Nicholas, and J. Umland, “Mars sample return mission concept status,” in 2020 IEEE Aerospace Conference. IEEE, 2020, pp. 1–8.

[6] L. P. Kaelbling, M. L. Littman, and A. R. Cassandra, “Planning and acting in partially observable stochastic domains,” Artif. Intell., vol. 101, no. 1–2, p. 99–134, may 1998.

[7] H. Kurniawati, “Partially observable markov decision processes and robotics,” Annual Review of Control, Robotics, and Autonomous Systems, vol. 5, no. 1, pp. 253–277, 2022.

[8] A. Krause, A. Singh, and C. Guestrin,  “Near-optimimal sensor placements in gaussian processes: Theory, efficient algorithms and empirical studies.” Journal of Machine Learning Research, vol. 9, no. 2, 2008.

[9] A. Candela, K. Edelson, M. M. Gierach, D. R. Thompson, G. Woodward, and D. Wettergreen, “Using remote sensing and in situ measurements for efficient mapping and optimal sampling of coral reefs,” Frontiers in Marine Science, vol. 8, p. 689489, 2021.

[10] C. E. Denniston, G. Salhotra, A. Kangaslahti, D. A. Caron, and G. S. Sukhatme, “Learned parameter selection for robotic information gathering,” in 2023 IEEE/RSJ International Conference on Intelligent Robots (IROS), 2023, pp. 10 519–10 526.

[11] C. E. Rasmussen,  “Gaussian processes in machine learning,” in Summer school on machine learning. Springer, 2003, pp. 63–71.

[12] A. West, I. Tsitsimpelis, M. Licata, A. Jazbec, L. Snoj, M. J. Joyce, V. Sind- hwani, C. Parada, and G. Aggarwal, “A contextual bandit approach for learning to plan in environments with probabilistic goal configurations,” in 2023 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2023, pp. 5645–5652.

[13] S. Wakayama and N. Ahmed,  “Active inference for autonomous decision-making with contextual multi-armed bandits,” in 2023 IEEE International Conference on Robotics and Automation (ICRA), 2023, pp. 7916–7922.

[14] ——,  “Observation-augmented contextual multi-armed bandits for robotic search and exploration,” IEEE Robotics and Automation Letters, vol. 9, no. 10, pp. 8531–8538, 2024.

[15] H. H. Schmitt,  “Apollo 17 report on the valley of taurus-littrow: A geological investigation of th

**Additional References**

[16] J. A. Grant, M. P. Golombek, S. A. Wilson, K. A. Farley, and A. Chen, “The science process for selecting the landing site for the 2020 mars rover,” Planetary and Space Science, vol. 164, pp. 106–126, 2018.

[17] J. R. Johnson, “Practicing mars 2020 ops,” 2019, https://www.planetary.org/articles/practicing-mars-2020-ops.

[18] J. Foust, “Europa clipper passes key review,” https://spacenews.com/europa-clipper-passes-key-review/.

[19] NASA, “Nasa’s mars 2020 project,” PDF, 2017, https://oig.nasa.gov/wp-content/uploads/2024/02/IG-17-009.pdf.

[20] B. K. Muirhead, A. Nicholas, and J. Umland, “Mars sample return mission concept status,” in 2020 IEEE Aerospace Conference. IEEE, 2020, pp. 1–8.

[21] L. P. Kaelbling, M. L. Littman, and A. R. Cassandra, “Planning and acting in partially observable stochastic domains,” Artif. Intell., vol. 101, no. 1–2, p. 99–134, may 1998.

[22] H. Kurniawati, “Partially observable markov decision processes and robotics,” Annual Review of Control, Robotics, and Autonomous Systems, vol. 5, no. 1, pp. 253–277, 2022.

[23] A. Krause, A. Singh, and C. Guestrin,  “Near-optimimal sensor placements in gaussian processes: Theory, efficient algorithms and empirical studies.” Journal of Machine Learning Research, vol. 9, no. 2, 2008.

[24] A. Candela, K. Ed

---

**Summary Statistics:**
- Input: 9,228 words (59,904 chars)
- Output: 1,102 words
- Compression: 0.12x
- Generation: 69.4s (15.9 words/sec)
- Quality Score: 1.00/1.0
- Attempts: 1

**Quality Check:** Passed
