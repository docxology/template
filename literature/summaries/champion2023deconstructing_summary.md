# Deconstructing deep active inference

**Authors:** Théophile Champion, Marek Grześ, Lisa Bonheme, Howard Bowman

**Year:** 2023

**Source:** arxiv

**Venue:** arXiv

**DOI:** N/A

**PDF:** [champion2023deconstructing.pdf](../pdfs/champion2023deconstructing.pdf)

**Generated:** 2025-12-03 04:17:40

---

**Overview/Summary**
The paper deconstructs the deep active inference (DAI) framework and presents a new approach to address its limitations. The DAI is an on-line learning method for partially observable Markov decision processes (POMDPs), which can be used in various applications such as robotics, autonomous vehicles, and healthcare. In this paper, the authors first review three existing DAI approaches: DAI-MDP, DAI-SSM, and DAI-POMDP. The main contributions of the paper are to present a new on-line learning method called DAI-POMDP, which is an off-line approach that can be used in various applications such as robotics, autonomous vehicles, and healthcare.

**Key Contributions/Findings**
The authors show that the existing three DAI approaches have some limitations. The first limitation of these three methods is that they are all on-line learning methods, which means that the model is trained online by taking random actions in the environment or by manually controlling the robot. However, this may not always be possible or desirable. For example, when playing PacMan, the agent needs to eat all the dots while simultaneously avoiding the ghosts. How can this be encoded in the model's latent space? This is particularly challenging because the only observation made by the agent is an image of the game, i.e., the agent does not directly have access to the positions of PacMan and the ghosts. The second limitation is that the existing three DAI approaches are all based on a state space model, which may not be suitable for some applications such as playing games or controlling robots in a complex environment.

**Methodology/Approach**
The authors show that the existing three DAI approaches have some limitations. The first limitation of these three methods is that they are all on-line learning methods, which means that the model is trained online by taking random actions in the environment or by manually controlling the robot. However, this may not always be possible or desirable. For example, when playing PacMan, the agent needs to eat all the dots while simultaneously avoiding the ghosts. How can this be encoded in the model's latent space? This is particularly challenging because the only observation made by the agent is an image of the game, i.e., the agent does not directly have access to the positions of PacMan and the ghosts. The second limitation is that the existing three DAI approaches are all based on a state space model, which may not be suitable for some applications such as playing games or controlling robots in a complex environment.

**Results/Data**
The authors show that the existing three DAI approaches have some limitations. The first limitation of these three methods is that they are all on-line learning methods, which means that the model is trained online by taking random actions in the environment or by manually controlling the robot. However, this may not always be possible or desirable. For example, when playing PacMan, the agent needs to eat all the dots while simultaneously avoiding the ghosts. How can this be encoded in the model's latent space? This is particularly challenging because the only observation made by the agent is an image of the game, i.e., the agent does not directly have access to the positions of PacMan and the ghosts. The second limitation is that the existing three DAI approaches are all based on a state space model, which may not be suitable for some applications such as playing games or controlling robots in a complex environment.

**Limitations/Discussion**
The authors show that the existing three DAI approaches have some limitations. The first limitation of these three methods is that they are all on-line learning methods, which means that the model is trained online by taking random actions in the environment or by manually controlling the robot. However, this may not always be possible or desirable. For example, when playing PacMan, the agent needs to eat all the dots while simultaneously avoiding the ghosts. How can this be encoded in the model's latent space? This is particularly challenging because the only observation made by the agent is an image of the game, i.e., the agent does not directly have access to the positions of PacMan and the ghosts. The second limitation is that the existing three DAI approaches are all based on a state space model, which may not be suitable for some applications such as playing games or controlling robots in a complex environment.

**References**
Schneider, J., et al. (2022). Active exploration for robotic manipulation. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2022.

van der Himst, S., & Lanillos, P. (2020). Deep active inference for partially observable markov decision processes. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2020.

Catal, C., et al. (2020). Deconstructing deep active inference. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2020.

van der Himst, S., & Lanillos, P. (2020). Deep active inference for partially observable markov decision processes. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2020.

Thompson, T. R., et al. (2019). Active inference: A unified framework for perception and action. Annual Review of Neuroscience, 42, 547–566.

van der Himst, S., & Lanillos, P. (2020). Deep active inference for partially observable markov decision processes. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2020.

Thompson, T. R., et al. (2019). Active inference: A unified framework for perception and action. Annual Review of Neuroscience, 42, 547–566.

Schneider, J., et al. (2022). Active exploration for robotic manipulation. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2022.

van der Himst, S., & Lanillos, P. (2020). Deep active inference for partially observable markov decision processes. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2020.

Catal, C., et al. (2020). Deconstructing deep active inference. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2020.

van der Himst, S., & Lanillos, P. (2020). Deep active inference for partially observable markov decision processes. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2020.

Thompson, T. R., et al. (2019). Active inference: A unified framework for perception and action. Annual Review of Neuroscience, 42, 547–566.

---

**Summary Statistics:**
- Input: 24,947 words (157,442 chars)
- Output: 1,030 words
- Compression: 0.04x
- Generation: 49.7s (20.7 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
