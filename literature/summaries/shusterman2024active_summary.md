# An Active Inference Strategy for Prompting Reliable Responses from Large Language Models in Medical Practice

**Authors:** Roma Shusterman, Allison C. Waters, Shannon O`Neill, Phan Luu, Don M. Tucker

**Year:** 2024

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [shusterman2024active.pdf](../pdfs/shusterman2024active.pdf)

**Generated:** 2025-12-05 13:33:07

---

**Overview/Summary**

The paper proposes an active inference strategy to encourage reliable responses from large language models (LLMs) by leveraging a self-critiquing approach that can be used for both generation and evaluation of LLMs. The authors argue that the current use of LLMs in healthcare is imperative, but also requires regulatory oversight.

**Key Contributions/Findings**

The main contribution of this work is to propose a new method called CritiqueLLM (Critiquing Large Language Models) which can be used for both generation and evaluation of LLMs. The authors first describe the challenges for regulating medical use of large language models, then introduce their proposed approach, and finally discuss the potential benefits of their strategy.

**Methodology/Approach**

The authors start by describing the challenges for regulating medical use of LLMs. They argue that the current use of LLMs in healthcare is imperative, but also requires regulatory oversight. The authors then describe the current state-of-the-art methods for evaluating and training LLMs. These include a retrieval-augmented generation approach (RAG) which trains an LLM to generate text based on the real-time information needs of another LLM, and a self-critiquing approach that uses a trained LLM as a critic for another LLM. The authors then describe their proposed method, CritiqueLLM, which is a combination of RAG and self-critiquing. They also propose an extension to the self-critiquing approach called SelfCheck, which can be used to zero-shot check the step-by-step reasoning of a trained LLM.

**Results/Data**

The authors first describe the challenges for regulating medical use of large language models. The authors then present their proposed method, CritiqueLLM, and its extension, SelfCheck. They also compare their approach with other existing approaches. Finally, they discuss the potential benefits of their strategy.

**Limitations/Discussion**

The authors argue that the current use of LLMs in healthcare is imperative, but also requires regulatory oversight. The authors then describe the challenges for regulating medical use of large language models. They argue that the current use of LLMs in healthcare is imperative, but also requires regulatory oversight. The authors then present their proposed method, CritiqueLLM, and its extension, SelfCheck. They also compare their approach with other existing approaches. Finally, they discuss the potential benefits of their strategy.

**References**

The paper cites 21 references.

---

**Summary Statistics:**
- Input: 10,023 words (69,516 chars)
- Output: 364 words
- Compression: 0.04x
- Generation: 24.7s (14.7 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
