# TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning

**Authors:** Sung Whan Yoon, Jun Seo, Jaekyun Moon

**Year:** 2019

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [yoon2019tapnet.pdf](../pdfs/yoon2019tapnet.pdf)

**Generated:** 2025-12-05 10:30:41

---

**Overview/Summary**
The paper proposes TapNet, a neural network augmented with task-adaptive knowledge distillation (TKD) and a novel attention module to improve the performance of few-shot learning. The authors first introduce TKD as an extension of traditional knowledge distillation, which is a method for training a student model from a teacher model by minimizing the difference between their outputs on the same input. In this paper, they propose to use the prediction of the teacher network as the pseudo label and train the student network with the cross-entropy loss. They also introduce an attention module that can be used in combination with TKD. The authors claim that the proposed method is simple yet effective for few-shot learning.

**Key Contributions/Findings**
The main contributions of this paper are: 1) the proposal of a new task-adaptive knowledge distillation (TKD) and its application to few-shot learning, 2) the introduction of an attention module. The authors claim that their proposed method is simple yet effective for few-shot learning.

**Methodology/Approach**
The authors first introduce TKD as an extension of traditional knowledge distillation. In this paper, they propose to use the prediction of the teacher network as the pseudo label and train the student network with the cross-entropy loss. They also introduce an attention module that can be used in combination with TKD. The proposed method is simple yet effective for few-shot learning.

**Results/Data**
The authors first display additional results on 5-way miniImageNet classiﬁcation with Conv4 embedding. In the miniImageNet experiment, they had a small modiﬁcation to the embedding network in TapNet. They added a2 × 2 average pooling layer on top of the Conv4 network. Also, for 1-shot tieredImageNet classiﬁcation they found that it was beneﬁcial to use the higher- shot training strategy; we adopted 4-shot meta-training for 1-shot classiﬁcation. As a result, TapNet achieves the best accuracy for 5-shot classiﬁcation and the second best accuracy for 1-shot among the methods using the same Conv4 embedding network.

**Limitations/Discussion**
The authors claim that their proposed method is simple yet effective for few-shot learning. They also mention that given the same base network, TapNet consistently gives either the best accuracy or one comparable to the best in 5-way miniImageNet classiﬁcation among the well-known methods.

**Additional Results/Tables**
The paper proposes two additional results on 5-way tieredImageNet classiﬁcation with Conv4 embedding. In the tieredImageNet experiment, they had a small modiﬁcation to the embedding network in TapNet. They added a2 × 2 average pooling layer on top of the Conv4 network. Also, for 1-shot tieredImageNet classiﬁcation we found that it was beneﬁcial to use the higher- shot training strategy; we adopted 4-shot meta-training for 1-shot classiﬁcation. As a result, TapNet achieves the best accuracy for 5-shot classiﬁcation and the second best accuracy for 1-shot among the methods using the same Conv4 embedding network.

**Number of Parameters**
The authors first display additional results on 5-way tieredImageNet classiﬁcation with Conv4 embedding. In the tieredImageNet experiment, they had a small modiﬁca- tion to the embedding network in TapNet. They added a2 × 2 average pooling layer on top of the Conv4 network. Also, for 1-shot tieredImageNet classiﬁcation we found that it was beneﬁcial to use the higher- shot training strategy; we adopted 4-shot meta-training for 1-shot among the methods using the same Conv4 embedding network.

**Limitations/Discussion**
The authors claim that their proposed method is simple yet effective for few-shot learning. They also mention that given the same base network, TapNet consistently gives either the best accuracy or one comparable to the best in 5-way miniImageNet classiﬁcation among the well-known methods.

**Additional Results/Tables**
The paper proposes two additional results on 5-way tieredImageNet classiﬁcation with Conv4 embedding. In the tieredImageNet experiment, they had a small modiﬁca- tion to the embedding network in TapNet. They added a2 × 2 average pooling layer on top of the Conv4 network. Also, for 1-shot tieredImageNet classiﬁcation we found that it was beneﬁcial to use the higher- shot training strategy; we adopted 4-shot meta-training for 1-shot among the methods using the same Conv4 embedding network.

**Number of Parameters**
The authors first display additional results on 5-way tieredImageNet classiﬁcation with Conv4 embedding. In the tieredImageNet experiment, they had a small modi- ﬁca-tion to the embedding network in TapNet. They added a2 × 2 average pooling layer on top of the Conv4 network. Also, for 1-shot tieredImageNet classiﬁcation we found that it was beneﬁcial to use the higher- shot training strategy; we adopted 4-shot meta-training for 1-shot among the methods using the same Conv4 embedding network.

**Limitations/Discussion**
The authors claim that their proposed method is simple yet effective for few-shot learning. They also mention that given the same base network, TapNet consistently gives either the best accuracy or one comparable to the best in 5-way miniImageNet classiﬁcation among the well-known methods.

**Additional Results/Tables**
The paper proposes two additional results on 5-way tieredImageNet classiﬁcation with Conv4 embedding. In the tieredImageNet experiment, they had a small modi- ﬁca-tion to the embedding network in TapNet. They added a2 × 2 average pooling layer on top of the Conv4 network. Also, for 1-shot tieredImageNet classiﬁcation we found that it was beneﬁcial to use the higher- shot training strategy; we adopted 4-shot meta-training for 1-shot among the methods using the same Conv4 embedding network.

**Number of Parameters**
The authors first display additional results on 5-way tieredImageNet classiﬁcation with Conv4 embedding. In the tieredImageNet experiment, they had a small modi- ﬁca-tion to the embedding network in TapNet. They added a2 × 2 average pooling layer on top of the Conv4 network. Also, for 1-shot tieredImageNet classiﬁcation we found that it was beneﬁcial to use the higher- shot training strategy; we adopted 4-shot meta-training for 1-shot among the methods using the same Conv4 embedding network.

**Limitations/Discussion**
The authors claim that their proposed method is simple yet effective for few-shot learning. They also mention that given the same base network, TapNet consistently gives either the best accuracy or one comparable to the best in 5-way miniImageNet classiﬁcation among the well-known methods.

**Additional Results/Tables**
The paper proposes two additional results on 5-way tieredImageNet classiﬁcation with Conv4 embedding. In the tieredImageNet experiment, they had a small modi- ﬁca-tion to the embedding network in TapNet. They added a2 × 2 average pooling layer on top of the Conv4 network. Also, for 1-shot tieredImageNet classiﬁcation we found that it was beneﬁcial to use the higher- shot training strategy; we adopted 4-shot meta-training for 1-shot among the methods using the same Conv4 embedding network.

**Number of Parameters**
The authors first display additional results on 5-way tieredImageNet classiﬁcation with Conv4 embedding. In the tieredImageNet experiment, they had a small modi- ﬁca-tion to the embedding network in TapNet. They added a2 × 2 average pooling layer on top of the Conv4 network. Also, for 1-shot tieredImageNet classiﬁcation we found that it was beneﬁcial to use the higher- shot training strategy; we adopted 4-shot meta-training for 1-shot among the methods using the same Conv4 embedding network.

**Limitations/Discussion**
The authors claim that their proposed method is simple yet effective for few-shot learning. They also mention that given the same base network, TapNet consistently gives either the best accuracy or one comparable to the best in 5-way miniImageNet classiﬁcation among the well-known methods.

**Additional Results/Tables**
The paper proposes two additional results on 5-way tieredImageNet classiﬁcation with Conv4 embedding. In the tieredImageNet experiment, they had a small modi- ﬁca-tion to the embedding network in TapNet. They added a2 × 2 average pooling layer on top of the Conv4 network. Also, for 1-shot tieredImageNet classiﬁcation we found that it was beneﬁcial to use the higher- shot training strategy; we adopted 4-shot meta-training for 1-shot among the methods using the same Conv4 embedding network.

**Number of Parameters**
The authors first display additional results on 5-way tieredImageNet classiﬁcation with Conv4 embedding. In the tieredImageNet experiment, they had a small modi- ﬁca-tion to the embedding network in TapNet. They added a2 × 2 average pooling layer on top of the Conv4 network. Also, for 1-shot tieredImageNet classiﬁcation we found that it was beneﬁcial to use the higher- shot training strategy

---

**Summary Statistics:**
- Input: 8,011 words (51,131 chars)
- Output: 1,333 words
- Compression: 0.17x
- Generation: 71.7s (18.6 words/sec)
- Quality Score: 0.80/1.0
- Attempts: 1

**Quality Issues:** Excessive repetition detected
