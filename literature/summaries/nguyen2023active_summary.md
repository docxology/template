# Active Membership Inference Attack under Local Differential Privacy in Federated Learning

**Authors:** Truc Nguyen, Phung Lai, Khang Tran, NhatHai Phan, My T. Thai

**Year:** 2023

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [nguyen2023active.pdf](../pdfs/nguyen2023active.pdf)

**Generated:** 2025-12-05 12:17:42

---

**Overview/Summary**

The paper "Active Membership Inference Attack under Local Differential Privacy in Federated Learning" by Truc Nguyen, Phung Lai, Khang Tran, and My T. Thai is a security study that investigates the membership inference attack (MIA) problem in federated learning with local differential privacy (LDP). The authors show that the current state-of-the-art AMI attacks are not secure under LDP and propose an improved attack called AD, M-LDP. The main contributions of this work are threefold: 1) it is shown that the linearity assumption for the current AMI attacks does not hold in the LDP setting; 2) a new AMI attack, namely AD, M-LDP, is proposed to solve the membership inference problem under LDP; and 3) the authors show that the proposed attack is feasible with high probability. The paper also provides an experimental study on the effectiveness of the proposed attack.

**Key Contributions/Findings**

The first contribution is to show that the linearity assumption for the current AMI attacks does not hold in the LDP setting. Specifically, it is shown that the linear relationship between the expected value of the chosen neuron and the target data sample does not exist in the LDP setting. The authors prove this by showing a counterexample: given the target data sample t and any other data samples x ̸= M(t, ε), there exists no W that can satisfy Eq. (4) for all x ̸= t. This is shown by choosing two different sets of values for the first neuron and all the others in the counterexample. The first set of values is t1 + c and ti for i > 1, where c > 0; while the second set of values is t1 - c and ti for i > 1. In this case, the two equations (13) and (14) are contradictory. Therefore, there exists no W that can satisfy Eq. (4) for all x ̸= t.

The second contribution is to propose an improved attack called AD, M-LDP. The authors show that the proposed attack is feasible with high probability. Following the expected output stability property in LDP [Lecuyer et al., 2019], the trained attack AD, M-LDP is certifiably robust to M(·) if it can ensure that the chosen neuron is activated only by the LDP- preserving M(·). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy the condition (15).

The third contribution is to show that the proposed attack is feasible with high probability. Given the target sample t and any data samples x ̸= M(t, ε), the AMI attack AD, M-LDP is successful in determining the membership of t if it can ensure that the chosen neuron is activated only by the LDP-preserving M(·). The authors show that the proposed attack is feasible with high probability. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the trained attack AD, M-LDP is certifiably robust to M(·) if the following condition holds: (15). The authors show that the proposed attack is successful in determining the membership of t if it can satisfy this condition. Following the expected output stability property in LDP [Lecuyer et al., 2019], in which the expected value of an ε-LDP algorithm with bounded output is not sensitive to small changes in the input, the

---

**Summary Statistics:**
- Input: 11,424 words (64,985 chars)
- Output: 1,527 words
- Compression: 0.13x
- Generation: 67.8s (22.5 words/sec)
- Quality Score: 0.40/1.0
- Attempts: 1

**Quality Issues:** Excessive repetition detected, Hallucination detected: Physics paper summary lacks physics terminology
