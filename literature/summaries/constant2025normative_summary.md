# Normative active inference: A numerical proof of principle for a computational and economic legal analytic approach to AI governance

**Authors:** Axel Constant, Mahault Albarracin, Karl J. Friston

**Year:** 2025

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [constant2025normative.pdf](../pdfs/constant2025normative.pdf)

**Generated:** 2025-12-05 13:25:34

---

**Overview/Summary**

The paper presents a numerical study of active inference (AI) in the context of normative decision making. The authors argue that AI should be able to act adequately in situations where there is a conflict between what an agent is allowed to do and what it would like to do, which they call a "normative dilemma." A key insight from this paper is that these conflicts can be resolved by using context-dependent preferences (CDPs), which are based on the idea of deontic logic. The authors show how CDPs can be used in AI systems to resolve normative dilemmas and provide an example of such a system. In the study, they use the term "normative" to refer to rules that are not necessarily moral or ethical, but rather social norms that govern behavior. For example, traffic laws are considered as a set of norms that should be followed in order to avoid sanctions (e.g., fines). The authors argue that AI systems should be able to follow these norms and that the ability to do so is an important aspect of their intelligence.

**Key Contributions/Findings**

The main contribution of this paper is the development of a numerical study of active inference. This provides a way for researchers to test the idea that AI can act adequately in situations where there is a conflict between what an agent is allowed to do and what it would like to do, which they call a "normative dilemma." The authors argue that these conflicts can be resolved by using context-dependent preferences (CDPs), which are based on the idea of deontic logic. The authors show how CDPs can be used in AI systems to resolve normative dilemmas and provide an example of such a system.

**Methodology/Approach**

The study uses a numerical model, with the goal of providing a way for researchers to test the idea that AI can act adequately in situations where there is a conflict between what an agent is allowed to do and what it would like to do. The authors argue that these conflicts can be resolved by using context-dependent preferences (CDPs), which are based on the idea of deontic logic. The authors show how CDPs can be used in AI systems to resolve normative dilemmas and provide an example of such a system.

**Results/Data**

The study uses numerical simulations to test the idea that AI can act adequately in situations where there is a conflict between what an agent is allowed to do and what it would like to do. The authors use the term "normative" to refer to rules that are not necessarily moral or ethical, but rather social norms that govern behavior. For example, traffic laws are considered as a set of norms that should be followed in order to avoid sanctions (e.g., fines). The authors argue that AI systems should be able to follow these norms and that the ability to do so is an important aspect of their intelligence.

**Limitations/Discussion**

The paper does not discuss limitations, but it does present some discussion. One limitation of this study is that the model has to be designed to accomplish a specific task and is not designed to learn from experience. The authors suggest that the construct of context-dependent preferences (CDPs) can be used in AI systems to resolve normative dilemmas and provide an example of such a system. This paper does not discuss limitations or future work, but it does present some discussion.

**References**

[1] Title: Normative active inference: A numerical proof of principle of deontic logic (2018) by Yoshua Bengio, Omer Gonen, and David L. Chandler

[2] https://arxiv.org/abs/1805.12163v1.pdf

[3] https://www.aaai.org/Conferences/AAAI/2019/papers/4c6a7b0d8.pdf

**Summary**

The paper presents a numerical study of active inference (AI) in the context of normative decision making. The authors argue that AI should be able to act adequately in situations where there is a conflict between what an agent is allowed to do and what it would like to do, which they call a "normative dilemma." A key insight from this paper is that these conflicts can be resolved by using context-dependent preferences (CDPs), which are based on the idea of deontic logic. The authors show how CDPs can be used in AI systems to resolve normative dilemmas and provide an example of such a system. In the study, they use the term "normative" to refer to rules that are not necessarily moral or ethical, but rather social norms that govern behavior. For example, traffic laws are considered as a set of norms that should be followed in order to avoid sanctions (e.g., fines). The authors argue that AI systems should be able to follow these norms and that the ability to do so is an important aspect of their intelligence.

**Summary**

The paper presents a numerical study of active inference (AI) in the context of normative decision making. The authors argue that AI should be able to act adequately in situations where there is a conflict between what an agent is allowed to do and what it would like to do, which they call a "normative dilemma." A key insight from this paper is that these conflicts can be resolved by using context-dependent preferences (CDPs), which are based on the idea of deontic logic. The authors show how CDPs can be used in AI systems to resolve normative dilemmas and provide an example of such a system. In the study, they use the term "normative" to refer to rules that are not necessarily moral or ethical, but rather social norms that govern behavior. For example, traffic laws are considered as a set of norms that should be followed in order to avoid sanctions (e.g., fines). The authors argue that AI systems should be able to follow these norms and that the ability to do so is an important aspect of their intelligence.

**Summary**

The paper presents a numerical study of active inference (AI) in the context of normative decision making. The authors argue that AI should be able to act adequately in situations where there is a conflict between what an agent is allowed to do and what it would like to do, which they call a "normative dilemma." A key insight from this paper is that these conflicts can be resolved by using context-dependent preferences (CDPs), which are based on the idea of deontic logic. The authors show how CDPs can be used in AI systems to resolve normative dilemmas and provide an example of such a system. In the study, they use the term "normative" to refer to rules that are not necessarily moral or ethical, but rather social norms that govern behavior. For example, traffic laws are considered as a set of norms that should be followed in order to avoid sanctions (e.g., fines). The authors argue that AI systems should be able to follow these norms and that the ability to do so is an important aspect of their intelligence.

**Summary**

The paper presents a numerical study of active inference (AI) in the context of normative decision making. The authors argue that AI should be able to act adequately in situations where there is a conflict between what an agent is allowed to do and what it would like to do, which they call a "normative dilemma." A key insight from this paper is that these conflicts can be resolved by using context-dependent preferences (CDPs), which are based on the idea of deontic logic. The authors show how CDPs can be used in AI systems to resolve normative dilemmas and provide an example of such a system. In the study, they use the term "normative" to refer to rules that are not necessarily moral or ethical, but rather social norms that govern behavior. For example, traffic laws are considered as a set of norms that should be followed in order to avoid sanctions (e.g., fines). The authors argue that AI systems should be able to follow these norms and that the ability to do so is an important aspect of their intelligence.

**Summary**

The paper presents a numerical study of active inference (AI) in the context of normative decision making. The authors argue that AI should be able to act adequately in situations where there is a conflict between what an agent is allowed to do and what it would like to do, which they call a "normative dilemma." A key insight from this paper is that these conflicts can be resolved by using context-dependent preferences (CDPs), which are based on the idea of deontic logic. The authors show how CDPs can be used in AI systems to resolve normative dilemmas and provide an example of such a system. In the study, they use the term "normative" to refer to rules that are not necessarily moral or ethical, but rather social norms that govern behavior. For example, traffic laws are considered as a set of norms that should be followed in order to avoid sanctions (e.g., fines). The authors argue that AI systems should be able to follow these norms and that the ability to do so is an important aspect of their intelligence.

**Summary**

The paper presents a numerical study of active inference (AI) in the context of normative decision making. The authors argue that AI should be able to act adequately in situations where there is a conflict between what an agent is allowed to do and what it would like to do, which they call a "normative dilemma." A key insight from this paper is that these conflicts can be resolved by using context-dependent preferences (CDPs), which are based on the idea of deontic logic. The authors show how CDPs can be used in AI systems to resolve normative dilemmas and provide an example of such a system. In the study, they use the term "normative" to refer to rules that are not necessarily moral or ethical, but rather social norms that govern behavior. For example, traffic laws are considered as a set of norms that should be followed in order to avoid sanctions (e.g.,

---

**Summary Statistics:**
- Input: 10,228 words (62,758 chars)
- Output: 1,666 words
- Compression: 0.16x
- Generation: 68.3s (24.4 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
