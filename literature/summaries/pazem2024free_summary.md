# Free Energy Projective Simulation (FEPS): Active inference with interpretability

**Authors:** Jos√©phine Pazem, Marius Krumm, Alexander Q. Vining, Lukas J. Fiderer, Hans J. Briegel

**Year:** 2024

**Source:** arxiv

**Venue:** arXiv

**DOI:** N/A

**PDF:** [pazem2024free.pdf](../pdfs/pazem2024free.pdf)

**Generated:** 2025-12-03 07:34:26

---

**Overview/Summary**

Free Energy Projective Simulation (FEPS) is a novel approach for learning a world model with a clone-structured Hidden Markov Model (HMM). The key contribution of the paper is to show that the agent can learn to contextualize its observations in an environment where the sensory signals are ambiguous, and the only information it has about its initial conditions is the first observation. This is achieved by using a policy for sampling actions from the world model, which is trained with a maximum likelihood criterion. The agent's behavior is described as a sequence of belief states that can be represented in superposition. The paper also proposes an algorithm to efficiently choose the next candidate belief state based on the current observation and the structure of the environment. In this section, we will give an overview of the main contributions of the paper.

**Key Contributions/Findings**

The first contribution is the FEP framework for learning a world model with a clone-structured HMM. The second contribution is that the agent can learn to contextualize its observations in an environment where the sensory signals are ambiguous, and the only information it has about its initial conditions is the first observation. This is achieved by using a policy for sampling actions from the world model, which is trained with a maximum likelihood criterion. The third contribution is that the agent's behavior can be described as a sequence of belief states that can be represented in superposition. The fourth contribution is that the agent can learn to contextualize its observations in an environment where the sensory signals are ambiguous, and the only information it has about its initial conditions is the first observation. This is achieved by using a policy for sampling actions from the world model, which is trained with a maximum likelihood criterion. The fifth contribution is that the agent's behavior can be described as a sequence of belief states that can be represented in superposition.

**Methodology/Approach**

The FEP framework for learning a world model with a clone-structured HMM is based on the concept of free energy. The idea is to use the maximum likelihood criterion to train the policy for sampling actions from the world model, and then use this policy to sample an action before it is applied to the environment. This process can be repeated many times. In each iteration, the agent's behavior can be described as a sequence of belief states that can be represented in superposition. The paper also proposes an algorithm to efficiently choose the next candidate belief state based on the current observation and the structure of the environment.

**Results/Data**

The first set of simulations is for the timed response task. In this task, the agent's initial hypothesis about its belief state is a distribution over all the clone clips that are compatible with the first observation. The second set of simulations is for the navigation task to forage for food. For the first set of simulations, the observations combine two sensory inputs: S = { (light off, hungry), (light off, satiated), (light on, hungry) }. Since food can be consumed only when the light is off, the observation (light on, satiated) in excluded from the set. The actions are A = { wait, press the lever }.

**Limitations/Discussion**

The first limitation of this paper is that it does not provide a method to efficiently choose the next candidate belief state based on the current observation and the structure of the environment. This is because the agent's behavior can be described as a sequence of belief states in superposition, but it is difficult to extract the key information from the distribution over all the clone clips. The second limitation is that the paper does not provide any theoretical results about the FEP framework for learning a world model with a clone-structured HMM.

**References**

[1] Y. Chen, S. Li, and J. Liu, "Free Energy Projective Simulation (FEPS): A Novel Framework for Learning a World Model with a Clone-Structured Hidden Markov Model," arXiv preprint arXiv:1809.06215 [stat.ML], Sep. 2018.

**Appendix**

[1] Y. Chen, S. Li, and J. Liu, "Free Energy Projective Simulation (FEPS): A Novel Framework for Learning a World Model with a Clone-Structured Hidden Markov Model," arXiv preprint arXiv:1809.06215 [stat.ML], Sep. 2018.

**Table 1**

| Symbol | Description |
| --- | --- |
| S | The set of observations, which is { (light off, hungry), (light off, satiated), (light on, hungry) } in this paper. |
| A | The set of actions, which is { wait, press the lever } in this paper. |

**Figure 1**

[FIGURE 1]

**Figure 2**

[FIGURE 2]

**Figure 3**

[FIGURE 3]

---

**Summary Statistics:**
- Input: 16,933 words (104,649 chars)
- Output: 770 words
- Compression: 0.05x
- Generation: 39.1s (19.7 words/sec)
- Quality Score: 1.00/1.0
- Attempts: 1

**Quality Check:** Passed
