# Explanatory machine learning for sequential human teaching

**Authors:** Lun Ai, Johannes Langer, Stephen H. Muggleton, Ute Schmid

**Year:** 2022

**Source:** arxiv

**Venue:** N/A

**DOI:** 10.1007/s10994-023-06351-8

**PDF:** [ai2022explanatory.pdf](../pdfs/ai2022explanatory.pdf)

**Generated:** 2025-12-05 10:26:08

---

**Overview/Summary**

The paper "Explanatory machine learning for sequential human teaching" by [Authors] is a study on how to improve the efficiency of human teaching through using explanations from a learned model. The authors propose an approach to generate explanations from a minimum primitive solution, which can be used in a variety of applications such as education and training. In this paper, they first introduce the concept of cognitive window and explain that the size of the hypothesis space is one of the factors that affect human comprehension. Then, they describe the framework for generating explanations from a minimum primitive solution and provide an algorithm to generate these explanations. The authors also discuss two conjectures about how machine-learned theories can have a harmful or beneﬁcial eﬀect on human comprehension.

**Key Contributions/Findings**

The main contribution of this paper is the framework for generating explanations from a minimum primitive solution, which can be used to improve the efficiency of human teaching. The authors also provide an algorithm to generate these explanations and discuss two conjectures about how machine-learned theories can have a harmful or beneﬁcial eﬀect on comprehension.

**Methodology/Approach**

The approach in this paper is based on the concept of cognitive window, which is related to the MIL complexity analysis. The authors also describe the framework for generating explanations from a minimum primitive solution and provide an algorithm to generate these explanations. The two conjectures about how machine-learned theories can have a harmful or beneﬁcial eﬀect on comprehension are discussed in this paper.

**Results/Data**

The results of this paper are the two conjectures, which relate to the size of the hypothesis space and the cognitive complexity of the minimum primitive solution. The authors also provide an example to illustrate these two conjectures.

**Limitations/Discussion**

The limitations of this paper are that it does not discuss how to generate explanations from a non-minimum primitive solution and how to apply the approach in real applications. The authors do not mention any future work, but they suggest that the proposed framework can be used for other applications such as education and training.

**References**

[Authors] (Year). Explanatory machine learning for sequential human teaching. [Journal], pp. 1-18].

---

**Summary Statistics:**
- Input: 19,704 words (132,063 chars)
- Output: 358 words
- Compression: 0.02x
- Generation: 25.4s (14.1 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
