# Automatic Machine Learning by Pipeline Synthesis using Model-Based Reinforcement Learning and a Grammar

**Authors:** Iddo Drori, Yamuna Krishnamurthy, Raoni Lourenco, Remi Rampin, Kyunghyun Cho, Claudio Silva, Juliana Freire

**Year:** 2019

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [drori2019automatic.pdf](../pdfs/drori2019automatic.pdf)

**Generated:** 2025-12-05 10:25:02

---

**Overview/Summary**

The paper "Automatic Machine Learning by Pipeline Synthesis using Model-Based Reinforcement Learning and a Grammar" is an innovative work in the field of automated machine learning (AutoML). The authors propose a novel approach to automatically synthesize pipelines for machine learning, which they term "pipeline synthesis." They introduce a new framework that leverages model-based reinforcement learning and grammar to efficiently search through the vast space of possible pipelines. This paper is organized as follows.

**Key Contributions/Findings**

The key contributions of this work are threefold: (1) the introduction of a novel approach for pipeline synthesis, which they term "pipeline synthesis," (2) the design of a new algorithm called AlphaD3M that can automatically synthesize pipelines using this framework, and (3) an experimental evaluation of AlphaD3M. The authors' contributions are motivated by the fact that there is no existing method to automatically synthesize pipelines for machine learning.

**Methodology/Approach**

The first contribution is the introduction of a novel approach for pipeline synthesis. The second contribution is the design of a new algorithm called AlphaD3M that can automatically synthesize pipelines using this framework. The third and main contribution is an experimental evaluation of AlphaD3M, which demonstrates the effectiveness of their proposed approach.

**Results/Data**

The authors' contributions are motivated by the fact that there is no existing method to automatically synthesize pipelines for machine learning. They propose a new approach called pipeline synthesis, which is based on model-based reinforcement learning and grammar. The key idea is to represent the space of possible pipelines as a combinatorial structure (a context-free grammar) and then use this structure to guide the search process. This paper is organized as follows.

**Limitations/Discussion**

The authors' approach has several limitations. First, it may not be able to automatically synthesize the best pipeline for all problems. Second, the computational cost of their algorithm is high. Third, the existing evaluation only considers a small number of datasets and algorithms. Fourth, there are some potential biases in their experimental design.

**References**

The authors cite 19 papers in this paper.

---

**Summary Statistics:**
- Input: 3,208 words (21,458 chars)
- Output: 333 words
- Compression: 0.10x
- Generation: 23.9s (13.9 words/sec)
- Quality Score: 1.00/1.0
- Attempts: 1

**Quality Check:** Passed
