# Generating meaning: active inference and the scope and limits of passive AI

**Authors:** Giovanni Pezzulo, Thomas Parr, Paul Cisek, Andy Clark, Karl J. Friston

**Year:** 2023

**Source:** semanticscholar

**Venue:** Trends in Cognitive Sciences

**DOI:** 10.1016/j.tics.2023.10.002

**PDF:** [pezzulo2023generating.pdf](../pdfs/pezzulo2023generating.pdf)

**Generated:** 2025-12-03 07:35:46

---

**Overview/Summary**

This paper is about how to generate meaning in generative models. The authors argue that current AI systems do not understand what they are doing because the way we train them does not give them a good understanding of the world, and therefore it is hard for them to learn. They propose an approach called active inference (AI) which is based on the idea that all our knowledge comes from our own actions in the world. The authors say that this is how humans understand things too.

**Key Contributions/Findings**

The main contribution of the paper is a new training method, active inference, for generative models. This method allows the model to learn about the world by making predictions and then seeing if those predictions were correct or not. If they are wrong, the model can try again. The authors say that this is how humans learn too.

**Methodology/Approach**

The approach of the paper is based on the idea that all our knowledge comes from our own actions in the world. This means that we should train generative models by making them make predictions and then seeing if those predictions were correct or not. The authors say that this is how humans learn too.

**Results/Data**

The authors do not provide any concrete results, data, or measurements for their proposed approach. They are just proposing a new way of training generative models. They also discuss the differences between current AI systems and natural intelligence in terms of what they can do with the world. The authors say that this is how humans understand things too.

**Limitations/Discussion**

The paper does not provide any concrete results, data, or measurements for their proposed approach. The authors are just proposing a new way of training generative models. They also discuss the differences between current AI systems and natural intelligence in terms of what they can do with the world. The authors say that this is how humans understand things too.

**References**

The paper does not have any references.

---

**Summary Statistics:**
- Input: 12,524 words (84,456 chars)
- Output: 333 words
- Compression: 0.03x
- Generation: 21.3s (15.6 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
