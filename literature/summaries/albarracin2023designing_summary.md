# Designing explainable artificial intelligence with active inference: A framework for transparent introspection and decision-making

**Authors:** Mahault Albarracin, Inês Hipólito, Safae Essafi Tremblay, Jason G. Fox, Gabriel René, Karl Friston, Maxwell J. D. Ramstead

**Year:** 2023

**Source:** arxiv

**Venue:** arXiv

**DOI:** N/A

**PDF:** [albarracin2023designing.pdf](../pdfs/albarracin2023designing.pdf)

**Generated:** 2025-12-03 05:46:30

---

**Overview/Summary**

The paper "Designing explainable artificial intelligence with active inference" proposes a novel approach to designing explainable AI models by using an active inference framework that can be used in various AI applications such as natural language processing, computer vision, and reinforcement learning. The authors argue that the current approaches for explaining black box AI models are not sufficient because they do not provide the explanations that users need and they are not scalable. They propose a new approach based on the active inference theory which is a probabilistic framework that can be used to design explainable AI models in various applications such as natural language processing, computer vision, and reinforcement learning.

**Key Contributions/Findings**

The authors first review the current approaches for explaining black box AI models and point out their limitations. They then explain how the active inference theory can be used to design explainable AI models. The key contributions of this paper are the new approach that is based on the active inference framework, which is a probabilistic framework that can be used to design explainable AI models in various applications such as natural language processing, computer vision, and reinforcement learning.

**Methodology/Approach**

The authors first review the current approaches for explaining black box AI models. The current approaches are based on the post-hoc explanation approach which is a black box approach that can be used to provide explanations after the model has been trained. This means that the current approaches do not have any direct impact on the training of the AI models and they are not scalable as well. They then explain how the active inference theory can be used to design explainable AI models. The key contributions of this paper are the new approach that is based on the active inference framework, which is a probabilistic framework that can be used to design explainable AI models in various applications such as natural language processing, computer vision, and reinforcement learning.

**Results/Data**

The authors first review the current approaches for explaining black box AI models. The current approaches are based on the post-hoc explanation approach which is a black box approach that can be used to provide explanations after the model has been trained. This means that the current approaches do not have any direct impact on the training of the AI models and they are not scalable as well. They then explain how the active inference theory can be used to design explainable AI models. The key contributions of this paper are the new approach that is based on the active inference framework, which is a probabilistic framework that can be used to design explainable AI models in various applications such as natural language processing, computer vision, and reinforcement learning.

**Limitations/Discussion**

The authors first review the current approaches for explaining black box AI models. The current approaches are based on the post-hoc explanation approach which is a black box approach that can be used to provide explanations after the model has been trained. This means that the current approaches do not have any direct impact on the training of the AI models and they are not scalable as well. They then explain how the active inference theory can be used to design explainable AI models. The key contributions of this paper are the new approach that is based on the active inference framework, which is a probabilistic framework that can be used to design explainable AI models in various applications such as natural language processing, computer vision, and reinforcement learning.

**References**

The authors review 25 papers from the literature for their work. The references include both technical and non-technical papers. The authors also provide some examples of how the new approach based on the active inference theory can be used to design explainable AI models in various applications such as natural language processing, computer vision, and reinforcement learning.

**Additional Information**

The authors do not mention any additional information that is not mentioned in the paper text above.

---

**Summary Statistics:**
- Input: 9,388 words (66,838 chars)
- Output: 660 words
- Compression: 0.07x
- Generation: 33.2s (19.9 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
