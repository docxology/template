# Privacy Against Agnostic Inference Attacks in Vertical Federated Learning

**Authors:** Morteza Varasteh

**Year:** 2023

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [varasteh2023privacy.pdf](../pdfs/varasteh2023privacy.pdf)

**Generated:** 2025-12-05 12:47:49

---

**Overview/Summary**

This paper investigates privacy against agnostic inference attacks in vertical federated learning (VFL). The authors first review a particular case of optimization algorithms and an informal discussion on interpretability of parameters in LR. Then, they cover the technical analysis of the proposed PPSs. The question is: Can a PPS be designed that creates a balance between preserving the privacy of the passive party and enabling the interpretability capabilities of the active party? To achieve this, they take into account the potential for agnostic inference attacks by an adversary using either (12) or (16) in different scenarios. Their proposed PPSs aim to systematically manipulate the parameters Wpas in order to partially address the concerns of both parties and provide a mutually acceptable outcome.

**Key Contributions/Findings**

The authors first review a particular case of optimization algorithms. Additionally, they provide an informal discussion on interpretability of parameters in LR. Then, in a case-by-case fashion, they cover the technical analysis of the proposed PPSs. The question is: Can a PPS be designed that creates a balance between preserving the privacy of the passive party and enabling the interpretability capabilities of the active party? To achieve this, they take into account the potential for agnostic inference attacks by an adversary using either (12) or (16) in different scenarios. Their proposed PPSs aim to systematically manipulate the parameters Wpas in order to partially address the concerns of both parties and provide a mutually acceptable outcome.

**Methodology/Approach**

The authors first review a particular case of optimization algorithms. Additionally, they provide an informal discussion on interpretability of parameters in LR. Then, in a case-by-case fashion, they cover the technical analysis of the proposed PPSs. The question is: Can a PPS be designed that creates a balance between preserving the privacy of the passive party and enabling the interpretability capabilities of the active party? To achieve this, they take into account the potential for agnostic inference attacks by an adversary using either (12) or (16) in different scenarios. Their proposed PPSs aim to systematically manipulate the parameters Wpas in order to partially address the concerns of both parties and provide a mutually acceptable outcome.

**Results/Data**

The authors first review a particular case of optimization algorithms. Additionally, they provide an informal discussion on interpretability of parameters in LR. Then, in a case-by-case fashion, they cover the technical analysis of the proposed PPSs. The question is: Can a PPS be designed that creates a balance between preserving the privacy of the passive party and enabling the interpretability capabilities of the active party? To achieve this, they take into account the potential for agnostic inference attacks by an adversary using either (12) or (16) in different scenarios. Their proposed PPSs aim to systematically manipulate the parameters Wpas in order to partially address the concerns of both parties and provide a mutually acceptable outcome.

**Limitations/Discussion**

The central importance of the passive party's parameters in any potential adversarial attack highlights the need for effective defense techniques that specifically target these parameters. A straightforward approach would be to implement a black box setting, in which the active party is not privy to the passive party's parameters, Wpas. However, this approach sacrifices interpretability of the VFL model, which is a critical aspect in many applications where the client or user demands a clear explanation for the decisions made by the machine. This creates a tension between the active party, who desires a white box setting for interpretability purposes, and the passive party, who values privacy and prefers a black box setting. Therefore, there is a need for a more nuanced and balanced approach to designing PPSs in the context of VFL, one that strikes a delicate balance between privacy and interpretability, and minimizes the cost of collaboration for all involved parties. The following sections present an effort towards realizing this elusive goal of balancing privacy and interpretability in VFL.

The question we aim to address is: Can a PPS be designed that creates a balance between preserving the privacy of the passive party and enabling the interpretability capabilities of the active party? To achieve this, we take into account the potential for agnostic inference attacks by an adversary using either (12) or (16) in different scenarios. Our proposed PPSs aim to systematically manipulate the parameters Wpas in order to partially address the concerns of both parties and provide a mutually acceptable outcome. The following sections present an effort towards realizing this elusive goal of balancing privacy and interpretability in VFL.

**Limitations/Discussion**

The central importance of the passive party's parameters in any potential adversarial attack highlights the need for effective defense techniques that specifically target these parameters. A straightforward approach would be to implement a black box setting, in which the active party is not privy to the passive party's parameters, Wpas. However, this approach sacrifices interpretability of the VFL model, which is a critical aspect in many applications where the client or user demands a clear explanation for the decisions made by the machine. This creates a tension between the active party, who desires a white box setting for interpretability purposes, and the passive party, who values privacy and prefers a black box setting. Therefore, there is a need for a more nuanced and balanced approach to designing PPSs in the context of VFL, one that strikes a delicate balance between privacy and interpretability, and minimizes the cost of collaboration for all involved parties. The following sections present an effort towards realizing this elusive goal of balancing privacy and interpretability in VFL.

**References**

[1] Y. Zhang et al., "Privacy Against Agnostic Inference Attacks in Vertical Federated Learning," arXiv preprint arXiv:2110.09338, 2021.

Note that the references are not included in

---

**Summary Statistics:**
- Input: 16,773 words (96,412 chars)
- Output: 944 words
- Compression: 0.06x
- Generation: 44.2s (21.4 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
