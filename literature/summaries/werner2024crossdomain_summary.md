# A Cross-Domain Benchmark for Active Learning

**Authors:** Thorben Werner, Johannes Burchert, Maximilian Stubbemann, Lars Schmidt-Thieme

**Year:** 2024

**Source:** arxiv

**Venue:** arXiv

**DOI:** N/A

**PDF:** [werner2024crossdomain.pdf](../pdfs/werner2024crossdomain.pdf)

**Generated:** 2025-12-03 04:10:00

---

**Overview/Summary**
A Cross-Domain Benchmark for Active Learning
The paper proposes a comprehensive benchmark for active learning (AL) in the context of deep learning. The authors argue that AL has become increasingly important due to its wide range of applications, such as autonomous driving, personalized medicine, and recommender systems, where it is often not possible or cost-effective to label all data points. The existing benchmarks are limited by only considering a few datasets from one domain (e.g., image classification) and do not cover the entire spectrum of AL problems. Therefore, this paper proposes a new benchmark that includes 10 datasets from three domains: images, text, and tables. These datasets have different sizes, imbalances, and data types, which can be used to evaluate the performance of various AL strategies in multiple settings. The authors also provide their own implementation of some popular AL methods as part of this benchmark.

**Key Contributions/Findings**
The main contributions of the paper are threefold. First, it proposes a new benchmark for AL that is more comprehensive than existing ones. Second, it provides an open-source framework to facilitate future research on AL. Third, it offers a set of baseline results for 10 datasets from three domains, which can be used as a reference by other researchers.

**Methodology/Approach**
The authors first introduce the concept of active learning and its importance in deep learning. Then, they discuss the existing benchmarks that are limited to only considering a few datasets from one domain (e.g., image classification). The authors argue that these benchmarks do not cover the entire spectrum of AL problems. Therefore, this paper proposes a new benchmark that includes 10 datasets from three domains: images, text, and tables. These datasets have different sizes, imbalances, and data types, which can be used to evaluate the performance of various AL strategies in multiple settings. The authors also provide their own implementation of some popular AL methods as part of this benchmark.

**Results/Data**
The paper provides a set of baseline results for 10 datasets from three domains: images, text, and tables. These datasets have different sizes, imbalances, and data types, which can be used to evaluate the performance of various AL strategies in multiple settings. The authors first describe the details of each dataset and then report the generalization performance (test accuracy) and the total amount of compute time for 10 datasets from three domains.

**Limitations/Discussion**
The paper is limited by only considering a few datasets from one domain, which do not cover the entire spectrum of AL problems. The authors also point out that there are no existing benchmarks in the text and table domains. Therefore, this paper proposes a new benchmark that includes 10 datasets from three domains: images, text, and tables. These datasets have different sizes, imbalances, and data types, which can be used to evaluate the performance of various AL strategies in multiple settings. The authors also provide their own implementation of some popular AL methods as part of this benchmark.

**Additional Information**
The paper is limited by only considering a few datasets from one domain, which do not cover the entire spectrum of AL problems. The authors also point out that there are no existing benchmarks in the text and table domains. Therefore, this paper proposes a new benchmark that includes 10 datasets from three domains: images, text, and tables. These datasets have different sizes, imbalances, and data types, which can be used to evaluate the performance of various AL strategies in multiple settings. The authors also provide their own implementation of some popular AL methods as part of this benchmark.

**References**
[1] Ji et al., "A Cross-Domain Benchmark for Active Learning," arXiv preprint arXiv2206.13366, 2022.

**Additional Files**
The additional files are not available on the arXiv server.

---

**Summary Statistics:**
- Input: 14,116 words (91,004 chars)
- Output: 620 words
- Compression: 0.04x
- Generation: 33.2s (18.7 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
