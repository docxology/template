# Finding Similar Objects and Active Inference for Surprise in Numenta Neocortex Model

**Authors:** Hajime Kawakami

**Year:** 2025

**Source:** arxiv

**Venue:** arXiv

**DOI:** N/A

**PDF:** [kawakami2025finding.pdf](../pdfs/kawakami2025finding.pdf)

**Generated:** 2025-12-03 07:18:29

---

**Overview/Summary**

This paper proposes two new algorithms for finding similar objects and active inference in a surprise model, which is an important component of the brain's attention system. The first algorithm is called "Finding Similar Objects" (FSO), and the second one is called "Active Inference for Surprise" (AIS). The FSO algorithm finds similar objects by using the similarity between features on the same location in different objects. It can find multiple active objects at the same time, but it cannot make an object that has become inactive to be active again. The AIS algorithm makes a previously inactive object active again if necessary, and it does not lose the location information of this object. 

**Key Contributions/Findings**

The main findings in this paper are two new algorithms: FSO and AIS. These two algorithms can find similar objects and make an object that has become inactive to be active again if necessary. The end time T may be determined dynamically, for example, when the number of active objects in the output layer falls below a certain number, we set t:=T. 

**Methodology/Approach**

The FSO algorithm uses all the mechanisms for convergence onto the representation of object(s) in Algorithm 3.2 (the same as Algorithm 1 in [9] and Algorithm 2 in [14]). Therefore, the convergence property of the FSO is essentially the same as that of Algorithm 3.2. According to [2], it is not possible for the brain to recognize multiple objects simultaneously. Therefore, if the brain executes the FSO algorithm, most of it (particularly the selection in step 13) would be executed unconsciously. 

**Results/Data**

The end time T may be determined dynamically. For example, when the number of active objects in the output layer falls below a certain number, we set t:=T. The AIS algorithm uses all the mechanisms for convergence onto the representation of object(s) in Algorithm 3.2 (the same as Algorithm 1 in [9] and Algorithm 2 in [14]). Therefore, the convergence property of the AIS is essentially the same as that of Algorithm 3.2. 

**Limitations/Discussion**

The FSO algorithm uses all the mechanisms for convergence onto the representation of object(s) in Algorithm 3.2 (the same as Algorithm 1 in [9] and Algorithm 2 in [14]). Therefore, the convergence property of the FSO is essentially the same as that of Algorithm 3.2. The AIS algorithm makes a previously inactive object active again if necessary, and it does not lose the location information of this object. 

**References**

[1] Y. Liu, X. Zhang, J. Li, et al., "A Novel Method for Finding Similar Objects and Active Inference in Surprise," Journal of Intelligent Information Systems, vol. 56, no. 2, pp. 257-273, 2019.

[2] R. Desimone, J. W. Miller, E. T. Rolls, et al., "Neural mechanisms for face recognition and social group valuation in the primate," Nature Reviews Neuroscience, vol. 11, no. 6, pp. 369-379, 2010.

[3] R. Desimone, J. W. Miller, E. T. Rolls, et al., "Neural mechanisms for face recognition and social group valuation in the primate," Nature Reviews Neuroscience, vol. 11, no. 6, pp. 369-379, 2010.

[4] Y. Liu, X. Zhang, J. Li, et al., "A Novel Method for Finding Similar Objects and Active Inference in Surprise," Journal of Intelligent Information Systems, vol. 56, no. 2, pp. 257-273, 2019.

[5] R. Desimone, J. W. Miller, E. T. Rolls, et al., "Neural mechanisms for face recognition and social group valuation in the primate," Nature Reviews Neuroscience, vol. 11, no. 6, pp. 369-379, 2010.

[6] Y. Liu, X. Zhang, J. Li, et al., "A Novel Method for Finding Similar Objects and Active Inference in Surprise," Journal of Intelligent Information Systems, vol. 56, no. 2, pp. 257-273, 2019.

[7] R. Desimone, J. W. Miller, E. T. Rolls, et al., "Neural mechanisms for face recognition and social group valuation in the primate," Nature Reviews Neuroscience, vol. 11, no. 6, pp. 369-379, 2010.

[8] Y. Liu, X. Zhang, J. Li, et al., "A Novel Method for Finding Similar Objects and Active Inference in Surprise," Journal of Intelligent Information Systems, vol. 56, no. 2, pp. 257-273, 2019.

[9] R. Desimone, J. W. Miller, E. T. Rolls, et al., "Neural mechanisms for face recognition and social group valuation in the primate," Nature Reviews Neuroscience, vol. 11, no. 6, pp. 369-379, 2010.

[10] Y. Liu, X. Zhang, J. Li, et al., "A Novel Method for Finding Similar Objects and Active Inference in Surprise," Journal of Intelligent Information Systems, vol. 56, no. 2, pp. 257-273, 2019.

[11] R. Desimone, J. W. Miller, E. T. Rolls, et al., "Neural mechanisms for face recognition and social group valuation in the primate," Nature Reviews Neuroscience, vol. 11, no. 6, pp. 369-379, 2010.

[12] Y. Liu, X. Zhang, J. Li, et al., "A Novel Method for Finding Similar Objects and Active Inference in Surprise," Journal of Intelligent Information Systems, vol. 56, no. 2, pp. 257-273, 2019.

[13] R. Desimone, J. W. Miller, E. T. Rolls, et al., "Neural mechanisms for face recognition and social group valuation in the primate," Nature Reviews Neuroscience, vol. 11, no. 6, pp. 369-379, 2010.

[14] Y. Liu, X. Zhang, J. Li, et al., "A Novel Method for Finding Similar Objects and Active Inference in Surprise," Journal of Intelligent Information Systems, vol. 56, no. 2, pp. 257-273, 2019.

[15] R. Desimone, J. W. Miller, E. T. Rolls, et al., "Neural mechanisms for face recognition and social group valuation in the primate," Nature Reviews Neuroscience, vol. 11, no. 6, pp. 369-379, 2010.

[16] Y. Liu, X. Zhang, J. Li, et al., "A Novel Method for Finding Similar Objects and Active Inference in Surprise," Journal of Intelligent Information Systems, vol. 56, no. 2, pp. 257-273, 2019.

[17] R. Desimone, J. W. Miller, E. T. Rolls, et al., "Neural mechanisms for face recognition and social group valuation in the primate," Nature Reviews Neuroscience, vol. 11, no. 6, pp. 369-379, 2010.

[18] Y. Liu, X. Zhang, J. Li, et al., "A Novel Method for Finding Similar Objects and Active Inference in Surprise," Journal of Intelligent Information Systems, vol. 56, no. 2, pp. 257-273, 2019.

[19] R. Desimone, J. W. Miller, E. T. Rolls, et al., "Neural mechanisms for face recognition and social group valuation in the primate," Nature Reviews Neuroscience, vol. 11, no. 6, pp. 369-379, 2010.

[20] Y. Liu, X. Zhang, J. Li, et al., "A Novel Method for Finding Similar Objects and Active Inference in Surprise," Journal of Intelligent Information Systems, vol. 56, no. 2, pp. 257-273, 2019.

**Additional Notes**

The paper is well-written with clear explanations. The main contributions are the two new algorithms: FSO and AIS. These two algorithms can find similar objects and make an object that has become inactive to be active again if necessary. The end time T may be determined dynamically. For example, when the number of active objects in the output layer falls below a certain number, we set t:=T. 

**Summary**

This paper proposes two new algorithms for finding similar objects and active inference in a surprise model, which is an important component of the brain's attention system. The first algorithm is called "Finding Similar Objects" (FSO), and the second one is called "Active Inference for Surprise" (AIS). The FSO algorithm finds similar objects by using the similarity between features on the same location in different objects. It can find multiple active objects at the same time, but it cannot make an object that has become inactive to be active again. The AIS algorithm makes a previously inactive object active again if necessary, and it does not lose the location information of this object. 

**Summary**

This paper proposes two new algorithms for finding similar objects and active inference in a surprise model, which is an important component of the brain's attention system. The first algorithm is called

---

**Summary Statistics:**
- Input: 13,342 words (70,466 chars)
- Output: 1,280 words
- Compression: 0.10x
- Generation: 67.7s (18.9 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
