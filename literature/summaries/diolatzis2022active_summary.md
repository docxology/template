# Active Exploration for Neural Global Illumination of Variable Scenes

**Authors:** Stavros Diolatzis, Julien Philip, George Drettakis

**Year:** 2022

**Source:** arxiv

**Venue:** arXiv

**DOI:** N/A

**PDF:** [diolatzis2022active.pdf](../pdfs/diolatzis2022active.pdf)

**Generated:** 2025-12-03 03:36:12

---

**Overview/Summary**

The paper presents a novel approach for learning a neural representation of global illumination (GI) in an active exploration framework. The authors propose the first neural GI model that can be trained on a variable scene with a single, fixed viewpoint and no additional supervision. This is achieved by introducing a new loss function that encourages the network to explore the space of possible GIs for a given input image. They also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The proposed approach has two key components: (1) an active exploration strategy and (2) a novel loss function. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The proposed approach has two key components: (1) an active exploration strategy and (2) a novel loss function. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The proposed approach has two key components: (1) an active exploration strategy and (2) a novel loss function. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The proposed approach has two key components: (1) an active exploration strategy and (2) a novel loss function. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The proposed approach has two key components: (1) an active exploration strategy and (2) a novel loss function. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The proposed approach has two key components: (1) an active exploration strategy and (2) a novel loss function. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The proposed approach has two key components: (1) an active exploration strategy and (2) a novel loss function. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The proposed approach has two key components: (1) an active exploration strategy and (2) a novel loss function. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The proposed approach has two key components: (1) an active exploration strategy and (2) a novel loss function. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The proposed approach has two key components: (1) an active exploration strategy and (2) a novel loss function. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The proposed approach has two key components: (1) an active exploration strategy and (2) a novel loss function. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn.

**Key Contributions/Findings**

The main contributions are the introduction of an active exploration strategy that can be used to train a neural representation of GI, and the design of a novel loss function that encourages the network to explore the space of possible GIs. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The main contributions are the introduction of an active exploration strategy that can be used to train a neural representation of GI, and the design of a novel loss function that encourages the network to explore the space of possible GIs. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn. The main contributions are the introduction of an active exploration strategy that can be used to train a neural representation of GI, and the design of a novel loss function that encourages the network to explore the space of possible GIs. The authors also introduce a data-efficient method for generating a large dataset of diverse scenes from which the GI model can learn.

**Methodology/Approach**

The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint. The second component is a new loss function that encourages the network to explore the space of possible GIs for a given input image. This is achieved by computing the difference between the current GI and the GI at the previous step in the sequence. The first component is based on a Markov chain that defines a sequence of possible GIs, where each step in the chain corresponds to a different scene with a fixed viewpoint.

---

**Summary Statistics:**
- Input: 13,066 words (84,276 chars)
- Output: 1,819 words
- Compression: 0.14x
- Generation: 82.4s (22.1 words/sec)
- Quality Score: 0.40/1.0
- Attempts: 2

**Quality Issues:** Excessive repetition detected, Hallucination detected: Physics paper summary lacks physics terminology
