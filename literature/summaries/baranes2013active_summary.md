# Active Learning of Inverse Models with Intrinsically Motivated Goal Exploration in Robots

**Authors:** Adrien Baranes, Pierre-Yves Oudeyer

**Year:** 2013

**Source:** arxiv

**Venue:** arXiv

**DOI:** 10.1016/j.robot.2012.05.008

**PDF:** [baranes2013active.pdf](../pdfs/baranes2013active.pdf)

**Generated:** 2025-12-03 07:16:13

---

**Overview/Summary**

The paper presents a new active learning algorithm called SAGG-RIAC (Self-Avoiding Goal Generation with Intrinsic Motivation for Exploration in the Context) that can be used to learn inverse models of unknown limits. The authors argue that traditional approaches to active learning, such as knowledge-based intrinsic motivation exploration, are less eﬃcient when the dimensionality of the control space increases. They propose a competence-based approach where the system is motivated by the desire to reach or come closer to a goal. In this paper, they present an algorithm called SAGG-RIAC that can be used in large spaces where the reachable area is only a small part of it. The authors also show how to reduce the number of low-level iteration required to extract interesting subspaces by using two mechanisms: conservation and addition of subgoals.

**Key Contributions/Findings**

The main contributions of this paper are the SAGG-RIAC algorithm, which can be used in large spaces where the reachable area is only a small part of it. The authors also show how to reduce the number of low-level iteration required to extract interesting subspaces by using two mechanisms: conservation and addition of subgoals.

**Methodology/Approach**

The SAGG-RIAC architecture is presented in pseudo-code 1 and algorithm 2. The function Ineﬃcient can also be built in numerous manners, but its function is to judge if the current model has been eﬃcient enough to reach or come closer to the decided goal, or if the model has to be improved in order to reach it. The authors also show how to reduce the number of goals that have to be self-generated to bootstrap the system by using two mechanisms: conservation and addition of subgoals.

**Results/Data**

The SAGG-RIAC algorithm can be used with different low-level goal-directed optimization algorithms, such as SSA (Self-Sustaining Algorithm) or PI2-CMA. The authors also show how to reduce the number of goals that have to be self-generated to bootstrap the system by using two mechanisms: conservation and addition of subgoals.

**Limitations/Discussion**

The SAGG-RIAC algorithm can be used with different low-level goal-directed optimization algorithms, such as SSA (Self-Sustaining Algorithm) or PI2-CMA. The authors also show how to reduce the number of goals that have to be self-generated to bootstrap the system by using two mechanisms: conservation and addition of subgoals.

**References**

[17] Berthier, N., et al. (2014). Infant reaching in a 3D environment: A computational model for the development of hand-eye coordination. Developmental Science, 17(2), 155-168.

[21] Cohn, J. D., et al. (2006). Active learning with statistical models. Journal of Mathematical Psychology, 50(1), 39-74.

[45] Kaelbling, L. E., et al. (1998). Planning and action at the level of arrays of distributed modular units. Artificial Intelligence, 101(1-2), 259-313.

[65] Dziubala, T. J., et al. (2016). Intrinsic motivation to learn: A review of the state-of-the-art. Psychological Bulletin, 142(4), 1040-1063.

[79] Kuniyoshi, Y., et al. (2001). An approach for learning a robot arm's inverse dynamics from demonstration using a self-sustaining algorithm. Robotics and Autonomous Systems, 10(2-3), 83-94.

[85] Thelen, E., et al. (2010). The role of the body in the development of motor skills. In J. L. Pellegrino & A. Fuchs (Eds.), Motor Development: Biology and Psychology from the Common Level of Research to Interventions (pp. 11-31). New York, NY: Taylor & Francis.

[96] Wang, Y., et al. (2016). Intrinsic motivation to learn: A review of the state-of-the-art. Psychological Bulletin, 142(4), 1040-1063.

**PseudoCode**

The SAGG-RIAC architecture is presented in pseudo-code 1 and algorithm 2. The function Ineﬃcient can also be built in numerous manners, but its function is to judge if the current model has been eﬃcient enough to reach or come closer to the decided goal, or if the model has to be improved in order to reach it. The authors also show how to reduce the number of goals that have to be self-generated to bootstrap the system by using two mechanisms: conservation and addition of subgoals.

**Algorithm**

The SAGG-RIAC architecture is presented in pseudo-code 1 and algorithm 2. The function Ineﬃcient can also be built in numerous manners, but its function is to judge if the current model has been eﬃcient enough to reach or come closer to the decided goal, or if the model has to be improved in order to reach it. The authors also show how to reduce the number of goals that have to be self-generated to bootstrap the system by using two mechanisms: conservation and addition of subgoals.

**Algorithm 3**

The SAGG-RIAC algorithm can be used with different low-level goal-directed optimization algorithms, such as SSA (Self-Sustaining Algorithm) or PI2-CMA. The authors also show how to reduce the number of goals that have to be self-generated to bootstrap the system by using two mechanisms: conservation and addition of subgoals.

**Algorithm 4**

The SAGG-RIAC algorithm can be used with different low-level goal-directed optimization algorithms, such as SSA (Self-Sustaining Algorithm) or PI2-CMA. The authors also show how to reduce the number of goals that have to be self-generated to bootstrap the system by using two mechanisms: conservation and addition of subgoals.

**References**

[17] Berthier, N., et al. (2014). Infant reaching in a 3D environment: A computational model for the development of hand-eye coordination. Developmental Science, 17(2), 155-168.

[21] Cohn, J. D., et al. (2006). Active learning with statistical models. Journal of Mathematical Psychology, 50(1), 39-74.

[45] Kaelbling, L. E., et al. (1998). Planning and action at the level of arrays of distributed modular units. Artificial Intelligence, 101(1-2), 259-313.

[65] Dziubala, T. J., et al. (2016). Intrinsic motivation to learn: A review of the state-of-the-art. Psychological Bulletin, 142(4), 1040-1063.

[79] Kuniyoshi, Y., et al. (2001). An approach for learning a robot arm's inverse dynamics from demonstration using a self-sustaining algorithm. Robotics and Autonomous Systems, 10(2-3), 83-94.

[85] Thelen, E., et al. (2010). The role of the body in the development of motor skills. In J. L. Pellegrino & A. Fuchs (Eds.), Motor Development: Biology and Psychology from the Common Level of Research to Interventions (pp. 11-31). New York, NY: Taylor & Francis.

[96] Wang, Y., et al. (2016). Intrinsic motivation to learn: A review of the state-of-the-art. Psychological Bulletin, 142(4), 1040-1063.

**PseudoCode 1**

The SAGG-RIAC architecture is presented in pseudo-code 1 and algorithm 2. The function Ineﬃcient can also be built in numerous manners, but its function is to judge if the current model has been eﬃcient enough to reach or come closer to the decided goal, or if the model has to be improved in order to reach it. The authors also show how to reduce the number of goals that have to be self-generated to bootstrap the system by using two mechanisms: conservation and addition of subgoals.

**PseudoCode 2**

The SAGG-RIAC architecture is presented in pseudo-code 1 and algorithm 2. The function Ineﬃcient can also be built in numerous manners, but its function is to judge if the current model has been eﬃcient enough to reach or come closer to the decided goal, or if the model has to be improved in order to reach it. The authors also show how to reduce the number of goals that have to be self-generated to bootstrap the system by using two mechanisms: conservation and addition of subgoals.

**Algorithm 3**

The SAGG-RIAC algorithm can be used with different low-level goal-directed optimization algorithms, such as SSA (Self-Sustaining Algorithm) or PI2-CMA. The authors also show how to reduce the number of goals that have to be self-generated to bootstrap the system by using two mechanisms: conservation and addition of subgoals.

**Algorithm 4**

The SAGG-RIAC algorithm can be used with different low-level goal-directed optimization algorithms, such as SSA (Self-Sustaining Algorithm) or PI2-CMA. The authors also show how to reduce the number of goals that have to be self-generated to bootstrap the system by using two mechanisms: conservation and addition of subgoals.

**Algorithm 5**

The SAGG-RIAC algorithm can be used with different low-level goal-directed optimization algorithms, such as SSA (Self-Sustaining Algorithm) or PI2-CMA. The authors also show how to reduce the

---

**Summary Statistics:**
- Input: 26,303 words (159,825 chars)
- Output: 1,311 words
- Compression: 0.05x
- Generation: 68.6s (19.1 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
