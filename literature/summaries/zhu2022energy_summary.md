# Energy Management Based on Multi-Agent Deep Reinforcement Learning for A Multi-Energy Industrial Park

**Authors:** Dafeng Zhu, Bo Yang, Yuxiang Liu, Zhaojian Wang, Kai Ma, Xinping Guan

**Year:** 2022

**Source:** arxiv

**Venue:** arXiv

**DOI:** 10.1016/j.apenergy.2022.118636

**PDF:** [zhu2022energy.pdf](../pdfs/zhu2022energy.pdf)

**Generated:** 2025-12-02 07:03:36

---

**Overview/Summary**

This paper presents a novel multi-agent deep reinforcement learning (DRL) algorithm for energy management in industrial parks. The authors consider an industrial park with multiple factories and various types of devices including electricity, thermal, and gas supply systems. They first formulate the problem as a multi-energy management framework (MEMF), which is imperative for today's industrial production. Then, they design a novel multi-agent DRL algorithm based on counterfactual baseline and soft actor-critic (SAC) to obtain the optimal scheduling policy of each energy device. The authors also introduce an attention mechanism to focus on key information, which improves the exploration eﬃciency of the SAC. Finally, based on real data, the performance of DRL algorithms in terms of the number of agents and attention degree of information is analyzed, showing that the proposed algorithm is an effective solution for industrial energy management problems.

**Key Contributions/Findings**

The authors' main contributions are:
1) A MEMF is formulated to achieve centralized training and decentralized execution for energy devices. 2) The optimal scheduling policy of each energy device is obtained by a novel multi-agent DRL algorithm based on the counterfactual baseline and SAC. 3) An attention mechanism is introduced to focus on key information, which improves the exploration eﬃciency of the SAC. 4) The performance of DRL algorithms in terms of the number of agents and attention degree of information is analyzed, showing that the proposed algorithm is an effective solution for industrial energy management problems.

**Methodology/Approach**

The authors first formulate the problem as a MEMF, which is imperative for today's industrial production. Then, they design a novel multi-agent DRL algorithm based on the counterfactual baseline and SAC to obtain the optimal scheduling policy of each energy device. The authors also introduce an attention mechanism to focus on key information, which improves the exploration eﬃciency of the SAC. At last, based on real data, the performance of DRL algorithms in terms of the number of agents and attention degree of information is analyzed, showing that the proposed algorithm is an effective solution for industrial energy management problems.

**Results/Data**

The authors' main findings are:
1) The proposed multi-agent DRL algorithm can effectively reduce the costs of factories. 2) The strategy of battery agent is not good enough due to battery capacity limitations and changing electricity prices. 3) The proposed algorithm achieves the multi-energy complementation, multi-device cooperation and multi-energy supply.

**Limitations/Discussion**

The authors' main limitations are:
1) The energy of industrial production is suﬃcient supplied by energy hubs. 2) In actual industrial parks, some factories may have huge energy demand which cannot be satisﬁed due to the capacity of transformers. 3) The joint optimization of production scheduling and multi-energy generation/utilization is o f interest.

**References**

[1] X. Lu, Z. Liu, L. Ma et al.,  “A robust optimization approach for optimal load dispatch of community energy hub,” Applied Energy , vol. 259:114195, Feb. 2020.
[2] M. Jadidbonab, B. Mohammadi- I vatloo, M. Marzband and P. Siano,  “Short-Term Self-Scheduling of Virtual Energy Hub Plant Within Thermal Ene rgy Market,” IEEE Transactions on Industrial Electronics , vol. 68, no. 4, pp. 3124-3136, Apr. 2021.
[3] Heidari A,  “Stochastic eﬀects of ice storage on improvement of an energy hub optimal operation including demand response and renewable ene rgies,” Applied Energy , vol. 261:114393, Mar. 2020.
[4] N. Liu, L. Zhou, C. Wang, X. Yu and X. Ma,  “Heat-Electricity Coupled Peak Load Shifting for Multi-Energy Industrial Parks: A Stackelbe rg Game Approach,” IEEE Transactions on Sustainable Energy , vol. 11, no. 3, pp. 1858-1869, Jul. 2020.
[5] J. Wei, Y. Zhang, J. Wang and L. Wu,  “Distribution LMP-based Dem and Management in Industrial Park via a Bi-level Programming Approach,” IEEE Transactions on Sustainable Energy , vol. 12, no. 3, pp. 1695-1706, Feb. 2021.
[6] Z. Liu, M. Adams, R. Cote, Y. Geng, J. Ren, Q. Chen et al.,  “Co-be neﬁts accounting for the implementation of eco-industrial development s trategies in the scale of industrial park based on emergy analysis,” Renewable and Sustainable Energy Reviews , vol. 81, no.1, pp. 1522-1529, Jan. 2018.
[7] M. Shahidehpour, C. Li, X. Wang, W. Huang and T. Nengling,  “Two- Stage Full-Data Processing for Microgrid Planning With High Penetrations of Re- newable Energy Sources,” IEEE Transactions on Sustainable Energy , vol. 12, no.4, pp. 2042-2052, May 2018.

**Summary**

The authors' main summary is: The proposed multi-agent DRL algorithm can effectively reduce the costs of factories.

---

**Summary Statistics:**
- Input: 9,550 words (56,709 chars)
- Output: 727 words
- Compression: 0.08x
- Generation: 78.5s (9.3 words/sec)
- Quality Score: 1.00/1.0
- Attempts: 1

**Quality Check:** Passed
