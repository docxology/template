# Learning Generative Models for Active Inference using Tensor Networks

**Authors:** Samuel T. Wauthier, Bram Vanhecke, Tim Verbelen, Bart Dhoedt

**Year:** 2022

**Source:** arxiv

**Venue:** arXiv

**DOI:** N/A

**PDF:** [wauthier2022learning.pdf](../pdfs/wauthier2022learning.pdf)

**Generated:** 2025-12-03 05:11:42

---

=== OVERVIEW/SUMMARY ===

Learning Generative Models for Active Inference using Tensor Networks

This paper presents a new approach to learning generative models for active inference in the context of probabilistic graphical models. The authors propose an algorithm that can learn a generative model from data and use it for approximate inference, where the goal is to find the most likely explanation given evidence. They show that this problem is closely related to the problem of training a generative model on the same data. This paper also proposes a new approach to learning the parameters of an MPS (matrix product state) in the context of quantum information processing. The authors show that their algorithm can be used for approximate inference and that it can be used for training an MPS.

=== KEY CONTRIBUTIONS/FOUNDS ===

The main contributions of this paper are as follows: 1) a new approach to learning generative models for active inference; 2) a new approach to learning the parameters of an MPS. The authors show that their algorithm can be used for approximate inference and that it can be used for training an MPS.

=== METHODOLOGY/Approach ===

The authors use a tensor network (TN), which is a mathematical object that describes a set of probability distributions, as a generative model. They propose an algorithm to learn the parameters of the TN from data. This algorithm uses the negative log-likelihood function as the loss function. The authors show that their algorithm can be used for approximate inference and that it can be used for training an MPS.

=== RESULTS/DATA ===

The authors use a set of random variables, which are called the nodes in the graphical model, to describe the data. They also propose a new approach to learning the parameters of an MPS from data. The authors show that their algorithm can be used for approximate inference and that it can be used for training an MPS.

=== LIMITATIONS/DISCUSSION ===

The main limitation of this paper is that the authors do not discuss how to choose the hyperparameters in the proposed approach, such as the learning rate and the number of truncated singular values. The authors also do not compare their algorithm with other algorithms. The authors state that there are many possible ways to learn a generative model from data. They propose an algorithm to learn the parameters of an MPS from data. This paper also proposes an algorithm to use the learned generative model for approximate inference.

=== END PAPER CONTENT ===

---

**Summary Statistics:**
- Input: 4,833 words (30,474 chars)
- Output: 416 words
- Compression: 0.09x
- Generation: 25.4s (16.4 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
