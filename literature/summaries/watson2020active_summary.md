# Active Inference or Control as Inference? A Unifying View

**Authors:** Joe Watson, Abraham Imohiosen, Jan Peters

**Year:** 2020

**Source:** arxiv

**Venue:** arXiv

**DOI:** N/A

**PDF:** [watson2020active.pdf](../pdfs/watson2020active.pdf)

**Generated:** 2025-12-02 09:37:57

---

**Overview/Summary**
The paper by Watson et al. (2020) [1] presents a new perspective on active inference (AI), which is a probabilistic approach to solve the problem of control as inference. The authors argue that AI and control are two sides of the same coin, and the mathematical similarity between them when both are treated probabilistically can be used for approximate inference. They show that the formulation of state estimation as an inference problem in the past is equivalent to the formulation of control as a planning problem in the present. This perspective on the duality between AI and control is well-suited for approximate inference, which has been demonstrated by the authors using the linear quadratic regulator (LQR) solution.

**Key Contributions/Findings**
The main contribution of this paper is that it provides an equivalent formulation to active inference by considering partially-observed, inference-based optimal control. The authors show that the formulation of state estimation as an inference problem in the past is equivalent to the formulation of control as a planning problem in the present. This perspective on the duality between AI and control is well-suited for approximate inference, which has been demonstrated by the authors using the LQR solution.

**Methodology/Approach**
The authors first introduce the concept of active inference from the free energy principle (FEP) [2]. The FEP states that the brain's goal is to minimize the difference between the current state and its expected value. This minimum is the negative log-likelihood, which can be interpreted as the cost function for control. In this sense, the authors argue that AI or control are two sides of the same coin. They then introduce a new perspective on the duality between AI and control by considering partially-observed, inference-based optimal control. The authors show that the formulation of state estimation as an inference problem in the past is equivalent to the formulation of control as a planning problem in the present. This perspective on the duality between AI and control is well-suited for approximate inference, which has been demonstrated by the authors using the LQR solution.

**Results/Data**
The main results of this paper are that the formulation of state estimation as an inference problem in the past is equivalent to the formulation of control as a planning problem in the present. The authors also show that the i2c returns the LQR solution for the same initial state and planning horizon. This new perspective on the duality between AI and control can be used for approximate inference, which has been demonstrated by the authors using the LQR solution.

**Limitations/Discussion**
The main limitation of this paper is that it does not provide a comprehensive comparison with other approaches to active inference or control as inference. The authors only compare their approach with the i2c and the LQR solution, but do not discuss the relationship between AI and the CaI literature. This new perspective on the duality between AI and control can be used for approximate inference, which has been demonstrated by the authors using the LQR solution.

**References**
[1] Watson, J., Abdulsamad, H., Peters, J.: Stochastic optimal control as approximate input inference. In: Conference on Robot Learning (2019)
[2] Friston, K.: The free-ener gy principle: a uniÔ¨Åed brain theory? Nature reviews neuro-science (2010)

Please let me know if you would like me to revise anything!

---

**Summary Statistics:**
- Input: 3,133 words (18,913 chars)
- Output: 548 words
- Compression: 0.17x
- Generation: 36.9s (14.9 words/sec)
- Quality Score: 1.00/1.0
- Attempts: 1

**Quality Check:** Passed
