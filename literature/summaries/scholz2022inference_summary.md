# Inference of Affordances and Active Motor Control in Simulated Agents

**Authors:** Fedor Scholz, Christian Gumbsch, Sebastian Otte, Martin V. Butz

**Year:** 2022

**Source:** arxiv

**Venue:** arXiv

**DOI:** 10.3389/fnbot.2022.881673

**PDF:** [scholz2022inference.pdf](../pdfs/scholz2022inference.pdf)

**Generated:** 2025-12-03 06:16:22

---

=== OVERVIEW ===

The paper "Inference of Affordances and Active Motor Control" presents a novel approach to active inference in the context of embodied cognition. The authors propose an architecture that can infer affordances from visual input, which are then used as cues for motor control. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

=== KEY CONTRIBUTIONS/KEY FINDINGS ===

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control the movement of the agent's body and how to avoid regions of uncertainty during planning.

The authors propose a novel architecture that can be trained end-to-end for active inference. The proposed model is able to infer affordances from visual input, which are then used as cues for motor control. This work is the first one in the literature that can be trained end-to-end for active inference. In this work, they focus on the problem of how to use the inferred affordance information to actively control

---

**Summary Statistics:**
- Input: 13,566 words (88,482 chars)
- Output: 1,770 words
- Compression: 0.13x
- Generation: 67.8s (26.1 words/sec)
- Quality Score: 0.40/1.0
- Attempts: 1

**Quality Issues:** Excessive repetition detected, Hallucination detected: Physics paper summary lacks physics terminology
