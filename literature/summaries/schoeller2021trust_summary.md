# Trust as Extended Control: Active Inference and User Feedback During Human-Robot Collaboration

**Authors:** Felix Schoeller, Mark Miller, Roy Salomon, Karl J. Friston

**Year:** 2021

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [schoeller2021trust.pdf](../pdfs/schoeller2021trust.pdf)

**Generated:** 2025-12-05 12:05:08

---

**Overview/Summary**

The paper presents a theoretical framework for understanding trust in human-robot interaction (HRI) from the perspective of active inference and user control. The authors argue that the traditional definition of trust is too narrow and does not account for the fact that users' control over robots can be extended beyond their physical bodies, which they call "trust as extended control." They propose a new understanding of trust based on the idea that people's minds are constructive statistical organs that generate hypotheses to predict the most likely causes of sensory data. The authors also present a model of trust as the best explanation for a reliable sensory exchange with an extended motor plant or partner, and they argue that this model is more comprehensive than traditional definitions.

**Key Contributions/Findings**

The authors first discuss the concept of trust from the standpoint of control and perception-action loops. They then examine the concept of trust from the standpoint of active inference, which is a statistical framework for understanding how people's minds work. The authors argue that the traditional definition of trust as extended to include not only competence but also benevolence is best cast in terms of an action-cognitive hierarchy. By examining trust from the standpoint of active inference, they were better able to understand phenomena such as exploration related accidents and the gradual building of trust with shared goals, narratives, and agency. The authors conclude that the science of human-robot interaction could make rapid progress if objective measures of trust were developed, and the neuroscience of agency does offer such metrics.

**Methodology/Approach**

The paper is a theoretical work based on active inference. It does not report any experiments or data collection.

**Results/Data**

The authors do not present any results or data in this paper. The paper only presents an analysis of the concept of trust from the standpoint of control and perception-action loops, and then again from the perspective of active inference. They do not use any data to support their arguments. The paper does not report any statistical significance tests.

**Limitations/Discussion**

The authors conclude that the science of human-robot interaction could make rapid progress if objective measures of trust were developed, and the neuroscience of agency does offer such metrics. The authors also mention that current models suggest that the rise of subjectivity and the "self" are grounded in privileged predictive capacities regarding the states of the organism compared to the external environment. As such, dyadic trust in another agent (biological or artificial) can be viewed as a process of extending these predictive processes beyond the body and rendering the external agent as part of a self-model.

**References**

The paper references 30 papers. The references are mostly from psychology, neuroscience, philosophy, and cognitive science. Some of the references are also from computer science.

---

**Summary Statistics:**
- Input: 8,754 words (59,902 chars)
- Output: 462 words
- Compression: 0.05x
- Generation: 25.5s (18.1 words/sec)
- Quality Score: 0.60/1.0
- Attempts: 1

**Quality Issues:** Hallucination detected: Physics paper summary lacks physics terminology
