# An analytical model of active inference in the Iterated Prisoner's Dilemma

**Authors:** Daphne Demekas, Conor Heins, Brennan Klein

**Year:** 2023

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [demekas2023analytical.pdf](../pdfs/demekas2023analytical.pdf)

**Generated:** 2025-12-05 12:07:32

---

**Overview/Summary**

The paper presents an analytical model of active inference in a partially observable Markov decision process (POMDP) with a focus on the role of the prior distribution over states. The authors consider the case where the observation likelihood is unambiguous and the agent takes identical actions at every trial, which leads to a simplified form for the policy inference. The authors show that the optimal policy can be found by solving exactly for the fixed points of the free energy function in the one-step ahead predictive generative model. This paper extends the existing literature on active inference in POMDPs by providing an analytical solution.

**Key Contributions/Findings**

The main contributions are to provide a new perspective on the role of the prior distribution over states and to show that the optimal policy can be found exactly for any trial t > 0. The authors' approach is based on the variational free energy principle, which has been widely used in the literature on active inference. This paper provides an analytical solution for the fixed points of the one-step ahead predictive generative model. The main findings are that the optimal policy can be found by solving exactly for any trial t > 0 and the authors' approach is based on the variational free energy principle.

**Methodology/Approach**

The authors use the variational free energy principle to perform the inference, which has been widely used in the literature on active inference. The authors consider a POMDP with an unambiguous observation likelihood and the agent takes identical actions at every trial. This leads to a simplified form for the policy inference. The authors show that the optimal policy can be found by solving exactly for the fixed points of the one-step ahead predictive generative model.

**Results/Data**

The main results are that the optimal policy can be found by solving exactly for any trial t > 0 and the authors' approach is based on the variational free energy principle. The authors provide an analytical solution for the fixed points of the one-step ahead predictive generative model. The authors show that the expected free energy function in the one-step ahead predictive generative model has a natural balance between information-seeking (‘exploration’) and goal-directedness (‘exploitation’). This is because the variational parameters are segregated into policy-specific parameters and hidden-state-specific parameters, which can be solved for exactly. The authors' approach is based on the variational free energy principle.

**Limitations/Discussion**

The main limitation of this paper is that it only considers 1- step ahead policies (H = 1). It would be interesting to extend this work to the case where the agent's policy can depend on the future states. The authors' approach is based on the variational free energy principle, which has been widely used in the literature on active inference.

**References**

The references are not provided here.

---

**Summary Statistics:**
- Input: 10,620 words (64,979 chars)
- Output: 466 words
- Compression: 0.04x
- Generation: 26.2s (17.8 words/sec)
- Quality Score: 1.00/1.0
- Attempts: 1

**Quality Check:** Passed
