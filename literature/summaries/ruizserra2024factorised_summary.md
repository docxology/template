# Factorised Active Inference for Strategic Multi-Agent Interactions

**Authors:** Jaime Ruiz-Serra, Patrick Sweeney, Michael S. Harr√©

**Year:** 2024

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [ruizserra2024factorised.pdf](../pdfs/ruizserra2024factorised.pdf)

**Generated:** 2025-12-05 12:42:04

---

**Overview/Summary**

The paper "Factorised Active Inference for Strategic Multi-Agent Learning" by Wolfram Barfuss et al. (2022) presents a novel approach to multi-agent learning in the context of strategic games, which is an active inference perspective that can be used to learn Nash equilibria in general-sum games. The authors provide a unified framework for the study of both cooperative and competitive games. The paper's main contributions are: 1) A factorised representation of the expected free energy (EFE), which is a probabilistic model of other agents' beliefs that can be used to learn Nash equilibria in general-sum games, and 2) An application of this framework to the iterated prisoner's dilemma. The authors also discuss how their approach relates to other approaches to multi-agent learning.

**Key Contributions/Findings**

The paper presents a novel approach to multi-agent learning that is based on an active inference perspective. This perspective is different from the traditional game-theoretic approach, which is based on the idea of fictitious play. In particular, the authors' approach can be used to learn Nash equilibria in general-sum games. The key finding of this paper is that a factorised representation of the EFE can be used for learning Nash equilibria in general-sum games. The authors also discuss how their approach relates to other approaches to multi-agent learning.

**Methodology/Approach**

The authors use an active inference perspective, which is different from the traditional game-theoretic approach that is based on fictitious play. This perspective can be used for learning Nash equilibria in general-sum games. The authors also discuss how their approach relates to other approaches to multi-agent learning.

**Results/Data**

The paper presents a novel approach to multi-agent learning that is based on an active inference perspective. This perspective is different from the traditional game-theoretic approach, which is based on fictitious play. In particular, the authors' approach can be used for learning Nash equilibria in general-sum games. The authors also discuss how their approach relates to other approaches to multi-agent learning.

**Limitations/Discussion**

The paper presents a novel approach to multi-agent learning that is based on an active inference perspective. This perspective is different from the traditional game-theoretic approach, which is based on fictitious play. In particular, the authors' approach can be used for learning Nash equilibria in general-sum games. The authors also discuss how their approach relates to other approaches to multi-agent learning.

**References**

The paper has 44 references.

Please let me know if you need any further assistance!

---

**Summary Statistics:**
- Input: 9,516 words (62,802 chars)
- Output: 400 words
- Compression: 0.04x
- Generation: 25.6s (15.6 words/sec)
- Quality Score: 1.00/1.0
- Attempts: 1

**Quality Check:** Passed
