% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmainfont[]{Times New Roman}
  \setmonofont[]{Courier New}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  colorlinks=true,
  linkcolor={blue},
  filecolor={blue},
  citecolor={blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1.5cm,top=1.5cm,bottom=1.5cm,left=1.5cm,right=1.5cm,includeheadfoot]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{3}
% Essential packages for academic documents
\usepackage{amsmath,amssymb}          % Mathematical symbols and environments
\usepackage{amsfonts}                 % Additional math fonts
\usepackage{amsthm}                   % Theorem environments
\usepackage{graphicx}                 % Include graphics
\usepackage{float}                    % Better float placement
\usepackage{booktabs}                 % Professional tables
\usepackage{longtable}                % Long tables spanning pages
\usepackage{array}                    % Advanced table formatting
\usepackage{multirow}                 % Multi-row table cells
\usepackage{caption}                  % Enhanced caption formatting
\usepackage{subcaption}               % Sub-figures and sub-tables
\usepackage{bm}                       % Bold math symbols
\usepackage{url}                      % URL formatting
\usepackage{hyperref}                 % Hyperlinks and cross-references
\usepackage{cleveref}                 % Intelligent cross-referencing
\usepackage[capitalise]{cleveref}     % Capitalize cross-reference labels
\usepackage{natbib}                   % Bibliography support
\usepackage{doi}                      % DOI links

% Configure figure numbering and captions
\renewcommand{\figurename}{Figure}
\captionsetup{
    justification=centering,
    font=small,
    labelfont=bf,
    labelsep=period
}

% Configure table numbering and captions
\renewcommand{\tablename}{Table}
\captionsetup[table]{
    justification=centering,
    font=small,
    labelfont=bf,
    labelsep=period
}

% Configure section numbering
\setcounter{secnumdepth}{3}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}}

% Configure equation numbering
\numberwithin{equation}{section}

% Configure hyperref for proper linking
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue,
    filecolor=blue,
    pdfborder={0 0 0},
    bookmarks=true,
    bookmarksnumbered=true,
    bookmarkstype=toc,
    pdftitle={Research Project Template},
    pdfauthor={Template Author},
    pdfsubject={Academic Research},
    pdfkeywords={research, template, academic, LaTeX},
    pdfcreator={render_pdf.sh},
    pdfproducer={XeLaTeX}
}

% Configure cleveref for intelligent cross-references
\crefname{section}{Section}{Sections}
\crefname{subsection}{Subsection}{Subsections}
\crefname{subsubsection}{Subsubsection}{Subsubsections}
\crefname{equation}{Equation}{Equations}
\crefname{figure}{Figure}{Figures}
\crefname{table}{Table}{Tables}
\crefname{appendix}{Appendix}{Appendices}

% Configure fonts for Unicode support with fallbacks
\usepackage{newunicodechar}
\newunicodechar{⁴}{\textsuperscript{4}}
\newunicodechar{₄}{\textsubscript{4}}
\newunicodechar{²}{\textsuperscript{2}}
\newunicodechar{₀}{\textsubscript{0}}
\newunicodechar{₁}{\textsubscript{1}}
\newunicodechar{₂}{\textsubscript{2}}
\newunicodechar{₃}{\textsubscript{3}}

% Use standard fonts for better compatibility
\usepackage{lmodern}
\usepackage[T1]{fontenc}

% Enhanced code block styling for better contrast and readability
\usepackage{fancyvrb}
\usepackage{xcolor}
\usepackage{listings}

% Define custom colors for code blocks
\definecolor{codebg}{RGB}{248, 248, 248}      % Very light gray background
\definecolor{codeborder}{RGB}{200, 200, 200}  % Medium gray border
\definecolor{codefg}{RGB}{34, 34, 34}         % Dark gray text
\definecolor{commentcolor}{RGB}{102, 102, 102} % Comment color
\definecolor{keywordcolor}{RGB}{0, 0, 0}       % Keyword color
\definecolor{stringcolor}{RGB}{0, 102, 0}      % String color

% Configure Verbatim environment for inline code
\DefineVerbatimEnvironment{Verbatim}{Verbatim}{%
    fontsize=\small,
    frame=single,
    framerule=0.5pt,
    framesep=3pt,
    rulecolor=\color{codeborder},
    bgcolor=\color{codebg},
    fgcolor=\color{codefg}
}

% Configure code block styling
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{%
    fontsize=\footnotesize,
    frame=single,
    framerule=0.5pt,
    framesep=5pt,
    rulecolor=\color{codeborder},
    bgcolor=\color{codebg},
    fgcolor=\color{codefg}
}

% Style inline code with \texttt
\renewcommand{\texttt}[1]{%
    \colorbox{codebg}{\color{codefg}\ttfamily #1}%
}

% Configure listings package for code blocks
\lstset{
    backgroundcolor=\color{codebg},
    basicstyle=\footnotesize\ttfamily\color{codefg},
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    commentstyle=\color{commentcolor},
    deletekeywords={...},
    escapeinside={\%*}{*)},
    extendedchars=true,
    frame=single,
    framerule=0.5pt,
    framesep=5pt,
    keepspaces=true,
    keywordstyle=\color{keywordcolor}\bfseries,
    language=Python,
    morekeywords={*,...},
    numbers=left,
    numbersep=5pt,
    numberstyle=\tiny\color{codefg},
    rulecolor=\color{codeborder},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    stepnumber=1,
    stringstyle=\color{stringcolor},
    tabsize=4,
    title=\lstname
}

% Override any Pandoc default lstset configurations
\AtBeginDocument{
    \lstset{
        backgroundcolor=\color{codebg},
        basicstyle=\footnotesize\ttfamily\color{codefg},
        frame=single,
        framerule=0.5pt,
        framesep=5pt,
        rulecolor=\color{codeborder},
        numbers=left,
        numbersep=5pt,
        numberstyle=\tiny\color{codefg}
    }
}

% Configure bibliography
\bibliographystyle{unsrt}  % Unsorted bibliography style
% Bibliography is handled in 07_references.md

% Simple page break support for document structure
% Note: Page breaks are handled in the markdown generation, not here

% Ensure proper spacing and formatting
\frenchspacing  % Single space after periods
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{S01 supplemental methods}
\author{ORCID: 0000-0000-0000-0000\\ Email: author@example.com}
\date{November 13, 2025}

\begin{document}
\maketitle

{
\hypersetup{linkcolor=black}
\setcounter{tocdepth}{3}
\tableofcontents
}
\setstretch{1.2}
\hypertarget{sec:supplemental_methods}{%
\section{Supplemental Methods}\label{sec:supplemental_methods}}

This section provides detailed methodological information that
supplements Section \ref{sec:methodology}.

\hypertarget{s1.1-extended-algorithm-variants}{%
\subsection{S1.1 Extended Algorithm
Variants}\label{s1.1-extended-algorithm-variants}}

\hypertarget{s1.1.1-stochastic-variant}{%
\subsubsection{S1.1.1 Stochastic
Variant}\label{s1.1.1-stochastic-variant}}

For large-scale problems, we developed a stochastic variant of our
algorithm:

\begin{equation}\label{eq:stochastic_update}
x_{k+1} = x_k - \alpha_k \nabla f_{i_k}(x_k) + \beta_k (x_k - x_{k-1})
\end{equation}

where \(i_k\) is a randomly sampled index from \(\{1, \ldots, n\}\) at
iteration \(k\).

\textbf{Convergence Analysis}: Under appropriate sampling strategies,
this variant achieves \(O(1/\sqrt{k})\) convergence rate for
non-strongly convex problems, following the analysis in
\cite{kingma2014, ruder2016}.

\hypertarget{s1.1.2-mini-batch-variant}{%
\subsubsection{S1.1.2 Mini-Batch
Variant}\label{s1.1.2-mini-batch-variant}}

To balance between computational efficiency and convergence speed:

\begin{equation}\label{eq:minibatch_update}
x_{k+1} = x_k - \alpha_k \frac{1}{|B_k|} \sum_{i \in B_k} \nabla f_i(x_k) + \beta_k (x_k - x_{k-1})
\end{equation}

where \(B_k \subset \{1, \ldots, n\}\) is a mini-batch of size
\(|B_k| = b\).

\hypertarget{s1.2-detailed-convergence-analysis}{%
\subsection{S1.2 Detailed Convergence
Analysis}\label{s1.2-detailed-convergence-analysis}}

\hypertarget{s1.2.1-strong-convexity-assumptions}{%
\subsubsection{S1.2.1 Strong Convexity
Assumptions}\label{s1.2.1-strong-convexity-assumptions}}

We assume the objective function \(f\) satisfies:

\begin{equation}\label{eq:strong_convexity_detailed}
f(y) \geq f(x) + \nabla f(x)^T (y - x) + \frac{\mu}{2} \|y - x\|^2, \quad \forall x, y \in \mathcal{X}
\end{equation}

where \(\mu > 0\) is the strong convexity parameter.

\hypertarget{s1.2.2-lipschitz-continuity}{%
\subsubsection{S1.2.2 Lipschitz
Continuity}\label{s1.2.2-lipschitz-continuity}}

The gradient is Lipschitz continuous:

\begin{equation}\label{eq:lipschitz_detailed}
\|\nabla f(x) - \nabla f(y)\| \leq L \|x - y\|, \quad \forall x, y \in \mathcal{X}
\end{equation}

The condition number \(\kappa = L/\mu\) determines the convergence rate:
\(\rho = \sqrt{1 - 1/\kappa}\), as established in
\cite{nesterov2018, boyd2004}.

\hypertarget{s1.3-additional-theoretical-results}{%
\subsection{S1.3 Additional Theoretical
Results}\label{s1.3-additional-theoretical-results}}

\hypertarget{s1.3.1-worst-case-complexity-bounds}{%
\subsubsection{S1.3.1 Worst-Case Complexity
Bounds}\label{s1.3.1-worst-case-complexity-bounds}}

\textbf{Theorem S1}: Under the assumptions of Lipschitz continuity and
strong convexity, the algorithm requires at most
\(O(\kappa \log(1/\epsilon))\) iterations to achieve
\(\epsilon\)-accuracy.

\textbf{Proof}: From the convergence rate \eqref{eq:convergence}, we
have:

\begin{equation}\label{eq:iterations_bound}
\|x_k - x^*\| \leq C \rho^k \leq \epsilon \Rightarrow k \geq \frac{\log(C/\epsilon)}{\log(1/\rho)} = O(\kappa \log(1/\epsilon))
\end{equation}

since \(\log(1/\rho) \approx 1/\kappa\) for small \(1/\kappa\).
\(\square\)

\hypertarget{s1.3.2-expected-convergence-for-stochastic-variants}{%
\subsubsection{S1.3.2 Expected Convergence for Stochastic
Variants}\label{s1.3.2-expected-convergence-for-stochastic-variants}}

For the stochastic variant \eqref{eq:stochastic_update}:

\begin{equation}\label{eq:stochastic_convergence}
\mathbb{E}[\|x_k - x^*\|^2] \leq \frac{C}{k} + \sigma^2
\end{equation}

where \(\sigma^2\) is the variance of the stochastic gradient estimates.

\hypertarget{s1.4-implementation-considerations}{%
\subsection{S1.4 Implementation
Considerations}\label{s1.4-implementation-considerations}}

\hypertarget{s1.4.1-numerical-stability}{%
\subsubsection{S1.4.1 Numerical
Stability}\label{s1.4.1-numerical-stability}}

To ensure numerical stability, we implement the following safeguards:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Gradient clipping}:
  \(\nabla f(x_k) \leftarrow \min(1, \theta/\|\nabla f(x_k)\|) \nabla f(x_k)\)
\item
  \textbf{Step size bounds}:
  \(\alpha_{\min} \leq \alpha_k \leq \alpha_{\max}\)
\item
  \textbf{Momentum bounds}: \(0 \leq \beta_k \leq \beta_{\max} < 1\)
\end{enumerate}

\hypertarget{s1.4.2-initialization-strategies}{%
\subsubsection{S1.4.2 Initialization
Strategies}\label{s1.4.2-initialization-strategies}}

We tested three initialization strategies:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Random}: \(x_0 \sim \mathcal{N}(0, I)\)
\item
  \textbf{Warm start}: \(x_0 = \text{solution from simpler problem}\)
\item
  \textbf{Problem-specific}:
  \(x_0 = \text{domain knowledge-based initialization}\)
\end{enumerate}

Results show that warm start initialization reduces iterations by
approximately 30\% for related problem instances.

\hypertarget{s1.5-extended-mathematical-framework}{%
\subsection{S1.5 Extended Mathematical
Framework}\label{s1.5-extended-mathematical-framework}}

\hypertarget{s1.5.1-generalized-objective-function}{%
\subsubsection{S1.5.1 Generalized Objective
Function}\label{s1.5.1-generalized-objective-function}}

The framework extends to more general objectives:

\begin{equation}\label{eq:general_objective}
f(x) = \sum_{i=1}^{n} w_i \phi_i(x) + \sum_{j=1}^{m} \lambda_j R_j(x) + \sum_{k=1}^{p} \gamma_k C_k(x)
\end{equation}

where: - \(\phi_i(x)\): Data fitting terms - \(R_j(x)\): Regularization
terms (e.g., \(\ell_1\), \(\ell_2\), elastic net) - \(C_k(x)\):
Constraint terms (penalty or barrier functions)

\hypertarget{s1.5.2-adaptive-weight-selection}{%
\subsubsection{S1.5.2 Adaptive Weight
Selection}\label{s1.5.2-adaptive-weight-selection}}

Weights \(w_i\) can be adapted during optimization:

\begin{equation}\label{eq:adaptive_weights}
w_i^{(k+1)} = w_i^{(k)} \cdot \exp\left(-\gamma \frac{|\phi_i(x_k)|}{|\phi(x_k)|}\right)
\end{equation}

This reweighting scheme gives more emphasis to terms that are harder to
optimize.

\hypertarget{s1.6-convergence-diagnostics}{%
\subsection{S1.6 Convergence
Diagnostics}\label{s1.6-convergence-diagnostics}}

\hypertarget{s1.6.1-diagnostic-criteria}{%
\subsubsection{S1.6.1 Diagnostic
Criteria}\label{s1.6.1-diagnostic-criteria}}

We monitor the following quantities for convergence:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Gradient norm}: \(\|\nabla f(x_k)\| < \epsilon_g\)
\item
  \textbf{Step size}: \(\|x_{k+1} - x_k\| < \epsilon_x\)
\item
  \textbf{Function improvement}: \(|f(x_{k+1}) - f(x_k)| < \epsilon_f\)
\item
  \textbf{Relative improvement}:
  \(|f(x_{k+1}) - f(x_k)|/|f(x_k)| < \epsilon_r\)
\end{enumerate}

All four criteria must be satisfied for declared convergence.

\hypertarget{s1.6.2-failure-detection}{%
\subsubsection{S1.6.2 Failure
Detection}\label{s1.6.2-failure-detection}}

Algorithm failure is detected if:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Maximum iterations exceeded
\item
  Step size becomes too small (\(\alpha_k < \alpha_{\min}\))
\item
  NaN or Inf values encountered
\item
  Objective function increases for consecutive iterations
\end{enumerate}

\hypertarget{s1.7-parameter-sensitivity}{%
\subsection{S1.7 Parameter
Sensitivity}\label{s1.7-parameter-sensitivity}}

Detailed sensitivity analysis for each parameter:

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Parameter} & \textbf{Nominal} & \textbf{Range} & \textbf{Impact on Performance} \\
\hline
$\alpha_0$ & 0.01 & [0.001, 0.1] & High (±30\%) \\
$\beta$ & 0.9 & [0.5, 0.99] & Medium (±15\%) \\
$\lambda$ & 0.001 & [0, 0.01] & Low (±5\%) \\
\hline
\end{tabular}
\caption{Parameter sensitivity analysis results}
\label{tab:parameter_sensitivity_detailed}
\end{table}

The learning rate \(\alpha_0\) has the strongest impact on convergence
speed, while regularization \(\lambda\) primarily affects the final
solution quality rather than convergence dynamics.

\end{document}
