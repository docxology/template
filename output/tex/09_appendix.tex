% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmainfont[]{Times New Roman}
  \setmonofont[]{Courier New}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  colorlinks=true,
  linkcolor={blue},
  filecolor={blue},
  citecolor={blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1.5cm,top=1.5cm,bottom=1.5cm,left=1.5cm,right=1.5cm,includeheadfoot]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{3}
% Essential packages for academic documents
\usepackage{amsmath,amssymb}          % Mathematical symbols and environments
\usepackage{amsfonts}                 % Additional math fonts
\usepackage{amsthm}                   % Theorem environments
\usepackage{graphicx}                 % Include graphics
\usepackage{float}                    % Better float placement
\usepackage{booktabs}                 % Professional tables
\usepackage{longtable}                % Long tables spanning pages
\usepackage{array}                    % Advanced table formatting
\usepackage{multirow}                 % Multi-row table cells
\usepackage{caption}                  % Enhanced caption formatting
\usepackage{subcaption}               % Sub-figures and sub-tables
\usepackage{bm}                       % Bold math symbols
\usepackage{url}                      % URL formatting
\usepackage{hyperref}                 % Hyperlinks and cross-references
\usepackage{cleveref}                 % Intelligent cross-referencing
\usepackage[capitalise]{cleveref}     % Capitalize cross-reference labels
\usepackage{natbib}                   % Bibliography support
\usepackage{doi}                      % DOI links

% Configure figure numbering and captions
\renewcommand{\figurename}{Figure}
\captionsetup{
    justification=centering,
    font=small,
    labelfont=bf,
    labelsep=period
}

% Configure table numbering and captions
\renewcommand{\tablename}{Table}
\captionsetup[table]{
    justification=centering,
    font=small,
    labelfont=bf,
    labelsep=period
}

% Configure section numbering
\setcounter{secnumdepth}{3}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}}

% Configure equation numbering
\numberwithin{equation}{section}

% Configure hyperref for proper linking
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue,
    filecolor=blue,
    pdfborder={0 0 0},
    bookmarks=true,
    bookmarksnumbered=true,
    bookmarkstype=toc,
    pdftitle={Research Project Template},
    pdfauthor={Template Author},
    pdfsubject={Academic Research},
    pdfkeywords={research, template, academic, LaTeX},
    pdfcreator={render_pdf.sh},
    pdfproducer={XeLaTeX}
}

% Configure cleveref for intelligent cross-references
\crefname{section}{Section}{Sections}
\crefname{subsection}{Subsection}{Subsections}
\crefname{subsubsection}{Subsubsection}{Subsubsections}
\crefname{equation}{Equation}{Equations}
\crefname{figure}{Figure}{Figures}
\crefname{table}{Table}{Tables}
\crefname{appendix}{Appendix}{Appendices}

% Configure fonts for Unicode support with fallbacks
\usepackage{newunicodechar}
\newunicodechar{⁴}{\textsuperscript{4}}
\newunicodechar{₄}{\textsubscript{4}}
\newunicodechar{²}{\textsuperscript{2}}
\newunicodechar{₀}{\textsubscript{0}}
\newunicodechar{₁}{\textsubscript{1}}
\newunicodechar{₂}{\textsubscript{2}}
\newunicodechar{₃}{\textsubscript{3}}

% Use standard fonts for better compatibility
\usepackage{lmodern}
\usepackage[T1]{fontenc}

% Enhanced code block styling for better contrast and readability
\usepackage{fancyvrb}
\usepackage{xcolor}
\usepackage{listings}

% Define custom colors for code blocks
\definecolor{codebg}{RGB}{248, 248, 248}      % Very light gray background
\definecolor{codeborder}{RGB}{200, 200, 200}  % Medium gray border
\definecolor{codefg}{RGB}{34, 34, 34}         % Dark gray text
\definecolor{commentcolor}{RGB}{102, 102, 102} % Comment color
\definecolor{keywordcolor}{RGB}{0, 0, 0}       % Keyword color
\definecolor{stringcolor}{RGB}{0, 102, 0}      % String color

% Configure Verbatim environment for inline code
\DefineVerbatimEnvironment{Verbatim}{Verbatim}{%
    fontsize=\small,
    frame=single,
    framerule=0.5pt,
    framesep=3pt,
    rulecolor=\color{codeborder},
    bgcolor=\color{codebg},
    fgcolor=\color{codefg}
}

% Configure code block styling
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{%
    fontsize=\footnotesize,
    frame=single,
    framerule=0.5pt,
    framesep=5pt,
    rulecolor=\color{codeborder},
    bgcolor=\color{codebg},
    fgcolor=\color{codefg}
}

% Style inline code with \texttt
\renewcommand{\texttt}[1]{%
    \colorbox{codebg}{\color{codefg}\ttfamily #1}%
}

% Configure listings package for code blocks
\lstset{
    backgroundcolor=\color{codebg},
    basicstyle=\footnotesize\ttfamily\color{codefg},
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    commentstyle=\color{commentcolor},
    deletekeywords={...},
    escapeinside={\%*}{*)},
    extendedchars=true,
    frame=single,
    framerule=0.5pt,
    framesep=5pt,
    keepspaces=true,
    keywordstyle=\color{keywordcolor}\bfseries,
    language=Python,
    morekeywords={*,...},
    numbers=left,
    numbersep=5pt,
    numberstyle=\tiny\color{codefg},
    rulecolor=\color{codeborder},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    stepnumber=1,
    stringstyle=\color{stringcolor},
    tabsize=4,
    title=\lstname
}

% Override any Pandoc default lstset configurations
\AtBeginDocument{
    \lstset{
        backgroundcolor=\color{codebg},
        basicstyle=\footnotesize\ttfamily\color{codefg},
        frame=single,
        framerule=0.5pt,
        framesep=5pt,
        rulecolor=\color{codeborder},
        numbers=left,
        numbersep=5pt,
        numberstyle=\tiny\color{codefg}
    }
}

% Configure bibliography
\bibliographystyle{unsrt}  % Unsorted bibliography style
% Bibliography is handled in 07_references.md

% Simple page break support for document structure
% Note: Page breaks are handled in the markdown generation, not here

% Ensure proper spacing and formatting
\frenchspacing  % Single space after periods
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{09 appendix}
\author{ORCID: 0000-0000-0000-1234\ Email: author@example.com\ DOI: 10.5281/zenodo.12345678}
\date{November 13, 2025}

\begin{document}
\maketitle

{
\hypersetup{linkcolor=black}
\setcounter{tocdepth}{3}
\tableofcontents
}
\setstretch{1.2}
\hypertarget{sec:appendix}{%
\section{Appendix}\label{sec:appendix}}

This appendix provides additional technical details and derivations that
support the main results.

\hypertarget{a.-detailed-proofs}{%
\subsection{A. Detailed Proofs}\label{a.-detailed-proofs}}

\hypertarget{a.1-proof-of-convergence-theorem-1}{%
\subsubsection{A.1 Proof of Convergence (Theorem
1)}\label{a.1-proof-of-convergence-theorem-1}}

The convergence rate established in \eqref{eq:convergence} follows from
the following detailed analysis.

\textbf{Proof}: Let \(x_k\) be the iterate at step \(k\). From the
update rule \eqref{eq:update}, we have:

\begin{equation}\label{eq:appendix_update}
x_{k+1} = x_k - \alpha_k \nabla f(x_k) + \beta_k (x_k - x_{k-1})
\end{equation}

By the Lipschitz continuity of \(\nabla f\), there exists a constant
\(L > 0\) such that:

\begin{equation}\label{eq:lipschitz}
\|\nabla f(x) - \nabla f(y)\| \leq L \|x - y\|, \quad \forall x, y \in \mathcal{X}
\end{equation}

Using strong convexity with parameter \(\mu > 0\)
\cite{boyd2004, nesterov2018}:

\begin{equation}\label{eq:strong_convexity}
f(y) \geq f(x) + \nabla f(x)^T (y - x) + \frac{\mu}{2} \|y - x\|^2
\end{equation}

Combining these properties with the adaptive step size rule
\eqref{eq:adaptive_step}, following the analysis framework in
\cite{duchi2011, bertsekas2015}, we obtain the linear convergence rate
with \(\rho = \sqrt{1 - \mu/L}\). \(\square\)

\hypertarget{a.2-complexity-analysis}{%
\subsubsection{A.2 Complexity Analysis}\label{a.2-complexity-analysis}}

The computational complexity per iteration is derived as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Gradient computation}: \(O(n)\) for dense problems, \(O(k)\)
  for sparse problems with \(k\) non-zeros
\item
  \textbf{Update rule}: \(O(n)\) for vector operations
\item
  \textbf{Adaptive step size}: \(O(1)\) for the update in
  \eqref{eq:adaptive_step}
\item
  \textbf{Momentum term}: \(O(n)\) for the momentum computation
\end{enumerate}

Total per-iteration complexity: \(O(n)\) for dense problems.

For structured problems, we can exploit the separable structure of
\eqref{eq:objective} to achieve \(O(n \log n)\) complexity using
efficient data structures (see Figure \ref{fig:data_structure}).

\hypertarget{b.-additional-experimental-details}{%
\subsection{B. Additional Experimental
Details}\label{b.-additional-experimental-details}}

\hypertarget{b.1-hyperparameter-tuning}{%
\subsubsection{B.1 Hyperparameter
Tuning}\label{b.1-hyperparameter-tuning}}

The following hyperparameters were used in our experiments:

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Parameter} & \textbf{Symbol} & \textbf{Value} & \textbf{Range Tested} \\
\hline
Learning rate & $\alpha_0$ & 0.01 & [0.001, 0.1] \\
Momentum & $\beta$ & 0.9 & [0.5, 0.99] \\
Regularization & $\lambda$ & 0.001 & [0, 0.01] \\
Tolerance & $\epsilon$ & $10^{-6}$ & [10^{-8}, 10^{-4}] \\
\hline
\end{tabular}
\caption{Hyperparameter settings used in experiments}
\label{tab:hyperparameters}
\end{table}

\hypertarget{b.2-computational-environment}{%
\subsubsection{B.2 Computational
Environment}\label{b.2-computational-environment}}

All experiments were conducted on: - \textbf{CPU}: Intel Xeon E5-2690 v4
@ 2.60GHz (28 cores) - \textbf{RAM}: 128GB DDR4 - \textbf{GPU}: NVIDIA
Tesla V100 (32GB VRAM) for large-scale experiments - \textbf{OS}: Ubuntu
20.04 LTS - \textbf{Python}: 3.10.12 - \textbf{NumPy}: 1.24.3 -
\textbf{SciPy}: 1.10.1

\hypertarget{b.3-dataset-preparation}{%
\subsubsection{B.3 Dataset Preparation}\label{b.3-dataset-preparation}}

Datasets were preprocessed using standard normalization:

\begin{equation}\label{eq:normalization}
\tilde{x}_i = \frac{x_i - \mu}{\sigma}
\end{equation}

where \(\mu\) and \(\sigma\) are the mean and standard deviation
computed from the training set.

\hypertarget{c.-extended-results}{%
\subsection{C. Extended Results}\label{c.-extended-results}}

\hypertarget{c.1-additional-benchmark-comparisons}{%
\subsubsection{C.1 Additional Benchmark
Comparisons}\label{c.1-additional-benchmark-comparisons}}

Table \ref{tab:extended_comparison} provides detailed performance
comparison across all tested methods.

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Method} & \textbf{Time (s)} & \textbf{Iterations} & \textbf{Final Error} & \textbf{Memory (MB)} \\
\hline
Our Method & 12.3 & 245 & $1.2 \times 10^{-6}$ & 156 \\
Gradient Descent & 18.7 & 412 & $1.5 \times 10^{-6}$ & 312 \\
Adam & 15.4 & 358 & $1.4 \times 10^{-6}$ & 298 \\
L-BFGS & 16.2 & 198 & $1.1 \times 10^{-6}$ & 425 \\
\hline
\end{tabular}
\caption{Extended performance comparison with computational details}
\label{tab:extended_comparison}
\end{table}

\hypertarget{c.2-sensitivity-analysis}{%
\subsubsection{C.2 Sensitivity
Analysis}\label{c.2-sensitivity-analysis}}

Detailed sensitivity analysis for all hyperparameters shows robust
performance across wide parameter ranges, confirming the theoretical
predictions from Section \ref{sec:methodology}.

\hypertarget{d.-implementation-details}{%
\subsection{D. Implementation Details}\label{d.-implementation-details}}

\hypertarget{d.1-pseudocode}{%
\subsubsection{D.1 Pseudocode}\label{d.1-pseudocode}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ optimize(f, x0, alpha0, beta, max\_iter, tol):}
    \CommentTok{"""}
\CommentTok{    Optimization algorithm implementation.}
\CommentTok{    }
\CommentTok{    Args:}
\CommentTok{        f: Objective function}
\CommentTok{        x0: Initial point}
\CommentTok{        alpha0: Initial learning rate}
\CommentTok{        beta: Momentum coefficient}
\CommentTok{        max\_iter: Maximum iterations}
\CommentTok{        tol: Convergence tolerance}
\CommentTok{    }
\CommentTok{    Returns:}
\CommentTok{        x\_opt: Optimal solution}
\CommentTok{        history: Convergence history}
\CommentTok{    """}
\NormalTok{    x }\OperatorTok{=}\NormalTok{ x0}
\NormalTok{    x\_prev }\OperatorTok{=}\NormalTok{ x0}
\NormalTok{    history }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    grad\_sum\_sq }\OperatorTok{=} \DecValTok{0}
    
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(max\_iter):}
        \CommentTok{\# Compute gradient}
\NormalTok{        grad }\OperatorTok{=}\NormalTok{ compute\_gradient(f, x)}
\NormalTok{        grad\_sum\_sq }\OperatorTok{+=}\NormalTok{ np.linalg.norm(grad)}\OperatorTok{**}\DecValTok{2}
        
        \CommentTok{\# Adaptive step size}
\NormalTok{        alpha }\OperatorTok{=}\NormalTok{ alpha0 }\OperatorTok{/}\NormalTok{ np.sqrt(}\DecValTok{1} \OperatorTok{+}\NormalTok{ grad\_sum\_sq)}
        
        \CommentTok{\# Update with momentum}
\NormalTok{        x\_new }\OperatorTok{=}\NormalTok{ x }\OperatorTok{{-}}\NormalTok{ alpha }\OperatorTok{*}\NormalTok{ grad }\OperatorTok{+}\NormalTok{ beta }\OperatorTok{*}\NormalTok{ (x }\OperatorTok{{-}}\NormalTok{ x\_prev)}
        
        \CommentTok{\# Check convergence}
        \ControlFlowTok{if}\NormalTok{ np.linalg.norm(x\_new }\OperatorTok{{-}}\NormalTok{ x) }\OperatorTok{\textless{}}\NormalTok{ tol:}
            \ControlFlowTok{break}
        
        \CommentTok{\# Update history}
\NormalTok{        history.append(\{}\StringTok{\textquotesingle{}iter\textquotesingle{}}\NormalTok{: k, }\StringTok{\textquotesingle{}error\textquotesingle{}}\NormalTok{: f(x\_new)\})}
        
        \CommentTok{\# Prepare next iteration}
\NormalTok{        x\_prev }\OperatorTok{=}\NormalTok{ x}
\NormalTok{        x }\OperatorTok{=}\NormalTok{ x\_new}
    
    \ControlFlowTok{return}\NormalTok{ x, history}
\end{Highlighting}
\end{Shaded}

\hypertarget{d.2-performance-optimizations}{%
\subsubsection{D.2 Performance
Optimizations}\label{d.2-performance-optimizations}}

Key performance optimizations implemented: 1. Vectorized operations
using NumPy 2. Sparse matrix representations when applicable 3. In-place
updates to reduce memory allocation 4. Parallel gradient computations
for separable problems

\end{document}
