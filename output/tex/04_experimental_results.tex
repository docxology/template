% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmainfont[]{Times New Roman}
  \setmonofont[]{Courier New}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  colorlinks=true,
  linkcolor={blue},
  filecolor={blue},
  citecolor={blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1.5cm,top=1.5cm,bottom=1.5cm,left=1.5cm,right=1.5cm,includeheadfoot]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{3}
% Essential packages for academic documents
\usepackage{amsmath,amssymb}          % Mathematical symbols and environments
\usepackage{amsfonts}                 % Additional math fonts
\usepackage{amsthm}                   % Theorem environments
\usepackage{graphicx}                 % Include graphics
\usepackage{float}                    % Better float placement
\usepackage{booktabs}                 % Professional tables
\usepackage{longtable}                % Long tables spanning pages
\usepackage{array}                    % Advanced table formatting
\usepackage{multirow}                 % Multi-row table cells
\usepackage{caption}                  % Enhanced caption formatting
\usepackage{subcaption}               % Sub-figures and sub-tables
\usepackage{bm}                       % Bold math symbols
\usepackage{url}                      % URL formatting
\usepackage{hyperref}                 % Hyperlinks and cross-references
\usepackage{cleveref}                 % Intelligent cross-referencing
\usepackage[capitalise]{cleveref}     % Capitalize cross-reference labels
\usepackage{natbib}                   % Bibliography support
\usepackage{doi}                      % DOI links

% Configure figure numbering and captions
\renewcommand{\figurename}{Figure}
\captionsetup{
    justification=centering,
    font=small,
    labelfont=bf,
    labelsep=period
}

% Configure table numbering and captions
\renewcommand{\tablename}{Table}
\captionsetup[table]{
    justification=centering,
    font=small,
    labelfont=bf,
    labelsep=period
}

% Configure section numbering
\setcounter{secnumdepth}{3}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}}

% Configure equation numbering
\numberwithin{equation}{section}

% Configure hyperref for proper linking
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue,
    filecolor=blue,
    pdfborder={0 0 0},
    bookmarks=true,
    bookmarksnumbered=true,
    bookmarkstype=toc,
    pdftitle={Research Project Template},
    pdfauthor={Template Author},
    pdfsubject={Academic Research},
    pdfkeywords={research, template, academic, LaTeX},
    pdfcreator={render_pdf.sh},
    pdfproducer={XeLaTeX}
}

% Configure cleveref for intelligent cross-references
\crefname{section}{Section}{Sections}
\crefname{subsection}{Subsection}{Subsections}
\crefname{subsubsection}{Subsubsection}{Subsubsections}
\crefname{equation}{Equation}{Equations}
\crefname{figure}{Figure}{Figures}
\crefname{table}{Table}{Tables}
\crefname{appendix}{Appendix}{Appendices}

% Configure fonts for Unicode support with fallbacks
\usepackage{newunicodechar}
\newunicodechar{⁴}{\textsuperscript{4}}
\newunicodechar{₄}{\textsubscript{4}}
\newunicodechar{²}{\textsuperscript{2}}
\newunicodechar{₀}{\textsubscript{0}}
\newunicodechar{₁}{\textsubscript{1}}
\newunicodechar{₂}{\textsubscript{2}}
\newunicodechar{₃}{\textsubscript{3}}

% Use standard fonts for better compatibility
\usepackage{lmodern}
\usepackage[T1]{fontenc}

% Enhanced code block styling for better contrast and readability
\usepackage{fancyvrb}
\usepackage{xcolor}
\usepackage{listings}

% Define custom colors for code blocks
\definecolor{codebg}{RGB}{248, 248, 248}      % Very light gray background
\definecolor{codeborder}{RGB}{200, 200, 200}  % Medium gray border
\definecolor{codefg}{RGB}{34, 34, 34}         % Dark gray text
\definecolor{commentcolor}{RGB}{102, 102, 102} % Comment color
\definecolor{keywordcolor}{RGB}{0, 0, 0}       % Keyword color
\definecolor{stringcolor}{RGB}{0, 102, 0}      % String color

% Configure Verbatim environment for inline code
\DefineVerbatimEnvironment{Verbatim}{Verbatim}{%
    fontsize=\small,
    frame=single,
    framerule=0.5pt,
    framesep=3pt,
    rulecolor=\color{codeborder},
    bgcolor=\color{codebg},
    fgcolor=\color{codefg}
}

% Configure code block styling
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{%
    fontsize=\footnotesize,
    frame=single,
    framerule=0.5pt,
    framesep=5pt,
    rulecolor=\color{codeborder},
    bgcolor=\color{codebg},
    fgcolor=\color{codefg}
}

% Style inline code with \texttt
\renewcommand{\texttt}[1]{%
    \colorbox{codebg}{\color{codefg}\ttfamily #1}%
}

% Configure listings package for code blocks
\lstset{
    backgroundcolor=\color{codebg},
    basicstyle=\footnotesize\ttfamily\color{codefg},
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    commentstyle=\color{commentcolor},
    deletekeywords={...},
    escapeinside={\%*}{*)},
    extendedchars=true,
    frame=single,
    framerule=0.5pt,
    framesep=5pt,
    keepspaces=true,
    keywordstyle=\color{keywordcolor}\bfseries,
    language=Python,
    morekeywords={*,...},
    numbers=left,
    numbersep=5pt,
    numberstyle=\tiny\color{codefg},
    rulecolor=\color{codeborder},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    stepnumber=1,
    stringstyle=\color{stringcolor},
    tabsize=4,
    title=\lstname
}

% Override any Pandoc default lstset configurations
\AtBeginDocument{
    \lstset{
        backgroundcolor=\color{codebg},
        basicstyle=\footnotesize\ttfamily\color{codefg},
        frame=single,
        framerule=0.5pt,
        framesep=5pt,
        rulecolor=\color{codeborder},
        numbers=left,
        numbersep=5pt,
        numberstyle=\tiny\color{codefg}
    }
}

% Configure bibliography
\bibliographystyle{unsrt}  % Unsorted bibliography style
% Bibliography is handled in 07_references.md

% Simple page break support for document structure
% Note: Page breaks are handled in the markdown generation, not here

% Ensure proper spacing and formatting
\frenchspacing  % Single space after periods
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{04 experimental results}
\author{ORCID: 0000-0000-0000-1234\ Email: author@example.com\ DOI: 10.5281/zenodo.12345678}
\date{November 13, 2025}

\begin{document}
\maketitle

{
\hypersetup{linkcolor=black}
\setcounter{tocdepth}{3}
\tableofcontents
}
\setstretch{1.2}
\hypertarget{sec:experimental_results}{%
\section{Experimental Results}\label{sec:experimental_results}}

\hypertarget{experimental-setup}{%
\subsection{Experimental Setup}\label{experimental-setup}}

Our experimental evaluation follows the methodology described in Section
\ref{sec:methodology}. We implemented the algorithm in Python using the
framework outlined in Section \ref{sec:methodology}, with all code
available in the \texttt{src/} directory.

The experiments were conducted on a diverse set of benchmark problems,
ranging from small-scale optimization tasks to large-scale machine
learning problems. Figure \ref{fig:experimental_setup} illustrates our
experimental pipeline, which includes data preprocessing, algorithm
execution, and performance evaluation.

\hypertarget{benchmark-datasets}{%
\subsection{Benchmark Datasets}\label{benchmark-datasets}}

We evaluated our approach on three main categories of problems:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Convex Optimization}: Standard test functions from the
  optimization literature
\item
  \textbf{Non-convex Problems}: Challenging landscapes with multiple
  local minima
\item
  \textbf{Large-scale Problems}: High-dimensional problems with
  \(n \geq 10^6\)
\end{enumerate}

The problem characteristics are summarized in Table
\ref{tab:dataset_summary}.

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Dataset} & \textbf{Size} & \textbf{Type} & \textbf{Features} & \textbf{Avg Value} & \textbf{Max Value} & \textbf{Min Value} \\
\hline
Small Convex & 100 & Convex & 10 & 0.118 & 2.597 & -2.316 \\
Medium Convex & 1000 & Convex & 50 & 0.001 & 3.119 & -3.855 \\
Large Convex & 10000 & Convex & 100 & 0.005 & 3.953 & -3.752 \\
Small Non-convex & 100 & Non-convex & 10 & 0.081 & 2.359 & -2.274 \\
Medium Non-convex & 1000 & Non-convex & 50 & -0.047 & 3.353 & -3.422 \\
\hline
\end{tabular}
\caption{Dataset characteristics and problem sizes used in experiments}
\label{tab:dataset_summary}
\end{table}

\hypertarget{performance-comparison}{%
\subsection{Performance Comparison}\label{performance-comparison}}

\hypertarget{convergence-analysis}{%
\subsubsection{Convergence Analysis}\label{convergence-analysis}}

Figure \ref{fig:convergence_plot} shows the convergence behavior of our
algorithm compared to baseline methods
\cite{ruder2016, kingma2014, schmidt2017}. The results demonstrate that
our approach achieves the theoretical convergence rate
\eqref{eq:convergence} in practice, with empirical constants
\(C \approx 1.2\) and \(\rho \approx 0.85\), matching predictions from
convex optimization theory \cite{nesterov2018}.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{../output/figures/convergence_plot.png}
\caption{Algorithm convergence comparison showing performance improvement}
\label{fig:convergence_plot}
\end{figure}

The adaptive step size rule \eqref{eq:adaptive_step} proves crucial for
stable convergence, as shown in the detailed analysis in Figure
\ref{fig:step_size_analysis}.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{../output/figures/step_size_analysis.png}
\caption{Detailed analysis of adaptive step size behavior}
\label{fig:step_size_analysis}
\end{figure}

\hypertarget{computational-efficiency}{%
\subsubsection{Computational
Efficiency}\label{computational-efficiency}}

Our implementation achieves the theoretical \(O(n \log n)\) complexity
per iteration, as demonstrated in Figure \ref{fig:scalability_analysis}.
The memory usage follows the predicted scaling \eqref{eq:memory}, making
our method suitable for problems that don't fit in main memory.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{../output/figures/scalability_analysis.png}
\caption{Scalability analysis showing computational complexity}
\label{fig:scalability_analysis}
\end{figure}

Table \ref{tab:performance_comparison} provides a detailed comparison
with state-of-the-art methods
\cite{kingma2014, ruder2016, schmidt2017, reddi2018} across different
problem sizes.

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Method} & \textbf{Convergence Rate} & \textbf{Memory Usage} & \textbf{Success Rate (\%)} \\
\hline
Our Method & 0.85 & $O(n)$ & 94.3 \\
Gradient Descent & 0.9 & $O(n^2)$ & 85.0 \\
Adam & 0.9 & $O(n^2)$ & 85.0 \\
L-BFGS & 0.9 & $O(n^2)$ & 85.0 \\
\hline
\end{tabular}
\caption{Performance comparison with state-of-the-art methods}
\label{tab:performance_comparison}
\end{table}

\hypertarget{ablation-studies}{%
\subsection{Ablation Studies}\label{ablation-studies}}

\hypertarget{component-analysis}{%
\subsubsection{Component Analysis}\label{component-analysis}}

We conducted extensive ablation studies to understand the contribution
of each component. Figure \ref{fig:ablation_study} shows the impact of:

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{../output/figures/ablation_study.png}
\caption{Ablation study results showing component contributions}
\label{fig:ablation_study}
\end{figure}

\begin{itemize}
\tightlist
\item
  The regularization term \(R(x)\) from \eqref{eq:objective}
\item
  The momentum term in the update rule \eqref{eq:update}
\item
  The adaptive step size strategy \eqref{eq:adaptive_step}
\end{itemize}

\hypertarget{hyperparameter-sensitivity}{%
\subsubsection{Hyperparameter
Sensitivity}\label{hyperparameter-sensitivity}}

The algorithm performance is robust to hyperparameter choices within
reasonable ranges. Figure \ref{fig:hyperparameter_sensitivity}
demonstrates that the learning rate \(\alpha_0\) and momentum
coefficient \(\beta_k\) can vary by \(\pm 50\%\) without significant
performance degradation.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{../output/figures/hyperparameter_sensitivity.png}
\caption{Hyperparameter sensitivity analysis showing robustness}
\label{fig:hyperparameter_sensitivity}
\end{figure}

\hypertarget{real-world-applications}{%
\subsection{Real-world Applications}\label{real-world-applications}}

\hypertarget{case-study-1-image-classification}{%
\subsubsection{Case Study 1: Image
Classification}\label{case-study-1-image-classification}}

We applied our optimization framework to train deep neural networks for
image classification. The results, shown in Figure
\ref{fig:image_classification_results}, demonstrate that our method
achieves competitive accuracy while requiring fewer iterations than
standard optimizers.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{../output/figures/image_classification_results.png}
\caption{Image classification results comparing our method with baselines}
\label{fig:image_classification_results}
\end{figure}

The training curves follow the expected convergence pattern
\eqref{eq:convergence}, with the algorithm finding good solutions in
approximately 30\% fewer epochs.

\hypertarget{case-study-2-recommendation-systems}{%
\subsubsection{Case Study 2: Recommendation
Systems}\label{case-study-2-recommendation-systems}}

For large-scale recommendation systems, our approach scales efficiently
to problems with millions of users and items. Figure
\ref{fig:recommendation_scalability} shows the performance scaling,
confirming our theoretical analysis.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{../output/figures/recommendation_scalability.png}
\caption{Recommendation system scalability analysis}
\label{fig:recommendation_scalability}
\end{figure}

\hypertarget{statistical-significance}{%
\subsection{Statistical Significance}\label{statistical-significance}}

All reported improvements are statistically significant at the
\(p < 0.01\) level, computed using paired t-tests across multiple random
initializations. The confidence intervals are shown as shaded regions in
the performance plots.

\hypertarget{limitations-and-future-work}{%
\subsection{Limitations and Future
Work}\label{limitations-and-future-work}}

While our approach shows promising results, several limitations remain:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Problem Structure}: The method assumes certain structural
  properties that may not hold in all domains
\item
  \textbf{Hyperparameter Tuning}: Some parameters still require manual
  tuning for optimal performance
\item
  \textbf{Theoretical Guarantees}: Convergence guarantees are currently
  limited to convex problems
\end{enumerate}

Future work will address these limitations and extend the framework to
broader problem classes. Extended analysis and additional application
examples are provided in Sections \ref{sec:supplemental_analysis} and
\ref{sec:supplemental_applications}.

\end{document}
