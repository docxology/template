% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
  ignorenonframetext,
]{beamer}
\newif\ifbibliography
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% remove section numbering
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{section title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{subsection title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{\texorpdfstring{}{}}
\date{}

\begin{document}

\section{\texorpdfstring{Conclusion: Evidence Landscape, Methodological
Limitations, and Research Agenda
\label{sec:conclusion}}{Conclusion: Evidence Landscape, Methodological Limitations, and Research Agenda }}\label{conclusion-evidence-landscape-methodological-limitations-and-research-agenda}

\begin{frame}{Summary}
\protect\phantomsection\label{summary}
This work demonstrates that the infrastructure for computational
meta-analysis of a rapidly growing scientific field is feasible with
current technology. By combining multi-source retrieval (\(N = 1208\)
papers from three databases), LLM-based assertion extraction encoded as
nanopublications, and citation-weighted hypothesis scoring, we produce a
queryable, RDF-compatible knowledge graph that tracks the evolving
evidence for eight core Active Inference claims.
\end{frame}

\begin{frame}{Constraints and Methodological Scope}
\protect\phantomsection\label{constraints-and-methodological-scope}
Several conscious design constraints scope these findings.

\begin{block}{Keyword Classifier Resolution}
\protect\phantomsection\label{keyword-classifier-resolution}
The keyword-based classifier utilizes a deterministic priority system
that strategically routes papers to specific application domains
(C1--C5) before testing tools (B), formal theory (A1), and the
qualitative philosophy catch-all (A2). While the expanded A1 keyword set
(65+ mathematical indicators) and word-boundary-aware matching
substantially suppress misclassification of formal papers into A2,
keyword-based taxonomic gating inherently lacks the granular semantic
depth of latent embedding-based approaches. Residual A2 concentration
must therefore be interpreted structurally---as a ceiling on broad
theoretical generality rather than a literal measure of exclusive
philosophical focus.
\end{block}

\begin{block}{Citation Network Coverage Gaps}
\protect\phantomsection\label{citation-network-coverage-gaps}
The 2\{,\}780 intra-corpus edges spanning 700 distinct connected
components provide a meaningful topological skeleton, yet cross-source
identifier mismatches inevitably inflate the isolated component count.
Exhaustive DOI-level cross-matching would further condense the graph.
\end{block}

\begin{block}{Temporal and Citation-Count Biases}
\protect\phantomsection\label{temporal-and-citation-count-biases}
Citation counts remain fundamentally subject to Matthew effects and
cumulative field-size biases. Partial-year indexing for the most recent
calendar year predictably undercounts concluding publications.
Consequently, the measured 6.63\% CAGR explicitly reflects the dilutive
effect of the extensive longitudinal span (1972--2026); the localized
growth phase from 2010 onward traverses an aggressively steeper
trajectory.
\end{block}

\begin{block}{LLM Extraction Fidelity}
\protect\phantomsection\label{llm-extraction-fidelity}
Systematic zero-shot extraction biases include over-extraction
(hallucinating claims the paper merely mentions) and direction inversion
errors (misclassifying opposing evidence as structurally supporting).
While human review and the explicit ``irrelevant'' filtering predicate
mitigate these hazards, they are not eliminated. Zero-shot confidence
calibration remains arguably the central open challenge for automated
evidence synthesis architectures.
\end{block}
\end{frame}

\begin{frame}{Future Directions: Beyond Tally-Based Evidence
Aggregation}
\protect\phantomsection\label{future-directions-beyond-tally-based-evidence-aggregation}
The current scoring formula (Section 2) aggregates LLM-extracted
assertions through a simple citation-weighted tally. While this approach
provides a transparent and reproducible baseline, it leaves substantial
room for methodological sophistication. We identify six directions,
ordered by expected impact, with the first three specifically addressing
the limitations of tally-based evidence synthesis.

\begin{block}{Hierarchical Bayesian Hypothesis Scoring}
\protect\phantomsection\label{hierarchical-bayesian-hypothesis-scoring}
The most direct extension replaces the additive tally with a
\textbf{hierarchical Bayesian model} that treats each hypothesis score
as a latent variable inferred from noisy assertion observations. Under
this formulation, each assertion \(a_i\) contributes a likelihood term
\(P(a_i | \theta_H, \sigma)\) parameterized by the hypothesis-level
evidence strength \(\theta_H\) and an observation noise term \(\sigma\)
capturing LLM extraction uncertainty. A hierarchical prior
\(\theta_H \sim \mathcal{N}(\mu_{\text{field}}, \tau^2)\) pools
information across hypotheses, enabling principled shrinkage for
hypotheses with sparse evidence (e.g., H6 Clinical Utility, with only 45
assertions). This framework naturally produces posterior credible
intervals rather than point estimates, providing honest uncertainty
quantification that the current tally-based scores cannot offer.
Temporal dynamics can be modeled through time-varying parameters
\(\theta_H(t)\) using state-space formulations that re-weight older
evidence rather than treating all cumulative assertions equally.
\end{block}

\begin{block}{Causal Evidence Graphs}
\protect\phantomsection\label{causal-evidence-graphs}
A second-generation knowledge graph would encode not only
assertion-level relationships (paper → supports → hypothesis) but also
\textbf{causal dependencies among hypotheses} themselves. For example,
evidence for predictive coding (H4) often implicitly supports FEP
universality (H1), yet the tally-based approach treats them as
independent. A causal evidence graph---structured as a directed acyclic
graph (DAG) over hypotheses with edge weights learned from co-assertion
patterns---would enable cross-hypothesis evidence propagation using
belief propagation or variational message passing. This is particularly
relevant for the Active Inference literature, where hypotheses are
theoretically nested: FEP universality (H1) logically entails predictive
coding (H4), and Markov blanket realism (H3) is a prerequisite for
certain formulations of H1. Encoding these dependencies would prevent
the double-counting of evidence from papers that support multiple
related hypotheses and enable identification of which specific claims
drive support for downstream hypotheses. The resulting causal structure
itself would be a scientific contribution---a formal map of evidential
dependencies within the field's theoretical architecture.
\end{block}

\begin{block}{Evidential Diversity and Source Weighting}
\protect\phantomsection\label{evidential-diversity-and-source-weighting}
The current formula weights assertions by
\(\log(1 + \text{citations}) \cdot \text{confidence}\), treating all
assertion sources symmetrically. A more nuanced approach would introduce
an \textbf{evidential diversity index} that downweights correlated
evidence from papers sharing authors, institutions, or methodological
approaches. Concretely, assertions could be weighted by the inverse of
their similarity to previously counted assertions, measured via cosine
similarity of paper embeddings. This would address the observation that
H1 (FEP universality) accumulates a large neutral tally partly because
many A2 (philosophy) papers invoke the FEP without independently testing
it---a form of evidential redundancy that inflates the evidence base
without adding independent information. Additionally, assertions could
be stratified by evidence type (empirical, theoretical, review) with
configurable type-specific weights, enabling users to compute evidence
scores that privilege experimental results over theoretical commentary.
\end{block}

\begin{block}{Additional Directions}
\protect\phantomsection\label{additional-directions}
\begin{enumerate}
\item
  \textbf{Confidence calibration.} A pilot study comparing LLM-generated
  assertions with domain expert assessments would establish
  inter-annotator agreement (\(\kappa\)) and identify systematic biases.
  This is the prerequisite for all downstream improvements.
\item
  \textbf{Agentic LLM Extractors.} Drawing on recent work demonstrating
  LLMs as adaptive active inference agents \citep{heins2024active},
  replacing static prompt templates with goal-directed, actor-critic LLM
  architectures could significantly solve prevailing confidence
  calibration challenges.
\item
  \textbf{Domain adaptation.} The framework is domain-agnostic by
  design. Adaptation to foundation models, quantum computing, or
  synthetic biology requires only domain-specific hypothesis definitions
  and keyword lists within the A/B/C taxonomy.
\end{enumerate}
\end{block}
\end{frame}

\begin{frame}{Broader Impact}
\protect\phantomsection\label{broader-impact}
The vision motivating this work is straightforward: a living literature
review---a continuously updated knowledge graph tracking what a field
claims, what evidence supports those claims, and where the frontiers of
understanding lie. This vision builds on the foundation established by
Knight et al.~\citep{knight2022fep}, who identified the development of
systems that could ``encompass increased scope of relevant works,''
``integrate multiple forms of annotation and participation,'' and
``facilitate integration of manual and artificial contributions'' as key
goals for the field.

By demonstrating that LLM-driven assertion extraction can produce
scalable, queryable representations of scientific evidence---processing
\(N = 1208\) papers spanning nearly five decades (1972--2026),
extracting structured semantic assertions, and systematically evaluating
8 core hypotheses---this work provides a robust computational machinery
for realizing this vision. The generated citation network metrics
(2\{,\}780 edges, a density of 0.19\%, and an average in-degree of 2.3)
quantify the rapid expansion of the active inference ecosystem, which
has grown to a 6.63\% CAGR while diversifying across 5 major application
domains.

Crucially, the inherent limitations of keyword-based retrieval across
disjoint academic repositories dictate that any retrieved corpus will
contain both false positives and false negatives. There is no single
methodological threshold capable of perfectly defining inclusion or
exclusion for a dynamic, interdisciplinary research field. Therefore,
the primary contribution of this work is not simply a definitive
``golden list'' of papers. Rather, it is an open-source, modularly
updatable, and versioned software package. This tool is built in
reference to custom literature bibliographies that can be iteratively
curated for relevance through time by the community.

The combination of multi-source retrieval, LLM-based extraction, and
probabilistic knowledge graph construction provides a reusable template
that advances each of these goals. As LLM capabilities improve and
standardized metadata adoption grows, the cost of maintaining such
systems will decrease while their utility increases. By open-sourcing
the pipeline and publishing the schema, we provide both a concrete tool
for the Active Inference community and a modular blueprint that other
fields can adapt and refine.

Community recommendations, actionable implications, and open questions
arising from this work are detailed in the Discussion (see
\hyperref[sec:discussion]{Section 5a}).
\end{frame}

\end{document}
