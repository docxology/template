% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
  ignorenonframetext,
]{beamer}
\newif\ifbibliography
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% remove section numbering
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{section title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{subsection title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{\texorpdfstring{}{}}
\date{}

\begin{document}

\section{\texorpdfstring{Discussion: Implications and Community
Recommendations
\label{sec:discussion}}{Discussion: Implications and Community Recommendations }}\label{discussion-implications-and-community-recommendations}

\begin{frame}{Tactical and Strategic Priorities}
\protect\phantomsection\label{tactical-and-strategic-priorities}
\begin{block}{Demand Rigorous Reporting Metadata}
\protect\phantomsection\label{demand-rigorous-reporting-metadata}
Papers must systematically report DOIs, ORCIDs, and explicit hypothesis
commitments. To prevent fragmented citation subgraphs, submitted
preprints must rigorously forward-link to their definitive published
versions. Our extraction pipeline prioritizes the DOI as the apex
canonical identifier; failing that, deduplication cascades to arXiv IDs,
Semantic Scholar IDs, and OpenAlex IDs. Systemic DOI adoption
fundamentally solves the cross-source mismatch barrier, enabling
high-resolution evidence mapping.
\end{block}

\begin{block}{Deploy Open Knowledge Graph Infrastructure}
\protect\phantomsection\label{deploy-open-knowledge-graph-infrastructure}
We advocate the deployment of a federated nanopublication server
architecture to house community-contributed assertions, birthing an
uninterrupted, living literature review that seamlessly updates as
adjacent work publishes. Interlocking this pipeline with the Active
Inference Institute's operational Knowledge-Engineering infrastructure
\citep{knight2022fep} would furnish the standardized semantic vocabulary
necessary for flawless cross-study comparison.
\end{block}

\begin{block}{Standardize the Ontological Lexicon}
\protect\phantomsection\label{standardize-the-ontological-lexicon}
Immediate future extraction cycles must structurally align assertion
predicates against the formally curated Active Inference Ontology.
Enforcing shared ontological primitives across disparate studies will
dramatically accelerate the direct mathematical aggregation of evidence
spanning siloed research enclaves, actualizing the ultimate
interoperability goal mapped by Knight et al.~\citep{knight2022fep}.
\end{block}
\end{frame}

\begin{frame}{Empirical and Theoretical Imperatives}
\protect\phantomsection\label{empirical-and-theoretical-imperatives}
\begin{block}{Architect Unified Performance Benchmarks}
\protect\phantomsection\label{architect-unified-performance-benchmarks}
The computational tools domain (B) suffers from a critical absence of
standardized performance benchmarks preventing raw comparative
evaluation against deep reinforcement learning architectures.
Formalizing baseline metrics analogous to standard RL environments
(e.g., OpenAI Gym) is the mandatory prerequisite catalyst for
transitioning theoretical propositions into hardened applied systems.
\end{block}

\begin{block}{Aggressively Fund Empirical Validation}
\protect\phantomsection\label{aggressively-fund-empirical-validation}
Biology (C5) and Language (C3) possess profound theoretical reservoirs
but mathematically starved empirical foundations. Direct financial and
operational investment in targeted experiments validating structural FEP
mechanics---such as isolating morphogenesis strictly as Bayesian
inference---promises to multiply the aggregate evidence base far faster
than further purely theoretical iterations alone.
\end{block}
\end{frame}

\begin{frame}{Open Questions}
\protect\phantomsection\label{open-questions}
This meta-analysis surfaces questions warranting dedicated
investigation:

\begin{itemize}
\tightlist
\item
  \textbf{Classifier calibration:} What proportion of A1 papers would be
  reclassified under embedding-based or expert-annotated schemes?
\item
  \textbf{Scoring sensitivity:} How sensitive are hypothesis scores to
  the choice of weighting function? Would square-root or linear weights
  qualitatively change the evidence landscape?
\item
  \textbf{Model sensitivity:} How much do hypothesis scores vary across
  different LLM models? Are some hypotheses more robust to model choice
  than others?
\item
  \textbf{Domain boundaries:} Do domain boundaries stabilize as the
  field matures, or continue to shift? Is the 8-category (A/B/C)
  taxonomy optimal?
\item
  \textbf{Cross-hypothesis evidence:} When a neuroscience (C1) paper
  supports predictive coding, does this constitute evidence for
  scalability? How should cross-hypothesis evidence be handled?
\item
  \textbf{Temporal dynamics:} Do hypotheses follow predictable
  lifecycles (emergence → rapid support → contestation → resolution),
  and can these patterns inform research prioritization?
\end{itemize}
\end{frame}

\end{document}
