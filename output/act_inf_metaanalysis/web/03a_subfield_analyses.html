<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>03a_subfield_analyses</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<h1 id="domain-analyses-growth-trajectories-and-open-problems">Domain
Analyses: Growth Trajectories and Open Problems </h1>
<p><em>This supplementary section provides detailed characterizations of
each of the eight tracked Active Inference domains, organized under
three tiers: A (Core Theory), B (Tools &amp; Translation), and C
(Application Domains).</em></p>
<h2 id="domain-a-core-theory">Domain A: Core Theory</h2>
<h3 id="a1-quantitative-formal-theory-n-120-9.9">A1 — Quantitative &amp;
Formal Theory (<span class="math inline">\(n = 120\)</span>, 9.9%)</h3>
<p>The A1 domain develops the mathematical foundations underpinning the
Free Energy Principle: information geometry, category-theoretic
formulations of Markov blankets, path integral formulations of free
energy minimization, and gauge-theoretic perspectives on
self-organization. A central debate concerns the ontological status of
Markov blankets—whether they correspond to real physical boundaries or
are merely useful statistical constructs . Recent work on Bayesian
mechanics aims to place the FEP on firmer mathematical footing. With 120
papers, A1 captures nearly 10% of the corpus, reflecting the improved
classifier’s ability to route papers with mathematical formalism
(theorems, proofs, convergence, posterior distributions, Fokker–Planck
equations) into this domain rather than the qualitative philosophy
catch-all.</p>
<h3 id="a2-qualitative-philosophy-general-theory-n-154-12.7">A2 —
Qualitative Philosophy &amp; General Theory (<span
class="math inline">\(n = 154\)</span>, 12.7%)</h3>
<p>The A2 domain encompasses papers that develop, extend, or review the
core Free Energy Principle and Active Inference framework without
restricting attention to a specific application domain. This includes
Friston’s foundational work on variational free energy minimization ,
the textbook treatment by Parr, Pezzulo, and Friston , and numerous
tutorial and review papers. The priority-based classifier mitigates
over-assignment to A2 by routing papers with mathematical formalism to
A1 and papers with domain-specific vocabulary to C1–C5 or B before the
A2 catch-all is reached. Nevertheless, the count likely still conceals
meaningful internal structure: papers addressing embodied cognition,
Bayesian brain theory, and philosophical implications of the FEP are all
subsumed under this heading. Key ongoing debates concern the explanatory
scope of the FEP—whether it is a principle of physics, biology, or
cognition—and the relationship between active inference and competing
frameworks such as reinforcement learning and optimal control
theory.</p>
<h2 id="domain-b-tools-translation-methods">Domain B: Tools &amp;
Translation Methods</h2>
<h3 id="b-algorithms-scaling-and-software-n-267-22.1">B — Algorithms,
Scaling, and Software (<span class="math inline">\(n = 267\)</span>,
22.1%)</h3>
<p>Domain B addresses the computational challenge of making active
inference practical in complex, high-dimensional environments. Early
implementations relied on small discrete state spaces amenable to exact
message passing. Recent work has introduced deep active inference using
neural networks to amortize inference , Monte Carlo tree search for
planning , and hybrid architectures combining model-based planning with
model-free components. The central open question is whether active
inference agents can match deep reinforcement learning performance on
standard benchmarks while retaining interpretability and sample
efficiency. The availability of the pymdp library has lowered
implementation barriers, contributing to this domain’s growth. The
recent establishment of the Pymdp Fellowship program in 2025 and the
release of real-time stream processing tools like RxInfer.jl v4.0.0
indicate a vibrant and maturing software ecosystem.</p>
<h2 id="domain-c-application-domains">Domain C: Application Domains</h2>
<h3 id="c1-neuroscience-n-206-17.1">C1 — Neuroscience (<span
class="math inline">\(n = 206\)</span>, 17.1%)</h3>
<p>Neuroscience represents the historical core of the Active Inference
research program. The predictive processing account—in which cortical
hierarchies minimize prediction errors through both perceptual inference
and active sampling—remains one of the most empirically tested aspects
of the framework . The broader neuroscience literature on Dynamic Causal
Modeling and predictive coding is extensive; the relatively modest count
here likely reflects the keyword classifier’s inability to distinguish
neuroscience-specific applications from general FEP theory. Bridging the
gap between computational models and empirical neuroimaging data remains
the domain’s primary challenge.</p>
<h3 id="c2-robotics-n-170-14.1">C2 — Robotics (<span
class="math inline">\(n = 170\)</span>, 14.1%)</h3>
<p>Robotics applications treat embodied agents as free energy minimizing
systems that unify perception and action through proprioceptive and
exteroceptive prediction errors . Applications include robotic arm
control, mobile navigation, manipulation, and multi-robot coordination.
Active inference offers roboticists a principled framework for
integrating sensory processing, motor planning, and adaptive behavior
without separate perception and control modules. Key challenges include
real-time computational feasibility on embedded hardware, continuous
high-dimensional action spaces, and sim-to-real transfer.</p>
<h3 id="c3-language-processing-n-57-4.7">C3 — Language Processing (<span
class="math inline">\(n = 57\)</span>, 4.7%)</h3>
<p>The C3 domain formally conceptualizes linguistic processes—speech
perception, sentence comprehension, sequential dialogue, and reading—as
active inference operating over deep hierarchical generative models of
linguistic structure . Active inference models of reading have
deterministically accounted for saccadic eye-movement patterns, while
models of speech perception mathematically explain how human listeners
integrate topological prior expectations with continuous acoustic
evidence. Recent breakthroughs tightly couple active inference to large
language models, pragmatics, and multi-agent communication. Notably,
recent literature has conceptualized LLMs themselves as atypical active
inference agents, introducing frameworks that deploy active inference as
a metacognitive governor to enable adaptive, self-evolving LLM behavior
.</p>
<h3 id="c4-computational-psychiatry-n-34-2.8">C4 — Computational
Psychiatry (<span class="math inline">\(n = 34\)</span>, 2.8%)</h3>
<p>Computational psychiatry aggressively leverages active inference to
natively model psychiatric conditions as structural aberrations in
belief updating, precision weighting, or prior expectation rigidity .
Schizophrenia has been modeled as a critical failure of precision
weighting on bottom-up prediction errors; clinical depression
corresponds to excessively precise, inescapable negative priors; and
autism spectrum profiles as atypical sensory precision allocation. The
domain continues to expand rapidly: 2025 frameworks such as Active
Intersubjective Inference (AISI) seamlessly integrate psychodynamic
theory (e.g., self-identity formation via embodied interactions) with
predictive processing algorithms to mathematically unify the
environmental and biological factors underlying stress disorders .
Translating these expanding computational models into scalable
diagnostic markers and therapeutic real-world protocols remains an
urgent, ongoing objective.</p>
<h3 id="c5-biology-morphogenesis-n-200-16.6">C5 — Biology &amp;
Morphogenesis (<span class="math inline">\(n = 200\)</span>, 16.6%)</h3>
<p>The C5 domain applies active inference and the FEP to biological
systems beyond the brain: cellular behavior, morphogenesis, evolutionary
dynamics, and the origins of life. Morphogenetic processes have been
modeled as collective active inference, where groups of cells coordinate
to minimize a shared free energy functional . Recent models (e.g.,
MorphoNAS) demonstrate how simple rules derived from the FEP drive
“neuromorphic development,” steering systems with morphological degrees
of freedom to independently self-organize the complex neural computing
topologies fundamental to bioengineering . As the second-largest domain,
C5 reflects growing interest in extending the FEP to encompass all
living systems, though the ratio of theoretical proposals to empirical
validation remains high.</p>
<h2 id="comparative-synthesis">Comparative Synthesis</h2>
<p>Taken together, the three domains reveal a field in transition from a
focused neuroscience program to a broad interdisciplinary framework. The
core–periphery structure is clear: Domain A provides the theoretical and
mathematical substrate, Domain B pursues engineering viability through
scalable algorithms and software, and Domain C tests the framework’s
generality across neuroscience (C1), robotics (C2), language (C3),
psychiatry (C4), and biology (C5). The consistent pattern across applied
domains—strong theoretical motivation paired with limited empirical
validation—suggests that the field’s next phase of growth will be
determined less by new theory than by the accumulation of decisive
experimental evidence.</p>
<p>In direct response to <strong>RQ1</strong> (How is the Active
Inference field structured?), the domain taxonomy reveals an asymmetric
three-tier architecture: a dominant theoretical core (A), a growing
translational layer (B), and an expanding but empirically sparse
application periphery (C). The keyword classifier’s heavy A2
concentration likely masks genuine diversity within the theoretical
core, but the architecture itself—theory → tools → applications—is
robust across classification approaches.</p>
<h3 id="domainhypothesis-cross-reference">Domain–Hypothesis
Cross-Reference</h3>
<p>Each domain has a primary hypothesis linkage (see the detailed
hypothesis evidence analysis in ):</p>
<table>
<thead>
<tr>
<th>Domain</th>
<th>Category</th>
<th><span class="math inline">\(n\)</span></th>
<th>Primary Hypothesis</th>
<th>Evidence Direction</th>
</tr>
</thead>
<tbody>
<tr>
<td>A1</td>
<td>Formal</td>
<td>120</td>
<td>H3 Markov Blanket Realism</td>
<td>Contested</td>
</tr>
<tr>
<td>A2</td>
<td>Philosophy</td>
<td>154</td>
<td>H1 FEP Universality</td>
<td>Strongly supporting</td>
</tr>
<tr>
<td>B</td>
<td>Tools</td>
<td>267</td>
<td>H5 Scalability</td>
<td>Mixed</td>
</tr>
<tr>
<td>C1</td>
<td>Neuroscience</td>
<td>206</td>
<td>H4 Predictive Coding</td>
<td>Supporting</td>
</tr>
<tr>
<td>C2</td>
<td>Robotics</td>
<td>170</td>
<td>H2 AIF Optimality, H5 Scalability</td>
<td>Mixed</td>
</tr>
<tr>
<td>C3</td>
<td>Language</td>
<td>57</td>
<td>H8 Language AIF</td>
<td>Emerging</td>
</tr>
<tr>
<td>C4</td>
<td>Psychiatry</td>
<td>34</td>
<td>H6 Clinical Utility</td>
<td>Supporting</td>
</tr>
<tr>
<td>C5</td>
<td>Biology</td>
<td>200</td>
<td>H7 Morphogenesis</td>
<td>Supporting</td>
</tr>
</tbody>
</table>
<p>The evidence directions summarized above are elaborated
quantitatively—with citation-weighted scores, temporal trends, and
three-tier evidence profiling—in the hypothesis results section (see
).</p>
</body>
</html>
