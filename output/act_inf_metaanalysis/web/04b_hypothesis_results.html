<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>04b_hypothesis_results</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<h1 id="hypothesis-evidence-landscape-and-temporal-dynamics">Hypothesis
Evidence Landscape and Temporal Dynamics </h1>
<p>The LLM-based extraction pipeline produced a total of 3{,}684
assertions across the eight tracked hypotheses, drawn from the full
corpus of <span class="math inline">\(N = 1208\)</span> papers. The
distribution of assertion types and the resulting citation-weighted
scores reveal a differentiated evidence landscape:</p>
<table style="width:100%;">
<colgroup>
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr>
<th>Hypothesis</th>
<th>Score</th>
<th>Supports</th>
<th>Neutral</th>
<th>Contradicts</th>
<th>Total</th>
<th>Character</th>
</tr>
</thead>
<tbody>
<tr>
<td>H4: Predictive Coding</td>
<td><span class="math inline">\(+0.59\)</span></td>
<td>837</td>
<td>417</td>
<td>0</td>
<td>1{,}254</td>
<td>Strong consensus</td>
</tr>
<tr>
<td>H5: Scalability</td>
<td><span class="math inline">\(+0.62\)</span></td>
<td>142</td>
<td>110</td>
<td>0</td>
<td>252</td>
<td>Strong consensus</td>
</tr>
<tr>
<td>H6: Clinical Utility</td>
<td><span class="math inline">\(+0.41\)</span></td>
<td>16</td>
<td>29</td>
<td>0</td>
<td>45</td>
<td>Moderate, growing</td>
</tr>
<tr>
<td>H8: Language AIF</td>
<td><span class="math inline">\(+0.39\)</span></td>
<td>54</td>
<td>96</td>
<td>0</td>
<td>150</td>
<td>Moderate, emerging</td>
</tr>
<tr>
<td>H7: Morphogenesis</td>
<td><span class="math inline">\(+0.35\)</span></td>
<td>23</td>
<td>61</td>
<td>1</td>
<td>85</td>
<td>Moderate, emerging</td>
</tr>
<tr>
<td>H2: AIF Optimality</td>
<td><span class="math inline">\(+0.22\)</span></td>
<td>166</td>
<td>569</td>
<td>19</td>
<td>754</td>
<td>Weakly contested</td>
</tr>
<tr>
<td>H1: FEP Universality</td>
<td><span class="math inline">\(+0.16\)</span></td>
<td>297</td>
<td>1{,}071</td>
<td>2</td>
<td>1{,}370</td>
<td>Broad but diffuse</td>
</tr>
<tr>
<td>H3: Markov Blanket Realism</td>
<td><span class="math inline">\(+0.02\)</span></td>
<td>14</td>
<td>181</td>
<td>6</td>
<td>201</td>
<td>Heavily contested</td>
</tr>
</tbody>
</table>
<h2 id="interpretation-of-evidence-profiles">Interpretation of Evidence
Profiles</h2>
<p>The eight hypotheses cluster into three distinct tiers. The
<strong>consensus tier</strong> (H4, H5) comprises hypotheses with
strong positive scores (<span class="math inline">\(&gt; 0.5\)</span>)
and no contradicting assertions. Predictive coding (H4), the most
extensively assessed hypothesis with 1,254 assertions, has accumulated
uniformly supportive evidence since the 1970s, reflecting the deep
empirical grounding of hierarchical prediction error models in
neuroscience. Scalability (H5), while assessed by fewer papers, shows a
similarly strong positive trajectory that accelerated after 2017 as deep
active inference architectures emerged.</p>
<p>The <strong>moderate tier</strong> (H6, H7, H8) comprises hypotheses
with positive but lower scores (<span
class="math inline">\(0.3\)</span>–<span
class="math inline">\(0.4\)</span>). Clinical utility (H6) has the
smallest evidence base (45 assertions) but shows a temporally increasing
trend, consistent with the recent growth of computational psychiatry
applications. Language AIF (H8) and morphogenesis (H7) both show
moderate support with small contradicting evidence, reflecting their
status as active research frontiers where theoretical proposals outpace
empirical validation.</p>
<p>The <strong>diffuse or contested tier</strong> (H1, H2, H3) is the
most diagnostically informative for understanding the field’s
intellectual maturation. FEP universality (H1), despite generating the
largest raw evidence base (1,370 assertions), achieves a score of only
<span class="math inline">\(+0.16\)</span>—the vast majority of
assessments are strictly neutral, indicating that researchers frequently
<em>invoke</em> the FEP colloquially without explicitly testing its
universality claim. AIF optimality (H2) exhibits the largest volume of
contradicting evidence (19 assertions); crucially, its temporal trend
reveals a persistent decline from an early peak of <span
class="math inline">\(+0.38\)</span> (2012) to its current <span
class="math inline">\(+0.22\)</span>. This downward trajectory suggests
that as the field has transitioned from theory to empirical application,
absolute optimality claims have undergone increasingly stringent
critical scrutiny. Markov blanket realism (H3) remains the most heavily
contested hypothesis, exhibiting a near-zero aggregated score (<span
class="math inline">\(+0.02\)</span>) with six contradicting assertions
effectively neutralizing 14 supporting ones—empirically capturing the
intense, ongoing philosophical debate over whether Markov blankets
denote real thermodynamic boundaries or merely represent instrumental
statistical constructs.</p>
<h2 id="temporal-dynamics-of-evidence-accumulation">Temporal Dynamics of
Evidence Accumulation</h2>
<p>The cumulative evidence timeline (Figure <span
class="math inline">\(\ref{fig:evidence_timeline}\)</span>) reveals
three temporal patterns. First, <strong>early convergence</strong>: H4
(predictive coding) reached positive territory in the late 1970s and has
maintained a stable, high score since, reflecting the mature empirical
base in cognitive neuroscience. Second, <strong>recent
acceleration</strong>: H5 (scalability) and H6 (clinical utility) show
steep upward trends after 2017, tracking the emergence of deep active
inference tools and computational psychiatry applications. Third,
<strong>persistent contestation</strong>: H3 (Markov blanket realism)
has oscillated near zero since 2018, with gains from supporting papers
offset by targeted critiques.</p>
<h2 id="assertion-composition-and-distribution">Assertion Composition
and Distribution</h2>

<h2 id="limitations-of-the-current-scoring-approach">Limitations of the
Current Scoring Approach</h2>
<p>As noted in Section 2, these results reflect a <strong>tally-based
aggregation</strong> of independent LLM-extracted assertions, weighted
by citation count and confidence. This approach does not account for
evidential dependencies (e.g., papers from the same group testing the
same model), does not distinguish between empirical and theoretical
evidence, and treats the LLM’s confidence scores as calibrated
probabilities. The assertion counts are also sensitive to corpus
composition: H1’s large neutral tally (1,071) partially reflects the
keyword classifier’s tendency to assign papers to the broad A2
(philosophy) category, where FEP universality is implicitly invoked but
rarely explicitly tested. More sophisticated approaches—including
hierarchical Bayesian models, causal evidence graphs, and evidential
diversity weighting—are discussed as future directions in Section 5.</p>
</body>
</html>
