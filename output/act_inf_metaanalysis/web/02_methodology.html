<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>02_methodology</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<h1 id="methodology-pipeline-design-and-formal-definitions">Methodology:
Pipeline Design and Formal Definitions</h1>
<p>This section describes the six components of our computational
meta-analysis pipeline: literature retrieval, canonical deduplication,
LLM-based assertion extraction, probabilistic knowledge graph
construction, hypothesis scoring, and end-to-end orchestration. The
pipeline extends the systematic literature analysis approach of Knight
et al. —which combined manual annotation with ontology-based automated
analysis—by substituting manual coding with fully automated, LLM-driven
assertion extraction and citation-weighted hypothesis scoring.</p>
<h2 id="multi-source-literature-retrieval">Multi-Source Literature
Retrieval</h2>
<p>We retrieve papers from three complementary academic databases to
maximize coverage and enable cross-source deduplication:</p>
<p><strong>arXiv.</strong> We query the arXiv Atom API using the
phrase-matched search
<code>all:"active inference" OR all:"free energy principle"</code>. The
<code>all:</code> prefix searches titles, abstracts, and full text;
phrase matching reduces contamination from unrelated physics papers that
mention “free energy” in thermodynamic contexts.</p>
<p><strong>Semantic Scholar.</strong> We query the Semantic Scholar
Graph API with the same terms. Semantic Scholar provides citation
graphs, abstract embeddings, and links to published versions. Retry
logic with exponential backoff handles rate limiting.</p>
<p><strong>OpenAlex.</strong> We query OpenAlex to capture
journal-published work that may not appear on arXiv, including clinical
studies and neuroscience experiments in domain-specific venues. The
<code>referenced_works</code> field populates citation links for each
paper.</p>
<p>After retrieval, papers are assigned a canonical identifier using the
priority scheme: DOI <span class="math inline">\(&gt;\)</span> arXiv ID
<span class="math inline">\(&gt;\)</span> Semantic Scholar ID <span
class="math inline">\(&gt;\)</span> OpenAlex ID <span
class="math inline">\(&gt;\)</span> title hash. When the same paper
appears in multiple sources, the record with the highest metadata
completeness is retained. This deduplication produces <span
class="math inline">\(N = 1208\)</span> unique papers spanning
1972–2026.</p>
<h3 id="curation-and-keyword-limitations">Curation and Keyword
Limitations</h3>
<p>We emphasize that this process relies fundamentally on keyword search
strategies across divergent APIs. In any complex research field, there
is no single optimal word or threshold for definitive inclusion or
exclusion. Different information sources and repositories yield
differing schemas and representations, inevitably introducing both false
positives (extraneous papers overlapping in terminology, such as
unrelated database or biological toolkits) and false negatives (relevant
papers employing alternative nomenclature without standard
keywords).</p>
<p>Consequently, this pipeline is not intended to produce a static,
“golden” list of canonical papers. Rather, it is designed as an
open-source software package that can be modularly updated and
versioned. Researchers can configure the pipeline to operate on custom
literature bibliographies curated for specific relevance criteria
through time, treating the initial query-based retrieval as a
programmatic starting point rather than an absolute boundary.</p>
<h2 id="canonical-identifier-deduplication">Canonical Identifier
Deduplication</h2>
<p>For each incoming paper, we compute a canonical ID applying the
cascading priority scheme detailed above. Should a paper with an
identical canonical ID already exist within the dataset, the two records
are comparatively evaluated on metadata completeness—defined as the
count of non-empty attributes among {abstract, DOI, arXiv ID, venue,
citation count}. The pipeline reliably retains the structurally richer
record; in the event of a tie, the incumbent is preserved. This
“merge-on-add” strategy automatically aggregates the richest available
metadata without mandating an expensive downstream reconciliation
pass.</p>
<p>The priority hierarchy naturally tracks bibliographic realities: DOIs
serve as the most stable cross-platform identifiers; arXiv IDs guarantee
consistency across the preprint ecosystem; source-specific API IDs serve
as reliable fallbacks; and exact title hashing provides a robust final
failsafe for edge case papers devoid of structured identifiers.</p>
<p>After deduplication, a <strong>relevance filter</strong> removes
papers whose titles and abstracts lack any core Active Inference
terminology (e.g., <code>active inference,''</code>free energy
principle,’’ ``variational free energy’’), eliminating off-topic results
introduced by broad keyword overlap across heterogeneous databases.</p>
<h2 id="llm-based-assertion-extraction">LLM-Based Assertion
Extraction</h2>
<p>We extract assertions by prompting a locally hosted LLM (Ollama ) to
assess each paper’s abstract against eight standard hypotheses. The
model receives a structured prompt containing the paper title, abstract,
and hypothesis definitions, and returns a JSON array where each element
specifies a hypothesis ID, direction (supports, contradicts, neutral, or
irrelevant), a confidence score <span class="math inline">\(c \in [0,
1]\)</span>, and a reasoning string. Assertions marked “irrelevant” are
discarded; confidence values are clamped to <span
class="math inline">\([0, 1]\)</span>; and responses are validated
against the known hypothesis ID set. Papers lacking abstracts are
skipped.</p>
<p>Each assertion is encoded as a nanopublication —formally, a tuple
<span class="math inline">\((p, h, d, c)\)</span> where <span
class="math inline">\(p\)</span> is the paper identifier, <span
class="math inline">\(h\)</span> the hypothesis identifier, <span
class="math inline">\(d \in \{\text{supports}, \text{contradicts},
\text{neutral}\}\)</span> the direction, and <span
class="math inline">\(c\)</span> the confidence. Provenance metadata
records the LLM model, timestamp, and paper identifier.</p>
<h2 id="subfield-classification">Subfield Classification</h2>
<p>Each paper is classified into one of eight categories organized
across three domains: <strong>A – Core Theory</strong> (A1: quantitative
and formal mathematical theory; A2: qualitative philosophy and general
FEP theory), <strong>B – Tools &amp; Translation</strong> (algorithms,
scaling, and software development), and <strong>C – Application
Domains</strong> (C1: neuroscience, C2: robotics, C3: language
processing, C4: computational psychiatry, C5: biology and
morphogenesis). Classification uses word-boundary-aware keyword matching
against curated lists applied to titles and abstracts. A priority system
ensures that specific application domains (C1–C5, priority 1) take
precedence over tools (B, priority 2), formal theory (A1, priority 3),
and the broad qualitative philosophy catch-all (A2, priority 4). Within
a priority tier, the domain with the most keyword matches wins. A1’s
keyword set includes mathematical indicators such as <em>theorem</em>,
<em>proof</em>, <em>convergence</em>, <em>posterior</em>,
<em>equation</em>, and <em>Fokker–Planck</em>, ensuring that papers with
mathematical content are classified as formal theory rather than
defaulting to the philosophy category.</p>
<h2 id="knowledge-graph-schema">Knowledge Graph Schema</h2>
<p>The knowledge graph is an RDF-compatible directed graph with three
node types: <strong>paper nodes</strong> (metadata: title, abstract,
authors, year, venue, citation count, domain), <strong>assertion
nodes</strong> (claim text, direction, hypothesis ID, confidence), and
<strong>hypothesis nodes</strong> (the eight standard hypotheses). Edges
encode three relations: <code>aif:asserts</code> (paper <span
class="math inline">\(\to\)</span> assertion), <code>aif:cites</code>
(paper <span class="math inline">\(\to\)</span> paper), and
<code>aif:supports</code>/<code>aif:contradicts</code> (assertion <span
class="math inline">\(\to\)</span> hypothesis). The namespace
<code>http://activeinference.org/ontology/</code> defines all
predicates.</p>
<p>The graph is serialized using rdflib and persisted as JSON Lines,
with the schema designed for migration to full RDF triplestores.</p>
<h2 id="citation-weighted-hypothesis-scoring">Citation-Weighted
Hypothesis Scoring</h2>
<p>For each hypothesis <span class="math inline">\(H\)</span>, we
compute a citation-weighted evidence score:</p>
<p><span class="math display">\[
\text{score}(H) = \frac{\sum_{a \in S(H)} w(a) - \sum_{a \in C(H)}
w(a)}{\sum_{a \in A(H)} w(a)}
\]</span></p>
<p>where <span class="math inline">\(S(H)\)</span>, <span
class="math inline">\(C(H)\)</span>, and <span
class="math inline">\(A(H)\)</span> are the sets of supporting,
contradicting, and all assertions for <span
class="math inline">\(H\)</span>, and the weight function is:</p>
<p><span class="math display">\[
w(a) = \log(1 + \text{citations}(a)) \cdot \text{confidence}(a)
\]</span></p>
<p>The logarithmic citation weighting ensures that highly cited papers
carry more influence without allowing any single paper to dominate. The
score lies in <span class="math inline">\([-1, 1]\)</span>. Temporal
trends are computed by evaluating the cumulative score at each year,
using only assertions from papers published up to that year. A full
derivation appears in the Technical Appendix (A.1).</p>
<h2 id="tally-based-evidence-aggregation">Tally-Based Evidence
Aggregation</h2>
<p>We emphasize that this algorithmic scoring formula constitutes a
<strong>tally-based approach</strong> to evidence synthesis: each
nanopublication assertion operates as an independent evidential vote,
mathematically weighted by citation impact and the extraction model’s
semantic confidence. The aggregation is deliberately linear and
additive—supporting and contradicting assertions are summed and
differenced, independent from modeling dependencies, correlated evidence
clustering, or topological causal structure among claims. This
intentional design choice prioritizes operational transparency, rigorous
reproducibility, and computational tractability over abstract
statistical sophistication.</p>
<p>The tally-based framing introduces three distinct constraints. First,
assertions extracted from methodologically related papers (e.g.,
iterative publications originating from a single research group
validating the same structural model) are counted identically and
independently, inherently amplifying correlated evidence. Second, the
scoring metric imposes symmetrical treatment across assertion source
types: an affirmative assertion parsed from a theoretical review and one
sourced from an empirical randomized controlled trial carry equivalent
leverage at a matched confidence bound. Finally, temporal scoring tracks
<em>cumulative running totals</em> rather than dynamic probabilistic
estimates; the score at year <span class="math inline">\(t\)</span>
computes the absolute integrated momentum of all historical evidence,
rather than a decaying posterior that incrementally downweights early
foundational texts.</p>
<p>We embrace these constraints deliberately. The tally-based execution
furnishes a stable, highly interpretable baseline upon which superior
configurations can be systematically evaluated. Section 5 scopes these
concrete extensions—specifically encompassing hierarchical Bayesian
scoring frameworks, causal evidence directed acyclic graphs (DAGs), and
evidential diversity indices that geometrically constrain correlated
research amplification.</p>
<h2 id="growth-rate-estimation">Growth-Rate Estimation</h2>
<p>We estimate field dynamics via two complementary metrics. The
<strong>mean year-over-year growth rate</strong> <span
class="math inline">\(\bar{g}\)</span> is the arithmetic mean of annual
growth rates for years with non-zero prior-year publications. The
<strong>doubling time</strong> <span class="math inline">\(t_d = \ln 2 /
\ln(1 + \bar{g})\)</span>. The <strong>compound annual growth
rate</strong> (CAGR) captures the annualized rate across the full
temporal span. Mathematical details are provided in the Technical
Appendix (A.3).</p>
<h2 id="pipeline-architecture-and-reproducibility">Pipeline Architecture
and Reproducibility</h2>
<p>The complete pipeline operates in five stages:</p>
<ol type="1">
<li><p><strong>Literature Search</strong>
(<code>01_literature_search.py</code>). Query arXiv, Semantic Scholar,
and OpenAlex; merge into a deduplicated corpus; persist as
JSONL.</p></li>
<li><p><strong>Meta-Analysis</strong>
(<code>02_meta_analysis_pipeline.py</code>). Classify domains (A/B/C);
compute temporal metrics; build TF-IDF matrix ; extract NMF topics ;
construct citation network; compute network metrics.</p></li>
<li><p><strong>Knowledge Graph</strong>
(<code>03_build_knowledge_graph.py</code>). Extract LLM-based assertions
from abstracts; wrap in nanopublications; score hypotheses; compute
temporal trends. Assertions are <strong>incrementally saved</strong> to
<code>nanopublications.jsonl</code> at configurable checkpoint intervals
(default: every 50 papers), enabling the pipeline to resume from where
it left off after interruption without re-processing already-analyzed
papers.</p></li>
<li><p><strong>Figure Generation</strong>
(<code>04_generate_figures.py</code>). Render 16 publication-ready
visualizations from analysis outputs: field summary, domain
distribution, growth curve, domain timeline, citation network, degree
distribution, hypothesis dashboard, evidence timeline, assertion
breakdown, assertion summary, word cloud, PCA embeddings, term heatmap,
dendrogram, topic-term bars, and co-occurrence matrix.</p></li>
<li><p><strong>Variable Injection</strong>
(<code>05_inject_variables.py</code>). Compute dynamic variables from
pipeline outputs (e.g., corpus counts, temporal metrics, hypothesis
scores) and inject them into the manuscript Markdown templates.</p></li>
</ol>
<p>All computation resides in tested library modules; scripts act as
thin orchestrators that import methods and handle file I/O. The test
suite uses real data and computation without mocking. The pipeline is
deterministic given fixed random seeds and API responses. Source code,
configuration, and outputs are available under CC-BY-4.0.</p>
</body>
</html>
