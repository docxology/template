<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>01_introduction</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<h1
id="introduction-evidence-gaps-in-a-rapidly-expanding-field">Introduction:
Evidence Gaps in a Rapidly Expanding Field</h1>
<h2 id="the-free-energy-principle-and-active-inference-framework">The
Free Energy Principle and Active Inference Framework</h2>
<p>The Free Energy Principle (FEP), introduced by Karl Friston, proposes
that self-organizing systems maintain their structural and functional
integrity by minimizing variational free energy—an upper bound on
sensory surprise . Under this principle, living systems are cast as
approximate Bayesian inference engines that build generative models of
their environment and act to reduce the discrepancy between predicted
and observed states. Active Inference (AIF) extends this picture from
passive perception to goal-directed behavior: agents select actions that
bring about observations consistent with their preferred states,
unifying perception, learning, and decision-making within a single
variational framework . Since its initial formulation for sensorimotor
control, AIF has been applied to navigation, visual foraging, language
comprehension, social cognition, and multi-agent coordination.</p>
<h2 id="challenges-posed-by-rapid-literature-growth">Challenges Posed by
Rapid Literature Growth</h2>
<p>The active inference literature has expanded exponentially over the
past two decades, sustaining peak publication volumes into the late
2020s. While early research concentrated almost exclusively on
theoretical neuroscience, the field has since diversified across biology
(C5), robotics (C2), computational psychiatry (C4), algorithm scaling
(B), and formal mathematics (A1). This rapid, multi-disciplinary growth
creates three interrelated challenges. First, tracking which core
theoretical claims—such as FEP universality or the physical realism of
Markov blankets—are deeply supported, contested, or merely assumed
becomes intractable. Second, because the relationship between
mathematical formalisms and empirical evidence remains frequently
implicit, systematic evidence synthesis demands prohibitive manual
labor. Third, new entrants must navigate a literature heavily weighted
toward broad qualitative philosophy (A2), interspersed with rapidly
accelerating, highly specialized applied pockets.</p>
<p>Traditional narrative reviews attempt to address these challenges but
are inherently static, subjective, and quickly outdated. Systematic
reviews from evidence-based medicine offer rigorous aggregation but are
structurally customized for clinical trial data with homogeneous outcome
measures, rendering them ill-suited for the heterogeneous ontological
and computational claims endemic to this theoretical literature. The
expansion of predictive processing and the emergence of formal
parameterizations like Bayesian mechanics further broaden the scope of
assertions that any comprehensive meta-analysis must reconcile.</p>
<h2 id="related-work-and-prior-meta-analyses">Related Work and Prior
Meta-Analyses</h2>
<p>Several prior efforts have surveyed aspects of the Active Inference
landscape. Sajid et al.  compare active inference with alternative
decision-making frameworks; Da Costa et al.  synthesize the
discrete-state-space formulation; Lanillos et al.  survey robotics
applications; Smith et al.  provide a tutorial bridging theory and
empirical data; and Millidge et al.  examine information-theoretic
foundations of exploration behavior. Ramstead et al.  extend the FEP to
questions of biological self-organization, while Pezzulo et al.  connect
active inference to homeostatic regulation.</p>
<p>Closest to our work, Knight, Cordes, and Friedman conducted a
systematic literature analysis of publications using the terms “Free
Energy Principle” or “Active Inference,” with an emphasis on works by
Karl J. Friston. Their analysis—maintained by the Active Inference
Institute—combined manual annotation of structural, visual, and
mathematical features with automated analyses using the Active Inference
Ontology at the scale of thousands of citations and hundreds of
annotated papers. That study identified six development
directions—including broader scope, richer annotation, and transferable
approaches—and represents an important precursor to automated
meta-analysis of this field.</p>
<p>These works are primarily narrative reviews: they synthesize
qualitative findings but do not strictly quantify the balance of
evidence across the field’s central claims. The systematic analysis of
Knight et al.  pioneered quantitative literature analysis for this field
using manual annotation and ontology-based automated analysis. Our
framework advances this line of work by (1) fully automating assertion
extraction via LLM-based hypothesis scoring, (2) constructing a
structured, RDF-compatible knowledge graph scored by citation-weighted
evidence, and (3) tracking how evidence for core claims evolves over
time through temporal trend analysis.</p>
<h2 id="synergizing-knowledge-graphs-and-llms">Synergizing Knowledge
Graphs and LLMs</h2>
<p>Recent systematic literature initiatives underscore a powerful
reciprocal synergy between Large Language Models (LLMs) and Knowledge
Graphs: LLMs parse unstructured text to rapidly extract semantic claims,
efficiently populating the structured, queryable architecture of the
graph . We adopt the <em>nanopublication</em> —a minimal,
machine-readable unit of scientific evidence comprising a core assertion
bound to explicit provenance metadata—as the fundamental serialization
format for this extracted knowledge.</p>
<h2 id="this-study-approach-and-overview">This Study: Approach and
Overview</h2>
<p>This paper presents a computational meta-analysis of the Active
Inference literature (<span class="math inline">\(N = 1208\)</span>).
Rather than relying exclusively on bibliometric metadata or slow manual
coding, we deploy a Large Language Model (LLM) to “read” each paper’s
abstract and assess its relationship to eight core hypotheses within the
FEP paradigm. We serialize these assessments as nanopublications—each
encoding an assertion (“Paper X supports Hypothesis Y”) coupled with the
LLM’s natural-language reasoning and confidence score. The resulting
knowledge graph aggregates these nanopublications and links them to
paper metadata, citation networks, subfield classifications, and
hypothesis definitions. A citation-weighted scoring formula quantifies
the net evidence for or against each hypothesis, producing scores in
<span class="math inline">\([-1, 1]\)</span> that reflect both the
direction and strength of published evidence.</p>
<h2 id="research-questions">Research Questions</h2>
<p>This meta-analysis addresses four primary research questions:</p>
<ol type="1">
<li><strong>RQ1 (Field Structure):</strong> What is the disciplinary
structure and growth trajectory of the Active Inference literature, and
how are papers distributed across the three domains—Core Theory (A),
Tools &amp; Translation (B), and Application Domains (C)?</li>
<li><strong>RQ2 (Growth Dynamics):</strong> What are the temporal growth
dynamics of the field, and which subfields are experiencing the most
rapid expansion?</li>
<li><strong>RQ3 (Hypothesis Evidence):</strong> What is the current
balance of evidence for and against the eight standard hypotheses, and
how has this balance evolved over time? (See hypothesis dashboard and
assertion figures in §4.)</li>
<li><strong>RQ4 (Tooling Readiness):</strong> What is the state of
software tooling and infrastructure for Active Inference research, and
what gaps remain?</li>
</ol>
<h2 id="scope-and-delimitations">Scope and Delimitations</h2>
<p>This study focuses on the English-language peer-reviewed and preprint
literature retrievable from arXiv, Semantic Scholar, and OpenAlex. We do
not include book chapters or monographs not indexed by these sources,
software documentation, or non-English publications. Domain
classification uses keyword matching rather than expert annotation—a
deliberate trade-off favoring reproducibility over precision, whose
consequences we quantify in Section 3. Hypothesis scoring relies on
LLM-extracted assertions; the fidelity and limitations of this approach
are examined in Section 4a. The hypothesis definitions and domain
taxonomy are informed by, but not identical to, the Active Inference
Ontology used by Knight et al. ; future alignment would enable direct
comparison with that earlier analysis.</p>
<h2 id="principal-contributions">Principal Contributions</h2>
<p>This work makes five contributions:</p>
<ol type="1">
<li><p><strong>A multi-source retrieval and deduplication
pipeline</strong> for Active Inference literature, using a canonical
identifier hierarchy across three academic databases.</p></li>
<li><p><strong>A nanopublication-based knowledge graph schema</strong>
encoding directed, confidence-scored assertions about eight core
hypotheses with full provenance tracking.</p></li>
<li><p><strong>A quantitative field overview</strong> characterizing the
growth, domain distribution (A/B/C taxonomy), citation topology, and
latent topic structure of the Active Inference literature.</p></li>
<li><p><strong>An LLM-based hypothesis scoring dashboard</strong> that
produces differentiated evidence profiles with temporal trend
visualization.</p></li>
<li><p><strong>A tooling assessment</strong> of the software ecosystem
supporting Active Inference research, including the implemented
extraction pipeline, existing software (pymdp, SPM, RxInfer.jl), and
knowledge graph infrastructure.</p></li>
</ol>
<p>The remainder of this paper is organized as follows. Section 2
describes the methodology. Section 3 presents the field overview with
domain-level analysis (RQ1, RQ2), supplemented by detailed domain
analyses (§3a), text analytics (§3b), and citation network topology
(§3c). Section 4 surveys the tooling landscape (RQ4) with a
supplementary extraction pipeline (§4a), and Section 4b presents the
hypothesis evidence landscape (RQ3). Section 5 concludes with
limitations and future directions; Section 5a provides community
recommendations and open questions. Appendix A provides notation,
abbreviations, and hypothesis definitions.</p>
</body>
</html>
