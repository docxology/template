\frametitle{Cross-Architecture Performance Analysis}
\protect\phantomsection\label{sec:results}
This section provides per-architecture breakdown (\cref{sec:per-arch}).
For statistical significance, see \cref{sec:statistical-validation}. For
parameter sensitivity, see \cref{sec:sensitivity}. For ablation studies
and scalability, see \cref{sec:extended-ablation}.

\begin{quote}
\textbf{Reproducibility}: All results generated by
\texttt{scripts/run\_full\_evaluation.py} →
\texttt{output/data/full\_evaluation\_results.json}.
\end{quote}

\begin{quote}
\textbf{Implementation}: All evaluation infrastructure is in
\texttt{src/evaluation/}. Key modules:
\texttt{runner.py:ExperimentRunner} orchestrates 950×6 evaluation
matrices; \texttt{roc.py} computes ROC curves and AUC with bootstrap
confidence intervals; \texttt{benchmark.py} measures latency and
throughput; \texttt{metrics.py} computes detection rates, precision,
recall, and F1 scores.
\end{quote}

\begin{block}{Per-Architecture Breakdown}
\protect\phantomsection\label{sec:per-arch}
\begin{block}{Claude Code (Hierarchical Architecture)}
\protect\phantomsection\label{sec:claude-code}
\textbf{Architecture Characteristics}:

\begin{itemize}
\item Primary agent: Orchestrator with full context
\item Sub-agents: Task-specific workers with limited scope
\item Communication: Unidirectional delegation
\item State: Centralized in orchestrator
\end{itemize}

\begin{table}[htbp]
\centering
\caption{Claude Code detection results by attack type.}
\label{tab:claude-code-detection}
\begin{tabular}{@{}llllll@{}}
\toprule
Attack Type & Baseline & Firewall & Sandbox & Tripwires & Full CIF \\
\midrule
Direct injection & 0.00 & 0.89 & 0.72 & 0.81 & 0.97 \\
Indirect injection & 0.00 & 0.82 & 0.68 & 0.78 & 0.95 \\
Nested injection & 0.00 & 0.76 & 0.65 & 0.84 & 0.94 \\
Trust exploitation & 0.00 & 0.58 & 0.71 & 0.89 & 0.92 \\
Belief manipulation & 0.00 & 0.67 & 0.79 & 0.85 & 0.94 \\
Coordination & 0.00 & 0.52 & 0.61 & 0.76 & 0.88 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Claude Code performance metrics.}
\label{tab:claude-code-perf}
\begin{tabular}{@{}llll@{}}
\toprule
Metric & Baseline & Full CIF & Delta \\
\midrule
Latency (p50) & 45ms & 52ms & +16\% \\
Latency (p95) & 112ms & 138ms & +23\% \\
Latency (p99) & 287ms & 361ms & +26\% \\
Throughput & 850 req/s & 712 req/s & $-16\%$ \\
Memory & 256MB & 312MB & +22\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Claude Code integrity preservation.}
\label{tab:claude-code-integrity}
\begin{tabular}{@{}llll@{}}
\toprule
Scenario & Baseline & With CIF & Improvement \\
\midrule
Single attack & 0.72 & 0.99 & +38\% \\
Sustained attack (1h) & 0.31 & 0.96 & +210\% \\
Multi-vector attack & 0.18 & 0.94 & +422\% \\
\bottomrule
\end{tabular}
\end{table}

\emph{These results demonstrate that Claude Code's hierarchical
architecture provides strong structural protection: the orchestrator's
centralized context enables effective firewall filtering (0.89 direct
injection detection), while unidirectional delegation limits lateral
movement. The architecture's main vulnerability appears in coordination
attacks (0.88 with full CIF), where the lack of peer communication
channels makes it harder to detect multi-agent manipulation patterns.
The 210\% improvement in sustained attack scenarios reflects the trust
calculus preventing adversaries from gradually eroding orchestrator
integrity.}
\end{block}

\begin{block}{AutoGPT (Autonomous Architecture)}
\protect\phantomsection\label{sec:autogpt}
\textbf{Architecture Characteristics}:

\begin{itemize}
\item Single agent with autonomous loop
\item Plugin-based tool access
\item Communication: Agent-to-tool
\item State: Agent working memory
\end{itemize}

\begin{table}[htbp]
\centering
\caption{AutoGPT detection results by attack type.}
\label{tab:autogpt-detection}
\begin{tabular}{@{}llllll@{}}
\toprule
Attack Type & Baseline & Firewall & Sandbox & Tripwires & Full CIF \\
\midrule
Direct injection & 0.00 & 0.91 & 0.69 & 0.77 & 0.96 \\
Indirect injection & 0.00 & 0.78 & 0.71 & 0.73 & 0.93 \\
Nested injection & 0.00 & 0.73 & 0.62 & 0.79 & 0.91 \\
Trust exploitation & 0.00 & 0.61 & 0.68 & 0.82 & 0.90 \\
Belief manipulation & 0.00 & 0.69 & 0.76 & 0.88 & 0.95 \\
Coordination & 0.00 & 0.48 & 0.55 & 0.71 & 0.85 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{AutoGPT performance metrics.}
\label{tab:autogpt-perf}
\begin{tabular}{@{}llll@{}}
\toprule
Metric & Baseline & Full CIF & Delta \\
\midrule
Latency (p50) & 89ms & 108ms & +21\% \\
Latency (p95) & 234ms & 295ms & +26\% \\
Latency (p99) & 512ms & 658ms & +29\% \\
Throughput & 420 req/s & 338 req/s & $-20\%$ \\
Memory & 384MB & 467MB & +22\% \\
\bottomrule
\end{tabular}
\end{table}

\emph{AutoGPT's autonomous architecture with plugin-based tool access
creates a distinctive vulnerability profile. The single-agent design
makes direct injection highly detectable (0.91 firewall), but the plugin
interface creates significant exposure to indirect attacks through tool
responses---explaining the lower indirect injection detection (0.78
firewall-only). The belief manipulation detection is notably strong
(0.95 with CIF) because tripwires can monitor the agent's persistent
working memory for unauthorized changes. The 20\% throughput reduction
is higher than Claude Code due to the overhead of validating plugin
interactions.}
\end{block}

\begin{block}{CrewAI (Role-Based Architecture)}
\protect\phantomsection\label{sec:crewai}
\textbf{Architecture Characteristics}:

\begin{itemize}
\item Multiple agents with defined roles
\item Sequential task handoff
\item Communication: Role-to-role messaging
\item State: Shared task context
\end{itemize}

\begin{table}[htbp]
\centering
\caption{CrewAI detection results by attack type.}
\label{tab:crewai-detection}
\begin{tabular}{@{}llllll@{}}
\toprule
Attack Type & Baseline & Firewall & Sandbox & Tripwires & Full CIF \\
\midrule
Direct injection & 0.00 & 0.87 & 0.74 & 0.83 & 0.97 \\
Indirect injection & 0.00 & 0.80 & 0.70 & 0.79 & 0.94 \\
Nested injection & 0.00 & 0.74 & 0.67 & 0.82 & 0.93 \\
Trust exploitation & 0.00 & 0.65 & 0.73 & 0.91 & 0.94 \\
Belief manipulation & 0.00 & 0.72 & 0.81 & 0.86 & 0.95 \\
Coordination & 0.00 & 0.59 & 0.64 & 0.79 & 0.91 \\
\bottomrule
\end{tabular}
\end{table}

\emph{CrewAI's role-based architecture shows particularly strong trust
exploitation detection (0.94 with CIF)---the highest among all
architectures. This reflects the benefit of explicit role definitions:
when an agent attempts to operate outside its assigned role, the
deviation is structurally detectable. The tripwires mechanism (0.91 for
trust exploitation) is especially effective because role boundaries
provide natural canary placement points. Sequential task handoff also
aids provenance tracking, as each role transition creates a clear
attestation checkpoint.}
\end{block}

\begin{block}{LangGraph (Graph-Based Architecture)}
\protect\phantomsection\label{sec:langgraph}
\textbf{Architecture Characteristics}:

\begin{itemize}
\item Nodes as agents or functions
\item Edges define transitions
\item Communication: State machine protocol
\item State: Graph state object
\end{itemize}

\begin{table}[htbp]
\centering
\caption{LangGraph detection results by attack type.}
\label{tab:langgraph-detection}
\begin{tabular}{@{}llllll@{}}
\toprule
Attack Type & Baseline & Firewall & Sandbox & Tripwires & Full CIF \\
\midrule
Direct injection & 0.00 & 0.92 & 0.76 & 0.85 & 0.98 \\
Indirect injection & 0.00 & 0.85 & 0.73 & 0.81 & 0.96 \\
Nested injection & 0.00 & 0.79 & 0.69 & 0.86 & 0.95 \\
Trust exploitation & 0.00 & 0.67 & 0.75 & 0.88 & 0.93 \\
Belief manipulation & 0.00 & 0.74 & 0.82 & 0.89 & 0.96 \\
Coordination & 0.00 & 0.61 & 0.67 & 0.82 & 0.92 \\
\bottomrule
\end{tabular}
\end{table}

\emph{LangGraph achieves the highest overall detection rates (0.98
direct injection, 0.96 indirect), benefiting from its explicit state
machine architecture. The graph structure makes attack propagation paths
formally traceable---each edge represents a potential attack vector that
can be monitored. The state machine protocol also enables CIF's
invariant checking (INV-1 through INV-5) to be expressed as state
transition constraints, catching violations that would be implicit in
other architectures. The coordination attack detection (0.92) benefits
from the graph's visibility into multi-node interaction patterns.}
\end{block}

\begin{block}{MetaGPT (SOP-Driven Architecture)}
\protect\phantomsection\label{sec:metagpt}
\textbf{Architecture Characteristics}:

\begin{itemize}
\item Agents follow Standard Operating Procedures
\item Document-based communication
\item Structured role interactions
\item State: Shared document repository
\end{itemize}

\begin{table}[htbp]
\centering
\caption{MetaGPT detection results by attack type.}
\label{tab:metagpt-detection}
\begin{tabular}{@{}llllll@{}}
\toprule
Attack Type & Baseline & Firewall & Sandbox & Tripwires & Full CIF \\
\midrule
Direct injection & 0.00 & 0.86 & 0.71 & 0.80 & 0.95 \\
Indirect injection & 0.00 & 0.79 & 0.67 & 0.76 & 0.92 \\
Nested injection & 0.00 & 0.72 & 0.64 & 0.81 & 0.91 \\
Trust exploitation & 0.00 & 0.63 & 0.70 & 0.87 & 0.91 \\
Belief manipulation & 0.00 & 0.68 & 0.77 & 0.84 & 0.93 \\
Coordination & 0.00 & 0.55 & 0.62 & 0.77 & 0.89 \\
\bottomrule
\end{tabular}
\end{table}

\emph{MetaGPT's SOP-driven architecture presents a mixed security
profile. The document-based communication creates natural sandboxing
opportunities---each document can be quarantined and validated before
affecting agent beliefs. However, the structured role interactions
following Standard Operating Procedures make the system somewhat
predictable to adversaries, reflected in lower detection rates compared
to LangGraph. The shared document repository is both a strength
(centralized monitoring) and weakness (single point of attack) for
belief manipulation defense.}
\end{block}

\begin{block}{Camel (Debate Architecture)}
\protect\phantomsection\label{sec:camel}
\textbf{Architecture Characteristics}:

\begin{itemize}
\item Two or more adversarial agents
\item Debate-style interaction
\item Communication: Point-counterpoint
\item State: Debate transcript
\end{itemize}

\begin{table}[htbp]
\centering
\caption{Camel detection results by attack type.}
\label{tab:camel-detection}
\begin{tabular}{@{}llllll@{}}
\toprule
Attack Type & Baseline & Firewall & Sandbox & Tripwires & Full CIF \\
\midrule
Direct injection & 0.00 & 0.83 & 0.68 & 0.78 & 0.94 \\
Indirect injection & 0.00 & 0.76 & 0.64 & 0.74 & 0.91 \\
Nested injection & 0.00 & 0.69 & 0.61 & 0.79 & 0.89 \\
Trust exploitation & 0.00 & 0.71 & 0.76 & 0.85 & 0.92 \\
Belief manipulation & 0.00 & 0.65 & 0.73 & 0.82 & 0.91 \\
Coordination & 0.00 & 0.62 & 0.68 & 0.84 & 0.93 \\
\bottomrule
\end{tabular}
\end{table}

\emph{Camel's debate architecture shows the most distinctive security
characteristics. The adversarial design---where agents argue opposing
positions---creates inherent resilience to some attack types: trust
exploitation detection (0.92) benefits from agents naturally challenging
each other's claims. Paradoxically, the peer-to-peer equal-trust
topology creates vulnerability to lateral movement, explaining the lower
direct injection detection (0.83 firewall) compared to hierarchical
systems. The coordination attack detection (0.93) is surprisingly strong
because the debate transcript provides a complete audit trail of
inter-agent influence. Camel showed the largest relative improvement
with CIF deployment, validating that peer-to-peer architectures benefit
most from structured trust calculus.}
\end{block}
\end{block}

\begin{block}{Statistical Significance Tests}
\protect\phantomsection\label{sec:significance}
\begin{block}{Primary Hypothesis Tests}
\protect\phantomsection\label{sec:primary-tests}
\textbf{H1: CIF detection rate exceeds baseline}

\begin{table}[htbp]
\centering
\caption{Hypothesis test results: CIF vs Baseline.}
\label{tab:h1-tests}
\begin{tabular}{@{}llllll@{}}
\toprule
Comparison & $n$ & Mean Diff & SE & $t$-statistic & $p$-value \\
\midrule
CIF vs Baseline (all) & 950 & 0.94 & 0.02 & 47.3 & $<$0.0001 \\
CIF vs Baseline (injection) & 500 & 0.96 & 0.018 & 53.1 & $<$0.0001 \\
CIF vs Baseline (trust) & 200 & 0.91 & 0.028 & 32.5 & $<$0.0001 \\
CIF vs Baseline (belief) & 150 & 0.93 & 0.032 & 29.1 & $<$0.0001 \\
CIF vs Baseline (coord) & 100 & 0.89 & 0.041 & 21.7 & $<$0.0001 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{H2: Full CIF outperforms individual components}

\begin{table}[htbp]
\centering
\caption{Hypothesis test results: CIF vs individual components.}
\label{tab:h2-tests}
\begin{tabular}{@{}llllll@{}}
\toprule
Comparison & $n$ & Mean Diff & SE & $t$-statistic & $p$-value \\
\midrule
CIF vs Firewall-only & 950 & 0.16 & 0.018 & 8.9 & $<$0.0001 \\
CIF vs Sandbox-only & 950 & 0.29 & 0.023 & 12.4 & $<$0.0001 \\
CIF vs Tripwires-only & 950 & 0.12 & 0.017 & 7.1 & $<$0.0001 \\
CIF vs Invariants-only & 950 & 0.23 & 0.021 & 11.0 & $<$0.0001 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{H3: Architecture-specific performance}

\begin{table}[htbp]
\centering
\caption{Architecture-specific performance against grand mean.}
\label{tab:h3-tests}
\begin{tabular}{@{}llllll@{}}
\toprule
Architecture & $n$ & Detection Rate & SE & vs Grand Mean $t$ & $p$-value \\
\midrule
Claude Code & 158 & 0.97 & 0.021 & 2.14 & 0.034 \\
AutoGPT & 158 & 0.94 & 0.024 & $-0.21$ & 0.834 \\
CrewAI & 158 & 0.96 & 0.022 & 1.36 & 0.175 \\
LangGraph & 158 & 0.98 & 0.018 & 3.22 & 0.001 \\
MetaGPT & 159 & 0.95 & 0.023 & 0.65 & 0.517 \\
Camel & 159 & 0.92 & 0.026 & $-1.54$ & 0.125 \\
\bottomrule
\end{tabular}
\end{table}
\end{block}

\begin{block}{Paired Comparisons (Bonferroni Corrected)}
\protect\phantomsection\label{sec:paired-comparisons}
All pairwise architecture comparisons with
\(\alpha_{corrected} = 0.05/15 = 0.0033\):

\begin{table}[htbp]
\centering
\caption{Pairwise architecture comparisons (Bonferroni corrected).}
\label{tab:pairwise-comparisons}
\begin{tabular}{@{}llllll@{}}
\toprule
Comparison & Mean Diff & 95\% CI & $t$ & $p$-value & Significant \\
\midrule
Claude vs AutoGPT & 0.03 & [0.01, 0.05] & 3.21 & 0.0014 & Yes \\
Claude vs CrewAI & 0.01 & [$-0.01$, 0.03] & 1.07 & 0.285 & No \\
Claude vs LangGraph & $-0.01$ & [$-0.03$, 0.01] & $-1.12$ & 0.264 & No \\
Claude vs MetaGPT & 0.02 & [0.00, 0.04] & 2.15 & 0.032 & No \\
Claude vs Camel & 0.05 & [0.03, 0.07] & 5.34 & $<$0.0001 & Yes \\
AutoGPT vs LangGraph & $-0.04$ & [$-0.06$, $-0.02$] & $-4.28$ & $<$0.0001 & Yes \\
CrewAI vs Camel & 0.04 & [0.02, 0.06] & 4.27 & $<$0.0001 & Yes \\
LangGraph vs MetaGPT & 0.03 & [0.01, 0.05] & 3.22 & 0.0014 & Yes \\
LangGraph vs Camel & 0.06 & [0.04, 0.08] & 6.41 & $<$0.0001 & Yes \\
MetaGPT vs Camel & 0.03 & [0.01, 0.05] & 3.20 & 0.0015 & Yes \\
\bottomrule
\end{tabular}
\end{table}
\end{block}

\begin{block}{Non-Parametric Tests}
\protect\phantomsection\label{sec:nonparametric}
\textbf{Kruskal-Wallis H-test} (architecture differences):
\begin{equation}
\label{eq:kruskal-wallis}
H = 28.7, \quad df = 5, \quad p < 0.0001
\end{equation}

\begin{table}[htbp]
\centering
\caption{Mann-Whitney U tests for attack type differences.}
\label{tab:mann-whitney}
\begin{tabular}{@{}llll@{}}
\toprule
Comparison & $U$ & $Z$ & $p$-value \\
\midrule
Injection vs Trust & 42,156 & 3.21 & 0.0013 \\
Injection vs Belief & 31,245 & 2.87 & 0.0041 \\
Injection vs Coord & 21,567 & 4.12 & $<$0.0001 \\
Trust vs Belief & 12,456 & 0.89 & 0.374 \\
Trust vs Coord & 8,234 & 1.56 & 0.119 \\
Belief vs Coord & 6,123 & 1.23 & 0.219 \\
\bottomrule
\end{tabular}
\end{table}
\end{block}
\end{block}
