<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>04_experimental_setup</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<h1 id="sec:experimental-setup">Experimental Validation</h1>
<p>This section demonstrates the practical viability of CIF’s formal
mechanisms through empirical evaluation across production multiagent
architectures. We present experimental setup () and key findings ().
Detailed statistical analysis, ablation studies, and scalability metrics
are provided in .</p>
<blockquote>
<p><strong>Reproducibility</strong>: Evaluation data generated by
<code>scripts/run_full_evaluation.py</code> →
<code>output/data/full_evaluation_results.json</code>. All results use
deterministic seed=42.</p>
</blockquote>
<h2 id="sec:exp-setup">Experimental Setup</h2>
<h3 id="target-architectures">Target Architectures</h3>
<p>We evaluated CIF across six production multiagent systems
representing diverse architectural patterns:</p>
<blockquote>
<p><strong>Implementation</strong>: Each architecture is abstracted via
an adapter in <code>src/architectures/</code>. The common interface is
defined in <code>src/architectures/base.py:ArchitectureAdapter</code>.
Adapters: <code>claude_code.py:ClaudeCodeAdapter</code>,
<code>autogpt.py:AutoGPTAdapter</code>,
<code>crewai.py:CrewAIAdapter</code>,
<code>langgraph.py:LangGraphAdapter</code>,
<code>metagpt.py:MetaGPTAdapter</code>,
<code>camel.py:CamelAdapter</code>.</p>
</blockquote>
<h3 id="attack-corpus">Attack Corpus</h3>
<p>We assembled a corpus of 950 cognitive attacks across four
categories: prompt injection (500), trust exploitation (200), belief
manipulation (150), and coordination attacks (100). Sources include
published jailbreak datasets, custom adversarial prompts, red team
exercises, and synthetic generation via adversarial models.</p>
<h3 id="sec:eval-methodology">Evaluation Methodology</h3>
<p>Our evaluation employs <strong>architecture-aware simulation</strong>
rather than direct integration with production systems:</p>
<ol type="1">
<li><p><strong>Architecture Modeling</strong>: Each production system is
abstracted via an adapter that captures its trust topology
(hierarchical, flat, role-based, graph, SOP, debate), communication
pattern (hub-spoke, mesh, chain, broadcast), delegation depth, and
attack surface characteristics.</p></li>
<li><p><strong>Threat Simulation</strong>: Attack detection is simulated
using difficulty-weighted base rates modulated by architecture-specific
attack surface multipliers (<code>src/evaluation/runner.py</code>). This
approach enables:</p>
<ul>
<li>Reproducible, deterministic results (seed=42)</li>
<li>Systematic comparison across architectural patterns</li>
<li>Isolation of topological effects from implementation variations</li>
</ul></li>
<li><p><strong>Defense Implementation</strong>: The CIF defense
mechanisms (firewall, sandbox, trust calculus, tripwires, consensus) are
<strong>fully implemented</strong> and tested via 191 unit tests; the
simulation layer assesses their effectiveness given
architecture-specific characteristics.</p></li>
</ol>
<blockquote>
<p><strong>Important</strong>: Results characterize expected behavior
given architecture topology rather than measuring production system
performance directly. Real-world deployment may encounter
implementation-specific variations not captured by topological
modeling.</p>
</blockquote>
<h2 id="sec:key-findings">Key Findings</h2>
<h3
id="finding-1-layered-defense-significantly-outperforms-single-mechanisms">Finding
1: Layered Defense Significantly Outperforms Single Mechanisms</h3>
<p>The central empirical finding validates CIF’s layered approach. No
single defense mechanism achieves acceptable protection, but their
composition yields substantial improvement.</p>
<figure id="fig:detection-performance">
<embed src="figures/detection_performance.pdf" style="width:95.0%" />
<figcaption aria-hidden="true">Detection Performance Comparison. Bar
chart comparing detection rates across defense configurations (Baseline,
Firewall-only, Sandbox-only, Tripwires-only, Full CIF) for each attack
category (Prompt Injection, Trust Exploitation, Belief Manipulation,
Coordination). Error bars show 95% confidence intervals. Full CIF
consistently achieves <span class="math inline">\(&gt;90\%\)</span>
detection across all categories, while individual mechanisms show
significant gaps—validating the defense composition algebra (Part 1,
Theorems 3.1-3.2).</figcaption>
</figure>
<p>As illustrated in , the compositional approach yields detection rates
exceeding 90% across all attack categories.</p>
<p>The gap between firewall-only and full CIF is most pronounced for
coordination and temporal attacks, which require multi-component
detection. This validates the defense composition algebra (Section 4
(Defense Composition, Part 1)): defenses targeting orthogonal attack
surfaces compose multiplicatively.</p>
<h3 id="finding-2-trust-calculus-prevents-amplification-attacks">Finding
2: Trust Calculus Prevents Amplification Attacks</h3>
<figure id="fig:roc-curves">
<embed src="figures/roc_curves.pdf" style="width:90.0%" />
<figcaption aria-hidden="true">ROC Curves by Attack Category. Receiver
Operating Characteristic curves showing the tradeoff between True
Positive Rate (sensitivity) and False Positive Rate (1-specificity) for
CIF detection across four attack categories. All categories achieve AUC
<span class="math inline">\(&gt; 0.92\)</span>, with Prompt Injection
showing the strongest discrimination (AUC = 0.97) and Coordination
Attacks showing the widest confidence band due to smaller sample
size.</figcaption>
</figure>
<p>The ROC analysis () confirms strong discrimination across all attack
categories, with AUC values consistently above 0.92.</p>
<p>Across all tested architectures, the bounded trust decay (<span
class="math inline">\(\delta^d\)</span>) successfully prevented trust
laundering and amplification attempts. In adversarial scenarios where
attackers attempted to relay high-impact content through multiple
trusted intermediaries, the exponential decay ensured that delegated
trust remained below action thresholds.</p>
<p>Critically, this held even when individual agents in the delegation
chain were compromised—the trust bound is a guarantee independent of
agent behavior.</p>
<h3
id="finding-3-integrity-improvement-scales-across-architectures">Finding
3: Integrity Improvement Scales Across Architectures</h3>
<p>CIF improved belief integrity scores substantially across all six
architectures, with particularly strong results for systems with deeper
delegation hierarchies (Camel, AutoGPT) where the trust calculus
provides the greatest benefit.</p>
<p>The peer-to-peer architectures (Camel) showed the largest relative
improvement, consistent with our analysis that equal-trust topologies
are most vulnerable to lateral movement attacks ().</p>
<h3
id="finding-4-performance-overhead-is-acceptable-for-security-contexts">Finding
4: Performance Overhead Is Acceptable for Security Contexts</h3>
<p>Full CIF deployment introduces latency overhead in the 20-25% range
with memory requirements scaling with agent count. For security-critical
deployments, this overhead is acceptable given the integrity improvement
achieved.</p>
<p>The overhead is dominated by the cognitive firewall (input
classification) and Byzantine consensus (coordination). For environments
where consensus is unnecessary, lighter configurations achieve
comparable detection with lower overhead (Table 3 (Risk-Based
Configuration, Part 1)).</p>
<h3 id="finding-5-attack-type-specific-vulnerabilities-remain">Finding
5: Attack-Type Specific Vulnerabilities Remain</h3>
<p>Despite strong overall performance, specific attack types remain
challenging:</p>
<p>These gaps define the frontier for future defense research.</p>
<h2 id="interpretation">Interpretation</h2>
<p>The empirical results validate that CIF’s formal mechanisms translate
to practical protection. The key insight is not the specific detection
rates achieved—which reflect current attack sophistication and will
degrade as adversaries adapt—but rather the properties:</p>
<p>These properties hold independent of specific detection thresholds
and provide the foundation for long-term security assurance.</p>
<p>For detailed statistical analysis including significance testing,
confidence intervals, ablation studies, and scalability benchmarks, see
the Extended Results ().</p>
</body>
</html>
