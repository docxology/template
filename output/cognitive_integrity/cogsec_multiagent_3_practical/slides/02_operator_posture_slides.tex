% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
  ignorenonframetext,
]{beamer}
\newif\ifbibliography
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% remove section numbering
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{section title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{subsection title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{longtable,booktabs,array}
\newcounter{none} % for unnumbered tables
\usepackage{calc} % for calculating minipage widths
\usepackage{caption}
% Make caption package work with longtable
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{\texorpdfstring{}{}}
\date{}

\begin{document}

\begin{frame}
\newpage
\end{frame}

\section{Cognitive Security Operator
Posture}\label{sec:operator-posture}

\begin{frame}{Overview}
\protect\phantomsection\label{overview}
\textbf{Cognitive Security Operator Posture} describes the mindset,
capabilities, and operational practices required when deploying
multiagent AI systems in environments where adversarial manipulation is
a realistic threat. The core observation motivating this framework is
that multiagent systems introduce attack surfaces that traditional
security measures---firewalls, access controls, encryption---cannot
address.

In single-agent systems, security focuses primarily on input validation
(preventing malicious prompts from reaching the model), output filtering
(ensuring generated content meets safety criteria), and access control
(managing who can invoke the agent and what resources it can access).
These remain necessary but become insufficient when agents communicate
with each other. The multiagent setting introduces qualitatively new
concerns:

\begin{itemize}
\item
  \textbf{Belief propagation}: An agent forms beliefs based on
  information from other agents. If one agent is compromised or
  manipulated, those corrupted beliefs can propagate through the
  network, infecting previously secure agents without any direct attack
  on them.
\item
  \textbf{Trust amplification}: Delegation relationships can
  inadvertently launder trust. A low-trust agent might influence a
  medium-trust agent, which then influences a high-trust agent, enabling
  capabilities that the original attacker should never have accessed.
\item
  \textbf{Coordination manipulation}: Collective decisions that appear
  robust (because multiple agents agree) may be vulnerable to strategic
  attacks that manipulate the coordination mechanism itself---timing
  attacks, sybil attacks, or quorum manipulation.
\end{itemize}

These concerns require operators to adopt a distinct mental model.
Traditional security treats the system as a collection of components
with well-defined interfaces; the goal is to protect each interface.
Cognitive security treats the system as a reasoning network with
emergent beliefs and behaviors; the goal is to maintain the integrity of
that reasoning despite adversarial influence.

This section provides an assessment framework for evaluating cognitive
security posture. Subsequent sections translate assessment results into
specific recommendations.
\end{frame}

\begin{frame}{The Five Pillars of Cognitive Security Posture}
\protect\phantomsection\label{the-five-pillars-of-cognitive-security-posture}
Cognitive security posture rests on five interconnected pillars.
Weakness in any pillar creates opportunities for attackers; strength
across all five provides defense in depth. Figure
\ref{fig:posture-radar} provides a visual assessment framework for
evaluating organizational posture across all five dimensions.

\begin{figure}
\centering
\includegraphics[width=0.85\linewidth,height=\textheight,keepaspectratio,alt={Five Pillars Security Posture Assessment. This radar chart visualizes an organization's cognitive security posture across the five CIF pillars: Cognitive Firewall (F), Belief Sandbox (W), Identity Tripwire (T), Behavioral Invariants (I), and Epistemic Provenance (P). The concentric rings represent maturity levels from minimal (25\%) through standard (50\%), elevated (75\%), to maximum (90\%). The example assessment shows strong invariant enforcement (90\%) but weaker provenance tracking (55\%), indicating a prioritization opportunity.}]{../figures/posture_radar.pdf}
\caption{Five Pillars Security Posture Assessment. This radar chart
visualizes an organization's cognitive security posture across the five
CIF pillars: Cognitive Firewall (F), Belief Sandbox (W), Identity
Tripwire (T), Behavioral Invariants (I), and Epistemic Provenance (P).
The concentric rings represent maturity levels from minimal (25\%)
through standard (50\%), elevated (75\%), to maximum (90\%). The example
assessment shows strong invariant enforcement (90\%) but weaker
provenance tracking (55\%), indicating a prioritization
opportunity.}\label{fig:posture-radar}
\end{figure}

\begin{block}{Pillar 1: Trust Boundary Awareness}
\protect\phantomsection\label{pillar-1-trust-boundary-awareness}
\begin{quote}
\textbf{Theoretical Foundation}: This pillar implements Part 1's Trust
Calculus (Section 3), which formalizes trust relationships as scored
values \(\mathcal{T}_{i \to j} \in [0, 1]\) with bounded delegation
(Theorem 3.1: Trust Boundedness).
\end{quote}

Every multiagent system embodies implicit trust assumptions---beliefs
about which agents, channels, and data sources can be relied upon for
accurate information. These assumptions are often undocumented,
inherited from development environments where trust was universal, or
derived from optimistic assessments of adversary capabilities.

Trust boundary awareness requires making these assumptions explicit and
then subjecting them to adversarial analysis. Common trust relationships
in multiagent architectures include:

\begin{itemize}
\item
  \textbf{Orchestrator-worker trust}: The orchestrator typically trusts
  that worker agents will execute instructions faithfully and report
  results accurately. An attacker who compromises a worker can exploit
  this trust to influence orchestrator decisions.
\item
  \textbf{Agent-tool trust}: Agents trust that external tools (code
  execution, web retrieval, database queries) return accurate results.
  Tool poisoning attacks exploit this trust by corrupting the tool's
  outputs before they reach the agent.
\item
  \textbf{Inter-agent communication trust}: Agents receiving messages
  from other agents typically trust the sender's identity and the
  message's authenticity. Without cryptographic verification, these
  properties are assumptions rather than guarantees.
\item
  \textbf{Shared state trust}: When agents coordinate through shared
  state (caches, queues, databases, or file systems), each agent trusts
  that the state has not been manipulated by adversaries. This is
  particularly dangerous because the attack surface is large and
  modifications may be difficult to attribute.
\end{itemize}

\textbf{Assessment questions for trust boundary awareness}:

\begin{enumerate}
\tightlist
\item
  Have you documented all trust relationships in your architecture,
  including implicit assumptions?
\item
  For each trust assumption, what would happen if it were violated?
  Could an attacker escalate privileges, corrupt beliefs, or damage
  high-value assets?
\item
  How would you detect a trust violation? Do you have monitoring in
  place, or would violations be invisible until damage manifests?
\item
  What mechanisms limit damage from trust exploitation? Can a
  compromised trust relationship cascade through the system, or is blast
  radius contained?
\end{enumerate}

Organizations with strong trust boundary awareness maintain living
documentation of trust relationships, review them during architecture
changes, and design systems so that no single trust violation enables
catastrophic outcomes.
\end{block}

\begin{block}{Pillar 2: Belief Provenance}
\protect\phantomsection\label{pillar-2-belief-provenance}
\begin{quote}
\textbf{Theoretical Foundation}: This pillar implements Part 1's
Cognitive State Representation (Definition 2.2), which models agent
beliefs as \(\mathcal{B}_i\) with associated provenance metadata
\(\pi\), and the Provenance Verifiability property (Property 2.3).
\end{quote}

Agents form beliefs based on inputs---prompts, tool outputs, messages
from other agents, and observations of shared state. In multiagent
systems, beliefs propagate: Agent A forms a belief from a tool output,
communicates that belief to Agent B in a summary, and Agent B
incorporates the summary into its reasoning about what actions to
recommend.

This propagation is essential to multiagent cooperation but creates
provenance challenges. By the time a belief influences a critical
decision, it may have passed through multiple agents, been summarized,
combined with other information, and reformulated. The original
evidence---and its trustworthiness---becomes obscured.

Belief provenance tracking addresses this by maintaining metadata about
the origins and transformations of information as it flows through the
system. Key questions include:

\textbf{Assessment questions for belief provenance}:

\begin{enumerate}
\tightlist
\item
  Can you trace the origin of any belief an agent holds? Given a
  statement an agent makes or an action it takes, can you identify the
  inputs that led to that conclusion?
\item
  How trustworthy is each upstream source? Do you distinguish between
  beliefs derived from verified databases, unverified web content, user
  assertions, and other agent outputs?
\item
  Could an adversary have influenced the belief chain? What would an
  attack path look like, and would your monitoring detect it?
\item
  Do you discount multi-hop information appropriately? Beliefs that have
  passed through multiple summarization steps should carry less weight
  than direct observations.
\end{enumerate}

Organizations with strong belief provenance implement structured
information passing (rather than free-form summaries), maintain
provenance metadata through agent interactions, and train agents to
distinguish evidence quality in their reasoning.
\end{block}

\begin{block}{Pillar 3: Delegation Hygiene}
\protect\phantomsection\label{pillar-3-delegation-hygiene}
Delegation is the mechanism by which one agent assigns tasks to another.
It amplifies capabilities---a supervising agent can accomplish more by
delegating subtasks than by performing everything itself---but this
amplification creates security risks if not properly bounded.

The fundamental problem is that delegation can launder provenance and
amplify trust. Consider this attack pattern:

\begin{enumerate}
\tightlist
\item
  An attacker compromises a low-trust agent (perhaps through prompt
  injection in an external data source that agent processes).
\item
  The compromised agent sends a plausible-seeming request to a
  medium-trust agent.
\item
  The medium-trust agent, finding the request reasonable, incorporates
  it into a task and delegates to a high-trust agent.
\item
  The high-trust agent, receiving the task from a trusted delegate,
  executes actions that the original attacker should never have been
  able to trigger.
\end{enumerate}

This ``trust laundering'' attack exploits the fact that delegation
implicitly transfers trust from the delegating agent to the delegated
task. Without explicit bounds, this transfer is unlimited.

\textbf{Assessment questions for delegation hygiene}:

\begin{enumerate}
\tightlist
\item
  Do you implement trust decay across delegation hops? The trust
  associated with information or requests should diminish as they pass
  through intermediaries, limiting the depth to which attacks can
  propagate.
\item
  Is there a maximum delegation depth? Can an agent delegate to an agent
  that delegates to another agent indefinitely, or is recursion bounded?
\item
  Can delegated authority exceed direct authority? If Agent A can only
  perform read operations, can it delegate a write operation to Agent B?
  Sound systems prevent such escalation.
\item
  Do you verify delegation chains? Can you audit who originated a
  delegated task and what transformations occurred along the way?
\end{enumerate}

The delegation decay parameter δ (formalized in Part 1, Definition 3.2)
provides a quantitative mechanism for bounding delegation. With δ = 0.7,
trust drops by 30\% at each hop; after four hops, trust has decayed to
24\% of its original value, limiting the impact of trust laundering.
\end{block}

\begin{block}{Pillar 4: Coordination Integrity}
\protect\phantomsection\label{pillar-4-coordination-integrity}
\begin{quote}
\textbf{Theoretical Foundation}: This pillar implements Part 1's
Byzantine Agreement Requirement (Theorem 5.3), which guarantees that all
honest agents agree when \(n \geq 3f + 1\) agents exist and at most
\(f\) are Byzantine.
\end{quote}

Multi-agent decision-making introduces coordination attack surfaces that
do not exist in single-agent systems. When agents vote, reach consensus,
or aggregate their outputs, the coordination mechanism itself becomes a
target.

Common coordination attacks include (evaluated empirically in Part 2,
finding them to be the most resilient to detection):

\begin{itemize}
\item
  \textbf{Sybil attacks}: An adversary creates multiple fake agents (or
  compromises multiple legitimate agents) to gain disproportionate
  influence in consensus processes. If quorum requires three agreements,
  an attacker controlling two sybil identities needs only one additional
  compromised agent.
\item
  \textbf{Strategic timing}: Consensus protocols often have timing
  windows. An attacker might delay legitimate agent messages while
  ensuring their compromised messages arrive first, shaping the
  information available when decisions are made.
\item
  \textbf{Quorum manipulation}: Rather than compromising agents, an
  attacker might prevent legitimate agents from participating (denial of
  service), artificially achieving quorum with fewer honest agents.
\item
  \textbf{Outcome manipulation}: In voting or aggregation schemes,
  strategic manipulation of input values can skew outcomes even when the
  attacker controls a minority of agents.
\end{itemize}

\textbf{Assessment questions for coordination integrity}:

\begin{enumerate}
\tightlist
\item
  Do critical decisions require Byzantine-tolerant consensus? Protocols
  that tolerate up to f failures require n ≥ 3f + 1 agents, ensuring
  honest majority even with substantial compromise.
\item
  Is agent identity verified before counting votes? Can an attacker
  trivially create additional voting agents, or is identity bound to
  verified credentials?
\item
  Do quorum requirements account for potential adversaries? If you
  assume 10\% of agents might be compromised, is your quorum threshold
  set accordingly?
\item
  Are coordination protocols time-bounded appropriately? Can an attacker
  delay messages to manipulate outcomes, or do timeouts prevent such
  attacks?
\end{enumerate}
\end{block}

\begin{block}{Pillar 5: Continuous Monitoring and Adaptation}
\protect\phantomsection\label{pillar-5-continuous-monitoring-and-adaptation}
\begin{quote}
\textbf{Theoretical Foundation}: This pillar implements Part 1's Drift
Detection (Definition 6.1) and Detection Bounds (Theorem 6.2), which
establish the information-theoretic limits of detecting progressive
manipulation attacks.
\end{quote}

Unlike traditional security, where defenses can be static once properly
configured, cognitive security requires continuous monitoring and
adaptation. The threat landscape evolves rapidly, agents learn and
change behavior over time, and adversaries adapt to observed defenses.

\textbf{Assessment questions for continuous monitoring}:

\begin{enumerate}
\tightlist
\item
  Do you monitor cognitive integrity metrics continuously? Metrics such
  as belief consistency, trust relationship stability, and delegation
  patterns should be tracked over time.
\item
  Can you detect drift from baseline behavior? Gradual manipulation that
  stays below individual-event thresholds may be visible as aggregate
  drift.
\item
  Do you have incident response procedures for cognitive attacks? When
  manipulation is detected, do your teams know how to contain,
  investigate, and remediate?
\item
  Do you conduct regular adversarial testing? Red team exercises that
  specifically target cognitive attack surfaces reveal gaps that
  theoretical analysis misses.
\end{enumerate}
\end{block}
\end{frame}

\begin{frame}{Maturity Assessment}
\protect\phantomsection\label{maturity-assessment}
Rate your organization on each dimension (1 = no practice, 5 = mature):

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.3056}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2778}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0833}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Question
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
1
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
5
\end{minipage} \\
\midrule\noalign{}
\endhead
Trust Mapping & Are trust assumptions documented and reviewed? & & & &
& \\
Detection & Could you detect belief manipulation in production? & & & &
& \\
Bounding & Do delegation limits prevent trust amplification? & & & &
& \\
Consensus & Are collective decisions manipulation-resistant? & & & &
& \\
Monitoring & Is cognitive integrity monitored continuously? & & & & & \\
Response & Do you have cognitive attack response procedures? & & & &
& \\
\bottomrule\noalign{}
\end{longtable}
}

\textbf{Total: \_\_\_ / 30}

\textbf{Interpretation}:

\begin{itemize}
\tightlist
\item
  \textbf{24-30 (Proactive)}: Strong posture. Maintain vigilance and
  pursue continuous improvement. Share your practices with the
  community.
\item
  \textbf{18-23 (Managed)}: Solid foundation with identified gaps.
  Prioritize addressing the lowest-scoring dimensions.
\item
  \textbf{12-17 (Developing)}: Basic awareness established. Systematic
  improvement program needed; consider external assessment.
\item
  \textbf{Below 12 (Reactive)}: Significant risk exposure. Begin
  immediately with trust mapping and basic monitoring.
\end{itemize}
\end{frame}

\begin{frame}{Operational Capabilities Checklist}
\protect\phantomsection\label{operational-capabilities-checklist}
Organizations deploying multiagent systems should implement these
capabilities:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2609}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1957}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5435}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Capability
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Implementation Guidance
\end{minipage} \\
\midrule\noalign{}
\endhead
\textbf{Stigmergic Audit Trail} & Track modifications to shared state
with attribution & Log all writes to shared caches, queues, and files
with agent ID, timestamp, and operation context \\
\textbf{Quorum Gates} & Require multi-agent agreement for consequential
actions & Implement voting or approval workflows for high-risk
operations; configure thresholds based on risk profile \\
\textbf{Collective Anomaly Detection} & Identify coordinated attacks or
emergent pathology & Monitor aggregate metrics (success rates,
latencies, output distributions) alongside individual agent health \\
\textbf{Sybil Resistance} & Prevent fake agent injection & Bind agent
identity to verified credentials; rate-limit new agent integration;
require human approval for capability grants \\
\textbf{Belief Provenance Tracking} & Maintain information origin chains
& Structured message formats with provenance metadata; trust scores that
decay through hops \\
\textbf{Resilience Testing} & Validate recovery from adversarial
conditions & Regular injection of faulty or adversarial agents in
staging; chaos engineering for cognitive systems \\
\textbf{Incident Response Playbooks} & Enable rapid response to detected
attacks & Documented procedures for cognitive attack containment,
investigation, and remediation \\
\bottomrule\noalign{}
\end{longtable}
}
\end{frame}

\begin{frame}{Design Principles for Cognitive Security}
\protect\phantomsection\label{design-principles-for-cognitive-security}
These principles should guide architectural decisions:

\textbf{Principle 1: Stigmergic Hygiene} Treat shared state as an attack
surface requiring scrutiny equivalent to direct communication channels.
Environment-mediated coordination (caches, queues, file systems,
databases) is often less protected than agent-to-agent messages, making
it an attractive attack vector.

\textbf{Principle 2: Quorum for Consequential Actions} High-impact
collective actions require explicit quorum approval. A single
compromised agent should never be able to trigger irreversible harm.
Design systems so that consequential actions require agreement from
multiple agents operating on independent information.

\textbf{Principle 3: Emergent Behavior Monitoring} Monitor collective
metrics alongside individual agent health. Pathological emergent
behavior may manifest as normal individual agent behavior---only the
aggregate pattern reveals the problem. Watch for belief convergence,
coordination anomalies, and output distribution shifts.

\textbf{Principle 4: Trust Localization} Trust should be specific rather
than general. An agent trusted to summarize documents should not
automatically be trusted to execute code. Design permission models with
minimal necessary trust, and verify that trust cannot be transferred to
unintended contexts.

\textbf{Principle 5: Defense Composability} Layer defenses so that
failure of any single mechanism does not enable successful attack. The
defense composition theorems in Part 1 demonstrate that appropriately
designed layers provide multiplicative protection; implement this
principle through architectural separation and independent verification.
\end{frame}

\begin{frame}{Next Steps}
\protect\phantomsection\label{next-steps}
The assessment results from this section should guide your reading of
subsequent sections:

\begin{itemize}
\tightlist
\item
  \textbf{If trust mapping scored low}: Focus on \textbf{Human
  Checklist} (Section 3) for systematic deployment guidance.
\item
  \textbf{If detection scored low}: Review \textbf{Agent Guidelines}
  (Section 4) for cognitive tripwire implementations.
\item
  \textbf{If bounding scored low}: Study \textbf{Deployment
  Considerations} (Section 5) for delegation parameter configuration.
\item
  \textbf{If consensus or monitoring scored low}: \textbf{Risk
  Assessment} (Section 6) provides threat modeling methodology for
  identifying gaps.
\item
  \textbf{If you identified specific anti-patterns}: \textbf{Common
  Pitfalls} (Section 7) catalogs known failure modes with mitigations.
\end{itemize}
\end{frame}

\end{document}
