% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
  ignorenonframetext,
]{beamer}
\newif\ifbibliography
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% remove section numbering
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{section title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{subsection title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{\texorpdfstring{}{}}
\date{}

\begin{document}

\begin{frame}
\newpage
\end{frame}

\begin{frame}{Detection Methods: Anomaly Detection, ROC Analysis, and
Provenance Tracking}
\protect\phantomsection\label{sec:detection-methods}
This section presents the formal foundations for cognitive attack
detection. We define anomaly detection metrics
(\cref{sec:anomaly-detection}), ROC curve framework
(\cref{sec:roc-analysis}), multi-detector fusion theory
(\cref{sec:detector-fusion}), online vs.~batch trade-offs
(\cref{sec:online-batch}), false positive mitigation strategies
(\cref{sec:fp-mitigation}), provenance analysis (\cref{sec:provenance}),
and real-time monitoring architecture (\cref{sec:monitoring}).

\begin{quote}
\textbf{Note}: For algorithm implementations and empirical performance
results, see Part 2 of this series.
\end{quote}

\begin{block}{Anomaly Detection}
\protect\phantomsection\label{sec:anomaly-detection}
\begin{block}{Cognitive Drift Scoring}
\protect\phantomsection\label{cognitive-drift-scoring}
\begin{definition}[Drift Score]
\label{def:drift-score}
The cognitive drift score measures belief distribution change over time:
\begin{equation}
\label{eq:drift-score}
S_{\text{drift}}(t) = D_{\text{KL}}(\mathcal{B}_i^t \| \mathcal{B}_i^{t-w}) + \lambda \cdot \max_\phi |\Delta \mathcal{B}_i(\phi)|
\end{equation}
\end{definition}

\begin{table}[htbp]
\centering
\caption{Drift score components and detection targets.}
\label{tab:drift-components}
\begin{tabular}{@{}llp{5cm}@{}}
\toprule
Component & Weight & Detection Target \\
\midrule
KL divergence & 1.0 & Gradual distribution shift \\
Max delta & $\lambda$ & Sudden belief injection \\
\bottomrule
\end{tabular}
\end{table}

\begin{property}[Drift Detection Threshold]
\label{prop:drift-threshold}
For normally distributed baseline drift, the threshold $\theta = \mu_{\text{baseline}} + k \cdot \sigma_{\text{baseline}}$ with $k = 3$ provides $99.7\%$ confidence under the null hypothesis of no attack.
\end{property}
\end{block}

\begin{block}{Behavioral Deviation}
\protect\phantomsection\label{behavioral-deviation}
\begin{definition}[Deviation Score]
\label{def:deviation-score}
The behavioral deviation score aggregates normalized feature anomalies:
\begin{equation}
\label{eq:deviation-score}
S_{\text{dev}}(a_i, t) = \sum_{k=1}^K w_k \cdot \frac{|f_k(\sigma_i^t) - \mu_k|}{\sigma_k}
\end{equation}
where $f_k$ are feature extractors and $(w_k, \mu_k, \sigma_k)$ are learned parameters.
\end{definition}
\end{block}

\begin{block}{Ensemble Detection}
\protect\phantomsection\label{ensemble-detection}
\begin{definition}[Ensemble Detector]
\label{def:ensemble-detector}
Combines multiple detector scores via learned fusion:
\begin{equation}
\label{eq:ensemble-detector}
P(\text{attack} \mid \mathbf{S}) = \sigma\left(\sum_d w_d \cdot S_d - b\right)
\end{equation}
where $\sigma$ is the sigmoid function and weights $(w_d, b)$ are learned from labeled examples.
\end{definition}
\end{block}
\end{block}

\begin{block}{ROC Curve Analysis}
\protect\phantomsection\label{sec:roc-analysis}
\begin{block}{Receiver Operating Characteristic Framework}
\protect\phantomsection\label{receiver-operating-characteristic-framework}
\begin{definition}[ROC Curve]
\label{def:roc-curve}
For detector $D$ with threshold $\tau$:
\begin{equation}
\label{eq:roc-curve}
\text{ROC}(D) = \{(\text{FPR}(\tau), \text{TPR}(\tau)) : \tau \in [0, 1]\}
\end{equation}
where the rates are defined as:
\begin{align}
\label{eq:tpr}
\text{TPR}(\tau) &= P(D(x) > \tau \mid x \in \mathcal{A}_{\text{attack}}) \\
\label{eq:fpr}
\text{FPR}(\tau) &= P(D(x) > \tau \mid x \in \mathcal{X}_{\text{benign}})
\end{align}
\end{definition}

\begin{definition}[Area Under Curve]
\label{def:auc}
\begin{equation}
\label{eq:auc}
\text{AUC}(D) = \int_0^1 \text{TPR}(\text{FPR}^{-1}(t)) \, dt
\end{equation}
\end{definition}

\begin{table}[htbp]
\centering
\caption{AUC interpretation scale.}
\label{tab:auc-interpretation}
\begin{tabular}{@{}ll@{}}
\toprule
AUC Range & Interpretation \\
\midrule
$0.5$ & Random classifier \\
$0.7$--$0.8$ & Acceptable discrimination \\
$0.8$--$0.9$ & Good discrimination \\
$0.9$--$1.0$ & Excellent discrimination \\
\bottomrule
\end{tabular}
\end{table}
\end{block}

\begin{block}{Confidence Intervals for AUC}
\protect\phantomsection\label{confidence-intervals-for-auc}
\begin{definition}[AUC Confidence Interval]
\label{def:auc-ci}
Using DeLong's method:
\begin{equation}
\label{eq:auc-ci}
\text{CI}_{95\%}(\text{AUC}) = \text{AUC} \pm 1.96 \cdot \sqrt{\text{Var}(\text{AUC})}
\end{equation}
where:
\begin{equation}
\label{eq:auc-variance}
\text{Var}(\text{AUC}) = \frac{1}{n_a} \sum_{i=1}^{n_a} (V_1^i - \text{AUC})^2 + \frac{1}{n_b} \sum_{j=1}^{n_b} (V_0^j - \text{AUC})^2
\end{equation}
\end{definition}
\end{block}
\end{block}

\begin{block}{Multi-Detector Fusion}
\protect\phantomsection\label{sec:detector-fusion}
\begin{block}{Fusion Strategies}
\protect\phantomsection\label{fusion-strategies}
\begin{definition}[Score-Level Fusion]
\label{def:score-fusion}
Weighted average of detector outputs:
\begin{equation}
\label{eq:score-fusion}
S_{\text{fused}} = \sum_{i=1}^k w_i \cdot S_i, \quad \sum_i w_i = 1
\end{equation}
\end{definition}

\begin{definition}[Decision-Level Fusion]
\label{def:decision-fusion}
Quorum voting on binary decisions:
\begin{equation}
\label{eq:decision-fusion}
D_{\text{fused}}(x) = \mathbb{1}\left[\sum_{i=1}^k \mathbb{1}[D_i(x) > \tau_i] \geq q\right]
\end{equation}
\end{definition}

\begin{definition}[Learned Fusion]
\label{def:learned-fusion}
Neural network combining scores:
\begin{equation}
\label{eq:learned-fusion}
S_{\text{fused}} = \text{MLP}(S_1, \ldots, S_k; \theta)
\end{equation}
\end{definition}
\end{block}

\begin{block}{Diversity-Aware Fusion}
\protect\phantomsection\label{diversity-aware-fusion}
\begin{definition}[Detector Diversity]
\label{def:detector-diversity}
\begin{equation}
\label{eq:detector-diversity}
\text{Diversity}(D_i, D_j) = 1 - \frac{|\text{errors}(D_i) \cap \text{errors}(D_j)|}{|\text{errors}(D_i) \cup \text{errors}(D_j)|}
\end{equation}
\end{definition}

\begin{theorem}[Diversity Benefit]
\label{thm:diversity-benefit}
For detectors with error rates $e_1, \ldots, e_k$ and pairwise diversity $\delta_{ij}$:
\begin{equation}
\label{eq:diversity-benefit}
e_{\text{fusion}} \leq \prod_i e_i + (1 - \bar{\delta}) \cdot \max_i e_i
\end{equation}
where $\bar{\delta}$ is the average pairwise diversity.
\end{theorem}

\begin{proof}
When detectors make independent errors (high diversity), the fusion error is the product of individual errors. Error correlation reduces this benefit proportionally to $(1 - \bar{\delta})$.
\end{proof}
\end{block}
\end{block}

\begin{block}{Online vs.~Batch Detection}
\protect\phantomsection\label{sec:online-batch}
\begin{block}{Comparison Framework}
\protect\phantomsection\label{comparison-framework}
\begin{table}[htbp]
\centering
\caption{Online vs. batch detection trade-offs.}
\label{tab:online-batch-comparison}
\begin{tabular}{@{}lll@{}}
\toprule
Dimension & Online Detection & Batch Detection \\
\midrule
Latency & Low (ms) & High (minutes--hours) \\
Accuracy & Moderate & High \\
Context & Limited (window) & Full history \\
Compute & Streaming & Offline \\
Memory & $O(w)$ window & $O(n)$ full \\
Use Case & Real-time response & Forensics, tuning \\
\bottomrule
\end{tabular}
\end{table}
\end{block}

\begin{block}{Streaming Detector Model}
\protect\phantomsection\label{streaming-detector-model}
\begin{definition}[Streaming Detector]
\label{def:streaming-detector}
Processes messages in real-time with bounded memory:
\begin{align}
\label{eq:streaming-output}
D_{\text{online}}(m_t) &= f(m_t, \text{state}_{t-1}) \\
\label{eq:streaming-state}
\text{state}_t &= g(\text{state}_{t-1}, m_t)
\end{align}
\end{definition}
\end{block}

\begin{block}{Hybrid Detection Architecture}
\protect\phantomsection\label{hybrid-detection-architecture}
\begin{definition}[Hybrid Detection System]
\label{def:hybrid-detection}
Combines online and batch detection via feedback loop:
\begin{equation}
\label{eq:hybrid-architecture}
\text{Online Path}: m \xrightarrow{\text{filter}} s \xrightarrow{\text{decide}} r \xrightarrow{\text{log}} H
\end{equation}
\begin{equation}
\label{eq:hybrid-feedback}
\text{Batch Path}: H \xrightarrow{\text{analyze}} \text{patterns} \xrightarrow{\text{update}} \text{filters}
\end{equation}
\end{definition}
\end{block}
\end{block}

\begin{block}{False Positive Mitigation}
\protect\phantomsection\label{sec:fp-mitigation}
\begin{block}{Strategy 1: Confirmation Cascade}
\protect\phantomsection\label{strategy-1-confirmation-cascade}
\begin{definition}[Confirmation Cascade]
\label{def:confirmation-cascade}
Multi-stage verification before alerting:
\begin{equation}
\label{eq:cascade-decision}
\text{Action}(\text{confidence}) = \begin{cases}
\text{suppress} & \text{if } c < C_{\text{low}} \\
\text{stage-2} & \text{if } c \in [C_{\text{low}}, C_{\text{high}}) \\
\text{stage-3} & \text{if } c \geq C_{\text{high}}
\end{cases}
\end{equation}
\end{definition}

\begin{theorem}[Cascade FPR Reduction]
\label{thm:cascade-fpr}
For a multi-stage cascade:
\begin{equation}
\label{eq:cascade-fpr}
\text{FPR}_{\text{cascade}} = \text{FPR}_1 \cdot P(\text{confirm}_2 \mid \text{FP}_1) \cdot P(\text{confirm}_3 \mid \text{FP}_2)
\end{equation}
\end{theorem}
\end{block}

\begin{block}{Strategy 2: Temporal Smoothing}
\protect\phantomsection\label{strategy-2-temporal-smoothing}
\begin{definition}[Smoothed Detection]
\label{def:smoothed-detection}
Apply exponential smoothing to scores:
\begin{equation}
\label{eq:smoothed-score}
\hat{S}_t = \alpha \cdot S_t + (1 - \alpha) \cdot \hat{S}_{t-1}
\end{equation}
\end{definition}

\begin{definition}[Burst Suppression]
\label{def:burst-suppression}
Require sustained anomaly over window $w$:
\begin{equation}
\label{eq:burst-suppression}
\text{Alert if } \frac{1}{w} \sum_{i=t-w+1}^{t} \mathbb{1}[S_i > \tau] > p_{\text{sustained}}
\end{equation}
\end{definition}
\end{block}

\begin{block}{Strategy 3: Contextual Whitelisting}
\protect\phantomsection\label{strategy-3-contextual-whitelisting}
\begin{definition}[Context-Aware Whitelist]
\label{def:context-whitelist}
\begin{equation}
\label{eq:whitelist-suppress}
\text{Suppress}(\text{alert}) \iff \text{context}(\text{alert}) \in \mathcal{W}_{\text{known}}
\end{equation}
\end{definition}
\end{block}

\begin{block}{Strategy 4: Cost-Sensitive Thresholding}
\protect\phantomsection\label{strategy-4-cost-sensitive-thresholding}
\begin{definition}[Cost-Sensitive Threshold]
\label{def:cost-threshold}
Optimize for total cost rather than accuracy:
\begin{equation}
\label{eq:cost-threshold}
\tau^* = \argmin_\tau \left[ C_{\text{FP}} \cdot \text{FPR}(\tau) + C_{\text{FN}} \cdot \text{FNR}(\tau) \right]
\end{equation}
\end{definition}
\end{block}
\end{block}

\begin{block}{Provenance Analysis}
\protect\phantomsection\label{sec:provenance}
\begin{block}{Information Flow Tracking}
\protect\phantomsection\label{information-flow-tracking}
\begin{definition}[Taint Label]
\label{def:taint-label}
Each belief carries provenance tags:
\begin{equation}
\label{eq:taint-label}
\text{taint}(\phi) = \{(\text{source}, \text{timestamp}, \text{confidence})\}
\end{equation}
\end{definition}

\begin{definition}[Taint Propagation]
\label{def:taint-propagation}
\begin{equation}
\label{eq:taint-propagation}
\text{taint}(\phi_{\text{derived}}) = \bigcup_{\psi \in \text{premises}(\phi_{\text{derived}})} \text{taint}(\psi)
\end{equation}
\end{definition}

\begin{table}[htbp]
\centering
\caption{Taint categories with trust levels.}
\label{tab:taint-categories}
\begin{tabular}{@{}lll@{}}
\toprule
Category & Trust Level & Example \\
\midrule
\textsc{system\_verified} & 1.0 & Hardcoded facts \\
\textsc{principal\_input} & 0.9 & Direct user commands \\
\textsc{agent\_internal} & 0.8 & Agent's own reasoning \\
\textsc{agent\_external} & 0.6 & Other agent claims \\
\textsc{tool\_output} & 0.5 & API/tool responses \\
\textsc{web\_content} & 0.3 & Fetched web pages \\
\textsc{unverified} & 0.1 & Unknown origin \\
\bottomrule
\end{tabular}
\end{table}
\end{block}

\begin{block}{Causal Attribution}
\protect\phantomsection\label{causal-attribution}
\begin{definition}[Causal Attribution]
\label{def:causal-attribution}
Identify likely source of compromised beliefs via Bayesian inference:
\begin{equation}
\label{eq:causal-attribution}
P(\text{source}_j \mid \phi \in \mathcal{B}_i^{\text{compromised}}) = \frac{P(\phi \mid \text{source}_j) \cdot P(\text{source}_j)}{\sum_k P(\phi \mid \text{source}_k) \cdot P(\text{source}_k)}
\end{equation}
\end{definition}
\end{block}

\begin{block}{Provenance Graph Analysis}
\protect\phantomsection\label{provenance-graph-analysis}
\begin{definition}[Provenance Graph]
\label{def:provenance-graph}
Directed graph of belief dependencies:
\begin{equation}
\label{eq:provenance-graph}
G = (V, E) \text{ where } V = \mathcal{B}_i, \; E = \{(\psi, \phi) : \psi \in \text{premises}(\phi)\}
\end{equation}
\end{definition}

\begin{table}[htbp]
\centering
\caption{Provenance graph attack indicators.}
\label{tab:provenance-indicators}
\begin{tabular}{@{}lp{6cm}@{}}
\toprule
Indicator & Attack Implication \\
\midrule
High in-degree from single source & Belief injection \\
Cycles in provenance & Circular reasoning attack \\
Missing edges & Fabricated evidence \\
Temporal anomalies & Future timestamp forgery \\
\bottomrule
\end{tabular}
\end{table}
\end{block}
\end{block}

\begin{block}{Real-Time Monitoring}
\protect\phantomsection\label{sec:monitoring}
\begin{block}{Alert Aggregation}
\protect\phantomsection\label{alert-aggregation}
\begin{definition}[Alert Aggregation]
\label{def:alert-aggregation}
Prevent alert fatigue through correlation:
\begin{equation}
\label{eq:alert-aggregation}
\text{Severity} = \begin{cases}
\textsc{critical} & \text{if } |\text{alerts}| > n_{\text{critical}} \text{ in window } w \\
\textsc{warning} & \text{if } |\text{alerts}| > n_{\text{warning}} \text{ in window } w \\
\textsc{info} & \text{otherwise}
\end{cases}
\end{equation}
\end{definition}
\end{block}

\begin{block}{Response Escalation}
\protect\phantomsection\label{response-escalation}
\begin{table}[htbp]
\centering
\caption{Response escalation levels.}
\label{tab:alert-escalation}
\begin{tabular}{@{}llp{4cm}@{}}
\toprule
Level & Trigger & Response \\
\midrule
L0 & Single anomaly & Log only \\
L1 & Repeated anomaly & Increase monitoring \\
L2 & Pattern match & Quarantine source \\
L3 & Confirmed attack & Halt agent, alert human \\
L4 & Systemic compromise & System shutdown \\
\bottomrule
\end{tabular}
\end{table}
\end{block}

\begin{block}{Empirical Validation}
\protect\phantomsection\label{empirical-validation}
The detection methods presented in this section have been empirically
validated in Part 2 of this series. Key results include:

\textbf{ROC Analysis}: Receiver Operating Characteristic curves
demonstrate the tradeoff between True Positive Rate and False Positive
Rate for each detector type. The ensemble achieves AUC \(> 0.84\), with
individual mechanisms ranging from \(0.74\) (Belief Sandbox) to \(0.81\)
(Tripwire Monitor). See Part 2, \S\{4\} for detailed ROC curves and
confidence intervals.

\textbf{Detection Performance by Attack Type}: Detection rates vary
across the five adversary classes (\(\Omega_1\)--\(\Omega_5\)). The
Cognitive Firewall excels at \(\Omega_1\) (external) attacks while
Tripwires and Invariants provide stronger coverage for \(\Omega_3\)
(compromised agent) and \(\Omega_4\) (inter-agent) attacks. See Part 2,
\S\{5\} for the complete detection matrix.

\textbf{False Positive Mitigation}: The confirmation cascade, temporal
smoothing, and contextual whitelisting strategies reduce false positive
rates by \(>80\%\) while maintaining \(>90\%\) true positive rates. See
Part 2, \S\{5.4\} for quantitative analysis of each mitigation strategy.
\end{block}
\end{block}
\end{frame}

\end{document}
