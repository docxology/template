% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
\documentclass[
  11pt,
]{article}
\usepackage{xcolor}
\usepackage[margin=1.5cm,top=1.5cm,bottom=1.5cm,left=1.5cm,right=1.5cm,includeheadfoot]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{3}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
  \setmainfont[]{Times New Roman}
  \setmonofont[]{Courier New}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{setspace}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
% Essential packages for academic documents
\usepackage{amsmath,amssymb}          % Mathematical symbols and environments
\usepackage{amsfonts}                 % Additional math fonts
\usepackage{amsthm}                   % Theorem environments
\usepackage{graphicx}                 % Include graphics
\usepackage{float}                    % Better float placement
\usepackage{booktabs}                 % Professional tables
\usepackage{longtable}                % Long tables spanning pages
\usepackage{array}                    % Advanced table formatting
\usepackage{multirow}                 % Multi-row table cells
\usepackage{caption}                  % Enhanced caption formatting
\usepackage{subcaption}               % Sub-figures and sub-tables
\usepackage{bm}                       % Bold math symbols
\usepackage{url}                      % URL formatting
\usepackage{hyperref}                 % Hyperlinks and cross-references
\usepackage{cleveref}                 % Intelligent cross-referencing
\usepackage[capitalise]{cleveref}     % Capitalize cross-reference labels
\usepackage{natbib}                   % Bibliography support
\usepackage{doi}                      % DOI links

% Configure figure numbering and captions
\renewcommand{\figurename}{Figure}
\captionsetup{
    justification=centering,
    font=small,
    labelfont=bf,
    labelsep=period
}

% Configure table numbering and captions
\renewcommand{\tablename}{Table}
\captionsetup[table]{
    justification=centering,
    font=small,
    labelfont=bf,
    labelsep=period
}

% Configure section numbering
\setcounter{secnumdepth}{3}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}}

% Configure equation numbering
\numberwithin{equation}{section}

% Configure hyperref for proper linking
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue,
    filecolor=blue,
    pdfborder={0 0 0},
    bookmarks=true,
    bookmarksnumbered=true,
    bookmarkstype=toc,
    pdftitle={Research Project Template},
    pdfauthor={Template Author},
    pdfsubject={Academic Research},
    pdfkeywords={research, template, academic, LaTeX},
    pdfcreator={render_pdf.sh},
    pdfproducer={XeLaTeX}
}

% Configure cleveref for intelligent cross-references
\crefname{section}{Section}{Sections}
\crefname{subsection}{Subsection}{Subsections}
\crefname{subsubsection}{Subsubsection}{Subsubsections}
\crefname{equation}{Equation}{Equations}
\crefname{figure}{Figure}{Figures}
\crefname{table}{Table}{Tables}
\crefname{appendix}{Appendix}{Appendices}

% Configure fonts for Unicode support with fallbacks
\usepackage{newunicodechar}
\newunicodechar{⁴}{\textsuperscript{4}}
\newunicodechar{₄}{\textsubscript{4}}
\newunicodechar{²}{\textsuperscript{2}}
\newunicodechar{₀}{\textsubscript{0}}
\newunicodechar{₁}{\textsubscript{1}}
\newunicodechar{₂}{\textsubscript{2}}
\newunicodechar{₃}{\textsubscript{3}}

% Use standard fonts for better compatibility
\usepackage{lmodern}
\usepackage[T1]{fontenc}

% Enhanced code block styling for better contrast and readability
\usepackage{fancyvrb}
\usepackage{xcolor}
\usepackage{listings}

% Define custom colors for code blocks
\definecolor{codebg}{RGB}{248, 248, 248}      % Very light gray background
\definecolor{codeborder}{RGB}{200, 200, 200}  % Medium gray border
\definecolor{codefg}{RGB}{34, 34, 34}         % Dark gray text
\definecolor{commentcolor}{RGB}{102, 102, 102} % Comment color
\definecolor{keywordcolor}{RGB}{0, 0, 0}       % Keyword color
\definecolor{stringcolor}{RGB}{0, 102, 0}      % String color

% Configure Verbatim environment for inline code
\DefineVerbatimEnvironment{Verbatim}{Verbatim}{%
    fontsize=\small,
    frame=single,
    framerule=0.5pt,
    framesep=3pt,
    rulecolor=\color{codeborder},
    bgcolor=\color{codebg},
    fgcolor=\color{codefg}
}

% Configure code block styling
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{%
    fontsize=\footnotesize,
    frame=single,
    framerule=0.5pt,
    framesep=5pt,
    rulecolor=\color{codeborder},
    bgcolor=\color{codebg},
    fgcolor=\color{codefg}
}

% Style inline code with \texttt
\renewcommand{\texttt}[1]{%
    \colorbox{codebg}{\color{codefg}\ttfamily #1}%
}

% Configure listings package for code blocks
\lstset{
    backgroundcolor=\color{codebg},
    basicstyle=\footnotesize\ttfamily\color{codefg},
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    commentstyle=\color{commentcolor},
    deletekeywords={...},
    escapeinside={\%*}{*)},
    extendedchars=true,
    frame=single,
    framerule=0.5pt,
    framesep=5pt,
    keepspaces=true,
    keywordstyle=\color{keywordcolor}\bfseries,
    language=Python,
    morekeywords={*,...},
    numbers=left,
    numbersep=5pt,
    numberstyle=\tiny\color{codefg},
    rulecolor=\color{codeborder},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    stepnumber=1,
    stringstyle=\color{stringcolor},
    tabsize=4,
    title=\lstname
}

% Override any Pandoc default lstset configurations
\AtBeginDocument{
    \lstset{
        backgroundcolor=\color{codebg},
        basicstyle=\footnotesize\ttfamily\color{codefg},
        frame=single,
        framerule=0.5pt,
        framesep=5pt,
        rulecolor=\color{codeborder},
        numbers=left,
        numbersep=5pt,
        numberstyle=\tiny\color{codefg}
    }
}

% Configure bibliography
\bibliographystyle{unsrt}  % Unsorted bibliography style
% Bibliography is handled in 07_references.md

% Simple page break support for document structure
% Note: Page breaks are handled in the markdown generation, not here

% Ensure proper spacing and formatting
\frenchspacing  % Single space after periods
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  colorlinks=true,
  linkcolor={blue},
  filecolor={blue},
  citecolor={blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}

\title{05 discussion}
\author{ORCID: 0000-0000-0000-1234\ Email: author@example.com\ DOI: 10.5281/zenodo.12345678}
\date{November 21, 2025}

\begin{document}
\maketitle

{
\hypersetup{linkcolor=black}
\setcounter{tocdepth}{3}
\tableofcontents
}
\setstretch{1.2}
\section{Discussion}\label{sec:discussion}

\subsection{Theoretical Implications}\label{theoretical-implications}

The experimental results presented in Section
\ref{sec:experimental_results} have several important theoretical
implications. Our analysis reveals that the convergence rate
\eqref{eq:convergence} is not only theoretically sound but also
practically achievable.

The experimental setup shown in Figure \ref{fig:experimental_setup}
demonstrates our comprehensive validation approach, which includes data
preprocessing, algorithm execution, and performance evaluation.

\subsubsection{Convergence Analysis}\label{convergence-analysis}

The empirical convergence constants \(C \approx 1.2\) and
\(\rho \approx 0.85\) from our experiments suggest that the theoretical
bound \eqref{eq:convergence} is tight. This is significant because it
means our algorithm achieves near-optimal performance in practice.

The adaptive step size strategy \eqref{eq:adaptive_step} plays a crucial
role in this achievement. By dynamically adjusting the learning rate
based on gradient history, the algorithm maintains stability while
accelerating convergence.

\subsubsection{Complexity Analysis}\label{complexity-analysis}

Our theoretical complexity analysis \(O(n \log n)\) per iteration is
validated by the scalability results shown in Figure
\ref{fig:scalability_analysis}. The empirical data closely follows the
theoretical prediction, confirming our analysis.

The memory scaling \eqref{eq:memory} is particularly important for
large-scale applications. Unlike many competing methods that require
\(O(n^2)\) memory, our approach scales linearly with problem size.

\subsection{Comparison with Existing
Work}\label{comparison-with-existing-work}

\subsubsection{State-of-the-Art Methods}\label{state-of-the-art-methods}

We compared our approach with several state-of-the-art optimization
methods:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Gradient Descent}: Standard first-order method with fixed step
  size \cite{ruder2016}
\item
  \textbf{Adam}: Adaptive moment estimation with momentum
  \cite{kingma2014}
\item
  \textbf{L-BFGS}: Limited-memory quasi-Newton method \cite{schmidt2017}
\item
  \textbf{Our Method}: Novel approach combining regularization and
  adaptive step sizes
\end{enumerate}

The results, summarized in Table \ref{tab:performance_comparison},
demonstrate that our method achieves superior performance across
multiple metrics.

\subsubsection{Key Advantages}\label{key-advantages}

Our approach offers several key advantages over existing methods:

\begin{equation}\label{eq:advantage_metric}
\text{Advantage} = \frac{\text{Performance}_{\text{ours}} - \text{Performance}_{\text{baseline}}}{\text{Performance}_{\text{baseline}}} \times 100\%
\end{equation}

Using this metric, our method shows an average improvement of 23.7\%
over the best baseline method.

\subsection{Limitations and
Challenges}\label{limitations-and-challenges}

\subsubsection{Theoretical Constraints}\label{theoretical-constraints}

While our method performs well in practice, several theoretical
limitations remain:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Convexity Assumption}: The convergence guarantee
  \eqref{eq:convergence} requires the objective function to be convex
\item
  \textbf{Lipschitz Continuity}: We assume the gradient is Lipschitz
  continuous with constant \(L\)
\item
  \textbf{Bounded Domain}: The feasible set \(\mathcal{X}\) must be
  bounded
\end{enumerate}

\subsubsection{Practical Challenges}\label{practical-challenges}

In real-world applications, we encountered several practical challenges:

\begin{equation}\label{eq:robustness_metric}
\text{Robustness} = \frac{\text{Successful runs}}{\text{Total runs}} \times 100\%
\end{equation}

Our method achieved a robustness score of 94.3\% across diverse problem
instances, which is competitive with state-of-the-art methods.

\subsection{Future Research
Directions}\label{future-research-directions}

\subsubsection{Algorithmic Improvements}\label{algorithmic-improvements}

Several promising directions for future research emerged from our
analysis:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Non-convex Extensions}: Extending the theoretical guarantees
  to non-convex problems
\item
  \textbf{Stochastic Variants}: Developing stochastic versions for
  large-scale problems
\item
  \textbf{Multi-objective Optimization}: Handling multiple conflicting
  objectives
\end{enumerate}

\subsubsection{Theoretical Developments}\label{theoretical-developments}

The theoretical analysis suggests several areas for future development:

\begin{equation}\label{eq:complexity_bound}
T(n) = O\left(n \log n \cdot \log\left(\frac{1}{\epsilon}\right)\right)
\end{equation}

where \(\epsilon\) is the desired accuracy. This bound could potentially
be improved through more sophisticated analysis techniques.

\subsection{Broader Impact}\label{broader-impact}

\subsubsection{Scientific Applications}\label{scientific-applications}

Our optimization framework has applications across multiple scientific
domains:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Machine Learning}: Training large-scale neural networks
  \cite{kingma2014, wright2010}
\item
  \textbf{Signal Processing}: Sparse signal reconstruction
  \cite{beck2009, parikh2014}
\item
  \textbf{Computational Biology}: Protein structure prediction
\item
  \textbf{Climate Modeling}: Parameter estimation in complex systems
  \cite{polak1997}
\end{enumerate}

\subsubsection{Industry Relevance}\label{industry-relevance}

The efficiency improvements demonstrated in our experiments have direct
implications for industry applications:

\begin{itemize}
\tightlist
\item
  \textbf{Reduced Computational Costs}: 30\% fewer iterations translate
  to significant cost savings
\item
  \textbf{Scalability}: Linear memory scaling enables larger problem
  sizes
\item
  \textbf{Robustness}: High success rates reduce the need for manual
  intervention
\end{itemize}

\subsection{Conclusion}\label{conclusion}

The experimental validation of our theoretical framework demonstrates
that the novel optimization approach achieves both theoretical
guarantees and practical performance. The convergence analysis confirms
the tightness of our bounds, while the scalability results validate our
complexity analysis. Extended theoretical analysis and additional
application examples are provided in Sections
\ref{sec:supplemental_analysis} and \ref{sec:supplemental_applications}.

Future work will focus on extending the theoretical guarantees to
broader problem classes and developing more sophisticated variants for
specific application domains. The foundation established here provides a
solid basis for these developments.

\end{document}
